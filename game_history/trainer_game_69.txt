 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[331.44614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   6  60   0   0   0   0   0   0   0   0   0   0   9   0] 
sum of rewards: 570 

action type: buy - action 10.0
Learning step: 27.395498275756836
desired expected reward: 49.48554611206055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[307.22128]
 [318.74594]
 [314.38766]
 [283.92874]
 [312.93646]
 [326.42722]
 [315.85822]
 [318.4229 ]
 [296.16412]
 [313.38937]
 [309.00616]
 [331.09598]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.57422924041748
desired expected reward: 324.3012390136719



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16.  0.  3.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[346.81055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.806408882141113
desired expected reward: 322.2895812988281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[314.4905 ]
 [329.0583 ]
 [324.78174]
 [288.52148]
 [340.12082]
 [324.67203]
 [323.03082]
 [347.39832]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.010733604431152
desired expected reward: 338.8066101074219



buy possibilites: [-1] 
expected returns: [[316.8538]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 10.0
Learning step: -8.222332954406738
desired expected reward: 314.80853271484375






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[316.1201]
 [299.9047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [4. 0. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -10.486797332763672
desired expected reward: 306.36700439453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[300.7836 ]
 [309.97873]
 [306.14044]
 [281.91733]
 [305.3239 ]
 [316.21634]
 [307.7977 ]
 [310.03348]
 [291.90573]
 [305.55875]
 [302.18008]
 [320.825  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [4. 0. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.255193710327148
desired expected reward: 303.3180236816406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [4. 0. 0. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [4. 0. 0. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[318.82007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 0.  0.  0. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -10.431879997253418
desired expected reward: 310.3930969238281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[289.30154]
 [297.97302]
 [264.27914]
 [298.4169 ]
 [317.10715]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 0.  0.  0. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.775941848754883
desired expected reward: 309.6404724121094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 16.  0.] 
cards in discard: [15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[318.41254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [4. 0. 0. 3. 0.] 
adversary cards in discard: [15.  1.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -10.24962329864502
desired expected reward: 306.8575134277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[300.85168]
 [311.9197 ]
 [307.83276]
 [287.48254]
 [280.05594]
 [306.38196]
 [320.00717]
 [309.099  ]
 [329.22455]
 [311.46762]
 [290.5649 ]
 [297.6093 ]
 [306.68396]
 [286.23816]
 [302.22998]
 [325.18985]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [4. 0. 0. 3. 0.] 
adversary cards in discard: [15.  1.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.507225036621094
desired expected reward: 309.74761962890625



buy possibilites: [-1] 
expected returns: [[263.41095]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [4. 0. 0. 3. 0.] 
adversary cards in discard: [15.  1.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 18 

action type: buy - action 25.0
Learning step: -9.634481430053711
desired expected reward: 319.5900573730469






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [4. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0. 3. 0.] 
cards in discard: [15.  1.  0.  3. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 3. 0.] 
cards in discard: [15.  1.  0.  3. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 3. 0.] 
cards in discard: [15.  1.  0.  3. 16.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 3. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[303.38605]
 [284.95108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 4. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15 10] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -8.086129188537598
desired expected reward: 255.32481384277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[277.89645]
 [250.73639]
 [303.2114 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 4. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15 10] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.207610130310059
desired expected reward: 292.041015625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [1. 4. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 4. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 25.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[304.28677]
 [312.0787 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8. 10.  9. 10. 10.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  0.] 
adversary cards in discard: [1. 4. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15 10] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -9.788297653198242
desired expected reward: 293.4230651855469



action possibilites: [-1] 
expected returns: [[261.2432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8.  9.  9. 10. 10.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  0.] 
adversary cards in discard: [1. 4. 3. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15 10  6] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -11 

action type: take_action - action 25.0
Learning step: -10.271879196166992
desired expected reward: 301.7251281738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[233.37718]
 [248.31763]
 [243.13513]
 [206.96713]
 [258.4684 ]
 [243.98547]
 [241.14384]
 [264.2691 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 29.  8.  9.  9. 10. 10.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  0.] 
adversary cards in discard: [1. 4. 3. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15 10  6] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1
Learning step: -7.983116149902344
desired expected reward: 253.26007080078125






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.  0.] 
cards in discard: [1. 4. 3. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  4 15 10  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8.  9.  9. 10. 10.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [25.  0.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [1. 4. 3. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15 10  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 30. 29.  8.  9.  9. 10. 10.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [25.  0.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1. 4. 3. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15 10  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 30. 29.  8.  9.  9. 10. 10.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [25.  0.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  4.  3.  0.  0.  6. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15 10  6 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 29.  8.  9.  9. 10. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [25.  0.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[286.07196]
 [265.63928]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [25.  0.  3.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8.  9.  9. 10. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 16. 10.] 
adversary cards in discard: [ 1.  4.  3.  0.  0.  6. 14. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15 10  6 14] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -7.352298259735107
desired expected reward: 242.7836456298828



action possibilites: [-1.] 
expected returns: [[303.6406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8.  9.  9. 10. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 16. 10.] 
adversary cards in discard: [ 1.  4.  3.  0.  0.  6. 14. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15 10  6 14] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action 10.0
Learning step: -6.4153313636779785
desired expected reward: 256.529541015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[270.89966]
 [283.47797]
 [279.7169 ]
 [245.62029]
 [277.27957]
 [292.50162]
 [279.7874 ]
 [282.6952 ]
 [258.71414]
 [278.17093]
 [273.11127]
 [298.24088]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 29.  8.  9.  9. 10. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 16. 10.] 
adversary cards in discard: [ 1.  4.  3.  0.  0.  6. 14. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15 10  6 14] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.835501670837402
desired expected reward: 294.8050842285156



buy possibilites: [-1] 
expected returns: [[275.67004]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8.  9.  8. 10. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 16. 10.] 
adversary cards in discard: [ 1.  4.  3.  0.  0.  6. 14. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15 10  6 14] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 30 

action type: buy - action 16.0
Learning step: -6.161403179168701
desired expected reward: 271.1181640625






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 16. 10.] 
cards in discard: [ 1.  4.  3.  0.  0.  6. 14. 15.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15 10  6 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8.  9.  8. 10. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 25.  0.] 
adversary cards in discard: [16. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 1.  4.  3.  0.  0.  6. 14. 15.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8.  9.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 25.  0.] 
adversary cards in discard: [16. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 1.  4.  3.  0.  0.  6. 14. 15.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 30. 29.  8.  9.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 25.  0.] 
adversary cards in discard: [16. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3.  3.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[312.72577]
 [320.73846]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 25.  0.] 
cards in discard: [16. 10.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8.  9.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -7.794355869293213
desired expected reward: 267.8757019042969



action possibilites: [-1] 
expected returns: [[314.40433]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8.  8.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: 0 

action type: take_action - action 25.0
Learning step: -8.779752731323242
desired expected reward: 308.2972412109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[292.10672]
 [306.83588]
 [300.35907]
 [262.24985]
 [299.3926 ]
 [314.5616 ]
 [303.18597]
 [305.72513]
 [276.68634]
 [298.4439 ]
 [292.5701 ]
 [317.8403 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 29.  8.  8.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1
Learning step: -8.917858123779297
desired expected reward: 305.4864807128906






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 16.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 29.  8.  8.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [25.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 16.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 29.  8.  8.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [25.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 16.] 
cards in discard: [6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 30. 29.  8.  8.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [25.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [16.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[277.8029 ]
 [260.13788]
 [260.00815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  0. 10.] 
cards in discard: [25.  3.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 29.  8.  8.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 4.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.437108039855957
desired expected reward: 307.4032287597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[258.1189 ]
 [265.31738]
 [236.55696]
 [267.05817]
 [281.42633]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  0. 10.] 
cards in discard: [25.  3.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 29.  8.  8.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 4.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.28869342803955
desired expected reward: 267.296142578125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [3. 0. 6. 3. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 4.] 
cards in discard: [ 6.  0.  0.  0.  0.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 29.  8.  8.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 4.] 
cards in discard: [ 6.  0.  0.  0.  0.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 30. 29.  8.  8.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[325.8706 ]
 [305.93677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 29.  8.  8.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [15. 11. 14.  3.  1.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0. 16.  3.  0.  6.  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -7.448703289031982
desired expected reward: 273.9776306152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[294.01758]
 [308.80255]
 [303.38022]
 [265.49075]
 [317.8232 ]
 [304.74393]
 [301.3859 ]
 [323.07758]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 29.  8.  8.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [15. 11. 14.  3.  1.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0. 16.  3.  0.  6.  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.918461799621582
desired expected reward: 316.75836181640625



buy possibilites: [-1] 
expected returns: [[287.82208]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0.  0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 29.  8.  8.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [15. 11. 14.  3.  1.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0. 16.  3.  0.  6.  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 1.0 

action type: buy - action 3.0
Learning step: -8.64301586151123
desired expected reward: 294.73724365234375






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [15. 11. 14.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 14.  3.  1.] 
cards in discard: [ 6.  0.  0.  0.  0.  0. 16.  3.  0.  6.  3.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8.  8.  8.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 25.  0.  0.] 
adversary cards in discard: [ 3.  3.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  3.  1.] 
cards in discard: [ 6.  0.  0.  0.  0.  0. 16.  3.  0.  6.  3.  4.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 25.  0.  0.] 
adversary cards in discard: [ 3.  3.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.  3.  1.] 
cards in discard: [ 6.  0.  0.  0.  0.  0. 16.  3.  0.  6.  3.  4.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 25.  0.  0.] 
adversary cards in discard: [ 3.  3.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.  3.  1.] 
cards in discard: [ 6.  0.  0.  0.  0.  0. 16.  3.  0.  6.  3.  4.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 25.  0.  0.] 
adversary cards in discard: [ 3.  3.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3] -> size -> 14 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 3.  3. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[263.2856]
 [267.1705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.  0.  0.] 
cards in discard: [ 3.  3.  0. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -8.952651977539062
desired expected reward: 278.86944580078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[244.42531]
 [251.80789]
 [222.62917]
 [252.46857]
 [268.1374 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25.  0.  0.] 
cards in discard: [ 3.  3.  0. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -7.93197774887085
desired expected reward: 255.41293334960938



buy possibilites: [-1] 
expected returns: [[273.31622]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25.  0.  0.] 
cards in discard: [ 3.  3.  0. 16.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 8 

action type: buy - action 3.0
Learning step: -6.040780067443848
desired expected reward: 245.76710510253906






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [ 0. 25. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[273.6153 ]
 [282.86298]
 [254.78136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 16. 14.  4. 11.] 
adversary cards in discard: [0. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -7.488760471343994
desired expected reward: 265.82745361328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[232.78528]
 [247.64641]
 [241.00972]
 [203.51552]
 [255.29552]
 [244.04872]
 [239.26848]
 [258.21448]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 16. 14.  4. 11.] 
adversary cards in discard: [0. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -7.350099086761475
desired expected reward: 251.44338989257812



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 1. 16. 14.  4. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16. 14.  4. 11.] 
cards in discard: [0. 0. 3. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [ 0. 25. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16. 14.  4. 11.] 
cards in discard: [0. 0. 3. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [ 0. 25. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  3.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[180.65727]
 [167.11203]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 16.  0.] 
cards in discard: [ 0. 25. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 15.  0.  6.  3.] 
adversary cards in discard: [ 0.  0.  3.  0.  0.  0.  1. 16. 14.  4. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1.0
Learning step: -8.983715057373047
desired expected reward: 249.23072814941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[162.2189 ]
 [167.797  ]
 [142.70561]
 [169.71918]
 [181.29024]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 16.  0.] 
cards in discard: [ 0. 25. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 15.  0.  6.  3.] 
adversary cards in discard: [ 0.  0.  3.  0.  0.  0.  1. 16. 14.  4. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -5.040719985961914
desired expected reward: 173.30364990234375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 6. 15.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  6.  3.] 
cards in discard: [ 0.  0.  3.  0.  0.  0.  1. 16. 14.  4. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 25. 10.  0.  0.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  6.  3.] 
cards in discard: [ 0.  0.  3.  0.  0.  0.  1. 16. 14.  4. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 25. 10.  0.  0.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  6.  3.] 
cards in discard: [ 0.  0.  3.  0.  0.  0.  1. 16. 14.  4. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 25. 10.  0.  0.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[223.6426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 0. 25. 10.  0.  0.  3.  3.  0. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  0.  0.  0.  1. 16. 14.  4. 11.  0.  6. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0] -> size -> 22 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1.0
Learning step: -4.0994672775268555
desired expected reward: 177.19076538085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[202.40097]
 [208.68796]
 [180.56618]
 [210.50722]
 [222.19809]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 0. 25. 10.  0.  0.  3.  3.  0. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 29.  8.  8.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  0.  0.  0.  1. 16. 14.  4. 11.  0.  6. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0] -> size -> 22 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -6.246081352233887
desired expected reward: 214.42259216308594



buy possibilites: [-1] 
expected returns: [[146.1322]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 0. 25. 10.  0.  0.  3.  3.  0. 16.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 27. 29.  8.  7.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  0.  0.  0.  1. 16. 14.  4. 11.  0.  6. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0] -> size -> 22 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -311.0 

action type: buy - action 6.0
Learning step: -21.290334701538086
desired expected reward: 159.27586364746094






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [ 0.  0.  3.  0.  0.  0.  1. 16. 14.  4. 11.  0.  6. 15.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 29.  8.  7.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6] -> size -> 16 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0.  0.  3.  0.  0.  0.  1. 16. 14.  4. 11.  0.  6. 15.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 29.  8.  7.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6] -> size -> 16 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0.  0.  3.  0.  0.  0.  1. 16. 14.  4. 11.  0.  6. 15.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 27. 29.  8.  7.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6] -> size -> 16 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 0.  3.  6. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[195.58333]
 [205.0214 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 25.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 29.  8.  7.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 3. 4. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -3.3193042278289795
desired expected reward: 142.81289672851562



action possibilites: [-1] 
expected returns: [[216.86351]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 29.  8.  6.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 3. 4. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: 11 

action type: take_action - action 25.0
Learning step: -4.78206729888916
desired expected reward: 199.44784545898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[194.73216]
 [208.47832]
 [202.89044]
 [169.7179 ]
 [201.60722]
 [216.24908]
 [204.87254]
 [207.47217]
 [181.83691]
 [201.0727 ]
 [195.64531]
 [220.19043]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 27. 29.  8.  6.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 3. 4. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action -1
Learning step: -5.68120002746582
desired expected reward: 211.18231201171875



buy possibilites: [-1] 
expected returns: [[208.42262]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 26. 29.  8.  6.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 3. 4. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 22.0 

action type: buy - action 3.0
Learning step: -4.355013370513916
desired expected reward: 198.53543090820312






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [6. 3. 3. 4. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 4. 8.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8.  6.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16. 10.  0.  3.  0.] 
adversary cards in discard: [ 3. 25.  0.  3.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3] -> size -> 17 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 4. 8.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8.  6.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16. 10.  0.  3.  0.] 
adversary cards in discard: [ 3. 25.  0.  3.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3] -> size -> 17 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 4. 8.] 
cards in discard: [6. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 29.  8.  6.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16. 10.  0.  3.  0.] 
adversary cards in discard: [ 3. 25.  0.  3.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3] -> size -> 17 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [16. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[180.01079]
 [162.51183]
 [161.96516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  0.  3.  0.] 
cards in discard: [ 3. 25.  0.  3.  6.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 29.  8.  6.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 14. 16.  0.] 
adversary cards in discard: [6. 0. 6. 3. 3. 4. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0] -> size -> 22 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1
Learning step: -6.0731048583984375
desired expected reward: 202.34951782226562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[157.67198]
 [163.7063 ]
 [138.60072]
 [165.30466]
 [179.46194]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 10.  0.  3.  0.] 
cards in discard: [ 3. 25.  0.  3.  6.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 29.  8.  6.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 14. 16.  0.] 
adversary cards in discard: [6. 0. 6. 3. 3. 4. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0] -> size -> 22 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: -4.506626605987549
desired expected reward: 171.8511199951172



buy possibilites: [-1] 
expected returns: [[192.78151]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 10.  0.  3.  0.] 
cards in discard: [ 3. 25.  0.  3.  6.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 26. 29.  8.  5.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 14. 16.  0.] 
adversary cards in discard: [6. 0. 6. 3. 3. 4. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -301.0 

action type: buy - action 6.0
Learning step: -17.642452239990234
desired expected reward: 120.958251953125






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 14. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 14. 16.  0.] 
cards in discard: [6. 0. 6. 3. 3. 4. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 29.  8.  5.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  0.] 
cards in discard: [6. 0. 6. 3. 3. 4. 8. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 29.  8.  4.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  0.] 
cards in discard: [6. 0. 6. 3. 3. 4. 8. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 29.  8.  4.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  0.] 
cards in discard: [6. 0. 6. 3. 3. 4. 8. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  4.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[189.22708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  4.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  4.  8.  6.  0. 16. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0] -> size -> 23 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -4.98561954498291
desired expected reward: 187.79588317871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[167.31868]
 [146.49915]
 [190.00536]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  4.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  4.  8.  6.  0. 16. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0] -> size -> 23 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -4.8860039710998535
desired expected reward: 181.9342803955078



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 6.  0.  6.  3.  3.  4.  8.  6.  0. 16. 11. 14.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  4.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10. 25.  0.  0.] 
adversary cards in discard: [3. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 6.  0.  6.  3.  3.  4.  8.  6.  0. 16. 11. 14.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 29. 30. 26. 29.  8.  4.  8.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10. 25.  0.  0.] 
adversary cards in discard: [3. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 6.  0.  6.  3.  3.  4.  8.  6.  0. 16. 11. 14.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 29. 30. 26. 29.  8.  4.  8.  9.  8.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10. 25.  0.  0.] 
adversary cards in discard: [3. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 3. 10. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[142.15544]
 [126.66806]
 [146.98721]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 25.  0.  0.] 
cards in discard: [3. 3. 3. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  4.  8.  9.  8.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 15.  0.  3.  3.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  4.  8.  6.  0. 16. 11. 14.  0.  8.  0.  0.  0.  0.
  1.] 
adversary owned cards: [ 0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -5.989655494689941
desired expected reward: 184.01568603515625



action possibilites: [-1] 
expected returns: [[213.93779]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.  0.] 
cards in discard: [3. 3. 3. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  3.  8.  9.  8.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 15.  0.  3.  3.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  4.  8.  6.  0. 16. 11. 14.  0.  8.  0.  0.  0.  0.
  1.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8
  6] -> size -> 25 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 31 

action type: take_action - action 25.0
Learning step: -0.3279685974121094
desired expected reward: 133.50340270996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[193.38013]
 [204.86935]
 [201.02185]
 [170.62404]
 [199.13799]
 [212.9166 ]
 [201.67575]
 [204.3016 ]
 [182.44162]
 [199.78572]
 [195.29521]
 [217.94388]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.  0.] 
cards in discard: [3. 3. 3. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 26. 29.  8.  3.  8.  9.  8.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 15.  0.  3.  3.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  4.  8.  6.  0. 16. 11. 14.  0.  8.  0.  0.  0.  0.
  1.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8
  6] -> size -> 25 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1
Learning step: -4.579761981964111
desired expected reward: 209.3580322265625






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 6. 15.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  3.  3.] 
cards in discard: [ 6.  0.  6.  3.  3.  4.  8.  6.  0. 16. 11. 14.  0.  8.  0.  0.  0.  0.
  1.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  3.  8.  9.  8.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  6.  0.  3.  6.] 
adversary cards in discard: [ 3.  3.  3.  3.  0. 25.  3. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3.] 
cards in discard: [ 6.  0.  6.  3.  3.  4.  8.  6.  0. 16. 11. 14.  0.  8.  0.  0.  0.  0.
  1.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 26. 29.  8.  3.  8.  9.  8.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  6.  0.  3.  6.] 
adversary cards in discard: [ 3.  3.  3.  3.  0. 25.  3. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3.] 
cards in discard: [ 6.  0.  6.  3.  3.  4.  8.  6.  0. 16. 11. 14.  0.  8.  0.  0.  0.  0.
  1.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 26. 29.  8.  3.  8.  9.  8.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  6.  0.  3.  6.] 
adversary cards in discard: [ 3.  3.  3.  3.  0. 25.  3. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3.] 
cards in discard: [ 6.  0.  6.  3.  3.  4.  8.  6.  0. 16. 11. 14.  0.  8.  0.  0.  0.  0.
  1.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  3.  8.  8.  8.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  6.  0.  3.  6.] 
adversary cards in discard: [ 3.  3.  3.  3.  0. 25.  3. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [16.  6.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[143.41042]
 [127.05835]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.  3.  6.] 
cards in discard: [ 3.  3.  3.  3.  0. 25.  3. 10.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 25 16  3  3  6  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  3.  8.  8.  8.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6
 11] -> size -> 25 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -6.8885345458984375
desired expected reward: 211.05531311035156



action possibilites: [-1] 
expected returns: [[185.97163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [ 3.  3.  3.  3.  0. 25.  3. 10.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  3.  8.  8.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6
 11] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 37 

action type: gain_card_n - action 9
Learning step: -2.075590133666992
desired expected reward: 160.12344360351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[166.35721]
 [145.43513]
 [187.6767 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 3.  3.  3.  3.  0. 25.  3. 10.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  3.  8.  8.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6
 11] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -3.9352269172668457
desired expected reward: 182.03640747070312






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [3. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  3.  8.  8.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 16.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  3.  8.  8.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 16.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 16.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
expected returns: [[76.694244]
 [65.47089 ]
 [82.688835]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3. 25.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  3.  8.  8.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6.  6.] 
adversary cards in discard: [3. 3. 6. 0. 3.] 
adversary owned cards: [ 0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6
 11] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -7.242317199707031
desired expected reward: 180.43438720703125



action possibilites: [-1] 
expected returns: [[131.29549]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  2.  8.  8.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6.  6.] 
adversary cards in discard: [3. 3. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6
 11  6] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 30 

action type: take_action - action 25.0
Learning step: 0.3736778199672699
desired expected reward: 81.98308563232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 98.254166]
 [111.053505]
 [105.401024]
 [ 72.39915 ]
 [117.54631 ]
 [107.77459 ]
 [103.54362 ]
 [120.50771 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 26. 29.  8.  2.  8.  8.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6.  6.] 
adversary cards in discard: [3. 3. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6
 11  6] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -2.6485824584960938
desired expected reward: 128.64691162109375






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  6.  6.] 
cards in discard: [3. 3. 6. 0. 3. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6
 11  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  2.  8.  8.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  6.  0.] 
adversary cards in discard: [25.  3. 16.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6.] 
cards in discard: [3. 3. 6. 0. 3. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 26. 29.  8.  2.  8.  8.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  6.  0.] 
adversary cards in discard: [25.  3. 16.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [3. 3. 6. 0. 3. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 26. 29.  8.  2.  8.  8.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  6.  0.] 
adversary cards in discard: [25.  3. 16.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [ 3.  3.  6.  0.  3.  6. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  2.  8.  7.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  6.  0.] 
adversary cards in discard: [25.  3. 16.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[108.45856]
 [ 92.55885]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  6.  0.] 
cards in discard: [25.  3. 16.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  2.  8.  7.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  6.  3.] 
adversary cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1.0
Learning step: -2.933110237121582
desired expected reward: 117.5746078491211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 83.71563 ]
 [ 90.372215]
 [ 63.778793]
 [ 90.438545]
 [105.02232 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  6.  0.] 
cards in discard: [25.  3. 16.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 29.  8.  2.  8.  7.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  6.  3.] 
adversary cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -2.0392820835113525
desired expected reward: 99.51192474365234



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [11.  0.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  6.  3.] 
cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  2.  8.  7.  8.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  6.  0.] 
adversary cards in discard: [25.  3. 16.  3.  0.  0.  0.  0.  3. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3.] 
cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  2.  8.  7.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 10.  3.  6.  0.] 
adversary cards in discard: [25.  3. 16.  3.  0.  0.  0.  0.  3. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3.] 
cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  2.  8.  7.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 10.  3.  6.  0.] 
adversary cards in discard: [25.  3. 16.  3.  0.  0.  0.  0.  3. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3. 10.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[173.56055]
 [162.57713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  6.  0.] 
cards in discard: [25.  3. 16.  3.  0.  0.  0.  0.  3. 10.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  2.  8.  7.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  4.  1.  0. 16.] 
adversary cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15. 11.  0.  6.  6.  3.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1.0
Learning step: -0.5443283319473267
desired expected reward: 104.4780044555664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[157.04591]
 [142.66612]
 [172.28174]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  6.  0.] 
cards in discard: [25.  3. 16.  3.  0.  0.  0.  0.  3. 10.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  2.  8.  7.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  4.  1.  0. 16.] 
adversary cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15. 11.  0.  6.  6.  3.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -4.0156121253967285
desired expected reward: 168.16294860839844



buy possibilites: [-1] 
expected returns: [[110.79437]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  6.  0.] 
cards in discard: [25.  3. 16.  3.  0.  0.  0.  0.  3. 10.  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  7.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  4.  1.  0. 16.] 
adversary cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15. 11.  0.  6.  6.  3.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15] -> size -> 27 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -293.0 

action type: buy - action 6.0
Learning step: -19.290433883666992
desired expected reward: 123.37570190429688






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  4.  1.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4.  1.  0. 16.] 
cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15. 11.  0.  6.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  7.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10. 10.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6] -> size -> 19 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  1.  0. 16.] 
cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15. 11.  0.  6.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  7.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10. 10.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6] -> size -> 19 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  1.  0. 16.] 
cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15. 11.  0.  6.  6.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  7.  8.  9.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10. 10.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6] -> size -> 19 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [10. 10.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[85.70053 ]
 [75.262764]
 [75.262764]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  7.  8.  9.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  8. 11.] 
adversary cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15. 11.  0.  6.  6.  3. 29.
  0.  4.  1.  0. 16.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29] -> size -> 28 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -3.3855228424072266
desired expected reward: 107.40885162353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[73.80526 ]
 [59.946358]
 [88.1064  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  7.  8.  9.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  8. 11.] 
adversary cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15. 11.  0.  6.  6.  3. 29.
  0.  4.  1.  0. 16.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29] -> size -> 28 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -2.0938334465026855
desired expected reward: 82.96532440185547



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  8. 11.] 
cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15. 11.  0.  6.  6.  3. 29.
  0.  4.  1.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  7.  8.  9.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10. 10.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6] -> size -> 19 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 11.] 
cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15. 11.  0.  6.  6.  3. 29.
  0.  4.  1.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  7.  8.  9.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 10.  3.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6] -> size -> 19 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 11.] 
cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15. 11.  0.  6.  6.  3. 29.
  0.  4.  1.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  7.  8.  9.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 10.  3.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6] -> size -> 19 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 11.] 
cards in discard: [ 3.  3.  6.  0.  3.  6. 11. 15.  0.  6.  6. 15. 11.  0.  6.  6.  3. 29.
  0.  4.  1.  0. 16. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  6.  8.  9.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 10.  3.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6] -> size -> 19 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[75.532104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 10.  3.  6.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  6.  8.  9.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: discard_down_to_3_cards - action 1
Learning step: -1.3015927076339722
desired expected reward: 63.94890213012695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[52.27257 ]
 [61.620125]
 [59.3884  ]
 [38.92487 ]
 [70.43194 ]
 [58.38995 ]
 [57.84817 ]
 [75.709984]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 10.  3.  6.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  6.  8.  9.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -1.726980447769165
desired expected reward: 69.87000274658203



buy possibilites: [-1] 
expected returns: [[53.999706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 10.  3.  6.  0.  3.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 25 

action type: buy - action 10.0
Learning step: -0.4274148941040039
desired expected reward: 57.42074966430664






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  6.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  3.  0.  0. 16.] 
adversary cards in discard: [10. 10.  3.  6.  0.  3.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  6.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  3.  0.  0. 16.] 
adversary cards in discard: [10. 10.  3.  6.  0.  3.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  3.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[102.343254]
 [ 91.755196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  0. 16.] 
cards in discard: [10. 10.  3.  6.  0.  3.  3. 10.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 14.  6.  0. 29.] 
adversary cards in discard: [ 3.  8. 11.  6.  0.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -0.11207161098718643
desired expected reward: 53.88763427734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 88.40173 ]
 [ 93.026436]
 [ 77.61899 ]
 [ 92.20816 ]
 [101.88148 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  0. 16.] 
cards in discard: [10. 10.  3.  6.  0.  3.  3. 10.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 29.  8.  1.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 14.  6.  0. 29.] 
adversary cards in discard: [ 3.  8. 11.  6.  0.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -2.6126019954681396
desired expected reward: 99.73065185546875



buy possibilites: [-1] 
expected returns: [[92.24686]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  0. 16.] 
cards in discard: [10. 10.  3.  6.  0.  3.  3. 10.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 14.  6.  0. 29.] 
adversary cards in discard: [ 3.  8. 11.  6.  0.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -17.005395889282227
desired expected reward: 60.61357879638672






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  6.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  6.  0. 29.] 
cards in discard: [ 3.  8. 11.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  6.  0. 29.] 
cards in discard: [ 3.  8. 11.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  6.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[116.854485]
 [123.41387 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 25.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -2.1322872638702393
desired expected reward: 90.11457061767578



action possibilites: [-1] 
expected returns: [[95.67219]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 17 

action type: take_action - action 25.0
Learning step: -3.0400826930999756
desired expected reward: 117.81404876708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[81.535774]
 [91.10377 ]
 [86.937294]
 [96.3944  ]
 [88.69389 ]
 [85.76452 ]
 [98.63134 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -1.871711015701294
desired expected reward: 93.80047607421875






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [10. 10.  6.  0.  0.] 
adversary cards in discard: [25.  0.  6.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [10. 10.  6.  0.  0.] 
adversary cards in discard: [25.  0.  6.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [10. 10.  6.  0.  0.] 
adversary cards in discard: [25.  0.  6.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [10. 10.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[91.16759]
 [82.92249]
 [82.92249]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  6.  0.  0.] 
cards in discard: [25.  0.  6.  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [6. 0. 4. 6. 6.] 
adversary cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.  0.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11  0] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -3.170985221862793
desired expected reward: 95.46036529541016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[76.511635]
 [80.04225 ]
 [81.78462 ]
 [87.27695 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  6.  0.  0.] 
cards in discard: [25.  0.  6.  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [6. 0. 4. 6. 6.] 
adversary cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.  0.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11  0] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -2.814551830291748
desired expected reward: 87.31314849853516



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [6. 0. 4. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 4. 6. 6.] 
cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.  0.  3. 11.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6. 10. 16.  6.] 
adversary cards in discard: [25.  0.  6.  3.  0.  0.  3. 10. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 4. 6. 6.] 
cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.  0.  3. 11.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6. 10. 16.  6.] 
adversary cards in discard: [25.  0.  6.  3.  0.  0.  3. 10. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 4. 6. 6.] 
cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.  0.  3. 11.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6. 10. 16.  6.] 
adversary cards in discard: [25.  0.  6.  3.  0.  0.  3. 10. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0.  6. 10. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[76.81908]
 [69.01196]
 [68.78254]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10. 16.  6.] 
cards in discard: [25.  0.  6.  3.  0.  0.  3. 10. 10.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [16.  1.  6. 15.  8.] 
adversary cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.  0.  3. 11.  0.  0.  3.  0.  6.
  0.  4.  6.  6.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11  0  0] -> size -> 31 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -2.900071859359741
desired expected reward: 84.37689971923828



action possibilites: [-1. 16.] 
expected returns: [[82.68086]
 [73.18497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16.  6.  0.] 
cards in discard: [25.  0.  6.  3.  0.  0.  3. 10. 10.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [16.  1.  6. 15.  8.] 
adversary cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.  0.  3. 11.  0.  0.  3.  0.  6.
  0.  4.  6.  6.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11  0  0] -> size -> 31 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 17 

action type: take_action - action 10.0
Learning step: -0.7984033823013306
desired expected reward: 68.21356964111328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[69.791565]
 [73.78995 ]
 [73.96892 ]
 [82.43674 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  6.  0.] 
cards in discard: [25.  0.  6.  3.  0.  0.  3. 10. 10.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [16.  1.  6. 15.  8.] 
adversary cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.  0.  3. 11.  0.  0.  3.  0.  6.
  0.  4.  6.  6.] 
adversary owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11  0  0] -> size -> 31 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: -1.5702968835830688
desired expected reward: 81.11058044433594






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [16.  1.  6. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  6. 15.  8.] 
cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.  0.  3. 11.  0.  0.  3.  0.  6.
  0.  4.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  4 15  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11
  6 11 15 29 11  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 16.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6.] 
cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.  0.  3. 11.  0.  0.  3.  0.  6.
  0.  4.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 16.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6.] 
cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.  0.  3. 11.  0.  0.  3.  0.  6.
  0.  4.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 26. 29.  8.  0.  8.  6.  8.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 16.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6.] 
cards in discard: [ 3.  8. 11.  6.  0.  0. 14.  6.  0. 29.  0.  3. 11.  0.  0.  3.  0.  6.
  0.  4.  6.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 16.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0. 16.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[56.06237 ]
 [47.092636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 1. 11. 15. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -3.0165772438049316
desired expected reward: 76.37791442871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[42.907993]
 [54.95737 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 26. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 1. 11. 15. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -1.721771240234375
desired expected reward: 51.96938705444336



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 1. 11. 15. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 15. 11.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10.  6.  6. 10.] 
adversary cards in discard: [ 0. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 11.  3.] 
cards in discard: [15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 10.  6.  6. 10.] 
adversary cards in discard: [ 0. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 11.  3.] 
cards in discard: [15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 26. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 10.  6.  6. 10.] 
adversary cards in discard: [ 0. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 11.  3.] 
cards in discard: [15.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 10.  6.  6. 10.] 
adversary cards in discard: [ 0. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 6. 10.  6.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[35.465168]
 [26.0393  ]
 [26.0393  ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6.  6. 10.] 
cards in discard: [ 0. 16.  3.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 8. 6. 0.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -2.754044532775879
desired expected reward: 52.203330993652344



action possibilites: [-1. 10.] 
expected returns: [[42.12775 ]
 [28.064154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  6. 10.  6.] 
cards in discard: [ 0. 16.  3.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 8. 6. 0.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action 10.0
Learning step: -0.07715149223804474
desired expected reward: 24.701704025268555





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.111273]
 [42.41032 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  6. 10.  6.] 
cards in discard: [ 0. 16.  3.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 2 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 8. 6. 0.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -0.9702842831611633
desired expected reward: 41.15746307373047






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 6. 0.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [ 0. 16.  3.  3.  3. 10.  6.  6.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 6. 0.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [ 0. 16.  3.  3.  3. 10.  6.  6.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[69.846725]
 [71.79724 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  0.  0.] 
cards in discard: [ 0. 16.  3.  3.  3. 10.  6.  6.  6. 10.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 29.  6.  4.  6.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -1.217017412185669
desired expected reward: 41.19330596923828



action possibilites: [-1] 
expected returns: [[53.39252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0. 3.] 
cards in discard: [ 0. 16.  3.  3.  3. 10.  6.  6.  6. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 29.  6.  4.  6.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 7 

action type: take_action - action 25.0
Learning step: -2.038529634475708
desired expected reward: 69.75869750976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[49.46939 ]
 [53.350307]
 [52.342693]
 [51.36586 ]
 [56.965534]
 [52.144295]
 [53.139862]
 [46.28879 ]
 [52.034958]
 [50.5923  ]
 [59.27821 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 3.] 
cards in discard: [ 0. 16.  3.  3.  3. 10.  6.  6.  6. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  6.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 29.  6.  4.  6.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -1.1194323301315308
desired expected reward: 52.27309036254883



buy possibilites: [-1] 
expected returns: [[62.385094]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 3.] 
cards in discard: [ 0. 16.  3.  3.  3. 10.  6.  6.  6. 10.  6. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 29.  6.  4.  6.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 10.5 

action type: buy - action 11.0
Learning step: -0.919611930847168
desired expected reward: 56.04591751098633






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  6.  4.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6.  4.  6.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [16. 10. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11] -> size -> 22 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6.  4.  6.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [16. 10. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11] -> size -> 22 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16. 10. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 10.] 
expected returns: [[72.3457  ]
 [61.131462]
 [61.50148 ]
 [61.50148 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [11.  8.  3.  0.  6.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6.] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -2.3127217292785645
desired expected reward: 60.07237243652344



action possibilites: [-1. 16. 10. 10.] 
expected returns: [[92.14185 ]
 [83.440506]
 [82.29657 ]
 [82.29657 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [11.  8.  3.  0.  6.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6.] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action 10.0
Learning step: -0.753944993019104
desired expected reward: 60.05092239379883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[85.85419]
 [90.26036]
 [91.53265]
 [99.32736]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 10.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  7.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [11.  8.  3.  0.  6.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6.] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -2.1650662422180176
desired expected reward: 89.97676849365234



buy possibilites: [-1] 
expected returns: [[67.2945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 10.  0.  0. 10.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [11.  8.  3.  0.  6.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6.] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 14 

action type: buy - action 8.0
Learning step: -2.362506866455078
desired expected reward: 89.17015075683594






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [11.  8.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  0.  6.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [6. 0. 3. 3. 3.] 
adversary cards in discard: [ 8. 10. 16. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3.  0.  6.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [6. 0. 3. 3. 3.] 
adversary cards in discard: [ 8. 10. 16. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[55.982716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 3.] 
cards in discard: [ 8. 10. 16. 10.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  8. 14.  0.  6.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6. 11.
  8.  3.  0.  6.] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -2.8051140308380127
desired expected reward: 64.48938751220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[47.52346]
 [56.73185]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 3.] 
cards in discard: [ 8. 10. 16. 10.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  8. 14.  0.  6.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6. 11.
  8.  3.  0.  6.] 
adversary owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -2.279033660888672
desired expected reward: 53.70368194580078



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  0.  6.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6. 11.
  8.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  4  6 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11
 15 29 11  0  0  8 15  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 25.  0. 11.] 
adversary cards in discard: [ 8. 10. 16. 10.  0.  0. 10.  6.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6. 11.
  8.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 25.  0. 11.] 
adversary cards in discard: [ 8. 10. 16. 10.  0.  0. 10.  6.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6. 11.
  8.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 25.  0. 11.] 
adversary cards in discard: [ 8. 10. 16. 10.  0.  0. 10.  6.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6. 11.
  8.  3.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 25.  0. 11.] 
adversary cards in discard: [ 8. 10. 16. 10.  0.  0. 10.  6.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0. 25.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[29.521002]
 [30.415617]
 [27.743948]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  0. 11.] 
cards in discard: [ 8. 10. 16. 10.  0.  0. 10.  6.  0.  3.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  3. 11.  0.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6. 11.
  8.  3.  0.  6.  0.  8.  0. 14.  0.] 
adversary owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3  0] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -3.3667945861816406
desired expected reward: 53.36507034301758



action possibilites: [-1] 
expected returns: [[67.43926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  6.  6.] 
cards in discard: [ 8. 10. 16. 10.  0.  0. 10.  6.  0.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  3. 11.  0.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6. 11.
  8.  3.  0.  6.  0.  8.  0. 14.  0.] 
adversary owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3  0] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 25.0
Learning step: -0.1141429916024208
desired expected reward: 28.51638412475586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[56.798244]
 [60.628014]
 [59.904907]
 [67.21081 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  6.  6.] 
cards in discard: [ 8. 10. 16. 10.  0.  0. 10.  6.  0.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  3. 11.  0.] 
adversary cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6. 11.
  8.  3.  0.  6.  0.  8.  0. 14.  0.] 
adversary owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3  0] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -2.134093999862671
desired expected reward: 65.30516815185547






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 11.  0.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6. 11.
  8.  3.  0.  6.  0.  8.  0. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [16.  6.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6. 11.
  8.  3.  0.  6.  0.  8.  0. 14.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [16.  6.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6. 11.
  8.  3.  0.  6.  0.  8.  0. 14.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [16.  6.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [15.  3. 11.  1. 15. 11.  3.  0.  3.  8.  6.  0.  0. 29.  6.  4.  6. 11.
  8.  3.  0.  6.  0.  8.  0. 14.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [16.  6.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [16.  6.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[56.758804]
 [46.772957]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  6.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3  0  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -3.3663997650146484
desired expected reward: 63.84441375732422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[43.81341 ]
 [48.396847]
 [48.101013]
 [57.10371 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  6.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3  0  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -2.7993721961975098
desired expected reward: 52.987239837646484



buy possibilites: [-1] 
expected returns: [[110.53581]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  3.  0.  0.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  6.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3  0  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -54.0 

action type: buy - action 0.0
Learning step: -2.4036149978637695
desired expected reward: 41.4098014831543






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  6.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  6. 15.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15
 29 11  0  0  8 15  3  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [25.  6.  6.  3. 10.] 
adversary cards in discard: [ 0. 16.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [25.  6.  6.  3. 10.] 
adversary cards in discard: [ 0. 16.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 25. 29.  8.  0.  8.  5.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [25.  6.  6.  3. 10.] 
adversary cards in discard: [ 0. 16.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [25.  6.  6.  3. 10.] 
adversary cards in discard: [ 0. 16.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [25.  6.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[33.45938 ]
 [35.733566]
 [26.5256  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  6.  3. 10.] 
cards in discard: [ 0. 16.  6.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  8.  6.  3. 11.] 
adversary cards in discard: [11. 15.  3.  6.  6.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -5.969640254974365
desired expected reward: 104.56616973876953



action possibilites: [-1] 
expected returns: [[85.76767]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3. 10. 10.  3.] 
cards in discard: [ 0. 16.  6.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  8.  6.  3. 11.] 
adversary cards in discard: [11. 15.  3.  6.  6.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 25.0
Learning step: -0.05690613016486168
desired expected reward: 35.676666259765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[71.37713 ]
 [84.791885]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  3. 10. 10.  3.] 
cards in discard: [ 0. 16.  6.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  8.  6.  3. 11.] 
adversary cards in discard: [11. 15.  3.  6.  6.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -2.662677526473999
desired expected reward: 83.10499572753906






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 6.  8.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  6.  3. 11.] 
cards in discard: [11. 15.  3.  6.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  6. 10.] 
adversary cards in discard: [ 0. 16.  6.  3.  0.  0. 25.  6.  6.  3. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 3.] 
cards in discard: [11. 15.  3.  6.  6.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  6. 10.] 
adversary cards in discard: [ 0. 16.  6.  3.  0.  0. 25.  6.  6.  3. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 3.] 
cards in discard: [11. 15.  3.  6.  6.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  6. 10.] 
adversary cards in discard: [ 0. 16.  6.  3.  0.  0. 25.  6.  6.  3. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 3.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  6. 10.] 
adversary cards in discard: [ 0. 16.  6.  3.  0.  0. 25.  6.  6.  3. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[19.8084  ]
 [18.848072]
 [15.732518]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  6. 10.] 
cards in discard: [ 0. 16.  6.  3.  0.  0. 25.  6.  6.  3. 10. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  0. 11.] 
adversary cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -5.0144572257995605
desired expected reward: 79.7774429321289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[14.693002]
 [16.688725]
 [16.713139]
 [20.344452]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  6. 10.] 
cards in discard: [ 0. 16.  6.  3.  0.  0. 25.  6.  6.  3. 10. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  0. 11.] 
adversary cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -1.7722681760787964
desired expected reward: 18.036134719848633



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0. 11.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0. 16.  6.  3.  0.  0. 25.  6.  6.  3. 10. 10.  3.  0. 11.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0. 11.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0. 16.  6.  3.  0.  0. 25.  6.  6.  3. 10. 10.  3.  0. 11.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0. 11.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0. 16.  6.  3.  0.  0. 25.  6.  6.  3. 10. 10.  3.  0. 11.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[11.229032 ]
 [ 2.8808403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [ 0. 16.  6.  3.  0.  0. 25.  6.  6.  3. 10. 10.  3.  0. 11.  0.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -2.0156683921813965
desired expected reward: 18.328779220581055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-0.20213461]
 [ 4.8744955 ]
 [ 4.587485  ]
 [12.49137   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [ 0. 16.  6.  3.  0.  0. 25.  6.  6.  3. 10. 10.  3.  0. 11.  0.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -1.5667463541030884
desired expected reward: 9.66230583190918



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  3.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [10.  6.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [10.  6.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  6. 10.  7.] 
adversary cards in hand: [10.  6.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  5. 10.  7.] 
adversary cards in hand: [10.  6.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [10.  6.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[74.6341 ]
 [66.37701]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  1.  8.  0. 11.] 
adversary cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3. 10. 29.  0.  0.  3.  8.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0 10] -> size -> 38 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -0.19584298133850098
desired expected reward: 12.295533180236816





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[63.22319 ]
 [66.6484  ]
 [66.135475]
 [74.56103 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  1.  8.  0. 11.] 
adversary cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3. 10. 29.  0.  0.  3.  8.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0 10] -> size -> 38 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -3.3387839794158936
desired expected reward: 71.29531860351562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8.  0. 11.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3. 10. 29.  0.  0.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  5. 10.  7.] 
adversary cards in hand: [16.  8.  3. 25.  0.] 
adversary cards in discard: [10.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8.  0. 11.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3. 10. 29.  0.  0.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  4.  6.  9.  9.  9. 10.  5. 10.  7.] 
adversary cards in hand: [16.  8.  3. 25.  0.] 
adversary cards in discard: [10.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8.  0. 11.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3. 10. 29.  0.  0.  3.  8. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0 10 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  3.  6.  9.  9.  9. 10.  5. 10.  7.] 
adversary cards in hand: [16.  8.  3. 25.  0.] 
adversary cards in discard: [10.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [16.  8.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 25.] 
expected returns: [[61.19632 ]
 [51.451622]
 [52.013496]
 [61.321907]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  3. 25.  0.] 
cards in discard: [10.  6.  6.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  3.  6.  9.  9.  9. 10.  5. 10.  7.] 
adversary cards in hand: [15.  0.  4.  0.  0.] 
adversary cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3. 10. 29.  0.  0.  3.  8. 11.  0.  1.  8.  0. 11.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0 10 11] -> size -> 39 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -3.607389211654663
desired expected reward: 70.9536361694336





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[48.941628]
 [61.341545]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3. 25.  0.] 
cards in discard: [10.  6.  6.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 25. 29.  8.  0.  8.  3.  6.  9.  9.  9. 10.  5. 10.  7.] 
adversary cards in hand: [15.  0.  4.  0.  0.] 
adversary cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3. 10. 29.  0.  0.  3.  8. 11.  0.  1.  8.  0. 11.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0 10 11] -> size -> 39 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -2.955530881881714
desired expected reward: 58.240787506103516



buy possibilites: [-1] 
expected returns: [[31.75313]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3. 25.  0.] 
cards in discard: [10.  6.  6.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  3.  6.  9.  9.  9. 10.  5. 10.  7.] 
adversary cards in hand: [15.  0.  4.  0.  0.] 
adversary cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3. 10. 29.  0.  0.  3.  8. 11.  0.  1.  8.  0. 11.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0 10 11] -> size -> 39 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -54.0 

action type: buy - action 0.0
Learning step: -4.299017429351807
desired expected reward: 41.970237731933594






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [15.  0.  4.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  4.  0.  0.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3. 10. 29.  0.  0.  3.  8. 11.  0.  1.  8.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  0  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29
 11  0  0  8 15  3  0  0  0 11  1  0  0 10 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  3.  6.  9.  9.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  6. 10.] 
adversary cards in discard: [10.  6.  6.  0.  0.  0. 16.  8.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3. 10. 29.  0.  0.  3.  8. 11.  0.  1.  8.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29 11
  0  0  8 15  3  0  0  0 11  1  0  0 10 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  3.  6.  9.  9.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  6. 10.] 
adversary cards in discard: [10.  6.  6.  0.  0.  0. 16.  8.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3. 10. 29.  0.  0.  3.  8. 11.  0.  1.  8.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29 11
  0  0  8 15  3  0  0  0 11  1  0  0 10 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  3.  6.  9.  9.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  6. 10.] 
adversary cards in discard: [10.  6.  6.  0.  0.  0. 16.  8.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0.] 
cards in discard: [11. 15.  3.  6.  6.  1.  0. 11.  6.  8.  6.  3.  0.  0. 11.  6.  0. 11.
  3. 10. 29.  0.  0.  3.  8. 11.  0.  1.  8.  0. 11. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29 11
  0  0  8 15  3  0  0  0 11  1  0  0 10 11 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  3.  6.  9.  8.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  6. 10.] 
adversary cards in discard: [10.  6.  6.  0.  0.  0. 16.  8.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[34.262638]
 [30.82997 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  6. 10.] 
cards in discard: [10.  6.  6.  0.  0.  0. 16.  8.  3. 25.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  3.  6.  9.  8.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 6. 15.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29 11
  0  0  8 15  3  0  0  0 11  1  0  0 10 11 29] -> size -> 39 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -2.0377585887908936
desired expected reward: 29.71537208557129





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[28.213087]
 [33.095955]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  6. 10.] 
cards in discard: [10.  6.  6.  0.  0.  0. 16.  8.  3. 25.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  3.  6.  9.  8.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 6. 15.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29 11
  0  0  8 15  3  0  0  0 11  1  0  0 10 11 29] -> size -> 39 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -2.1983611583709717
desired expected reward: 32.06428146362305



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 6. 15.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  3. 14.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  0  6  0  6  0  8  6 11  6 11 15 29 11
  0  0  8 15  3  0  0  0 11  1  0  0 10 11 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  3.  6.  9.  8.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  6. 10.] 
adversary cards in discard: [10.  6.  6.  0.  0.  0. 16.  8.  3. 25.  0.  0.  3.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 14.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  3.  6.  9.  8.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  6. 10.] 
adversary cards in discard: [10.  6.  6.  0.  0.  0. 16.  8.  3. 25.  0.  0.  3.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 14.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  3.  6.  9.  8.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  6. 10.] 
adversary cards in discard: [10.  6.  6.  0.  0.  0. 16.  8.  3. 25.  0.  0.  3.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 14.] 
cards in discard: [11.] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  6. 10.] 
adversary cards in discard: [10.  6.  6.  0.  0.  0. 16.  8.  3. 25.  0.  0.  3.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[10.058592 ]
 [ 7.1104684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  6. 10.] 
cards in discard: [10.  6.  6.  0.  0.  0. 16.  8.  3. 25.  0.  0.  3.  3.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  6. 29.  3.] 
adversary cards in discard: [11. 15.  6.  3. 14.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11] -> size -> 39 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -2.6465251445770264
desired expected reward: 30.449434280395508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 5.8261447]
 [ 7.4515586]
 [ 6.677241 ]
 [10.500694 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  6. 10.] 
cards in discard: [10.  6.  6.  0.  0.  0. 16.  8.  3. 25.  0.  0.  3.  3.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  6. 29.  3.] 
adversary cards in discard: [11. 15.  6.  3. 14.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11] -> size -> 39 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -1.5020040273666382
desired expected reward: 8.55659008026123



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 29.  3.] 
cards in discard: [11. 15.  6.  3. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  7.] 
adversary cards in hand: [16.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 29.  3.] 
cards in discard: [11. 15.  6.  3. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 25. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  7.] 
adversary cards in hand: [16.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 29.  3.] 
cards in discard: [11. 15.  6.  3. 14.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 24. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  7.] 
adversary cards in hand: [16.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [16.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[57.25407 ]
 [49.903225]
 [55.057114]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 24. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 11.  0. 29.  6.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3] -> size -> 40 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -0.9757794737815857
desired expected reward: 9.524916648864746



action possibilites: [-1] 
expected returns: [[23.845512]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0  0
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 24. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 11.  0. 29.  6.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3] -> size -> 40 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -9 

action type: gain_card_n - action 9
Learning step: -0.6338553428649902
desired expected reward: 13.773731231689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[13.592867]
 [16.76945 ]
 [16.288729]
 [23.243372]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0  0
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 24. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 11.  0. 29.  6.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3] -> size -> 40 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -1.9899330139160156
desired expected reward: 21.855579376220703






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29.  6.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 24. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [6. 0. 3. 6. 0.] 
adversary cards in discard: [15. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0  0
 15] -> size -> 25 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 29.  6.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 24. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [6. 0. 3. 6. 0.] 
adversary cards in discard: [15. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0  0
 15] -> size -> 25 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 29.  6.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 28. 30. 24. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [6. 0. 3. 6. 0.] 
adversary cards in discard: [15. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0  0
 15] -> size -> 25 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [6. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.28]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6. 0.] 
cards in discard: [15. 16.  0.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0  0
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 24. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [0. 3. 4. 0. 0.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0] -> size -> 41 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -3.000868558883667
desired expected reward: 20.242504119873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 8.405645]
 [10.983284]
 [10.334816]
 [18.151777]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 0.] 
cards in discard: [15. 16.  0.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0  0
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 24. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [0. 3. 4. 0. 0.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0] -> size -> 41 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -2.8312759399414062
desired expected reward: 15.448724746704102



buy possibilites: [-1] 
expected returns: [[8.710581]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 0.] 
cards in discard: [15. 16.  0.  0. 11.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0  0
 15  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 23. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [0. 3. 4. 0. 0.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0] -> size -> 41 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -26 

action type: buy - action 3.0
Learning step: -1.6531765460968018
desired expected reward: 9.330113410949707






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [0. 3. 4. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 4. 0. 0.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 23. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0  0
 15  3] -> size -> 26 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 4. 0. 0.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 28. 30. 23. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0  0
 15  3] -> size -> 26 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 4. 0. 0.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 23. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0  0
 15  3] -> size -> 26 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [3. 8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-12.380562]
 [-16.047647]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 6.] 
cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 25 16  3  3  6  3  6 10  6 10  6 11  8  0  0
 15  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 23. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 8. 11.  0.  6.  0.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1] -> size -> 42 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -2.436537981033325
desired expected reward: 6.274043083190918



action possibilites: [-1] 
expected returns: [[51.622746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 23. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 8. 11.  0.  6.  0.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1] -> size -> 42 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: trash_cards_n_from_hand - action 9
Learning step: 1.771264672279358
desired expected reward: -11.536537170410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[43.308464]
 [51.948563]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 27. 30. 23. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 8. 11.  0.  6.  0.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1] -> size -> 42 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -1.6151806116104126
desired expected reward: 50.007564544677734






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  6.  0.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 23. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 23. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 23. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 22. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 0.  6. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[14.450839]
 [ 9.640302]
 [ 9.640302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  0. 10.] 
cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 22. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 8. 11. 15.  1.  3.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.  3. 11.  8.  0.  6.  0.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3] -> size -> 44 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -3.9615445137023926
desired expected reward: 47.98701477050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 8.006977]
 [ 9.5878  ]
 [ 9.186973]
 [14.451699]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0. 10.] 
cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 22. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 8. 11. 15.  1.  3.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.  3. 11.  8.  0.  6.  0.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3] -> size -> 44 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -2.098100423812866
desired expected reward: 12.3527193069458



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 8. 11. 15.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 15.  1.  3.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.  3. 11.  8.  0.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 22. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 25. 10.  0.  3.] 
adversary cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.  8.  3.  0.  6. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 15.  1.  3.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.  3. 11.  8.  0.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 22. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 25. 10.  0.  3.] 
adversary cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.  8.  3.  0.  6. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 15.  1.  3.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.  3. 11.  8.  0.  6.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 25. 10.  0.  3.] 
adversary cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.  8.  3.  0.  6. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 3. 25. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[ 3.2555158]
 [ 4.3259583]
 [-3.713692 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 10.  0.  3.] 
cards in discard: [15. 16.  0.  0. 11.  3.  6.  0.  3.  6.  0.  8.  3.  0.  6. 10.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 10. 11.  6. 11.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.  3. 11.  8.  0.  6.  0.  3.  8. 11. 15.  1.  3.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3] -> size -> 45 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -2.812424898147583
desired expected reward: 11.639249801635742



action possibilites: [-1. 25.] 
expected returns: [[1.0414307]
 [1.2724555]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 10. 11.  6. 11.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.  3. 11.  8.  0.  6.  0.  3.  8. 11. 15.  1.  3.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3] -> size -> 45 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action 10.0
Learning step: -0.9370986819267273
desired expected reward: -4.650801181793213



action possibilites: [-1. 10. 10.] 
expected returns: [[30.01179 ]
 [20.562798]
 [20.562798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 10. 11.  6. 11.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.  3. 11.  8.  0.  6.  0.  3.  8. 11. 15.  1.  3.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3] -> size -> 45 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action 25.0
Learning step: 0.38452696800231934
desired expected reward: 1.656968593597412





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.029802]
 [28.287855]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 21. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 10. 11.  6. 11.] 
adversary cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.  3. 11.  8.  0.  6.  0.  3.  8. 11. 15.  1.  3.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3] -> size -> 45 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -1.0830224752426147
desired expected reward: 28.928754806518555






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 0. 10. 11.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  6. 11.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.  3. 11.  8.  0.  6.  0.  3.  8. 11. 15.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [16.  0.  0. 11.  6.] 
adversary cards in discard: [10. 25.  3.  0.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  6. 11.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.  3. 11.  8.  0.  6.  0.  3.  8. 11. 15.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 21. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [16.  0.  0. 11.  6.] 
adversary cards in discard: [10. 25.  3.  0.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  6. 11.] 
cards in discard: [11. 15.  6.  3. 14.  3.  0.  0.  6. 29.  3.  0.  0. 11.  0. 29.  6.  1.
  0.  3.  4.  0.  0. 10.  3. 11.  8.  0.  6.  0.  3.  8. 11. 15.  1.  3.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 27. 30. 21. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [16.  0.  0. 11.  6.] 
adversary cards in discard: [10. 25.  3.  0.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [16.  0.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[-10.015779]
 [ -9.62895 ]
 [-10.093622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 11.  6.] 
cards in discard: [10. 25.  3.  0.  3.  3. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [11.  3.  1. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0] -> size -> 46 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -3.784518003463745
desired expected reward: 24.50332260131836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ -9.034042]
 [ -8.891604]
 [ -9.907821]
 [-10.525055]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 11.  6.] 
cards in discard: [10. 25.  3.  0.  3.  3. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 27. 30. 21. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [11.  3.  1. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0] -> size -> 46 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -1.85781729221344
desired expected reward: -11.8735990524292



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [11.  3.  1. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  1. 11.  8.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  0.  6.] 
adversary cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11.  8.] 
cards in discard: [0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 21. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  0.  6.] 
adversary cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11.  8.] 
cards in discard: [0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 27. 30. 21. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  0.  6.] 
adversary cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11.  8.] 
cards in discard: [0. 3.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 20. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  0.  6.] 
adversary cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 0. 15.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[13.772332 ]
 [ 6.4487057]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.  6.] 
cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 20. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  6. 29.  3.  1.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3] -> size -> 48 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -1.8586972951889038
desired expected reward: -12.383755683898926



action possibilites: [-1] 
expected returns: [[-9.985525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 27. 30. 20. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  6. 29.  3.  1.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3] -> size -> 48 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action 15.0
Learning step: -2.1971092224121094
desired expected reward: 4.251588821411133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.184487]
 [-10.749272]
 [ -9.289587]
 [-10.476722]
 [ -9.732979]
 [-10.95062 ]
 [-11.056991]
 [ -8.832226]
 [ -9.354551]
 [ -9.235365]
 [-10.005554]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 27. 30. 20. 29.  8.  0.  8.  2.  6.  9.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  6. 29.  3.  1.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3] -> size -> 48 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: -1.3635982275009155
desired expected reward: -11.349123001098633



buy possibilites: [-1] 
expected returns: [[5.3115416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 20. 29.  8.  0.  8.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  6. 29.  3.  1.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3] -> size -> 48 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: -1 

action type: buy - action 14.0
Learning step: 0.5111209154129028
desired expected reward: -8.3211030960083






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 6.  6. 29.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 29.  3.  1.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 20. 29.  8.  0.  8.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [6. 3. 8. 0. 0.] 
adversary cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6. 14. 15.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 1.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 20. 29.  8.  0.  8.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [6. 3. 8. 0. 0.] 
adversary cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6. 14. 15.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 1.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 27. 30. 20. 29.  8.  0.  8.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [6. 3. 8. 0. 0.] 
adversary cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6. 14. 15.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 1.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 19. 29.  8.  0.  8.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [6. 3. 8. 0. 0.] 
adversary cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6. 14. 15.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
adversary victory points: 2
player victory points: 8 





Player: 0 
cards in hand: [6. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-2.5247154]
 [-2.9330702]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 0. 0.] 
cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6. 14. 15.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 19. 29.  8.  0.  8.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [10. 11.  0.  6.  0.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3] -> size -> 49 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -3.4748826026916504
desired expected reward: 1.8366589546203613





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-3.4124305]
 [-2.548346 ]
 [-3.253233 ]
 [-3.0473456]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0. 0.] 
cards in discard: [10. 25.  3.  0.  3.  3. 10. 10. 16.  0.  0. 11.  6. 14. 15.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 27. 30. 19. 29.  8.  0.  8.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [10. 11.  0.  6.  0.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3] -> size -> 49 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -3.0874311923980713
desired expected reward: -5.612146377563477



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [10. 11.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  6.  0.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 19. 29.  8.  0.  8.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0.  6.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3] -> size -> 49 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 19. 29.  8.  0.  8.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 19. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 27. 30. 19. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 18. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
adversary victory points: 2
player victory points: 9 





Player: 0 
cards in hand: [ 3.  8. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[ -7.174779]
 [-11.07357 ]
 [ -8.058556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 18. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 14.  0.  0.  3.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3] -> size -> 51 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -3.6785812377929688
desired expected reward: -6.725929260253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-11.550877 ]
 [ -7.721054 ]
 [-11.7295475]
 [ -6.837166 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 27. 30. 18. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 14.  0.  0.  3.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3] -> size -> 51 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -3.470600128173828
desired expected reward: -10.777405738830566



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  3.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 18. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  6. 10. 15.  0.] 
adversary cards in discard: [ 3.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  3.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 27. 30. 18. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  6. 10. 15.  0.] 
adversary cards in discard: [ 3.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  3.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3  3] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 17. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  6. 10. 15.  0.] 
adversary cards in discard: [ 3.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
adversary victory points: 2
player victory points: 10 





Player: 0 
cards in hand: [ 3.  6. 10. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[-0.82593906]
 [-2.6112416 ]
 [-3.6320646 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10. 15.  0.] 
cards in discard: [ 3.  8. 10.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 17. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 11.  6. 29.  3.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3  3] -> size -> 52 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -3.845461368560791
desired expected reward: -10.682628631591797





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.2607694 ]
 [-0.03398919]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10. 15.  0.] 
cards in discard: [ 3.  8. 10.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 27. 30. 17. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 11.  6. 29.  3.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3  3] -> size -> 52 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -4.129219055175781
desired expected reward: -4.955155849456787



buy possibilites: [-1] 
expected returns: [[-3.1840181]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10. 15.  0.] 
cards in discard: [ 3.  8. 10.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 11.  6. 29.  3.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3  3] -> size -> 52 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -113.0 

action type: buy - action 0.0
Learning step: -5.5586018562316895
desired expected reward: -8.819371223449707






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  6. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6. 29.  3.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  0.  3. 11. 25.] 
adversary cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3. 15.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  0.  3. 11. 25.] 
adversary cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 15.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3  3 10] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 6.  0.  3. 11. 25.] 
adversary cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 15.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3  3 10] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 6.  0.  3. 11. 25.] 
adversary cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: 10 





Player: 0 
cards in hand: [ 6.  0.  3. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[9.6569  ]
 [8.676498]
 [8.801194]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 11. 25.] 
cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  3. 15.  3.  8.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3  3 10] -> size -> 53 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1
Learning step: -3.7810113430023193
desired expected reward: -6.965029716491699





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[5.8955107]
 [9.112754 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 11. 25.] 
cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  3. 15.  3.  8.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3  3 10] -> size -> 53 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -4.447500705718994
desired expected reward: 5.209399700164795



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 15.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3.  8.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  0  6  0  6  0  8  6 11  6 11 15 29 11  0
  0  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3
  3 16  3  3 10] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0. 16.  3. 10.  0.] 
adversary cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.  6.  0.  3. 11. 25.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10] -> size -> 52 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0. 16.  3. 10.  0.] 
adversary cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.  6.  0.  3. 11. 25.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  2.  6.  9.  8.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0. 16.  3. 10.  0.] 
adversary cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.  6.  0.  3. 11. 25.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10 11] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  1.  6.  9.  8.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0. 16.  3. 10.  0.] 
adversary cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.  6.  0.  3. 11. 25.] 
adversary owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: 10 





Player: 0 
cards in hand: [ 0. 16.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[18.021534]
 [13.634709]
 [13.628566]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3. 10.  0.] 
cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.  6.  0.  3. 11. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  1.  6.  9.  8.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  0.  0. 11. 10.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10 11] -> size -> 53 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -4.23598051071167
desired expected reward: 4.876773357391357



action possibilites: [-1] 
expected returns: [[4.7149477]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.  6.  0.  3. 11. 25. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  1.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0.  0. 11. 10.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10 11] -> size -> 53 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -58 

action type: gain_card_n - action 9
Learning step: -4.468076229095459
desired expected reward: 29.015180587768555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 2.109525 ]
 [ 5.575905 ]
 [ 4.5824823]
 [12.146818 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.  6.  0.  3. 11. 25. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 17. 29.  8.  0.  7.  1.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0.  0. 11. 10.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10 11] -> size -> 53 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1
Learning step: -3.736423969268799
desired expected reward: 0.9785237312316895



buy possibilites: [-1] 
expected returns: [[5.6064396]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 3.  8. 10.  0.  0.  0.  3.  6. 10. 15.  0.  6.  0.  3. 11. 25. 15.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 16. 29.  8.  0.  7.  1.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0.  0. 11. 10.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10 11] -> size -> 53 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -55 

action type: buy - action 3.0
Learning step: -2.902650833129883
desired expected reward: 2.6732606887817383






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 10.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10 11] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 16. 29.  8.  0.  7.  1.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [10. 10.  3. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15
  3] -> size -> 25 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10 11] -> size -> 53 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 16. 29.  8.  0.  7.  1.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [10. 10.  3. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15
  3] -> size -> 25 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10 11  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  1.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [10. 10.  3. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15
  3] -> size -> 25 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10 11  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  1.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [10. 10.  3. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15
  3] -> size -> 25 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10 11  0 11] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [10. 10.  3. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15
  3] -> size -> 25 
adversary victory points: 2
player victory points: 10 





Player: 0 
cards in hand: [10. 10.  3. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 14.] 
expected returns: [[ 4.494177 ]
 [-2.4670992]
 [-2.4670992]
 [-3.3805056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 14.  6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [11.  1.  0.  8.  4.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.  0. 11. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10 11  0 11] -> size -> 55 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1
Learning step: -4.395913600921631
desired expected reward: 1.2105259895324707





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.3699226]
 [ 4.7005367]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3. 14.  6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15
  3] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [11.  1.  0.  8.  4.] 
adversary cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.  0. 11. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10 11  0 11] -> size -> 55 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -4.318345546722412
desired expected reward: 0.1758284568786621



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [11.  1.  0.  8.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  8.  4.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.  0. 11. 10. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  4 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0
  8 15  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3
 16  3  3 10 11  0 11] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [16. 10.  6. 15.  0.] 
adversary cards in discard: [10. 10.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15
  3] -> size -> 25 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.  0. 11. 10. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [16. 10.  6. 15.  0.] 
adversary cards in discard: [10. 10.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15
  3] -> size -> 25 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 0.  3. 11.  3.  1. 11.  8. 11.  3. 29.  6.  6.  3.  1. 16.  3. 10. 11.
  0.  6.  0.  6.  3.  0. 14.  0.  0.  3.  3. 10. 29. 11.  6.  3. 15. 11.
 15.  3.  3.  8.  0. 11. 10. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [16. 10.  6. 15.  0.] 
adversary cards in discard: [10. 10.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15
  3] -> size -> 25 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [16. 10.  6. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 15.] 
expected returns: [[30.478046]
 [22.501217]
 [23.211891]
 [21.683146]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  6. 15.  0.] 
cards in discard: [10. 10.  3. 14.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  6.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11] -> size -> 53 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -2.2728383541107178
desired expected reward: 2.4276974201202393



action possibilites: [-1] 
expected returns: [[2.7007596]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 15.] 
cards in discard: [10. 10.  3. 14.  6.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  5.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11] -> size -> 53 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -29 

action type: gain_card_n - action 2
Learning step: -0.43322277069091797
desired expected reward: -19.553424835205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.6561365]
 [ 2.4919174]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 15.] 
cards in discard: [10. 10.  3. 14.  6.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  5.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11] -> size -> 53 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: -1.778843879699707
desired expected reward: 0.9219157695770264






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  5.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.] 
adversary owned cards: [ 0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3
  8] -> size -> 25 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  5.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.] 
adversary owned cards: [ 0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3
  8] -> size -> 25 
adversary victory points: 2
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-11.270604]
 [-11.104229]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10 25 16  3  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  5.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [11.  3.  0. 11. 11.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.] 
adversary owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11] -> size -> 53 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -3.025459051132202
desired expected reward: -0.5335464477539062



action possibilites: [-1] 
expected returns: [[1.1160185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  5.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [11.  3.  0. 11. 11.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.] 
adversary owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11] -> size -> 53 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: trash_cards_n_from_hand - action 2
Learning step: -1.746087908744812
desired expected reward: -10.322122573852539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-9.459984 ]
 [-4.006812 ]
 [-7.903863 ]
 [ 0.1902101]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  5.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [11.  3.  0. 11. 11.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.] 
adversary owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11] -> size -> 53 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -2.3186724185943604
desired expected reward: -1.2026538848876953






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [11.  3.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 11. 11.] 
cards in discard: [ 0. 11.  0.  0.  3.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  5.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11. 15.  3.  0.] 
adversary cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8] -> size -> 23 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 11.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.] 
cards in deck: 43 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11  8] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11. 15.  3.  0.] 
adversary cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8] -> size -> 23 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 11.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.] 
cards in deck: 43 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11  8] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11. 15.  3.  0.] 
adversary cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8] -> size -> 23 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 11.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11  8  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11. 15.  3.  0.] 
adversary cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8] -> size -> 23 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [ 0. 11. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[-12.882078]
 [-12.16787 ]
 [-11.490664]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15.  3.  0.] 
cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  8. 10.  3. 10.  5.] 
adversary cards in hand: [15.  8.  6.  0.  6.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.] 
adversary owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11  8  0] -> size -> 55 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -3.476491928100586
desired expected reward: -3.2862794399261475



action possibilites: [-1] 
expected returns: [[-10.316457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.] 
cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  3. 10.  5.] 
adversary cards in hand: [15.  8.  6.  0.  6.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.] 
adversary owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11  8  0] -> size -> 55 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -28 

action type: gain_card_n - action 6
Learning step: -1.1188700199127197
desired expected reward: -11.38387680053711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ -7.5278788]
 [ -7.928319 ]
 [ -8.93505  ]
 [-10.024753 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  0.] 
cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  3. 10.  5.] 
adversary cards in hand: [15.  8.  6.  0.  6.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.] 
adversary owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11  8  0] -> size -> 55 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -1.86672842502594
desired expected reward: -12.183185577392578



buy possibilites: [-1] 
expected returns: [[-12.650494]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  0.] 
cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0. 14.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  3. 10.  5.] 
adversary cards in hand: [15.  8.  6.  0.  6.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.] 
adversary owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11  8  0] -> size -> 55 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -60.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -74.0 

action type: buy - action 0.0
Learning step: -3.6082420349121094
desired expected reward: -11.136122703552246






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [15.  8.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  6.  0.  6.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  6  8  3  6  0  6  0  8  6 11  6 11 15 29 11  0  0  8 15
  3  0  0  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3
  3 10 11  0 11  8  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 3. 25.  0.  3.  6.] 
adversary cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0. 14.  0. 11.  0. 15.
  3.  0.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 3. 25.  0.  3.  6.] 
adversary cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0. 14.  0. 11.  0. 15.
  3.  0.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0] -> size -> 52 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 3. 25.  0.  3.  6.] 
adversary cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0. 14.  0. 11.  0. 15.
  3.  0.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 3. 25.  0.  3.  6.] 
adversary cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0. 14.  0. 11.  0. 15.
  3.  0.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [ 3. 25.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-4.2477417]
 [-9.13071  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  3.  6.] 
cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0. 14.  0. 11.  0. 15.
  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0] -> size -> 53 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1
Learning step: -3.1929380893707275
desired expected reward: -15.84343147277832





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.958008]
 [-3.560514]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0.  3.  6.] 
cards in discard: [10. 10.  3. 14.  6.  8. 16. 10.  6. 15.  8.  0.  0. 14.  0. 11.  0. 15.
  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0] -> size -> 53 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -3.582399845123291
desired expected reward: -7.8301310539245605



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 6.  8. 11. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 6.  8. 11. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  5.] 
adversary cards in hand: [ 6.  8. 11. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [ 6.  8. 11. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.] 
expected returns: [[-2.6080399]
 [-6.3114047]
 [-3.5073082]
 [-9.194157 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 11. 14.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  5.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10] -> size -> 54 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1.0
Learning step: -3.614898681640625
desired expected reward: -7.175408363342285





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-10.334058 ]
 [ -4.1037936]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 11. 14.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  5.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10] -> size -> 54 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -3.700068712234497
desired expected reward: -6.308112144470215



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  5.] 
adversary cards in hand: [ 3.  6. 10.  8.  3.] 
adversary cards in discard: [ 6.  8. 11. 14.  0.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 16. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  5.] 
adversary cards in hand: [ 3.  6. 10.  8.  3.] 
adversary cards in discard: [ 6.  8. 11. 14.  0.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 15. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  5.] 
adversary cards in hand: [ 3.  6. 10.  8.  3.] 
adversary cards in discard: [ 6.  8. 11. 14.  0.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
adversary victory points: 1
player victory points: 9 





Player: 0 
cards in hand: [ 3.  6. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-1.702208 ]
 [-0.9657587]
 [-1.8916236]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  8.  3.] 
cards in discard: [ 6.  8. 11. 14.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 15. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  5.] 
adversary cards in hand: [11.  8. 29. 29.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3] -> size -> 55 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -3.7320594787597656
desired expected reward: -13.661126136779785



action possibilites: [-1.  8. 14.] 
expected returns: [[-12.246948]
 [ -8.212937]
 [ -4.529052]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  8.  3. 14.] 
cards in discard: [ 6.  8. 11. 14.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 15. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  5.] 
adversary cards in hand: [11.  8. 29. 29.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3] -> size -> 55 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action 10.0
Learning step: -3.300142288208008
desired expected reward: -4.265897750854492



action possibilites: [-1.  8.] 
expected returns: [[-6.8680906]
 [-6.883918 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 3.] 
cards in discard: [ 6.  8. 11. 14.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 8. 27. 30. 15. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  5.] 
adversary cards in hand: [11. 29.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3] -> size -> 55 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action 14.0
Learning step: -2.12817645072937
desired expected reward: -6.657228469848633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-6.15716  ]
 [-5.8094325]
 [-6.883918 ]
 [-6.893689 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 3.] 
cards in discard: [ 6.  8. 11. 14.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0] -> size -> 25 
action values: 1 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 15. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  5.] 
adversary cards in hand: [11. 29.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3] -> size -> 55 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -1.9949787855148315
desired expected reward: -8.863069534301758



buy possibilites: [-1] 
expected returns: [[-4.073044]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 3.] 
cards in discard: [ 6.  8. 11. 14.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 14. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  5.] 
adversary cards in hand: [11. 29.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3] -> size -> 55 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  40   0   0   0   0   0   0   0   8   0] 
sum of rewards: -25 

action type: buy - action 3.0
Learning step: -1.051171898841858
desired expected reward: -6.860604763031006






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 14. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  5.] 
adversary cards in hand: [ 3. 10. 16.  0.  3.] 
adversary cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 14. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3. 10. 16.  0.  3.] 
adversary cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15] -> size -> 56 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 14. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3. 10. 16.  0.  3.] 
adversary cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.] 
adversary owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 9 





Player: 0 
cards in hand: [ 3. 10. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[-10.154119]
 [ -9.517916]
 [ -9.789245]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 16.  0.  3.] 
cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 14. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [14.  0.  0.  3. 16.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15] -> size -> 56 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1
Learning step: -3.6642043590545654
desired expected reward: -7.737248420715332



action possibilites: [-1. 16. 15.] 
expected returns: [[-13.753931]
 [-14.076172]
 [-12.629875]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  3. 15.] 
cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14
  0  3] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 14. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [14.  0.  0.  3. 16.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15] -> size -> 56 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action 10.0
Learning step: -2.4687652587890625
desired expected reward: -11.98668098449707



action possibilites: [-1. 15.] 
expected returns: [[-8.18843 ]
 [-7.932994]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.] 
cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 13. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [14.  0.  0.  3. 16.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15] -> size -> 56 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  40   0   0   0   0   0   0   0   4   0] 
sum of rewards: -18 

action type: gain_card_n - action 1
Learning step: -0.9695931673049927
desired expected reward: -3.1788487434387207



action possibilites: [-1] 
expected returns: [[-6.89369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 16. 15.] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 13. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [14.  0.  0.  3. 16.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15] -> size -> 56 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action 15.0
Learning step: 0.1415412873029709
desired expected reward: -7.791444778442383





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.15716 ]
 [-6.893689]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 16. 15.] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 27. 30. 13. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [14.  0.  0.  3. 16.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15] -> size -> 56 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1
Learning step: 0.10164012759923935
desired expected reward: -6.792049884796143



buy possibilites: [-1] 
expected returns: [[-14.696446]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 16. 15.] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 13. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [14.  0.  0.  3. 16.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15] -> size -> 56 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  60 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action 0.0
Learning step: -1.6228119134902954
desired expected reward: -7.779971599578857






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [14.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3. 16.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 13. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [25.  0.  0. 10.  6.] 
adversary cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.  3.  0. 10. 16. 15.  3.
  3.] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3. 16.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15] -> size -> 56 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 27. 30. 13. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [25.  0.  0. 10.  6.] 
adversary cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.  3.  0. 10. 16. 15.  3.
  3.] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3. 16.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [25.  0.  0. 10.  6.] 
adversary cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.  3.  0. 10. 16. 15.  3.
  3.] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0] -> size -> 27 
adversary victory points: 3
player victory points: 10 





Player: 0 
cards in hand: [25.  0.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[-13.794046]
 [-14.903261]
 [-13.206277]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 10.  6.] 
cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.  3.  0. 10. 16. 15.  3.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [11. 10. 11.  1.  3.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3] -> size -> 57 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: buy - action -1
Learning step: -3.1716420650482178
desired expected reward: -17.868087768554688



action possibilites: [-1] 
expected returns: [[-3.9961576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  6.  0.  0.] 
cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.  3.  0. 10. 16. 15.  3.
  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [11. 10. 11.  1.  3.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3] -> size -> 57 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -50 

action type: take_action - action 25.0
Learning step: -1.8447507619857788
desired expected reward: -16.74800682067871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-8.374318 ]
 [-9.24067  ]
 [-9.081508 ]
 [-8.959088 ]
 [-8.87271  ]
 [-9.093303 ]
 [-7.4131584]
 [-8.785383 ]
 [-8.395533 ]
 [-6.519552 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  6.  0.  0.] 
cards in discard: [ 6.  8. 11. 14.  0.  3. 10. 14.  3.  6.  8.  3.  3.  0. 10. 16. 15.  3.
  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [11. 10. 11.  1.  3.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3] -> size -> 57 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1
Learning step: -2.5708024501800537
desired expected reward: -6.566960334777832






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [11. 10. 11.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  1.  3.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [14. 10.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0] -> size -> 27 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  1.  3.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [14. 10.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0] -> size -> 27 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  1.  3.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0] -> size -> 58 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [14. 10.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0] -> size -> 27 
adversary victory points: 3
player victory points: 10 





Player: 0 
cards in hand: [14. 10.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 15.] 
expected returns: [[-7.583706 ]
 [-4.671631 ]
 [-6.215267 ]
 [-5.8271494]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  3. 11. 15.  3.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0. 11. 10. 11.  1.  3.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0] -> size -> 58 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: buy - action -1.0
Learning step: -3.205101490020752
desired expected reward: -13.54876708984375



action possibilites: [-1] 
expected returns: [[-8.086705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [3. 3. 3.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0. 11. 10. 11.  1.  3. 11. 15.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0] -> size -> 58 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action 14.0
Learning step: -2.5483694076538086
desired expected reward: -7.220000267028809





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-7.5973425]
 [-8.369384 ]
 [-7.288041 ]
 [-8.343025 ]
 [-7.273222 ]
 [-7.9243784]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [3. 3. 3.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0. 11. 10. 11.  1.  3. 11. 15.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0] -> size -> 58 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1
Learning step: -2.3657517433166504
desired expected reward: -10.452457427978516



buy possibilites: [-1] 
expected returns: [[0.08250022]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 15.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [3. 3. 3.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0. 11. 10. 11.  1.  3. 11. 15.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0] -> size -> 58 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -70.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -82.0 

action type: buy - action 0.0
Learning step: -3.7182767391204834
desired expected reward: -11.315620422363281






         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0. 11. 10. 11.  1.  3. 11. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 11. 25.  6. 10.] 
adversary cards in discard: [ 0. 14. 10.  0.  3. 15.] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0. 11. 10. 11.  1.  3. 11. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0] -> size -> 58 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 11. 25.  6. 10.] 
adversary cards in discard: [ 0. 14. 10.  0.  3. 15.] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0. 11. 10. 11.  1.  3. 11. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 11. 25.  6. 10.] 
adversary cards in discard: [ 0. 14. 10.  0.  3. 15.] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 10 





Player: 0 
cards in hand: [ 0. 11. 25.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10.] 
expected returns: [[ -9.850748]
 [ -9.510738]
 [-11.095301]
 [ -8.769763]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  6. 10.] 
cards in discard: [ 0. 14. 10.  0.  3. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  8.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  3. 10.  1. 11.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0. 11. 10. 11.  1.  3. 11. 15.  0.  3.  3.  3.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0] -> size -> 59 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: buy - action -1
Learning step: -3.814138174057007
desired expected reward: -3.731637954711914



action possibilites: [-1] 
expected returns: [[0.04314756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  6. 10.] 
cards in discard: [ 0. 14. 10.  0.  3. 15. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  3. 10.  1. 11.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0. 11. 10. 11.  1.  3. 11. 15.  0.  3.  3.  3.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0] -> size -> 59 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -36 

action type: gain_card_n - action 5
Learning step: -1.3405170440673828
desired expected reward: -10.510758399963379





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-1.4064133 ]
 [ 0.07010651]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  6. 10.] 
cards in discard: [ 0. 14. 10.  0.  3. 15. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  3. 10.  1. 11.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0. 11. 10. 11.  1.  3. 11. 15.  0.  3.  3.  3.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0] -> size -> 59 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1
Learning step: -2.6096179485321045
desired expected reward: -2.5664703845977783






         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 10.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  1. 11.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0. 11. 10. 11.  1.  3. 11. 15.  0.  3.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0 29] -> size -> 29 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  1. 11.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0. 11. 10. 11.  1.  3. 11. 15.  0.  3.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0] -> size -> 59 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0 29] -> size -> 29 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  1. 11.] 
cards in discard: [ 0. 11.  0.  0.  3.  8.  0. 11.  3.  0. 11. 11.  0.  8.  6. 10.  0.  3.
  0. 10.  0.  3.  0.  3.  3.  8.  0.  8. 29. 15. 11. 29.  0.  3. 14.  0.
  0.  3. 16.  0. 11. 10. 11.  1.  3. 11. 15.  0.  3.  3.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 11. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0 29] -> size -> 29 
adversary victory points: 3
player victory points: 11 





Player: 0 
cards in hand: [3. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[10.864047 ]
 [ 4.9397726]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 8.] 
cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 11. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -82 

action type: buy - action -1.0
Learning step: -3.895326614379883
desired expected reward: -3.8252193927764893





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[0.84052634]
 [7.1408396 ]
 [3.064277  ]
 [9.795576  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 8.] 
cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 11. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -82 

action type: take_action - action -1.0
Learning step: -4.4789347648620605
desired expected reward: 6.385112285614014



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 68 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 11. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  0. 16.  3.  3.] 
adversary cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.  3.  0.  0.  6.  8.] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0 29] -> size -> 29 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 11. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  0. 16.  3.  3.] 
adversary cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.  3.  0.  0.  6.  8.] 
adversary owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0 29] -> size -> 29 
adversary victory points: 3
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 16.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[4.0784426]
 [0.7575667]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  3.] 
cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.  3.  0.  0.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 25 16  3  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0
  3  3  0  0 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 11. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 6. 6. 6.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -82 

action type: buy - action -1.0
Learning step: -4.518341064453125
desired expected reward: 5.2772369384765625



action possibilites: [-1] 
expected returns: [[-19.932077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.  3.  0.  0.  6.  8.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 11. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 6. 6. 6.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -64 

action type: gain_card_n - action 1
Learning step: -3.778644561767578
desired expected reward: -1.1751925945281982





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-18.454027]
 [-20.611845]
 [-21.105354]
 [-22.569225]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.  3.  0.  0.  6.  8.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 11. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 6. 6. 6.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1
Learning step: -3.0959248542785645
desired expected reward: -23.02800178527832



buy possibilites: [-1] 
expected returns: [[10.285397]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.  3.  0.  0.  6.  8.  1.
  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 10. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 6. 6. 6.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -54 

action type: buy - action 3.0
Learning step: -1.3884028196334839
desired expected reward: -22.000234603881836






         -------------------- Turn: 69 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [0. 0. 6. 6. 6.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 10. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [10. 15.  3.  3.  8.] 
adversary cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.  3.  0.  0.  6.  8.  1.
  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3] -> size -> 30 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [0. 0. 6. 6. 6.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 10. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [10. 15.  3.  3.  8.] 
adversary cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.  3.  0.  0.  6.  8.  1.
  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3] -> size -> 30 
adversary victory points: 3
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 15.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
expected returns: [[-3.6491976]
 [-4.882503 ]
 [-4.265162 ]
 [-7.259759 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3.  3.  8.] 
cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.  3.  0.  0.  6.  8.  1.
  3. 16.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 10. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  0. 10.  1.  0.] 
adversary cards in discard: [0. 0. 6. 6. 6. 8. 3. 0. 0. 3.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -82 

action type: buy - action -1
Learning step: -4.7130866050720215
desired expected reward: 5.572309970855713





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.403508 ]
 [-3.0925145]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  3.  3.  8.] 
cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.  3.  0.  0.  6.  8.  1.
  3. 16.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 26. 30. 10. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  0. 10.  1.  0.] 
adversary cards in discard: [0. 0. 6. 6. 6. 8. 3. 0. 0. 3.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -82 

action type: take_action - action -1.0
Learning step: -4.001267910003662
desired expected reward: -7.650458335876465



buy possibilites: [-1] 
expected returns: [[-7.0509014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  3.  3.  8.] 
cards in discard: [ 0. 14. 10.  0.  3. 15. 29. 11.  0. 25.  6. 10.  3.  0.  0.  6.  8.  1.
  3. 16.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 10. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  0. 10.  1.  0.] 
adversary cards in discard: [0. 0. 6. 6. 6. 8. 3. 0. 0. 3.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -112 

action type: buy - action 0.0
Learning step: -5.488470077514648
desired expected reward: -10.891971588134766






         -------------------- Turn: 70 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  1.  0.] 
cards in discard: [0. 0. 6. 6. 6. 8. 3. 0. 0. 3.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 10. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  6. 16. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0] -> size -> 31 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [0. 0. 6. 6. 6. 8. 3. 0. 0. 3.] 
cards in deck: 44 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 10. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  6. 16. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0] -> size -> 31 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [0. 0. 6. 6. 6. 8. 3. 0. 0. 3.] 
cards in deck: 44 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3] -> size -> 60 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 26. 30. 10. 29.  8.  0.  7.  0.  4.  9.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  6. 16. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0] -> size -> 31 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25.] 
cards in deck: 44 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 10. 29.  8.  0.  7.  0.  4.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  6. 16. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0] -> size -> 31 
adversary victory points: 3
player victory points: 11 





Player: 0 
cards in hand: [ 0.  6. 16. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[-8.421099]
 [-7.33045 ]
 [-4.863963]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16. 14.  6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 10. 29.  8.  0.  7.  0.  4.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 8. 29.  3.  0. 16.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25] -> size -> 61 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -82 

action type: buy - action -1
Learning step: -3.881474256515503
desired expected reward: -10.93237590789795



action possibilites: [-1] 
expected returns: [[-17.063847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16.  6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 26. 30. 10. 29.  8.  0.  7.  0.  4.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 8. 29.  0.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25] -> size -> 61 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: take_action - action 14.0
Learning step: -3.2407386302948
desired expected reward: -8.10470199584961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-15.7734585]
 [-17.331974 ]
 [-16.311329 ]
 [-16.921423 ]
 [-15.923536 ]
 [-17.22778  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 26. 30. 10. 29.  8.  0.  7.  0.  4.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 8. 29.  0.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25] -> size -> 61 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: take_action - action -1
Learning step: -2.6116034984588623
desired expected reward: -19.67544937133789



buy possibilites: [-1] 
expected returns: [[12.292503]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  6.] 
cards in discard: [8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 26. 30. 10. 29.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 8. 29.  0.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25] -> size -> 61 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -80.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -60.0 

action type: buy - action 8.0
Learning step: -1.8773475885391235
desired expected reward: -18.798768997192383






         -------------------- Turn: 71 -------------------- 
Player: 1 
cards in hand: [ 8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 10. 29.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [15. 10.  3.  1.  0.] 
adversary cards in discard: [ 8. 14.  0.  6. 16.  6.] 
adversary owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0  8] -> size -> 32 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25] -> size -> 61 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 26. 30. 10. 29.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [15. 10.  3.  1.  0.] 
adversary cards in discard: [ 8. 14.  0.  6. 16.  6.] 
adversary owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0  8] -> size -> 32 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 10. 29.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [15. 10.  3.  1.  0.] 
adversary cards in discard: [ 8. 14.  0.  6. 16.  6.] 
adversary owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0  8] -> size -> 32 
adversary victory points: 3
player victory points: 11 





Player: 0 
cards in hand: [15. 10.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[-7.47697 ]
 [-7.167079]
 [-6.832873]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  3.  1.  0.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 29.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  3.  0. 11. 11.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -82 

action type: buy - action -1
Learning step: -4.87235689163208
desired expected reward: 7.420146465301514



action possibilites: [-1. 15.] 
expected returns: [[-13.319379]
 [-10.245182]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  1.  0.  6.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3
  3  0  0 29  1  3  0  8] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 29.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  3.  0. 11. 11.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: take_action - action 10.0
Learning step: -3.007689952850342
desired expected reward: -9.840564727783203



action possibilites: [-1.] 
expected returns: [[-5.753109]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3  3
  0  0 29  1  3  0  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 3 
card supply: [ 2. 26. 30. 10. 29.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  3.  0. 11. 11.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action 15.0
Learning step: -1.7171858549118042
desired expected reward: -11.96236801147461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-5.3419485]
 [-6.71675  ]
 [-5.5428114]
 [-4.312836 ]
 [-6.0463715]
 [-6.5673494]
 [-8.18605  ]
 [-6.657439 ]
 [-4.175836 ]
 [-4.6221137]
 [-5.311915 ]
 [-3.973806 ]
 [-4.8109703]
 [-6.2525597]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3  3
  0  0 29  1  3  0  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 2. 26. 30. 10. 29.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  3.  0. 11. 11.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -1.9217668771743774
desired expected reward: -7.674875736236572



buy possibilites: [-1] 
expected returns: [[-8.4211]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.  4.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3  3
  0  0 29  1  3  0  8  4] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  3.  0. 11. 11.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0  40   0   0   0   0   0   0   0  50   0] 
sum of rewards: 41 

action type: buy - action 4.0
Learning step: 2.076167106628418
desired expected reward: -2.236668109893799






         -------------------- Turn: 72 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11. 11.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 8. 29. 14.  3. 10.] 
adversary cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.] 
adversary owned cards: [10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3  3
  0  0 29  1  3  0  8  4] -> size -> 32 
adversary victory points: 6
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 11. 11.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 8. 29. 14.  3. 10.] 
adversary cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.] 
adversary owned cards: [10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3  3
  0  0 29  1  3  0  8  4] -> size -> 32 
adversary victory points: 6
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 29. 14.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 14. 10.] 
expected returns: [[-22.64877 ]
 [-23.179295]
 [-23.208546]
 [-20.317524]
 [-21.995304]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 14.  3. 10.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3  3
  0  0 29  1  3  0  8  4] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  0. 29.  8. 10.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1
Learning step: -2.5099902153015137
desired expected reward: -10.931089401245117



action possibilites: [-1. 14. 10.] 
expected returns: [[-4.225573 ]
 [ 0.9876528]
 [-1.1322904]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3  3
  0  0 29  1  3  0  8  4] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  0. 29.  8. 10.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: discard_n_cards - action 7
Learning step: -0.42883560061454773
desired expected reward: -21.006162643432617



action possibilites: [-1. 14. 15.] 
expected returns: [[-14.8303385]
 [-12.377549 ]
 [-13.560486 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 15.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [10 25 16  3  6 10  6 10  6 11  8  0  0 15  3 14  0 15  3  8 14  0  3  3
  0  0 29  1  3  0  8  4] -> size -> 32 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  0. 29.  8. 10.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: take_action - action 10.0
Learning step: -0.6587662100791931
desired expected reward: -1.791064977645874



action possibilites: [-1. 14.] 
expected returns: [[21.948004]
 [ 3.803849]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10. 15.] 
owned cards: [10 25 16  3  6 10  6 10  6 11  8  0 15  3 14  0 15  3  8 14  0  3  3  0
  0 29  1  3  0  8  4] -> size -> 31 
action values: 1 
buys: 0 
player value: 4 
card supply: [ 2. 26. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  0. 29.  8. 10.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 11 

action type: take_action - action 15.0
Learning step: 1.6107949018478394
desired expected reward: -11.949701309204102





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 4.382269 ]
 [ 8.845363 ]
 [10.528807 ]
 [ 6.906334 ]
 [ 6.442959 ]
 [ 7.9135513]
 [ 2.730477 ]
 [ 9.657328 ]
 [ 7.657318 ]
 [20.589638 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10. 15.] 
owned cards: [10 25 16  3  6 10  6 10  6 11  8  0 15  3 14  0 15  3  8 14  0  3  3  0
  0 29  1  3  0  8  4] -> size -> 31 
action values: 1 
buys: 1 
player value: 4 
card supply: [ 2. 26. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  0. 29.  8. 10.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 11 

action type: take_action - action -1.0
Learning step: -0.2313344031572342
desired expected reward: 21.716684341430664



buy possibilites: [-1] 
expected returns: [[-23.587294]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10. 15.] 
owned cards: [10 25 16  3  6 10  6 10  6 11  8  0 15  3 14  0 15  3  8 14  0  3  3  0
  0 29  1  3  0  8  4  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  0. 29.  8. 10.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    6.  -50.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 15.5 

action type: buy - action 1.0
Learning step: -0.19798317551612854
desired expected reward: 8.647398948669434






         -------------------- Turn: 73 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  8. 10.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  3. 25. 10.  0.] 
adversary cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.  1. 29. 10. 15.
 14.] 
adversary owned cards: [10 25 16  3  6 10  6 10  6 11  8  0 15  3 14  0 15  3  8 14  0  3  3  0
  0 29  1  3  0  8  4  1] -> size -> 32 
adversary victory points: 6
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  8. 10.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0] -> size -> 62 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  3. 25. 10.  0.] 
adversary cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.  1. 29. 10. 15.
 14.] 
adversary owned cards: [10 25 16  3  6 10  6 10  6 11  8  0 15  3 14  0 15  3  8 14  0  3  3  0
  0 29  1  3  0  8  4  1] -> size -> 32 
adversary victory points: 6
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  8. 10.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0] -> size -> 63 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  3. 25. 10.  0.] 
adversary cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.  1. 29. 10. 15.
 14.] 
adversary owned cards: [10 25 16  3  6 10  6 10  6 11  8  0 15  3 14  0 15  3  8 14  0  3  3  0
  0 29  1  3  0  8  4  1] -> size -> 32 
adversary victory points: 6
player victory points: 11 





Player: 0 
cards in hand: [ 0.  3. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[ -7.158223]
 [-12.168105]
 [ -8.551551]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 10.  0.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.  1. 29. 10. 15.
 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10 25 16  3  6 10  6 10  6 11  8  0 15  3 14  0 15  3  8 14  0  3  3  0
  0 29  1  3  0  8  4  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3. 11. 15. 10.  3.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0] -> size -> 63 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1
Learning step: -1.4578245878219604
desired expected reward: -25.04511833190918



action possibilites: [-1. 25.  8.] 
expected returns: [[-15.622023]
 [-15.255759]
 [-13.729691]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  0.  8.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.  1. 29. 10. 15.
 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 25 16  3  6 10  6 10  6 11  8  0 15  3 14  0 15  3  8 14  0  3  3  0
  0 29  1  3  0  8  4  1] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3. 11. 15. 10.  3.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0] -> size -> 63 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: take_action - action 10.0
Learning step: -1.3452904224395752
desired expected reward: -9.896830558776855



action possibilites: [-1.] 
expected returns: [[16.748951]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.  1. 29. 10. 15.
 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  0  3  3  0  0 29  1  3
  0  8  4  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3. 11. 15. 10.  3.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0] -> size -> 63 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: trash_cards_n_from_hand - action 13
Learning step: 0.03384418413043022
desired expected reward: -13.106012344360352





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.7193 ]
 [17.51016]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.  1. 29. 10. 15.
 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  0  3  3  0  0 29  1  3
  0  8  4  1] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 1. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 3. 11. 15. 10.  3.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0] -> size -> 63 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1.0
Learning step: -1.4666727781295776
desired expected reward: 15.282278060913086






         -------------------- Turn: 74 -------------------- 
Player: 1 
cards in hand: [ 3. 11. 15. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15. 10.  3.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.  1. 29. 10. 15.
 14. 10.  8.] 
adversary owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  0  3  3  0  0 29  1  3
  0  8  4  1] -> size -> 28 
adversary victory points: 5
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10.  3.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0 10] -> size -> 64 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  1. 10.  4.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.  1. 29. 10. 15.
 14. 10.  8.] 
adversary owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  0  3  3  0  0 29  1  3
  0  8  4  1] -> size -> 28 
adversary victory points: 5
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 10.  3.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0 10] -> size -> 64 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  1. 10.  4.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.  1. 29. 10. 15.
 14. 10.  8.] 
adversary owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  0  3  3  0  0 29  1  3
  0  8  4  1] -> size -> 28 
adversary victory points: 5
player victory points: 11 





Player: 0 
cards in hand: [ 0.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[10.02468 ]
 [ 9.208305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.  1. 29. 10. 15.
 14. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  0  3  3  0  0 29  1  3
  0  8  4  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  1. 10.  4.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10. 10. 11.
  3. 15. 10.  3.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0 10] -> size -> 64 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: buy - action -1.0
Learning step: -3.65494966506958
desired expected reward: 13.855207443237305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 3.6058905]
 [ 6.521014 ]
 [ 6.6453953]
 [11.388736 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [ 8. 14.  0.  6. 16.  6.  4. 10. 15.  3.  1.  6.  8.  3.  1. 29. 10. 15.
 14. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  0  3  3  0  0 29  1  3
  0  8  4  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  1. 10.  4.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10. 10. 11.
  3. 15. 10.  3.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0 10] -> size -> 64 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: take_action - action -1.0
Learning step: -3.2982215881347656
desired expected reward: 6.7264604568481445



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 75 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  3.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10. 10. 11.
  3. 15. 10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0 10] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 10. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  1. 10.  4.] 
adversary cards in hand: [ 3. 15. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  0  3  3  0  0 29  1  3
  0  8  4  1] -> size -> 28 
adversary victory points: 5
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10. 10. 11.
  3. 15. 10.  3.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0 10  3] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30.  9. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  1. 10.  4.] 
adversary cards in hand: [ 3. 15. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  0  3  3  0  0 29  1  3
  0  8  4  1] -> size -> 28 
adversary victory points: 5
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10. 10. 11.
  3. 15. 10.  3.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0 10  3] -> size -> 65 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 25. 30.  9. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  1. 10.  4.] 
adversary cards in hand: [ 3. 15. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  0  3  3  0  0 29  1  3
  0  8  4  1] -> size -> 28 
adversary victory points: 5
player victory points: 12 





Player: 0 
cards in hand: [ 3. 15. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[11.040341]
 [10.399238]
 [10.880044]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  0  3  3  0  0 29  1  3
  0  8  4  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30.  9. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  1. 10.  4.] 
adversary cards in hand: [ 3. 11.  8. 15.  0.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10. 10. 11.
  3. 15. 10.  3.  3. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0 10  3] -> size -> 65 
adversary victory points: 12
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1.0
Learning step: -3.8243000507354736
desired expected reward: 7.564449310302734



action possibilites: [-1] 
expected returns: [[-26.75515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  3  3  0  0 29  1  3  0
  8  4  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 25. 30.  9. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  1. 10.  4.] 
adversary cards in hand: [ 3. 11.  8. 15.  0.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10. 10. 11.
  3. 15. 10.  3.  3. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0 10  3] -> size -> 65 
adversary victory points: 12
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: take_action - action 15.0
Learning step: -3.621952772140503
desired expected reward: 6.777286529541016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-21.585732]
 [-24.46463 ]
 [-23.20454 ]
 [-23.752666]
 [-22.793066]
 [-26.535591]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  3  3  0  0 29  1  3  0
  8  4  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 25. 30.  9. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  1. 10.  4.] 
adversary cards in hand: [ 3. 11.  8. 15.  0.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10. 10. 11.
  3. 15. 10.  3.  3. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0 10  3] -> size -> 65 
adversary victory points: 12
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: take_action - action -1
Learning step: -1.6740821599960327
desired expected reward: -28.429231643676758



Player 1 won the game! 



Player 0 bought cards:
Copper: 7 
Silver: 1 
Gold: 0 
Estate: 7 
Duchy: 1 
Province: 0 
Curse: 4 

Remodel: 1 
Workshop: 1 
Chapel: 2 
Witch: 1 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3. 11.  3.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 16  6 10  6 10  6 11  8 15  3 14 15  3  8 14  3  3  0  0 29  1  3  0
  8  4  1 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30.  9. 28.  8.  0.  7.  0.  3.  8.  7.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11.  8. 15.  0.] 
adversary cards in discard: [ 0.  0.  6.  6.  6.  8.  3.  0.  0.  3. 25. 10.  3.  0.  1.  0.  0.  3.
 16.  0.  8. 29.  0.  3.  3.  0. 11. 11.  0.  3.  0. 29.  8. 10. 10. 11.
  3. 15. 10.  3.  3. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 3  3  3 14 11  8  3  6  6  0  8  6 11  6 11 29 11  0  0  8 15  3  0  0
  0 11  1  0  0 10 11 29 11  3  0  1 10  3  3  0  0  3  3 16  3  3 10 11
  0 11  8  0  0 10  3 15  3  0  0  3 25  0  0 10  3] -> size -> 65 
adversary victory points: 12
player victory points: 5 

Reward from previous game state: 
[  -5 -500    5  -70    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -541 

action type: buy - action 10.0
Learning step: -25.91034507751465
desired expected reward: -48.703407287597656



