 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[83.386986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -240        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000245 

action type: buy - action -1
Learning step: -120009.546875
desired expected reward: -120015.671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[81.34649 ]
 [83.61906 ]
 [84.28398 ]
 [80.505775]
 [87.75341 ]
 [84.7306  ]
 [85.405945]
 [83.82749 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 81.9399185180664



buy possibilites: [-1] 
expected returns: [[88.35432]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 87.75340270996094






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[82.70813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.35431671142578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[80.92705]
 [83.33875]
 [84.04567]
 [80.03149]
 [80.9006 ]
 [87.70897]
 [84.52304]
 [85.27796]
 [83.60437]
 [85.237  ]
 [86.05799]
 [83.57873]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 80.29579162597656



buy possibilites: [-1] 
expected returns: [[85.53003]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 8.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 87.70897674560547






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[91.6343]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 85.530029296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[89.86879 ]
 [92.29309 ]
 [93.012794]
 [88.97062 ]
 [96.69664 ]
 [93.49747 ]
 [94.217834]
 [92.52399 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 89.76313781738281



buy possibilites: [-1] 
expected returns: [[86.86568]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 96.69664001464844






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0. 11.  0.  3.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0. 11.  0.  3.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0. 11.  0.  3.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [11.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[88.92477]
 [93.36475]
 [93.36475]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.  3.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 86.86567687988281



action possibilites: [-1] 
expected returns: [[84.43853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [11.  3.  3.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 92.5799560546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[84.51153]
 [87.91936]
 [83.53618]
 [88.44082]
 [87.42639]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [11.  3.  3.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.43852996826172



buy possibilites: [-1] 
expected returns: [[90.49964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [11.  3.  3.  0.  0.  0. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 88.44081115722656






Player: 1 
cards in hand: [3. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[90.15676]
 [91.8017 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.49964141845703



action possibilites: [-1.] 
expected returns: [[88.20882]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 89.38151550292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[89.90086 ]
 [92.459045]
 [93.20872 ]
 [88.95866 ]
 [89.86985 ]
 [97.049286]
 [93.71569 ]
 [94.50604 ]
 [92.74287 ]
 [94.465355]
 [95.32679 ]
 [92.7095  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 88.20881652832031



buy possibilites: [-1] 
expected returns: [[87.02716]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  6.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 28.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 97.04928588867188






Player: 1 
cards in hand: [3. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  6.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 11.  0.] 
adversary cards in discard: [11. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  6.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 11.  0.] 
adversary cards in discard: [11. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 11.  0.] 
adversary cards in discard: [11. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[93.9518  ]
 [98.479195]
 [98.479195]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 11.  0.] 
cards in discard: [11. 10.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.02716064453125



action possibilites: [-1] 
expected returns: [[83.58698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [11. 10.  0.  3.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 95.20063781738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[84.097824]
 [87.50815 ]
 [83.117676]
 [88.032364]
 [87.01982 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [11. 10.  0.  3.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.58698272705078



buy possibilites: [-1] 
expected returns: [[82.83744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [11. 10.  0.  3.  0.  0.  0. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 88.03235626220703






Player: 1 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [0. 3. 0. 0. 0. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [0. 3. 0. 0. 0. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 0 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 0.  3.  0.  0.  0.  1. 23.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  8. 10. 10. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[77.9369 ]
 [78.89455]
 [82.08751]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  8. 10. 10. 10.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.83744049072266



action possibilites: [-1] 
expected returns: [[87.446335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  8. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 79.01542663574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[87.7508  ]
 [91.1899  ]
 [86.75867 ]
 [91.714355]
 [90.68847 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  8. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.44633483886719



buy possibilites: [-1] 
expected returns: [[81.78299]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 91.71435546875






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [10.  8. 11.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [10.  8. 11.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[73.560524]
 [75.20218 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [10.  8. 11.  0.  8.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.78298950195312



action possibilites: [-1.] 
expected returns: [[94.74049]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  8. 11.  0.  8.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 71.47515106201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 95.946106]
 [ 98.42799 ]
 [ 99.14571 ]
 [ 95.02402 ]
 [102.83551 ]
 [ 99.6359  ]
 [100.35361 ]
 [ 98.68818 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  8. 11.  0.  8.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  6.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 94.74049377441406



buy possibilites: [-1] 
expected returns: [[84.68406]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  8. 11.  0.  8.  3.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 102.83550262451172






Player: 1 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8. 11.] 
adversary cards in discard: [10.  8. 11.  0.  8.  3.  0. 11. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8. 11.] 
adversary cards in discard: [10.  8. 11.  0.  8.  3.  0. 11. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 0.  0.  0.  3.  3. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8. 11.] 
adversary cards in discard: [10.  8. 11.  0.  8.  3.  0. 11. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[43.620384]
 [46.576935]
 [44.293728]
 [46.576935]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8. 11.] 
cards in discard: [10.  8. 11.  0.  8.  3.  0. 11. 10.  0.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  0.  3.  3. 14.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 84.6840591430664



action possibilites: [-1] 
expected returns: [[9.7011595]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.] 
cards in discard: [10.  8. 11.  0.  8.  3.  0. 11. 10.  0.  0.  3.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  0.  3.  3. 14.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 43.75707244873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[6.8286505]
 [8.816606 ]
 [6.3631115]
 [9.130052 ]
 [8.542905 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.] 
cards in discard: [10.  8. 11.  0.  8.  3.  0. 11. 10.  0.  0.  3.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  0.  3.  3. 14.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.701159477233887



buy possibilites: [-1] 
expected returns: [[4.2663517]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.] 
cards in discard: [10.  8. 11.  0.  8.  3.  0. 11. 10.  0.  0.  3.  3.  0. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  6. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  0.  3.  3. 14.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 9.130049705505371






Player: 1 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  3. 14.  0.  0.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  6. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  3. 14.  0.  0.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  6. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [10.  0.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[72.83522]
 [74.58804]
 [74.58804]
 [77.18299]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 10. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  6. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.266351699829102



action possibilites: [-1] 
expected returns: [[71.68081]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 10.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 73.85623931884766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[72.70733]
 [71.78394]
 [75.4689 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 10.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.6808090209961






Player: 1 
cards in hand: [ 0. 14.  1.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  3. 23.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  0. 10.  8.] 
adversary cards in discard: [10. 11. 10.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 23.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.] 
adversary cards in discard: [10. 11. 10.  0.  3. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 23.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.] 
adversary cards in discard: [10. 11. 10.  0.  3. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 23.] 
cards in discard: [4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.] 
adversary cards in discard: [10. 11. 10.  0.  3. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[81.28824]
 [82.82849]
 [82.16092]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.] 
cards in discard: [10. 11. 10.  0.  3. 10.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 4. 14.  0.  1.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0 302   0] 
sum of rewards: 207 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 9.987832069396973



action possibilites: [-1.  8.] 
expected returns: [[74.91472]
 [75.83028]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [10. 11. 10.  0.  3. 10.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 4. 14.  0.  1.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 77.52772521972656



action possibilites: [-1.] 
expected returns: [[84.39682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 11. 10.  0.  3. 10.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 4. 14.  0.  1.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 76.03741455078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[85.75491]
 [84.86753]
 [88.39209]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 11. 10.  0.  3. 10.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 4. 14.  0.  1.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 84.39682006835938






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 4. 14.  0.  1.  3. 23.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [10. 11. 10.  0.  3. 10.  3. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 22 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 4. 14.  0.  1.  3. 23.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [10. 11. 10.  0.  3. 10.  3. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 22 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 4. 14.  0.  1.  3. 23. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10.  9.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [10. 11. 10.  0.  3. 10.  3. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 22 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[64.36356]
 [65.82466]
 [67.99939]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.  0.] 
cards in discard: [10. 11. 10.  0.  3. 10.  3. 11. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  5.  6. 10. 10.  9.  9.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 4. 14.  0.  1.  3. 23. 15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.39207458496094



action possibilites: [-1] 
expected returns: [[35.61955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 11. 10.  0.  3. 10.  3. 11. 10.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  5.  6. 10. 10.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 4. 14.  0.  1.  3. 23. 15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 63.31055450439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[33.053375]
 [34.7206  ]
 [35.20105 ]
 [32.434696]
 [37.67938 ]
 [35.531082]
 [36.01153 ]
 [34.911297]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 11. 10.  0.  3. 10.  3. 11. 10.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  5.  6. 10. 10.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 4. 14.  0.  1.  3. 23. 15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.61954879760742



buy possibilites: [-1] 
expected returns: [[28.981468]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 11. 10.  0.  3. 10.  3. 11. 10.  8. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10. 10.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 4. 14.  0.  1.  3. 23. 15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: -21 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 37.67937469482422






Player: 1 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 4. 14.  0.  1.  3. 23. 15.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10. 10.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  8.  0. 11. 11.] 
adversary cards in discard: [10. 11. 10.  0.  3. 10.  3. 11. 10.  8. 10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 4. 14.  0.  1.  3. 23. 15.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10. 10.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  8.  0. 11. 11.] 
adversary cards in discard: [10. 11. 10.  0.  3. 10.  3. 11. 10.  8. 10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 4. 14.  0.  1.  3. 23. 15.  0.  0.  0.  0.  3. 23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10. 10.  9.  8.  4. 10.  9.] 
adversary cards in hand: [ 8.  8.  0. 11. 11.] 
adversary cards in discard: [10. 11. 10.  0.  3. 10.  3. 11. 10.  8. 10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 11.] 
expected returns: [[-0.05402493]
 [ 0.22854185]
 [ 0.22854185]
 [ 1.3016202 ]
 [ 1.3016202 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 11. 11.] 
cards in discard: [10. 11. 10.  0.  3. 10.  3. 11. 10.  8. 10. 11. 11. 10.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10. 10.  9.  8.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.981468200683594



action possibilites: [-1] 
expected returns: [[-2.5807009]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 11.] 
cards in discard: [10. 11. 10.  0.  3. 10.  3. 11. 10.  8. 10. 11. 11. 10.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10. 10.  9.  8.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 1.047863245010376





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-3.3788514]
 [-3.5191174]
 [-2.8956642]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  0. 11.] 
cards in discard: [10. 11. 10.  0.  3. 10.  3. 11. 10.  8. 10. 11. 11. 10.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10. 10.  9.  8.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.5807008743286133






Player: 1 
cards in hand: [ 0.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10. 10.  9.  8.  3. 10.  9.] 
adversary cards in hand: [11. 10.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10] -> size -> 25 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10. 10.  9.  8.  3. 10.  9.] 
adversary cards in hand: [11. 10.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10] -> size -> 25 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  3. 10.  9.] 
adversary cards in hand: [11. 10.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10] -> size -> 25 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [11. 10.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[50.88714 ]
 [54.787655]
 [52.451977]
 [51.776745]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  3. 10.  9.] 
adversary cards in hand: [23.  0.  3.  1. 23.] 
adversary cards in discard: [29.  0.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -2.8956637382507324



action possibilites: [-1] 
expected returns: [[64.04944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  3.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  2. 10.  9.] 
adversary cards in hand: [23.  0.  3.  1. 23.] 
adversary cards in discard: [29.  0.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 50.02362060546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[66.52218]
 [65.70212]
 [68.95419]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  3.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  2. 10.  9.] 
adversary cards in hand: [23.  0.  3.  1. 23.] 
adversary cards in discard: [29.  0.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.0494384765625






Player: 1 
cards in hand: [23.  0.  3.  1. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  3.  1. 23.] 
cards in discard: [29.  0.  0. 15.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  2. 10.  9.] 
adversary cards in hand: [11.  8. 10. 11.  3.] 
adversary cards in discard: [10. 11. 10.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10] -> size -> 26 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  3.  1. 23.] 
cards in discard: [29.  0.  0. 15.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  2. 10.  9.] 
adversary cards in hand: [11.  8. 10. 11.  3.] 
adversary cards in discard: [10. 11. 10.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10] -> size -> 26 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  3.  1. 23.] 
cards in discard: [29.  0.  0. 15.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  2. 10.  9.] 
adversary cards in hand: [11.  8. 10. 11.  3.] 
adversary cards in discard: [10. 11. 10.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10] -> size -> 26 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [11.  8. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10. 11.] 
expected returns: [[14.074332]
 [16.23639 ]
 [14.549703]
 [14.925792]
 [16.23639 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 10. 11.  3.] 
cards in discard: [10. 11. 10.  0.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  4.  0. 14.] 
adversary cards in discard: [29.  0.  0. 15.  0.  0.  3. 23.  0.  3.  1. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3] -> size -> 22 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 68.95419311523438



action possibilites: [-1] 
expected returns: [[3.8170745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11.  3.] 
cards in discard: [10. 11. 10.  0.  8.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  4.  0. 14.] 
adversary cards in discard: [29.  0.  0. 15.  0.  0.  3. 23.  0.  3.  1. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3] -> size -> 22 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 14.82201862335205





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[2.7796066]
 [2.4892857]
 [3.6976593]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 11.  3.] 
cards in discard: [10. 11. 10.  0.  8.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  4.  0. 14.] 
adversary cards in discard: [29.  0.  0. 15.  0.  0.  3. 23.  0.  3.  1. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3] -> size -> 22 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.8170745372772217






Player: 1 
cards in hand: [ 0.  0.  4.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  4.  0. 14.] 
cards in discard: [29.  0.  0. 15.  0.  0.  3. 23.  0.  3.  1. 23.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  1. 10.  9.] 
adversary cards in hand: [10. 11. 11.  0. 10.] 
adversary cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10] -> size -> 27 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  4.  0. 14.] 
cards in discard: [29.  0.  0. 15.  0.  0.  3. 23.  0.  3.  1. 23.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  1. 10.  9.] 
adversary cards in hand: [10. 11. 11.  0. 10.] 
adversary cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10] -> size -> 27 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  4.  0. 14.] 
cards in discard: [29.  0.  0. 15.  0.  0.  3. 23.  0.  3.  1. 23.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  1. 10.  9.] 
adversary cards in hand: [10. 11. 11.  0. 10.] 
adversary cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10] -> size -> 27 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10. 11. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[-2.3764021]
 [-2.148187 ]
 [-1.7789476]
 [-1.7789476]
 [-2.148187 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0. 10.] 
cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  1. 10.  9.] 
adversary cards in hand: [1. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0. 15.  0.  0.  3. 23.  0.  3.  1. 23.  0.  0.  0.  4.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 3.697660207748413



action possibilites: [-1] 
expected returns: [[0.96675014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10.] 
cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  9.] 
adversary cards in hand: [1. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0. 15.  0.  0.  3. 23.  0.  3.  1. 23.  0.  0.  0.  4.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -1.8885538578033447





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.02324653]
 [-0.2696855 ]
 [ 0.73549056]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 10.] 
cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  9.] 
adversary cards in hand: [1. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0. 15.  0.  0.  3. 23.  0.  3.  1. 23.  0.  0.  0.  4.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.9667501449584961






Player: 1 
cards in hand: [1. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0. 15.  0.  0.  3. 23.  0.  3.  1. 23.  0.  0.  0.  4.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  9.] 
adversary cards in hand: [10. 10.  0.  8.  3.] 
adversary cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3. 10. 11. 10. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10 10] -> size -> 28 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0. 15.  0.  0.  3. 23.  0.  3.  1. 23.  0.  0.  0.  4.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  9.] 
adversary cards in hand: [10. 10.  0.  8.  3.] 
adversary cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3. 10. 11. 10. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10 10] -> size -> 28 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0. 15.  0.  0.  3. 23.  0.  3.  1. 23.  0.  0.  0.  4.  0. 14.
 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  8.] 
adversary cards in hand: [10. 10.  0.  8.  3.] 
adversary cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3. 10. 11. 10. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10 10] -> size -> 28 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10. 10.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[18.750202]
 [19.960693]
 [19.960693]
 [19.432701]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  8.  3.] 
cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3. 10. 11. 10. 11.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 0.7354891300201416



action possibilites: [-1. 10.  8. 10.] 
expected returns: [[11.079286]
 [12.274129]
 [11.746612]
 [12.274129]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  3. 10.] 
cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3. 10. 11. 10. 11.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10 10] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 19.960693359375



action possibilites: [-1.  8. 10.  8.] 
expected returns: [[17.798105]
 [18.57053 ]
 [19.15422 ]
 [18.57053 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 10.  8.] 
cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3. 10. 11. 10. 11.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10 10] -> size -> 28 
action values: 3 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 12.274127006530762



action possibilites: [-1.  8.  8.] 
expected returns: [[8.556209]
 [9.237661]
 [9.237661]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 8. 0.] 
cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3. 10. 11. 10. 11.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11 11 10  8 11 10  8 10  8 11 10  8 10 10 11
 10 10 10 10] -> size -> 28 
action values: 4 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 19.154224395751953



action possibilites: [-1.] 
expected returns: [[12.703674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3. 10. 11. 10. 11.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10. 10.  8.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10] -> size -> 25 
action values: 3 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -75 

action type: trash_cards_n_from_hand - action 11
Learning step: 0
desired expected reward: 11.719767570495605





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.382699]
 [ 9.886209]
 [11.877965]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 11. 10.  0.  8.  3. 10. 11.  8. 10. 11.  3. 10. 11. 10. 11.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10. 10.  8.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.70367431640625






Player: 1 
cards in hand: [ 0. 29.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  8.] 
adversary cards in hand: [10.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10] -> size -> 25 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  8.] 
adversary cards in hand: [10.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10] -> size -> 25 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  8.] 
adversary cards in hand: [10.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10] -> size -> 25 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 5 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  8.] 
adversary cards in hand: [10.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10] -> size -> 25 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[35.434784]
 [36.756393]
 [38.708347]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  8.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 15. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 11.877963066101074



action possibilites: [-1] 
expected returns: [[46.564808]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  7.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 15. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.39216232299805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[47.082706]
 [49.822018]
 [46.297173]
 [50.242153]
 [49.434425]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  9.  9.  8.  0. 10.  7.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 15. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.5648078918457



buy possibilites: [-1] 
expected returns: [[49.73999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [15.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  7.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 15. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -119 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 50.24215316772461






Player: 1 
cards in hand: [1. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 0. 15. 29.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  7.] 
adversary cards in hand: [ 8. 10. 11.  8.  0.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8] -> size -> 27 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 0. 15. 29.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  7.] 
adversary cards in hand: [ 8. 10. 11.  8.  0.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8] -> size -> 27 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 0. 15. 29.  0.  0. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  6.] 
adversary cards in hand: [ 8. 10. 11.  8.  0.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8] -> size -> 27 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 8. 10. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.  8.] 
expected returns: [[-0.87763774]
 [-0.765816  ]
 [-0.67263746]
 [-0.31801963]
 [-0.765816  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11.  8.  0.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  6.] 
adversary cards in hand: [ 0. 23.  3.  0. 14.] 
adversary cards in discard: [ 0. 15. 29.  0.  0. 15.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0
 15] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.739990234375



action possibilites: [-1] 
expected returns: [[6.447239]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  0.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  5.] 
adversary cards in hand: [ 0. 23.  3.  0. 14.] 
adversary cards in discard: [ 0. 15. 29.  0.  0. 15.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0
 15] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -0.4232656955718994





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[5.1218157]
 [4.826659 ]
 [6.0492144]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.  0.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  5.] 
adversary cards in hand: [ 0. 23.  3.  0. 14.] 
adversary cards in discard: [ 0. 15. 29.  0.  0. 15.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0
 15] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.447238922119141






Player: 1 
cards in hand: [ 0. 23.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  3.  0. 14.] 
cards in discard: [ 0. 15. 29.  0.  0. 15.  1.  0.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  5.] 
adversary cards in hand: [11. 11. 10. 10. 10.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15] -> size -> 28 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.  3.] 
cards in discard: [ 0. 15. 29.  0.  0. 15.  1.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0
 15] -> size -> 25 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  5.] 
adversary cards in hand: [11. 11. 10. 10. 10.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15] -> size -> 28 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.  3.] 
cards in discard: [ 0. 15. 29.  0.  0. 15.  1.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0
 15] -> size -> 25 
action values: 0 
buys: 2 
player value: 3 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  5.] 
adversary cards in hand: [11. 11. 10. 10. 10.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15] -> size -> 28 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11. 11. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10. 10. 10.] 
expected returns: [[1.1552415]
 [2.5120547]
 [2.5120547]
 [1.6790612]
 [1.6790612]
 [1.6790612]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 10. 10.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  5.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [ 0. 15. 29.  0.  0. 15.  1.  0.  3.  0.  0. 23.  0.  3.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0
 15] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 6.049212455749512



action possibilites: [-1] 
expected returns: [[3.2786605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 10.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [ 0. 15. 29.  0.  0. 15.  1.  0.  3.  0.  0. 23.  0.  3.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0
 15] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 2.269540548324585





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[1.6844194]
 [1.2949655]
 [2.8731878]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10. 10.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [ 0. 15. 29.  0.  0. 15.  1.  0.  3.  0.  0. 23.  0.  3.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0
 15] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.278660535812378






Player: 1 
cards in hand: [ 0.  0.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [ 0. 15. 29.  0.  0. 15.  1.  0.  3.  0.  0. 23.  0.  3.  0. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  4.] 
adversary cards in hand: [10. 10.  0. 11. 10.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15. 11. 11. 10. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 15. 29.  0.  0. 15.  1.  0.  3.  0.  0. 23.  0.  3.  0. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  4.] 
adversary cards in hand: [10. 10.  0. 11. 10.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15. 11. 11. 10. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 15. 29.  0.  0. 15.  1.  0.  3.  0.  0. 23.  0.  3.  0. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  9.  9.  8.  0. 10.  4.] 
adversary cards in hand: [10. 10.  0. 11. 10.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15. 11. 11. 10. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 15. 29.  0.  0. 15.  1.  0.  3.  0.  0. 23.  0.  3.  0. 14.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  9.  9.  8.  0. 10.  4.] 
adversary cards in hand: [10. 10.  0. 11. 10.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15. 11. 11. 10. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10. 10.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 10.] 
expected returns: [[29.181868]
 [30.612453]
 [30.612453]
 [32.75044 ]
 [30.612453]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 11. 10.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15. 11. 11. 10. 10.
 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  9.  9.  8.  0. 10.  4.] 
adversary cards in hand: [15.  3. 23.  4.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 2.873187780380249



action possibilites: [-1] 
expected returns: [[5.058997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15. 11. 11. 10. 10.
 10. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  9.  9.  8.  0. 10.  3.] 
adversary cards in hand: [15.  3. 23.  4.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.12781524658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[3.23509  ]
 [2.710941 ]
 [4.8445826]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15. 11. 11. 10. 10.
 10. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  9.  9.  8.  0. 10.  3.] 
adversary cards in hand: [15.  3. 23.  4.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.05899715423584






Player: 1 
cards in hand: [15.  3. 23.  4.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 23.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 23.  4.  1.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  9.  9.  8.  0. 10.  3.] 
adversary cards in hand: [ 3. 10. 11.  8. 10.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15. 11. 11. 10. 10.
 10. 15. 11. 10. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  4.  1.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  9.  9.  8.  0. 10.  3.] 
adversary cards in hand: [ 3. 10. 11.  8. 10.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15. 11. 11. 10. 10.
 10. 15. 11. 10. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  4.  1.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  9.  9.  8.  0. 10.  3.] 
adversary cards in hand: [ 3. 10. 11.  8. 10.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15. 11. 11. 10. 10.
 10. 15. 11. 10. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8. 10.] 
expected returns: [[1.715491 ]
 [2.190108 ]
 [3.0868428]
 [1.9675114]
 [2.190108 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  8. 10.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15. 11. 11. 10. 10.
 10. 15. 11. 10. 10.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  9.  9.  8.  0. 10.  3.] 
adversary cards in hand: [14.  3.  8.  0. 29.] 
adversary cards in discard: [15.  3. 23.  4.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 4.8445844650268555



action possibilites: [-1] 
expected returns: [[-0.69055057]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8. 10.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15. 11. 11. 10. 10.
 10. 15. 11. 10. 10.  0. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  9.  9.  8.  0. 10.  2.] 
adversary cards in hand: [14.  3.  8.  0. 29.] 
adversary cards in discard: [15.  3. 23.  4.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 2.8113553524017334





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-1.1675673 ]
 [-1.3055978 ]
 [-0.73755693]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8. 10.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0. 15. 11.  8. 10.  8.  0. 15. 11. 11. 10. 10.
 10. 15. 11. 10. 10.  0. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  9.  9.  8.  0. 10.  2.] 
adversary cards in hand: [14.  3.  8.  0. 29.] 
adversary cards in discard: [15.  3. 23.  4.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.6905505657196045






Player: 1 
cards in hand: [14.  3.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8.  0. 29.] 
cards in discard: [15.  3. 23.  4.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  9.  9.  8.  0. 10.  2.] 
adversary cards in hand: [11.  8.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  0.  1.] 
cards in discard: [15.  3. 23.  4.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  9.  9.  8.  0. 10.  2.] 
adversary cards in hand: [11.  8.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  0.  1.] 
cards in discard: [15.  3. 23.  4.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  9.  9.  8.  0. 10.  2.] 
adversary cards in hand: [11.  8.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  0.  1.] 
cards in discard: [15.  3. 23.  4.  1.  3.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  9.  8.  0. 10.  2.] 
adversary cards in hand: [11.  8.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11.  8.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10. 11.] 
expected returns: [[12.615571]
 [15.006631]
 [13.1425  ]
 [13.556922]
 [15.006631]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  9.  8.  0. 10.  2.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8] -> size -> 26 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.7375569343566895



action possibilites: [-1] 
expected returns: [[6.6804123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 11.] 
cards in discard: [15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  9.  8.  0. 10.  1.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8] -> size -> 26 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 14.011609077453613





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[5.4795046]
 [5.14602  ]
 [6.5400763]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 11.] 
cards in discard: [15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  9.  8.  0. 10.  1.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8] -> size -> 26 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.680412292480469






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  9.  8.  0. 10.  1.] 
adversary cards in hand: [10.  8.  0. 10.  3.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  9.  8.  0. 10.  1.] 
adversary cards in hand: [10.  8.  0. 10.  3.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  8.  8.  0. 10.  1.] 
adversary cards in hand: [10.  8.  0. 10.  3.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  8.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
expected returns: [[-0.37193894]
 [-0.1810646 ]
 [-0.2732854 ]
 [-0.1810646 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 10.  3.] 
cards in discard: [15. 11.  8.  0. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  8.  8.  0. 10.  1.] 
adversary cards in hand: [15.  0. 23.  0.  3.] 
adversary cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8 14] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 6.540072441101074



action possibilites: [-1.  8. 10. 11.] 
expected returns: [[-0.8427268 ]
 [-0.7142751 ]
 [-0.61286926]
 [-0.23056579]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  3. 11.] 
cards in discard: [15. 11.  8.  0. 10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15 15] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  8.  8.  0. 10.  1.] 
adversary cards in hand: [15.  0. 23.  0.  3.] 
adversary cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8 14] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -0.18106484413146973



action possibilites: [-1.  8. 10.] 
expected returns: [[-1.6920002]
 [-1.6245435]
 [-1.5645614]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  3.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [15.  0. 23.  0.  3.] 
adversary cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8 14] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -51 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -0.3482654094696045



action possibilites: [-1.  8. 10.] 
expected returns: [[1.1875522]
 [1.3601997]
 [1.5017812]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15 15 15] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [15.  0. 23.  0.  3.] 
adversary cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8 14] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -1.5645606517791748



action possibilites: [-1.  8.  8.] 
expected returns: [[-0.39536452]
 [-0.29754806]
 [-0.29754806]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 8.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11. 10. 10.] 
owned cards: [ 0  0  0  0  3  3 11 11 11 10 11 10  8 10  8 11 10  8 10 10 11 10 10 10
 10 15  8 15 15 15 15 15 15] -> size -> 33 
action values: 3 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [15.  0. 23.  0.  3.] 
adversary cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8 14] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 1.501779317855835



action possibilites: [-1.] 
expected returns: [[21.942207]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11. 10. 10.  8.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [15.  0. 23.  0.  3.] 
adversary cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8 14] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0  100    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -55 

action type: trash_cards_n_from_hand - action 3
Learning step: 0
desired expected reward: -0.21291422843933105





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.71927 ]
 [18.194073]
 [20.306185]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11. 10. 10.  8.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
action values: 2 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [15.  0. 23.  0.  3.] 
adversary cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8 14] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0  100    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.94220733642578






Player: 1 
cards in hand: [15.  0. 23.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 23.  0.  3.] 
cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1. 14.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [10.  3. 15. 10. 15.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3.  0.] 
cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1. 14.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15
  8  8 14] -> size -> 27 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [10.  3. 15. 10. 15.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1. 14.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [ 0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8
  8 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [10.  3. 15. 10. 15.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1. 14.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [ 0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8
  8 14] -> size -> 26 
action values: 0 
buys: 2 
player value: 6 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [10.  3. 15. 10. 15.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: 7 


buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [15.  3. 23.  4.  1.  3.  8. 29. 14.  8.  0.  1. 14.  3.  0.  0.  0.  0.
 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [ 0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8
  8 14 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  3.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [10.  3. 15. 10. 15.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10.  3. 15. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10. 15.] 
expected returns: [[-0.38762212]
 [-0.2398467 ]
 [-0.1560626 ]
 [-0.2398467 ]
 [-0.1560626 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 15. 10. 15.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  3.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8
  8 14 11] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.30617904663086



action possibilites: [-1] 
expected returns: [[-1.0023246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 15.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  3.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8
  8 14 11] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -0.15606236457824707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-1.3265021]
 [-1.4128789]
 [-1.0509309]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10. 15.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  3.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8
  8 14 11] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.0023245811462402






Player: 1 
cards in hand: [ 0.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8
  8 14 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  3.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [10. 11. 10.  8. 10.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  3.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [10. 11. 10.  8. 10.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 28. 30. 29. 29.  8. 10. 10.  3.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [10. 11. 10.  8. 10.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [2.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 29.  8. 10. 10.  3.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [10. 11. 10.  8. 10.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10. 11. 10.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.  8. 10.] 
expected returns: [[ 8.045572]
 [ 9.064316]
 [10.655123]
 [ 9.064316]
 [ 8.615405]
 [ 9.064316]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  8. 10.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 29.  8. 10. 10.  3.  3. 10.  9.  8.  8.  0. 10.  0.] 
adversary cards in hand: [15. 11.  3. 23.  0.] 
adversary cards in discard: [ 2. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -1.0509302616119385



action possibilites: [-1] 
expected returns: [[-3.0317028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8. 10.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.
 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 29.  8. 10. 10.  3.  3. 10.  9.  7.  8.  0. 10.  0.] 
adversary cards in hand: [15. 11.  3. 23.  0.] 
adversary cards in discard: [ 2. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 8.615405082702637





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-3.3409715]
 [-3.3850417]
 [-3.073251 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8. 10.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.
 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 29. 29. 29.  8. 10. 10.  3.  3. 10.  9.  7.  8.  0. 10.  0.] 
adversary cards in hand: [15. 11.  3. 23.  0.] 
adversary cards in discard: [ 2. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.031702756881714






Player: 1 
cards in hand: [15. 11.  3. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 23.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3. 23.  0.] 
cards in discard: [ 2. 15.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 29.  8. 10. 10.  3.  3. 10.  9.  7.  8.  0. 10.  0.] 
adversary cards in hand: [ 0. 15. 15. 11. 10.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.
 14. 11. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14] -> size -> 32 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 23.  0.] 
cards in discard: [ 2. 15.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 28. 29.  8. 10. 10.  3.  3. 10.  9.  7.  8.  0. 10.  0.] 
adversary cards in hand: [ 0. 15. 15. 11. 10.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.
 14. 11. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14] -> size -> 32 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 23.  0.] 
cards in discard: [ 2. 15.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 29. 28. 29.  8. 10. 10.  3.  3. 10.  9.  7.  8.  0. 10.  0.] 
adversary cards in hand: [ 0. 15. 15. 11. 10.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.
 14. 11. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14] -> size -> 32 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 23.  0.] 
cards in discard: [ 2. 15.  0.  0.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  3.  3. 10.  9.  7.  8.  0. 10.  0.] 
adversary cards in hand: [ 0. 15. 15. 11. 10.] 
adversary cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.
 14. 11. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14] -> size -> 32 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 15. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 11. 10.] 
expected returns: [[3.078388 ]
 [3.9121907]
 [3.9121907]
 [4.5234404]
 [3.6196887]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 15. 11. 10.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.
 14. 11. 10. 10.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  3.  3. 10.  9.  7.  8.  0. 10.  0.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0] -> size -> 29 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -3.0732505321502686



action possibilites: [-1] 
expected returns: [[-0.9347873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 15. 10.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.
 14. 11. 10. 10.  8. 10. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  3.  3. 10.  9.  6.  8.  0. 10.  0.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0] -> size -> 29 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -101 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 3.3751399517059326





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-1.1866872]
 [-1.2353342]
 [-1.0229269]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 15. 10.] 
cards in discard: [15. 11.  8.  0. 10. 11. 15. 10. 11. 10. 10.  8.  3. 15. 10.  3. 10. 15.
 14. 11. 10. 10.  8. 10. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  3.  3. 10.  9.  6.  8.  0. 10.  0.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0] -> size -> 29 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.9347872734069824






Player: 1 
cards in hand: [14.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  3.] 
cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  3.  3. 10.  9.  6.  8.  0. 10.  0.] 
adversary cards in hand: [15. 10. 15. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14] -> size -> 33 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  3.] 
cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  3.  3. 10.  9.  6.  8.  0. 10.  0.] 
adversary cards in hand: [15. 10. 15. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14] -> size -> 33 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  3.] 
cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  2.  3. 10.  9.  6.  8.  0. 10.  0.] 
adversary cards in hand: [15. 10. 15. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14] -> size -> 33 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [15. 10. 15. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 15. 11.] 
expected returns: [[ 8.688626]
 [ 9.886708]
 [ 9.468475]
 [ 9.886708]
 [10.742088]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 15. 11.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  2.  3. 10.  9.  6.  8.  0. 10.  0.] 
adversary cards in hand: [ 1. 23.  0.  8. 14.] 
adversary cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0 11] -> size -> 30 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -1.0229276418685913



action possibilites: [-1] 
expected returns: [[11.014766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 15.  0.] 
cards in discard: [14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  2.  3. 10.  9.  5.  8.  0. 10.  0.] 
adversary cards in hand: [ 1. 23.  0.  8. 14.] 
adversary cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0 11] -> size -> 30 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -101 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 9.121259689331055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.309691]
 [ 8.936608]
 [10.499854]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 15.  0.] 
cards in discard: [14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  2.  3. 10.  9.  5.  8.  0. 10.  0.] 
adversary cards in hand: [ 1. 23.  0.  8. 14.] 
adversary cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0 11] -> size -> 30 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.014765739440918






Player: 1 
cards in hand: [ 1. 23.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 23.  0.  8. 14.] 
cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  2.  3. 10.  9.  5.  8.  0. 10.  0.] 
adversary cards in hand: [11. 10.  8. 15. 15.] 
adversary cards in discard: [14. 11. 15. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14] -> size -> 34 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 23.  0.  8. 14.] 
cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  2.  3. 10.  9.  5.  8.  0. 10.  0.] 
adversary cards in hand: [11. 10.  8. 15. 15.] 
adversary cards in discard: [14. 11. 15. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14] -> size -> 34 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 23.  0.  8. 14.] 
cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.
 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0 11 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  5.  8.  0. 10.  0.] 
adversary cards in hand: [11. 10.  8. 15. 15.] 
adversary cards in discard: [14. 11. 15. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14] -> size -> 34 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11. 10.  8. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 15. 15.] 
expected returns: [[0.316036  ]
 [0.7720423 ]
 [0.46447086]
 [0.394444  ]
 [0.56024146]
 [0.56024146]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8. 15. 15.] 
cards in discard: [14. 11. 15. 10. 15.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  5.  8.  0. 10.  0.] 
adversary cards in hand: [ 1.  3.  3. 29.  8.] 
adversary cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.
 11.  1. 23.  0.  8. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0 11 11] -> size -> 31 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.499848365783691



action possibilites: [-1] 
expected returns: [[-0.6601906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 15. 15.] 
cards in discard: [14. 11. 15. 10. 15.  0. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  4.  8.  0. 10.  0.] 
adversary cards in hand: [ 1.  3.  3. 29.  8.] 
adversary cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.
 11.  1. 23.  0.  8. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0 11 11] -> size -> 31 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -101 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 0.3944427967071533





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.79433656]
 [-0.8199847 ]
 [-0.67874956]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 15. 15.] 
cards in discard: [14. 11. 15. 10. 15.  0. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  4.  8.  0. 10.  0.] 
adversary cards in hand: [ 1.  3.  3. 29.  8.] 
adversary cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.
 11.  1. 23.  0.  8. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0 11 11] -> size -> 31 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.6601905822753906






Player: 1 
cards in hand: [ 1.  3.  3. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 29.  8.] 
cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.
 11.  1. 23.  0.  8. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0 11 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  4.  8.  0. 10.  0.] 
adversary cards in hand: [ 0. 10. 10. 10. 10.] 
adversary cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14] -> size -> 35 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 4.] 
cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.
 11.  1. 23.  0.  8. 14.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  1  1  0  0  0 23 14  4 15 23 29  3  0 15  0 15  8  8
 14 11  2  3  0 11 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  4.  8.  0. 10.  0.] 
adversary cards in hand: [ 0. 10. 10. 10. 10.] 
adversary cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14] -> size -> 35 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.
 11.  1. 23.  0.  8. 14.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  4.  8.  0. 10.  0.] 
adversary cards in hand: [ 0. 10. 10. 10. 10.] 
adversary cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14] -> size -> 35 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.
 11.  1. 23.  0.  8. 14.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  4.  8.  0. 10.  0.] 
adversary cards in hand: [ 0. 10. 10. 10. 10.] 
adversary cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14] -> size -> 35 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 2. 15.  0.  0.  0.  3.  0. 11. 15.  3. 23.  0. 11. 14.  0.  0.  0.  3.
 11.  1. 23.  0.  8. 14.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  4.  8.  0. 10.  0.] 
adversary cards in hand: [ 0. 10. 10. 10. 10.] 
adversary cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14] -> size -> 35 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 10.] 
expected returns: [[-0.87645674]
 [-0.69370484]
 [-0.69370484]
 [-0.69370484]
 [-0.69370484]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10. 10.] 
cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  4.  8.  0. 10.  0.] 
adversary cards in hand: [ 2.  1.  0. 23. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0] -> size -> 30 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.6787502765655518



action possibilites: [-1. 10. 10. 10. 11.] 
expected returns: [[1.1230254]
 [1.3897173]
 [1.3897173]
 [1.3897173]
 [1.8406513]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10. 11.] 
cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  4.  8.  0. 10.  0.] 
adversary cards in hand: [ 2.  1.  0. 23. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0] -> size -> 30 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -0.6937048435211182



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[ 9.863505]
 [10.828038]
 [10.828038]
 [10.828038]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10.] 
cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14 14] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  3.  8.  0. 10.  0.] 
adversary cards in hand: [ 2.  1.  0. 23. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0] -> size -> 30 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0 -10   0   0  64   0] 
sum of rewards: -1 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 1.2640211582183838



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[3.7746036]
 [4.4417343]
 [4.4417343]
 [5.58813  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11.] 
cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14 14] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  3.  8.  0. 10.  0.] 
adversary cards in hand: [ 2.  1.  0. 23. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0] -> size -> 30 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 10.828036308288574



action possibilites: [-1. 10. 10.] 
expected returns: [[1.7171595]
 [2.1780746]
 [2.1780746]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15. 14. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 11. 10. 11.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14 14 14] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  2.  8.  0. 10.  0.] 
adversary cards in hand: [ 2.  1.  0. 23. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0] -> size -> 30 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 29 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 4.146259307861328



action possibilites: [-1. 10. 10.] 
expected returns: [[-1.2035458]
 [-1.0132458]
 [-1.0132458]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15. 14. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 11. 10. 11. 10.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14 14 14] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  2.  8.  0. 10.  0.] 
adversary cards in hand: [ 2.  1.  0. 23. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0] -> size -> 30 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 2.1780736446380615



action possibilites: [-1. 10.  8.] 
expected returns: [[-0.5923965 ]
 [-0.38964415]
 [-0.4854374 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.] 
cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15. 14. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 11. 10. 11. 10. 10.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14 14 14] -> size -> 37 
action values: 3 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  2.  8.  0. 10.  0.] 
adversary cards in hand: [ 2.  1.  0. 23. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0] -> size -> 30 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -1.0132474899291992



action possibilites: [-1.  8. 14.] 
expected returns: [[-1.4748318]
 [-1.4148928]
 [-1.480887 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.] 
cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15. 14. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11. 10. 11. 10. 10. 10.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14 14 14] -> size -> 37 
action values: 4 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  2.  8.  0. 10.  0.] 
adversary cards in hand: [ 2.  1.  0. 23. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0] -> size -> 30 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -0.3896453380584717



action possibilites: [-1.] 
expected returns: [[-0.01459384]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15. 14. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11. 10. 11. 10. 10. 10.  8.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14 14] -> size -> 36 
action values: 3 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  2.  8.  0. 10.  0.] 
adversary cards in hand: [ 2.  1.  0. 23. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0] -> size -> 30 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0 160   0   0   0   0   0   0   0   0   0] 
sum of rewards: 65 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -1.3766810894012451





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.71712565]
 [-0.81214666]
 [-0.4081273 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15. 14. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11. 10. 11. 10. 10. 10.  8.] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14 14] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  2.  8.  0. 10.  0.] 
adversary cards in hand: [ 2.  1.  0. 23. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0] -> size -> 30 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0 160   0   0   0   0   0   0   0   0   0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.014593839645385742






Player: 1 
cards in hand: [ 2.  1.  0. 23. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  1.  0. 23. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  2.  8.  0. 10.  0.] 
adversary cards in hand: [15.  3. 10. 15. 10.] 
adversary cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15. 14. 14. 10. 11. 10. 11.
 10. 10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14 14] -> size -> 36 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  1.  0. 23. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  1.  3. 10.  9.  2.  8.  0. 10.  0.] 
adversary cards in hand: [15.  3. 10. 15. 10.] 
adversary cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15. 14. 14. 10. 11. 10. 11.
 10. 10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14 14] -> size -> 36 
adversary victory points: 2
player victory points: 5 


Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 5 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15.  3. 10. 15. 10.] 
cards in discard: [14. 11. 15. 10. 15.  0. 14. 11. 10.  8. 15. 15. 14. 14. 10. 11. 10. 11.
 10. 10. 10.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 11 11 10 11 10 10  8 11 10  8 10 10 11 10 10 10 10 15
  8 15 15 15 15 15 15 14 14 14 14 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 29.  8. 10. 10.  0.  3. 10.  9.  2.  8.  0. 10.  0.] 
adversary cards in hand: [ 2.  1.  0. 23. 15.] 
adversary cards in discard: [11.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  0  0 23 14 15 23 29  3  0 15  0 15  8  8 14 11
  2  3  0 11 11  0 11] -> size -> 31 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000095 

action type: buy - action -1.0
Learning step: -120003.7734375
desired expected reward: -120004.1796875



