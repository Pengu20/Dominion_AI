 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[288.4712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -2 -100    0    0   20    0    0    0    0  -21    0    0
    4    0] 
sum of rewards: -604 

action type: buy - action 8.0
Learning step: -29.396255493164062
desired expected reward: -45.47114181518555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[262.829  ]
 [278.93295]
 [272.00784]
 [230.0028 ]
 [269.7912 ]
 [287.84464]
 [274.6251 ]
 [275.12625]
 [246.59558]
 [269.97577]
 [262.97495]
 [291.62622]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.649629592895508
desired expected reward: 283.57635498046875



buy possibilites: [-1] 
expected returns: [[258.38818]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 16.0
Learning step: -6.1758270263671875
desired expected reward: 263.61541748046875






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[292.11047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [16.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.411501407623291
desired expected reward: 251.9766845703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[270.89694]
 [288.5939 ]
 [280.90088]
 [235.39331]
 [297.00888]
 [283.6609 ]
 [277.73868]
 [299.16837]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [16.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.485771179199219
desired expected reward: 285.19903564453125



buy possibilites: [-1] 
expected returns: [[286.28336]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [16.  0.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -7.053668975830078
desired expected reward: 273.8471984863281






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [15.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[271.87567]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.788505554199219
desired expected reward: 278.4948425292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[245.72427]
 [253.25616]
 [215.59927]
 [256.3485 ]
 [268.65134]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -7.455590724945068
desired expected reward: 262.5738220214844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [16.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[302.3967 ]
 [279.92386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [3. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15. 11.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -6.429815769195557
desired expected reward: 262.22149658203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[268.45145]
 [286.3133 ]
 [279.37933]
 [234.75665]
 [276.1492 ]
 [295.6225 ]
 [280.7084 ]
 [281.17056]
 [251.46606]
 [275.9522 ]
 [268.33734]
 [299.47464]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [3. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15. 11.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.454237937927246
desired expected reward: 293.72003173828125



buy possibilites: [-1] 
expected returns: [[285.40646]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [ 3.  3.  0.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15. 11.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 13.5 

action type: buy - action 11.0
Learning step: -7.6844801902771
desired expected reward: 287.9380187988281






Player: 1 
cards in hand: [ 3.  0.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15. 11.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.] 
cards in discard: [10.  3.  0.  0.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.] 
cards in discard: [10.  3.  0.  0.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.] 
cards in discard: [10.  3.  0.  0.  3.  0. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[318.376  ]
 [315.83633]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -6.71212911605835
desired expected reward: 278.6943359375



action possibilites: [-1] 
expected returns: [[283.68762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 38 

action type: gain_card_n - action 5
Learning step: -5.966424465179443
desired expected reward: 279.021484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[258.86804]
 [271.1639 ]
 [265.83145]
 [232.91644]
 [278.33112]
 [267.80072]
 [264.36368]
 [281.91498]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1
Learning step: -6.754164218902588
desired expected reward: 276.9334716796875



buy possibilites: [-1] 
expected returns: [[251.6742]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11 11  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -1.0 

action type: buy - action 0.0
Learning step: -7.330732822418213
desired expected reward: 251.5373077392578






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [11.  0. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11 11  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [11.  0. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11 11  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  6. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [11.  0. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11 11  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[324.78632]
 [308.20975]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  0.] 
cards in discard: [11.  0. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11 11  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  6. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -5.065889835357666
desired expected reward: 246.60830688476562



action possibilites: [-1] 
expected returns: [[318.56583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0. 11.  0.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  6. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 33 

action type: gain_card_n - action 2
Learning step: -5.706563472747803
desired expected reward: 284.779296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[291.10474]
 [308.51288]
 [300.61972]
 [257.4889 ]
 [316.98065]
 [303.90533]
 [298.00742]
 [318.85004]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0. 11.  0.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  6. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1
Learning step: -7.724391460418701
desired expected reward: 310.8414306640625



buy possibilites: [-1] 
expected returns: [[288.71024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0. 11.  0.  0.  3.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  6. 10. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 47 

action type: buy - action 10.0
Learning step: -6.054389476776123
desired expected reward: 291.9530029296875






Player: 1 
cards in hand: [11.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  6. 10. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  6. 10. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[196.85309]
 [183.11186]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 29. 15.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  8. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -9.676790237426758
desired expected reward: 279.033447265625



action possibilites: [-1. 16.] 
expected returns: [[196.8477 ]
 [179.45448]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 29. 15.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  8. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action 10.0
Learning step: -3.526644229888916
desired expected reward: 180.82330322265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[172.22139]
 [180.62437]
 [144.69081]
 [181.72849]
 [195.76582]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 29. 15.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  8. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -4.436956405639648
desired expected reward: 192.4108123779297



buy possibilites: [-1] 
expected returns: [[244.41095]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 16.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 29. 15.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  8. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -282.0 

action type: buy - action 6.0
Learning step: -15.835293769836426
desired expected reward: 128.8555145263672






Player: 1 
cards in hand: [ 3.  3. 29. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29. 15.  0.] 
cards in discard: [11.  3.  0.  0.  0.  0.  8. 11.  0. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[196.93246]
 [195.27214]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 6. 10.  0.  3.  0.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [29. 29. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.9087042808532715
desired expected reward: 236.5022430419922



action possibilites: [-1] 
expected returns: [[274.68027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6. 10.  0.  3.  0.  3. 16. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [29. 29. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 27 

action type: gain_card_n - action 9
Learning step: -2.382209062576294
desired expected reward: 195.8680877685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[252.38344]
 [265.4546 ]
 [259.70325]
 [226.53264]
 [257.95474]
 [271.6184 ]
 [261.88373]
 [261.90158]
 [238.8754 ]
 [257.4755 ]
 [251.73994]
 [272.53366]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6. 10.  0.  3.  0.  3. 16. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [29. 29. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -7.048919677734375
desired expected reward: 267.63134765625



buy possibilites: [-1] 
expected returns: [[208.04283]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6. 10.  0.  3.  0.  3. 16. 10. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [29. 29. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 50 

action type: buy - action 29.0
Learning step: -5.914117336273193
desired expected reward: 255.98748779296875






Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [29. 29. 15.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  3.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  0.  3. 16. 10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [29. 29. 15.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  3.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  0.  3. 16. 10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[170.50343]
 [169.6365 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.  0.] 
cards in discard: [ 6. 10.  0.  3.  0.  3. 16. 10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11. 11.  0. 10.  0.] 
adversary cards in discard: [29. 29. 15.  3.  3.  0.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.785686016082764
desired expected reward: 201.25714111328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[147.20424]
 [157.92921]
 [115.82933]
 [158.50804]
 [172.3826 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.  0.] 
cards in discard: [ 6. 10.  0.  3.  0.  3. 16. 10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11. 11.  0. 10.  0.] 
adversary cards in discard: [29. 29. 15.  3.  3.  0.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -4.977436542510986
desired expected reward: 160.61541748046875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 10.  0.] 
cards in discard: [29. 29. 15.  3.  3.  0.  0.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 10.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0.] 
cards in discard: [29. 29. 15.  3.  3.  0.  0.  0.  0.  0.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 10.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  0.] 
cards in discard: [29. 29. 15.  3.  3.  0.  0.  0.  0.  0.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 10.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11.  0. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[236.51843]
 [235.38445]
 [220.37296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  6.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 29.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -3.190781831741333
desired expected reward: 161.83152770996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[214.81004]
 [221.39867]
 [189.64594]
 [224.6882 ]
 [235.54906]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  6.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 29.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -6.941305637359619
desired expected reward: 227.94728088378906



buy possibilites: [-1] 
expected returns: [[242.85876]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  6.  0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  8.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 29.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -19.6679744720459
desired expected reward: 169.9779510498047






Player: 1 
cards in hand: [11.  0. 29.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  8.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 10.] 
adversary cards in discard: [ 6. 11.  0. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  8.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  8.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 10.] 
adversary cards in discard: [ 6. 11.  0. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  8.  3.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 10.] 
adversary cards in discard: [ 6. 11.  0. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[190.99512]
 [174.98123]
 [170.79991]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 10.] 
cards in discard: [ 6. 11.  0. 10.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  1.] 
adversary cards in discard: [ 0. 11.  0. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.845573425292969
desired expected reward: 234.01318359375



action possibilites: [-1. 29.] 
expected returns: [[214.93031]
 [203.54175]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [ 6. 11.  0. 10.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  1.] 
adversary cards in discard: [ 0. 11.  0. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 8 

action type: take_action - action 10.0
Learning step: -3.228745698928833
desired expected reward: 163.59999084472656



action possibilites: [-1.] 
expected returns: [[195.86244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6. 11.  0. 10.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6] -> size -> 20 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  1.] 
adversary cards in discard: [ 0. 11.  0. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: take_action - action 29.0
Learning step: -4.420182704925537
desired expected reward: 199.12156677246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[181.56708]
 [191.4665 ]
 [188.34471]
 [169.15489]
 [162.6794 ]
 [185.77226]
 [197.44359]
 [187.96437]
 [204.36653]
 [188.29097]
 [172.49553]
 [178.95459]
 [186.22264]
 [168.14209]
 [182.10481]
 [200.46284]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6. 11.  0. 10.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  1.] 
adversary cards in discard: [ 0. 11.  0. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: -4.28372859954834
desired expected reward: 191.57872009277344



buy possibilites: [-1] 
expected returns: [[240.53192]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6. 11.  0. 10.  6.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  6.  8. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  1.] 
adversary cards in discard: [ 0. 11.  0. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: 29.0 

action type: buy - action 8.0
Learning step: -2.536250352859497
desired expected reward: 185.42811584472656






Player: 1 
cards in hand: [ 3.  0.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  1.] 
cards in discard: [ 0. 11.  0. 29.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  6.  8. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 16.] 
adversary cards in discard: [ 6. 11.  0. 10.  6.  0.  8. 10. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6  8] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  1.] 
cards in discard: [ 0. 11.  0. 29.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  6.  8. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 16.] 
adversary cards in discard: [ 6. 11.  0. 10.  6.  0.  8. 10. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6  8] -> size -> 21 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  1.] 
cards in discard: [ 0. 11.  0. 29.  8.  3. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  6.  8. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 16.] 
adversary cards in discard: [ 6. 11.  0. 10.  6.  0.  8. 10. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6  8] -> size -> 21 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[68.48201 ]
 [52.160545]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 16.] 
cards in discard: [ 6. 11.  0. 10.  6.  0.  8. 10. 29.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  6.  8. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [ 0. 11.  0. 29.  8.  3. 14.  3.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -11.394628524780273
desired expected reward: 229.13729858398438



action possibilites: [-1] 
expected returns: [[99.8165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 6. 11.  0. 10.  6.  0.  8. 10. 29.  0.  0.  0.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6  8  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  6.  7. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [ 0. 11.  0. 29.  8.  3. 14.  3.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 11 

action type: gain_card_n - action 3
Learning step: -4.139443397521973
desired expected reward: 134.56683349609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 84.0765 ]
 [ 63.42807]
 [100.60486]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 6. 11.  0. 10.  6.  0.  8. 10. 29.  0.  0.  0.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6  8  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  6.  7. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [ 0. 11.  0. 29.  8.  3. 14.  3.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -2.7646610736846924
desired expected reward: 97.05183410644531



buy possibilites: [-1] 
expected returns: [[132.63693]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 6. 11.  0. 10.  6.  0.  8. 10. 29.  0.  0.  0.  0.  3.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6  8  8  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  7.  9.  6.  7. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [ 0. 11.  0. 29.  8.  3. 14.  3.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14] -> size -> 20 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -15.387072563171387
desired expected reward: 48.0410041809082






Player: 1 
cards in hand: [ 0.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [ 0. 11.  0. 29.  8.  3. 14.  3.  0.  0. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  7.  9.  6.  7. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 16.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6  8  8  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [ 0. 11.  0. 29.  8.  3. 14.  3.  0.  0. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  7.  9.  6.  7. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 16.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6  8  8  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [ 0. 11.  0. 29.  8.  3. 14.  3.  0.  0. 11.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  7.  9.  6.  7. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 16.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6  8  8  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 16.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[148.97743]
 [139.38052]
 [147.51193]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  3. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10  6 10 29  6  8  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  7.  9.  6.  7. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -4.633256435394287
desired expected reward: 128.00367736816406



action possibilites: [-1] 
expected returns: [[118.740654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7.  9.  6.  7. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: gain_card_n - action 0
Learning step: -4.4192214012146
desired expected reward: 114.39849853515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[102.05992]
 [ 80.51199]
 [117.78898]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  7.  9.  6.  7. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -3.3191826343536377
desired expected reward: 115.42147064208984



buy possibilites: [-1] 
expected returns: [[97.525055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.] 
cards in discard: [0. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  6.  9.  6.  7. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -17.031286239624023
desired expected reward: 63.48069763183594






Player: 1 
cards in hand: [ 0.  3.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  6.  9.  6.  7. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 10. 11.  6.] 
adversary cards in discard: [ 0.  6. 16.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8.  6.  9.  6.  7. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 10. 11.  6.] 
adversary cards in discard: [ 0.  6. 16.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 28. 30.  8.  6.  9.  6.  7. 10.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 10. 11.  6.] 
adversary cards in discard: [ 0.  6. 16.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  6.  9.  6.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0. 10. 11.  6.] 
adversary cards in discard: [ 0.  6. 16.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[85.514206]
 [74.07616 ]
 [70.260956]
 [84.92301 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 11.  6.] 
cards in discard: [ 0.  6. 16.  0.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  6.  9.  6.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [14.  3. 11.  1.  0.] 
adversary cards in discard: [10. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -4.328515529632568
desired expected reward: 93.19654083251953



action possibilites: [-1.  8. 11.] 
expected returns: [[105.40708 ]
 [ 93.58133 ]
 [103.679794]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  6.  0.] 
cards in discard: [ 0.  6. 16.  0.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  6.  9.  6.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [14.  3. 11.  1.  0.] 
adversary cards in discard: [10. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -3 

action type: take_action - action 10.0
Learning step: -1.3388607501983643
desired expected reward: 67.91602325439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 87.100815]
 [ 95.80601 ]
 [ 63.683464]
 [ 95.814156]
 [108.111115]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  6.  0.] 
cards in discard: [ 0.  6. 16.  0.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  6.  9.  6.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [14.  3. 11.  1.  0.] 
adversary cards in discard: [10. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -3.427600145339966
desired expected reward: 101.97948455810547



buy possibilites: [-1] 
expected returns: [[78.810646]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  6.  0.] 
cards in discard: [ 0.  6. 16.  0.  3. 11.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  5.  9.  6.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [14.  3. 11.  1.  0.] 
adversary cards in discard: [10. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10] -> size -> 21 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -315.0 

action type: buy - action 6.0
Learning step: -17.160934448242188
desired expected reward: 46.52252960205078






Player: 1 
cards in hand: [14.  3. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 11.  1.  0.] 
cards in discard: [10. 15.  3.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  5.  9.  6.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  6. 29.] 
adversary cards in discard: [ 0.  6. 16.  0.  3. 11.  6. 10.  8.  0. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  1.  0.] 
cards in discard: [10. 15.  3.  0. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  5.  9.  5.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  6. 29.] 
adversary cards in discard: [ 0.  6. 16.  0.  3. 11.  6. 10.  8.  0. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  1.  0.] 
cards in discard: [10. 15.  3.  0. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8.  5.  9.  5.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  6. 29.] 
adversary cards in discard: [ 0.  6. 16.  0.  3. 11.  6. 10.  8.  0. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  1.  0.] 
cards in discard: [10. 15.  3.  0. 10. 11. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  5.  9.  4.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  6. 29.] 
adversary cards in discard: [ 0.  6. 16.  0.  3. 11.  6. 10.  8.  0. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[53.16877 ]
 [45.043343]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  6. 29.] 
cards in discard: [ 0.  6. 16.  0.  3. 11.  6. 10.  8.  0. 11.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  5.  9.  4.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  8.] 
adversary cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -4.582164287567139
desired expected reward: 74.22848510742188



action possibilites: [-1. 10.] 
expected returns: [[101.05799]
 [ 89.43998]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  6. 10.] 
cards in discard: [ 0.  6. 16.  0.  3. 11.  6. 10.  8.  0. 11.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  5.  9.  4.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  8.] 
adversary cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: -0.8540863394737244
desired expected reward: 44.18925476074219



action possibilites: [-1.] 
expected returns: [[92.41996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [ 0.  6. 16.  0.  3. 11.  6. 10.  8.  0. 11.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6] -> size -> 24 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  5.  9.  4.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  8.] 
adversary cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: -2.142550230026245
desired expected reward: 87.29743957519531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[73.526596]
 [81.84016 ]
 [78.7075  ]
 [59.675056]
 [85.9062  ]
 [78.5669  ]
 [76.33606 ]
 [86.936104]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [ 0.  6. 16.  0.  3. 11.  6. 10.  8.  0. 11.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8.  5.  9.  4.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  8.] 
adversary cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: -2.615117073059082
desired expected reward: 89.80484008789062



buy possibilites: [-1] 
expected returns: [[124.263]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [ 0.  6. 16.  0.  3. 11.  6. 10.  8.  0. 11.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  4.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  8.] 
adversary cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -40.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -306.0 

action type: buy - action 6.0
Learning step: -15.487835884094238
desired expected reward: 44.18722152709961






Player: 1 
cards in hand: [ 3.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  8.] 
cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  4.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  3.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  3.  7. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0. 11.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  3.  6. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[88.56755]
 [84.43327]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 11 11  0  3 10 10 29  6  8  8  6  0  6  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  3.  6. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0. 11.  8. 11.  3.  0.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -6.578723907470703
desired expected reward: 117.68428039550781



action possibilites: [-1] 
expected returns: [[49.144444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  3.  6. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0. 11.  8. 11.  3.  0.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: trash_cards_n_from_hand - action 8
Learning step: -4.2021803855896
desired expected reward: 77.5008316040039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[38.162262]
 [25.920689]
 [48.438194]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  3.  6. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0. 11.  8. 11.  3.  0.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -2.903944730758667
desired expected reward: 46.24049758911133



buy possibilites: [-1] 
expected returns: [[77.67605]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0. 11.  8. 11.  3.  0.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8] -> size -> 25 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -337.0 

action type: buy - action 6.0
Learning step: -16.39832305908203
desired expected reward: 9.522363662719727






Player: 1 
cards in hand: [ 0.  0. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  1.] 
cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0. 11.  8. 11.  3.  0.  0.
  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [6. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6] -> size -> 23 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 29.] 
cards in discard: [10. 15.  3.  0. 10. 11. 11. 11. 14.  3.  1.  0. 11.  8. 11.  3.  0.  0.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [6. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6] -> size -> 23 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [6. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6] -> size -> 23 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 8 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [6. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6] -> size -> 23 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [22.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  7.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [6. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6] -> size -> 23 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[61.21421 ]
 [45.473568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [6. 8. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  7.  9. 10.  6.  9.  9.] 
adversary cards in hand: [14. 11. 10.  8.  0.] 
adversary cards in discard: [22. 29. 29.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22] -> size -> 26 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -5.574219703674316
desired expected reward: 72.1018295288086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[44.8911  ]
 [55.61082 ]
 [51.380028]
 [28.846375]
 [49.21595 ]
 [61.756905]
 [51.53158 ]
 [51.69153 ]
 [35.724213]
 [49.14688 ]
 [44.819122]
 [64.43516 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [6. 8. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  7.  9. 10.  6.  9.  9.] 
adversary cards in hand: [14. 11. 10.  8.  0.] 
adversary cards in discard: [22. 29. 29.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22] -> size -> 26 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -4.682021141052246
desired expected reward: 54.31084442138672



buy possibilites: [-1] 
expected returns: [[52.160694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 6.  8.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  7.  9. 10.  6.  9.  8.] 
adversary cards in hand: [14. 11. 10.  8.  0.] 
adversary cards in discard: [22. 29. 29.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22] -> size -> 26 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -25 

action type: buy - action 15.0
Learning step: -2.317340135574341
desired expected reward: 42.50177001953125






Player: 1 
cards in hand: [14. 11. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 10.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11. 10.  8.  0.] 
cards in discard: [22. 29. 29.  0.  0.  0.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  7.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 6. 29. 11. 16.  6.] 
adversary cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15] -> size -> 24 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  8.  0.] 
cards in discard: [22. 29. 29.  0.  0.  0.  1.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 6. 29. 11. 16.  6.] 
adversary cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15] -> size -> 24 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  8.  0.] 
cards in discard: [22. 29. 29.  0.  0.  0.  1.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 6. 29. 11. 16.  6.] 
adversary cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15] -> size -> 24 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 6. 29. 11. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 16.] 
expected returns: [[-21.963673]
 [-23.723885]
 [-22.949917]
 [-23.141941]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 11. 16.  6.] 
cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  3.  0. 11.  3.] 
adversary cards in discard: [22. 29. 29.  0.  0.  0.  1.  0. 29. 11. 14. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -5.973453044891357
desired expected reward: 46.18724060058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-22.721859]
 [-19.87339 ]
 [-21.895956]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29. 11. 16.  6.] 
cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  3.  0. 11.  3.] 
adversary cards in discard: [22. 29. 29.  0.  0.  0.  1.  0. 29. 11. 14. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -2.2341091632843018
desired expected reward: -24.197778701782227



buy possibilites: [-1] 
expected returns: [[23.715734]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29. 11. 16.  6.] 
cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  3.  0. 11.  3.] 
adversary cards in discard: [22. 29. 29.  0.  0.  0.  1.  0. 29. 11. 14. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action 0.0
Learning step: -2.6803033351898193
desired expected reward: -25.402158737182617






Player: 1 
cards in hand: [ 3.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.  3.] 
cards in discard: [22. 29. 29.  0.  0.  0.  1.  0. 29. 11. 14. 10.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 11.  3.  6.  0.] 
adversary cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.  0.  6. 29. 11. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15
  0] -> size -> 25 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 11.  3.] 
cards in discard: [22. 29. 29.  0.  0.  0.  1.  0. 29. 11. 14. 10.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 11.  3.  6.  0.] 
adversary cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.  0.  6. 29. 11. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15
  0] -> size -> 25 
adversary victory points: -2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[50.227615]
 [50.674824]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  6.  0.] 
cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.  0.  6. 29. 11. 16.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  9.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [11.  1. 15. 10.  8.] 
adversary cards in discard: [22. 29. 29.  0.  0.  0.  1.  0. 29. 11. 14. 10.  8.  0.  3.  3.  0. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -2.9004428386688232
desired expected reward: 20.815292358398438



action possibilites: [-1] 
expected returns: [[68.96601]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.  0.  6. 29. 11. 16.  6. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15
  0 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  8.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [11.  1. 15. 10.  8.] 
adversary cards in discard: [22. 29. 29.  0.  0.  0.  1.  0. 29. 11. 14. 10.  8.  0.  3.  3.  0. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -21 

action type: gain_card_n - action 4
Learning step: -0.9331802725791931
desired expected reward: 27.765125274658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[51.26151]
 [37.74711]
 [71.12061]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.  0.  6. 29. 11. 16.  6. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15
  0 16] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  3.  8.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [11.  1. 15. 10.  8.] 
adversary cards in discard: [22. 29. 29.  0.  0.  0.  1.  0. 29. 11. 14. 10.  8.  0.  3.  3.  0. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -4.082123279571533
desired expected reward: 64.8838882446289






Player: 1 
cards in hand: [11.  1. 15. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 15. 10.  8.] 
cards in discard: [22. 29. 29.  0.  0.  0.  1.  0. 29. 11. 14. 10.  8.  0.  3.  3.  0. 11.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  8.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  3.  0. 10.  8.] 
adversary cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.  0.  6. 29. 11. 16.  6. 16. 11.  3.
  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15
  0 16] -> size -> 26 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 10.  8.] 
cards in discard: [22. 29. 29.  0.  0.  0.  1.  0. 29. 11. 14. 10.  8.  0.  3.  3.  0. 11.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  8.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  3.  0. 10.  8.] 
adversary cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.  0.  6. 29. 11. 16.  6. 16. 11.  3.
  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15
  0 16] -> size -> 26 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 10.  8.] 
cards in discard: [22. 29. 29.  0.  0.  0.  1.  0. 29. 11. 14. 10.  8.  0.  3.  3.  0. 11.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  3.  8.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  3.  0. 10.  8.] 
adversary cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.  0.  6. 29. 11. 16.  6. 16. 11.  3.
  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15
  0 16] -> size -> 26 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[21.80199 ]
 [15.596538]
 [17.728878]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 10.  8.] 
cards in discard: [ 6.  8.  0. 15.  0.  0.  0.  0. 10.  0.  6. 29. 11. 16.  6. 16. 11.  3.
  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15
  0 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  8.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -5.989638328552246
desired expected reward: 65.13096618652344



action possibilites: [-1.  8. 16.] 
expected returns: [[11.375508]
 [11.159297]
 [ 9.97691 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  8. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 16  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15
  0 16] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  8.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action 10.0
Learning step: -2.385528326034546
desired expected reward: 13.211018562316895



action possibilites: [-1.] 
expected returns: [[69.35999]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  8.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.7104547619819641
desired expected reward: 3.5427112579345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[57.202774]
 [41.36795 ]
 [72.73335 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  8.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: -3.0198211669921875
desired expected reward: 66.34017181396484






Player: 1 
cards in hand: [ 0.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  8.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0. 16.  3.  8.] 
adversary cards in discard: [10.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16] -> size -> 24 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 28. 30.  8.  3.  8.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0. 16.  3.  8.] 
adversary cards in discard: [10.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16] -> size -> 24 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11.  0.] 
cards in discard: [3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0. 16.  3.  8.] 
adversary cards in discard: [10.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16] -> size -> 24 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11.  0. 16.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.  8.] 
expected returns: [[26.514137]
 [26.68819 ]
 [22.786625]
 [23.918741]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.  3.  8.] 
cards in discard: [10.  8.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  6. 10.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 22.  1. 29.  0.] 
adversary cards in discard: [ 3.  0.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -6.441993236541748
desired expected reward: 66.29134368896484



action possibilites: [-1] 
expected returns: [[4.302869]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [10.  8.  6.  3. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  6.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 22.  1. 29.  0.] 
adversary cards in discard: [ 3.  0.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0  25   0] 
sum of rewards: -22 

action type: gain_card_n - action 8
Learning step: -2.1788437366485596
desired expected reward: 21.334318161010742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 1.8064904]
 [-0.5322242]
 [ 4.004271 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [10.  8.  6.  3. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  6.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 22.  1. 29.  0.] 
adversary cards in discard: [ 3.  0.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -2.523630380630493
desired expected reward: 1.7792384624481201






Player: 1 
cards in hand: [ 3. 22.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22.  1. 29.  0.] 
cards in discard: [ 3.  0.  0. 11. 11.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  6.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 15.  6.  6.  0.] 
adversary cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25] -> size -> 24 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.  1. 29.  0.] 
cards in discard: [ 3.  0.  0. 11. 11.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  6.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 15.  6.  6.  0.] 
adversary cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25] -> size -> 24 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.  1. 29.  0.] 
cards in discard: [ 3.  0.  0. 11. 11.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  5.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 15.  6.  6.  0.] 
adversary cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25] -> size -> 24 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[22.085423]
 [ 8.750431]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  6.  0.] 
cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  5.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [14. 11.  0.  0. 11.] 
adversary cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8] -> size -> 29 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -3.1975958347320557
desired expected reward: 0.8066771030426025



action possibilites: [-1] 
expected returns: [[50.750946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  5.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [14. 11.  0.  0. 11.] 
adversary cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8] -> size -> 29 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action 15.0
Learning step: -1.6456260681152344
desired expected reward: 7.104818344116211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[38.09791 ]
 [45.272385]
 [43.09909 ]
 [26.41416 ]
 [41.079243]
 [48.63513 ]
 [42.324898]
 [42.2665  ]
 [31.973103]
 [40.734646]
 [37.763523]
 [49.93367 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  5.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [14. 11.  0.  0. 11.] 
adversary cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8] -> size -> 29 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -3.965336561203003
desired expected reward: 46.78561019897461






Player: 1 
cards in hand: [14. 11.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  0.  0. 11.] 
cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  5.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [29.  0.  6.  0.  0.] 
adversary cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8. 15.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25] -> size -> 23 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  0.  0. 11.] 
cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  5.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [29.  0.  6.  0.  0.] 
adversary cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8. 15.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25] -> size -> 23 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  0.  0. 11.] 
cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  4.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [29.  0.  6.  0.  0.] 
adversary cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8. 15.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25] -> size -> 23 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 9.250099  ]
 [-0.53645754]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  0.  0.] 
cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8. 15.  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  4.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [29. 29.  3.  8. 10.] 
adversary cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.  8. 14. 11.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -5.744461536407471
desired expected reward: 44.18921661376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-5.962167 ]
 [ 2.8017774]
 [-1.3099625]
 [-7.2006807]
 [ 7.9015546]
 [-1.6313385]
 [-3.7771044]
 [ 9.114964 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  6.  0.  0.] 
cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8. 15.  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  4.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [29. 29.  3.  8. 10.] 
adversary cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.  8. 14. 11.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.8048622608184814
desired expected reward: 5.445219993591309



buy possibilites: [-1] 
expected returns: [[30.496876]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  6.  0.  0.] 
cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8. 15.  6.  6.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [29. 29.  3.  8. 10.] 
adversary cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.  8. 14. 11.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -65.0 

action type: buy - action 8.0
Learning step: -2.482253074645996
desired expected reward: -4.113595962524414






Player: 1 
cards in hand: [29. 29.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  8. 10.] 
cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.  8. 14. 11.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0.  3.  6. 10.] 
adversary cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8. 15.  6.  6.  0.  8. 29.  0.  6.  0.
  0.] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8] -> size -> 24 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  3.  8. 10.] 
cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.  8. 14. 11.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0.  3.  6. 10.] 
adversary cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8. 15.  6.  6.  0.  8. 29.  0.  6.  0.
  0.] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8] -> size -> 24 
adversary victory points: -2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[75.24926]
 [73.65486]
 [67.39427]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  6. 10.] 
cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8. 15.  6.  6.  0.  8. 29.  0.  6.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [11.  3.  0.  8. 10.] 
adversary cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.  8. 14. 11.  0.  0. 11.
 29. 29.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -3.249906301498413
desired expected reward: 27.24696922302246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[62.068752]
 [52.96431 ]
 [73.310814]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  6. 10.] 
cards in discard: [10.  8.  6.  3. 25. 16.  0.  3.  8. 15.  6.  6.  0.  8. 29.  0.  6.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [11.  3.  0.  8. 10.] 
adversary cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.  8. 14. 11.  0.  0. 11.
 29. 29.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -5.690859317779541
desired expected reward: 69.55839538574219



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  3.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  8. 10.] 
cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.  8. 14. 11.  0.  0. 11.
 29. 29.  3.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  6.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 10.  6.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8] -> size -> 24 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 10.] 
cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.  8. 14. 11.  0.  0. 11.
 29. 29.  3.  8. 10. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 10.  6.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8] -> size -> 24 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 10.] 
cards in discard: [ 3.  0.  0. 11. 11.  0.  8.  3. 22.  1. 29.  0.  8. 14. 11.  0.  0. 11.
 29. 29.  3.  8. 10. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 10.  6.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8] -> size -> 24 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  6.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[12.605101]
 [ 8.011164]
 [ 5.247377]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  0. 15.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8 29] -> size -> 31 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -6.825170993804932
desired expected reward: 66.48563385009766



action possibilites: [-1. 15.] 
expected returns: [[41.228264]
 [30.11085 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8 29] -> size -> 31 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -46 

action type: take_action - action 10.0
Learning step: -1.77505624294281
desired expected reward: 5.926657676696777



action possibilites: [-1.] 
expected returns: [[71.36292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8 29] -> size -> 31 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action 15.0
Learning step: -1.2498770952224731
desired expected reward: 28.860979080200195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[58.96468 ]
 [66.0555  ]
 [63.885227]
 [49.9793  ]
 [45.53393 ]
 [61.939434]
 [69.66361 ]
 [63.300503]
 [74.10294 ]
 [63.230755]
 [52.023838]
 [56.8259  ]
 [61.868015]
 [49.09868 ]
 [58.794777]
 [70.80936 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8 29] -> size -> 31 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -3.547839403152466
desired expected reward: 67.8150863647461



buy possibilites: [-1] 
expected returns: [[20.155676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8 29] -> size -> 31 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -60.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -19.0 

action type: buy - action 14.0
Learning step: -3.0976881980895996
desired expected reward: 48.92612838745117






Player: 1 
cards in hand: [ 0.  8.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  1. 15.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 10 29  0 11  8 29  1  0 14  1 10 11 11 11
  8 22 29  3  8  8 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [14. 10. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8 14] -> size -> 24 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 11 10 29  0 11  8 29  0 14  1 10 11 11 11  8 22 29  3
  8  8 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [14. 10. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8 14] -> size -> 24 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 11 10 29  0 11  8 29  0 14  1 10 11 11 11  8 22 29  3
  8  8 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [14. 10. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8 14] -> size -> 24 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [8. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[9.779509 ]
 [6.0962543]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [14. 10. 15.  6.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11  0  3 10 10 29  8  8  6  0  6  6  6  6 15  0 16 25  8 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  0.  1.  3. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  3  3  3 11 10 29  0 11  8 29  0 14  1 10 11 11 11  8 22 29  3
  8  8 29] -> size -> 27 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -4.182366371154785
desired expected reward: 15.973309516906738



action possibilites: [-1] 
expected returns: [[34.735664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [14. 10. 15.  6.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  0.  1.  3. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  3  3  3 11 10 29  0 11  8 29  0 14  1 10 11 11 11  8 22 29  3
  8  8 29] -> size -> 27 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.895461082458496
desired expected reward: 4.644807815551758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.990694]
 [13.662335]
 [37.53684 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [14. 10. 15.  6.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  0.  1.  3. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  3  3  3 11 10 29  0 11  8 29  0 14  1 10 11 11 11  8 22 29  3
  8  8 29] -> size -> 27 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -3.490525484085083
desired expected reward: 31.24513816833496






Player: 1 
cards in hand: [ 8.  0.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1.  3. 11.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 10 29  0 11  8 29  0 14  1 10 11 11 11  8 22 29  3
  8  8 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6. 10.  8.  6.  0.] 
adversary cards in discard: [14. 10. 15.  6.  0.  0.  8.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14] -> size -> 21 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6. 10.  8.  6.  0.] 
adversary cards in discard: [14. 10. 15.  6.  0.  0.  8.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14] -> size -> 21 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6. 10.  8.  6.  0.] 
adversary cards in discard: [14. 10. 15.  6.  0.  0.  8.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14] -> size -> 21 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[40.625   ]
 [36.02473 ]
 [36.541542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  8.  6.  0.] 
cards in discard: [14. 10. 15.  6.  0.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0. 11. 29. 29.] 
adversary cards in discard: [ 8.  8.  3. 11.] 
adversary owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29] -> size -> 25 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -4.391162872314453
desired expected reward: 33.14566421508789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.343502]
 [28.294147]
 [39.459393]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  8.  6.  0.] 
cards in discard: [14. 10. 15.  6.  0.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0. 11. 29. 29.] 
adversary cards in discard: [ 8.  8.  3. 11.] 
adversary owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29] -> size -> 25 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -4.583114147186279
desired expected reward: 35.34246826171875



buy possibilites: [-1] 
expected returns: [[29.019335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  8.  6.  0.] 
cards in discard: [14. 10. 15.  6.  0.  0.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0. 11. 29. 29.] 
adversary cards in discard: [ 8.  8.  3. 11.] 
adversary owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29] -> size -> 25 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -97.0 

action type: buy - action 0.0
Learning step: -5.8642401695251465
desired expected reward: 27.479257583618164






Player: 1 
cards in hand: [ 0.  0. 11. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29. 29.] 
cards in discard: [ 8.  8.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  6. 25. 29.  3.] 
adversary cards in discard: [14. 10. 15.  6.  0.  0.  8.  0.  0.  6. 10.  8.  6.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0] -> size -> 22 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29. 29.] 
cards in discard: [ 8.  8.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  6. 25. 29.  3.] 
adversary cards in discard: [14. 10. 15.  6.  0.  0.  8.  0.  0.  6. 10.  8.  6.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0] -> size -> 22 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29. 29.] 
cards in discard: [ 8.  8.  3. 11.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  6. 25. 29.  3.] 
adversary cards in discard: [14. 10. 15.  6.  0.  0.  8.  0.  0.  6. 10.  8.  6.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0] -> size -> 22 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11.  6. 25. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29.] 
expected returns: [[-6.762084 ]
 [-6.285804 ]
 [-8.092136 ]
 [-7.5937223]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 25. 29.  3.] 
cards in discard: [14. 10. 15.  6.  0.  0.  8.  0.  0.  6. 10.  8.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  3.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 11. 11. 29.  3.] 
adversary cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.] 
adversary owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29  0] -> size -> 26 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -4.961824893951416
desired expected reward: 24.057510375976562



action possibilites: [-1] 
expected returns: [[-6.421358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 29.  3.  3. 16.] 
cards in discard: [14. 10. 15.  6.  0.  0.  8.  0.  0.  6. 10.  8.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  2.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 11. 11. 29.  3.] 
adversary cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6.] 
adversary owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29  0  6] -> size -> 27 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action 25.0
Learning step: -2.089874029159546
desired expected reward: -10.182003021240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -7.900564 ]
 [-11.457719 ]
 [ -6.4261055]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 29.  3.  3. 16.] 
cards in discard: [14. 10. 15.  6.  0.  0.  8.  0.  0.  6. 10.  8.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  2.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 11. 11. 29.  3.] 
adversary cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6.] 
adversary owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29  0  6] -> size -> 27 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -2.22045636177063
desired expected reward: -8.641814231872559



buy possibilites: [-1] 
expected returns: [[-10.528271]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 29.  3.  3. 16.] 
cards in discard: [14. 10. 15.  6.  0.  0.  8.  0.  0.  6. 10.  8.  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  1.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 11. 11. 29.  3.] 
adversary cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6.] 
adversary owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29  0  6] -> size -> 27 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3  -70    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -358 

action type: buy - action 6.0
Learning step: -17.564001083374023
desired expected reward: -29.021717071533203






Player: 1 
cards in hand: [ 3. 11. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11. 29.  3.] 
cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  1.  8.  3.  3.  9.  5.  8. 10.  6.  9.  8.] 
adversary cards in hand: [15.  0.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6] -> size -> 23 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29.  3.] 
cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29  0  6 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  1.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [15.  0.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6] -> size -> 23 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 29.  3.] 
cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29  0  6 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  1.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [15.  0.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6] -> size -> 23 
adversary victory points: -3
player victory points: 3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [15.  0.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[62.75841 ]
 [55.840435]
 [58.980347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.  0.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  1.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [14.  0. 10.  8. 11.] 
adversary cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.] 
adversary owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29  0  6 29] -> size -> 28 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -1.6353418827056885
desired expected reward: -12.163612365722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[53.73585 ]
 [56.38803 ]
 [44.095566]
 [56.73329 ]
 [60.51134 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.  0.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 27. 30.  8.  1.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [14.  0. 10.  8. 11.] 
adversary cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.] 
adversary owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29  0  6 29] -> size -> 28 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1.0
Learning step: -5.096214294433594
desired expected reward: 53.36643600463867



buy possibilites: [-1] 
expected returns: [[39.57782]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.  0.  8.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 27. 30.  8.  1.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [14.  0. 10.  8. 11.] 
adversary cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.] 
adversary owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29  0  6 29] -> size -> 28 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -98.0 

action type: buy - action 0.0
Learning step: -6.295727729797363
desired expected reward: 39.4288444519043






Player: 1 
cards in hand: [14.  0. 10.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10.  8. 11.] 
cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 10 29  0 11  8 29  0 14 10 11 11 11  8 22 29  3  8  8
 29  0  6 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  1.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  6.  0. 10. 29.] 
adversary cards in discard: [ 0. 15.  0.  6.  0.  8.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0] -> size -> 24 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 10 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0
  6 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  1.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  6.  0. 10. 29.] 
adversary cards in discard: [ 0. 15.  0.  6.  0.  8.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0] -> size -> 24 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 10 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0
  6 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  1.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  6.  0. 10. 29.] 
adversary cards in discard: [ 0. 15.  0.  6.  0.  8.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0] -> size -> 24 
adversary victory points: -3
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[-8.15033 ]
 [-9.275787]
 [-8.305715]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 10. 29.] 
cards in discard: [ 0. 15.  0.  6.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  1.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8. 10.  0. 29. 22.] 
adversary cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.  8.
  0. 10.] 
adversary owned cards: [ 0  0  3  3  3 10 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0
  6 29] -> size -> 26 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -5.562602519989014
desired expected reward: 34.01521682739258



action possibilites: [-1. 29.] 
expected returns: [[-7.8477483]
 [-6.6445217]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 29.  0.] 
cards in discard: [ 0. 15.  0.  6.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  1.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8. 10.  0. 29. 22.] 
adversary cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.  8.
  0. 10.] 
adversary owned cards: [ 0  0  3  3  3 10 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0
  6 29] -> size -> 26 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -47 

action type: take_action - action 10.0
Learning step: -2.0746331214904785
desired expected reward: -10.832420349121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-7.6203737]
 [-7.637123 ]
 [-7.1476536]
 [-7.4380064]
 [-8.678192 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 29.  0.] 
cards in discard: [ 0. 15.  0.  6.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 27. 30.  8.  1.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8. 10.  0. 29. 22.] 
adversary cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.  8.
  0. 10.] 
adversary owned cards: [ 0  0  3  3  3 10 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0
  6 29] -> size -> 26 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.180481433868408
desired expected reward: -10.028231620788574



buy possibilites: [-1] 
expected returns: [[20.347479]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 29.  0.] 
cards in discard: [ 0. 15.  0.  6.  0.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 27. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8. 10.  0. 29. 22.] 
adversary cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.  8.
  0. 10.] 
adversary owned cards: [ 0  0  3  3  3 10 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0
  6 29] -> size -> 26 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -70.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -359.0 

action type: buy - action 6.0
Learning step: -17.13479995727539
desired expected reward: -24.282453536987305






Player: 1 
cards in hand: [ 8. 10.  0. 29. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29. 22.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 29. 22.] 
cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.  8.
  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0
  6 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  3.  8.  6.  0.] 
adversary cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1.  8. 10. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 22.] 
cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.  8.
  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3 10 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0
  6 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  3.  8.  6.  0.] 
adversary cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.] 
cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.  8.
  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  3.  8.  6.  0.] 
adversary cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.] 
cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.  8.
  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 27. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  3.  8.  6.  0.] 
adversary cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.] 
cards in discard: [ 8.  8.  3. 11.  0.  0.  0. 11. 29. 29.  6. 29. 11.  3. 11. 29.  3.  8.
  0. 10.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  3.  8.  6.  0.] 
adversary cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [11.  3.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[-10.007927 ]
 [ -7.2440367]
 [ -9.642532 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  6.  0.] 
cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29  3] -> size -> 26 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1
Learning step: -5.66760778427124
desired expected reward: 14.67987060546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-12.127157]
 [-10.538867]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8.  6.  0.] 
cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29  3] -> size -> 26 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: take_action - action -1.0
Learning step: -4.203916072845459
desired expected reward: -14.21183967590332



buy possibilites: [-1] 
expected returns: [[-24.742441]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8.  6.  0.] 
cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 26. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29  3] -> size -> 26 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -119.0 

action type: buy - action 0.0
Learning step: -5.900346755981445
desired expected reward: -18.02750587463379






Player: 1 
cards in hand: [ 0.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [14.  6.  3.  8. 16.] 
adversary cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.  0. 11.  3.  8.  6.
  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 26. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [14.  6.  3.  8. 16.] 
adversary cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.  0. 11.  3.  8.  6.
  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0.  3.] 
cards in discard: [3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [14.  6.  3.  8. 16.] 
adversary cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.  0. 11.  3.  8.  6.
  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
adversary victory points: -4
player victory points: 5 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [14.  6.  3.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 16.] 
expected returns: [[-11.021731]
 [ -9.248129]
 [-12.205828]
 [-12.110696]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  3.  8. 16.] 
cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.  0. 11.  3.  8.  6.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [10. 29.  3.  3.  8.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29  3  3] -> size -> 27 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1
Learning step: -3.9620494842529297
desired expected reward: -28.704490661621094



action possibilites: [-1] 
expected returns: [[46.51773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  8. 16.] 
cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.  0. 11.  3.  8.  6.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [10.  3.  3.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8.] 
adversary owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29  3  3] -> size -> 27 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action 14.0
Learning step: -2.4409449100494385
desired expected reward: -11.689072608947754





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[42.692726]
 [45.207756]
 [46.26036 ]
 [48.890244]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  8. 16.] 
cards in discard: [ 0. 15.  0.  6.  0.  8.  6. 10.  6.  6.  0. 29.  0.  0. 11.  3.  8.  6.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [10.  3.  3.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8.] 
adversary owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29  3  3] -> size -> 27 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action -1
Learning step: -5.24354362487793
desired expected reward: 41.27418518066406






Player: 1 
cards in hand: [10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.] 
cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29  3  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 29.  8. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
adversary victory points: -4
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6
 29  3  3] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 29.  8. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
adversary victory points: -4
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 29.  8. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 29.  8. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  8. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 25. 10.] 
expected returns: [[43.700592]
 [40.007545]
 [40.140663]
 [47.119675]
 [38.54293 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  8. 25. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [22.  8. 29. 11.  6.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3] -> size -> 26 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1.0
Learning step: -6.016585826873779
desired expected reward: 42.87366485595703



action possibilites: [-1.  8. 25.] 
expected returns: [[30.193419]
 [29.001429]
 [36.442635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 25.  0.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [22.  8. 29. 11.  6.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3] -> size -> 26 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: discard_n_cards - action 1
Learning step: -4.648791790008545
desired expected reward: 33.75088882446289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[27.649853]
 [29.915792]
 [31.531275]
 [32.72326 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 25.  0.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [22.  8. 29. 11.  6.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3] -> size -> 26 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1.0
Learning step: -4.272489070892334
desired expected reward: 25.920940399169922



buy possibilites: [-1] 
expected returns: [[21.684748]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 25.  0.] 
cards in discard: [10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [22.  8. 29. 11.  6.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3] -> size -> 26 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -80.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -99.0 

action type: buy - action 0.0
Learning step: -5.749353408813477
desired expected reward: 21.900510787963867






Player: 1 
cards in hand: [22.  8. 29. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 29. 11.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  8. 29. 11.  6.] 
cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6. 14.  0.  3.  0.] 
adversary cards in discard: [10.  0. 29.  3.  8. 25.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0  0] -> size -> 27 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 29. 11. 11. 29.  0.] 
cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 29. 11.] 
owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6. 14.  0.  3.  0.] 
adversary cards in discard: [10.  0. 29.  3.  8. 25.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0  0] -> size -> 27 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 29. 11. 11. 29.  0.] 
cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 29. 11.] 
owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6. 14.  0.  3.  0.] 
adversary cards in discard: [10.  0. 29.  3.  8. 25.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0  0] -> size -> 27 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 29. 11. 11. 29.  0.] 
cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 29. 11.] 
owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6. 14.  0.  3.  0.] 
adversary cards in discard: [10.  0. 29.  3.  8. 25.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0  0] -> size -> 27 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 6. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-19.432997]
 [ -9.020203]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  3.  0.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.  0. 22. 29. 11.  8.  6. 29.
 11. 11. 29.  0.] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0] -> size -> 27 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1
Learning step: -5.8498735427856445
desired expected reward: 15.834874153137207



action possibilites: [-1] 
expected returns: [[-6.292018]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.  0. 22. 29. 11.  8.  6. 29.
 11. 11. 29.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0] -> size -> 27 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action 14.0
Learning step: -3.1405599117279053
desired expected reward: -12.1607666015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-5.578722 ]
 [-6.2314014]
 [-5.902541 ]
 [-5.985567 ]
 [-5.3940315]
 [-6.2370195]
 [-6.1934047]
 [-4.5344462]
 [-5.672247 ]
 [-5.245436 ]
 [-4.8383594]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 25. 30.  8.  0.  8.  3.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.  0. 22. 29. 11.  8.  6. 29.
 11. 11. 29.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0] -> size -> 27 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1
Learning step: -3.2609055042266846
desired expected reward: -9.552923202514648



buy possibilites: [-1] 
expected returns: [[4.099929]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 25. 30.  8.  0.  8.  2.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.  0. 22. 29. 11.  8.  6. 29.
 11. 11. 29.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0] -> size -> 27 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5.    0.   -4.  -80.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -64.5 

action type: buy - action 11.0
Learning step: -2.8630502223968506
desired expected reward: -8.257081031799316






Player: 1 
cards in hand: [ 3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.  0. 22. 29. 11.  8.  6. 29.
 11. 11. 29.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 30.  8.  0.  8.  2.  3.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  6. 10.  8.  0.] 
adversary cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0  0 11] -> size -> 28 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.  0. 22. 29. 11.  8.  6. 29.
 11. 11. 29.  0.  8.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  6. 10.  8.  0.] 
adversary cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0  0 11] -> size -> 28 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 3.  0.  3. 29.  0.  3. 29.  8. 10.  8.  3.  0. 22. 29. 11.  8.  6. 29.
 11. 11. 29.  0.  8.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  6. 10.  8.  0.] 
adversary cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0  0 11] -> size -> 28 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 6.  6. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-17.197435]
 [-17.364368]
 [-17.940462]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10.  8.  0.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0
  6  0  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [29. 10.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0  8] -> size -> 28 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1
Learning step: -5.048503398895264
desired expected reward: -0.9485745429992676



action possibilites: [-1] 
expected returns: [[32.81772]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6
  0  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [29. 10.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0  8] -> size -> 28 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: trash_cards_n_from_hand - action 2
Learning step: -1.854448914527893
desired expected reward: -18.997495651245117





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[27.68501 ]
 [32.819214]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6
  0  0 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [29. 10.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0  8] -> size -> 28 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1
Learning step: -4.408013343811035
desired expected reward: 28.409706115722656



buy possibilites: [-1] 
expected returns: [[11.555555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6
  0  0 11  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [29. 10.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0  8] -> size -> 28 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -80.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -99.0 

action type: buy - action 0.0
Learning step: -6.074251174926758
desired expected reward: 21.610767364501953






Player: 1 
cards in hand: [29. 10.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  3.  6.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [16.  0.  8. 11.  6.] 
adversary cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.  0.  8.  6.  6.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6
  0  0 11  0] -> size -> 28 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  3.  6.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0  8] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [16.  0.  8. 11.  6.] 
adversary cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.  0.  8.  6.  6.  0.] 
adversary owned cards: [ 0  3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6
  0  0 11  0] -> size -> 28 
adversary victory points: -4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [16.  0.  8. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 11.] 
expected returns: [[-12.315446 ]
 [ -6.2433157]
 [ -6.3380938]
 [ -9.017526 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8. 11.  6.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.  0.  8.  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6
  0  0 11  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11. 29. 22.  3.  8.] 
adversary cards in discard: [29. 10.  3.  6.  8.] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0  8] -> size -> 28 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1
Learning step: -5.216630458831787
desired expected reward: 6.338924884796143





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.3455706]
 [-9.472043 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8. 11.  6.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.  0.  8.  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6
  0  0 11  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11. 29. 22.  3.  8.] 
adversary cards in discard: [29. 10.  3.  6.  8.] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0  8] -> size -> 28 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: take_action - action -1.0
Learning step: -4.010837554931641
desired expected reward: -16.326255798339844



buy possibilites: [-1] 
expected returns: [[-2.1181598]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8. 11.  6.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.  0.  8.  6.  6.  0.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6
  0  0 11  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11. 29. 22.  3.  8.] 
adversary cards in discard: [29. 10.  3.  6.  8.] 
adversary owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0  8] -> size -> 28 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -119.0 

action type: buy - action 0.0
Learning step: -5.680380344390869
desired expected reward: -12.025949478149414






Player: 1 
cards in hand: [11. 29. 22.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 22.  3.  8.] 
cards in discard: [29. 10.  3.  6.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  0 11  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29
  3  3  0  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  6. 15.  6.  0.] 
adversary cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.  0.  8.  6.  6.  0.
  0. 16.  0.  8. 11.  6.] 
adversary owned cards: [ 0  3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6
  0  0 11  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.] 
cards in discard: [29. 10.  3.  6.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  6. 15.  6.  0.] 
adversary cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.  0.  8.  6.  6.  0.
  0. 16.  0.  8. 11.  6.] 
adversary owned cards: [ 0  3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6
  0  0 11  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.] 
cards in discard: [29. 10.  3.  6.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  6. 15.  6.  0.] 
adversary cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.  0.  8.  6.  6.  0.
  0. 16.  0.  8. 11.  6.] 
adversary owned cards: [ 0  3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6
  0  0 11  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-0.51082325]
 [-2.1759121 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  6.  0.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.  0.  8.  6.  6.  0.
  0. 16.  0.  8. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6
  0  0 11  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [29.  3.  0. 11.  8.] 
adversary cards in discard: [29. 10.  3.  6.  8.  8. 22.] 
adversary owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8] -> size -> 25 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1
Learning step: -3.8736042976379395
desired expected reward: -5.991764068603516



action possibilites: [-1] 
expected returns: [[1.4642723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.  0.  8.  6.  6.  0.
  0. 16.  0.  8. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0
  0 11  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [29.  3.  0. 11.  8.] 
adversary cards in discard: [29. 10.  3.  6.  8.  8. 22.] 
adversary owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8] -> size -> 25 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action 15.0
Learning step: -2.808258056640625
desired expected reward: -4.984173774719238





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 0.55395865]
 [ 7.9207573 ]
 [ 4.968029  ]
 [ 3.7233732 ]
 [ 8.376616  ]
 [ 5.8435516 ]
 [ 5.432561  ]
 [-6.678008  ]
 [ 3.3196938 ]
 [-0.17173481]
 [ 4.7246733 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.  0.  8.  6.  6.  0.
  0. 16.  0.  8. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0
  0 11  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  4.  8. 10.  6.  9.  8.] 
adversary cards in hand: [29.  3.  0. 11.  8.] 
adversary cards in discard: [29. 10.  3.  6.  8.  8. 22.] 
adversary owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8] -> size -> 25 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1
Learning step: -2.9412412643432617
desired expected reward: -1.4769690036773682



buy possibilites: [-1] 
expected returns: [[1.6957724]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [10.  0. 29.  3.  8. 25.  0. 11. 14.  6.  0.  3.  0.  0.  8.  6.  6.  0.
  0. 16.  0.  8. 11.  6. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0
  0 11  0  0 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [29.  3.  0. 11.  8.] 
adversary cards in discard: [29. 10.  3.  6.  8.  8. 22.] 
adversary owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8] -> size -> 25 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: -27 

action type: buy - action 29.0
Learning step: -1.5301107168197632
desired expected reward: 3.9024500846862793






Player: 1 
cards in hand: [29.  3.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 11.  8.] 
cards in discard: [29. 10.  3.  6.  8.  8. 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  8.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0
  0 11  0  0 29] -> size -> 29 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 11.  8.] 
cards in discard: [29. 10.  3.  6.  8.  8. 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  8.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0
  0 11  0  0 29] -> size -> 29 
adversary victory points: -4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 11.  8.] 
cards in discard: [29. 10.  3.  6.  8.  8. 22.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  8.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0
  0 11  0  0 29] -> size -> 29 
adversary victory points: -4
player victory points: 3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25.] 
expected returns: [[-0.20270085]
 [-1.8373666 ]
 [-1.8373666 ]
 [ 0.13075233]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  8. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  0  3 10 29  8  8  0  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0
  0 11  0  0 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  0. 29.  0.  0.] 
adversary cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.] 
adversary owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8  0] -> size -> 26 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1
Learning step: -4.050897121429443
desired expected reward: -2.3551247119903564



action possibilites: [-1] 
expected returns: [[-9.946266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3 10 29  8  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0  0 11  0
  0 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  0. 29.  0.  0.] 
adversary cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.] 
adversary owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8  0] -> size -> 26 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.146681547164917
desired expected reward: -3.6888670921325684





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-14.499418]
 [-11.076676]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3 10 29  8  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0  0 11  0
  0 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  0. 29.  0.  0.] 
adversary cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.] 
adversary owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8  0] -> size -> 26 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1
Learning step: -2.7389512062072754
desired expected reward: -12.685216903686523



buy possibilites: [-1] 
expected returns: [[25.448177]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3 10 29  8  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0  0 11  0
  0 29  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  0. 29.  0.  0.] 
adversary cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.] 
adversary owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8  0] -> size -> 26 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action 0.0
Learning step: -3.15244460105896
desired expected reward: -17.651874542236328






Player: 1 
cards in hand: [ 8.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  0.  0.] 
cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0
  8  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 0.  8. 25.] 
adversary owned cards: [ 3 11  3 10 29  8  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0  0 11  0
  0 29  0] -> size -> 27 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 0.  8. 25.] 
adversary owned cards: [ 3 11  3 10 29  8  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0  0 11  0
  0 29  0] -> size -> 27 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 0.  8. 25.] 
adversary owned cards: [ 3 11  3 10 29  8  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0  0 11  0
  0 29  0] -> size -> 27 
adversary victory points: -4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 0.  8. 25.] 
adversary owned cards: [ 3 11  3 10 29  8  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0  0 11  0
  0 29  0] -> size -> 27 
adversary victory points: -4
player victory points: 3 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 16.] 
expected returns: [[-6.0386686]
 [-4.4744663]
 [-3.3774524]
 [-3.77823  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10. 16.] 
cards in discard: [ 0.  8. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10 29  8  6  6  6  6 15  0 16 25  8 14  0  6  0  6  0  0 11  0
  0 29  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0.  3. 29.  3.] 
adversary cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.  0.  8. 29.] 
adversary owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0] -> size -> 24 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1
Learning step: -5.3324151039123535
desired expected reward: 20.11576271057129



action possibilites: [-1] 
expected returns: [[38.152283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.] 
cards in discard: [ 0.  8. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0.  3. 29.  3.] 
adversary cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.  0.  8. 29.] 
adversary owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0] -> size -> 24 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: trash_cards_n_from_hand - action 4
Learning step: -2.08878231048584
desired expected reward: -2.144611120223999





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[35.24465 ]
 [38.435593]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.] 
cards in discard: [ 0.  8. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0.  3. 29.  3.] 
adversary cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.  0.  8. 29.] 
adversary owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0] -> size -> 24 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1
Learning step: -4.027344226837158
desired expected reward: 34.12493896484375



buy possibilites: [-1] 
expected returns: [[18.614807]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.] 
cards in discard: [ 0.  8. 25.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0.  3. 29.  3.] 
adversary cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.  0.  8. 29.] 
adversary owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0] -> size -> 24 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -70.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -89.0 

action type: buy - action 0.0
Learning step: -5.793399810791016
desired expected reward: 29.451255798339844






Player: 1 
cards in hand: [11.  0.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 29.  3.] 
cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.  0.  8. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 30.  8.  0.  8.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [29.  0. 11.  0.  3.] 
adversary cards in discard: [ 0.  8. 25.  0.  8.  0. 16.] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0] -> size -> 26 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.] 
cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.  0.  8. 29. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [29.  0. 11.  0.  3.] 
adversary cards in discard: [ 0.  8. 25.  0.  8.  0. 16.] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0] -> size -> 26 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.] 
cards in discard: [29. 10.  3.  6.  8.  8. 22.  0. 29.  3.  0. 11.  8.  0.  8. 29. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [29.  0. 11.  0.  3.] 
adversary cards in discard: [ 0.  8. 25.  0.  8.  0. 16.] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0] -> size -> 26 
adversary victory points: -4
player victory points: 3 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [29.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[-6.9310236]
 [-8.918445 ]
 [-7.22521  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  0.  3.] 
cards in discard: [ 0.  8. 25.  0.  8.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0
 16] -> size -> 25 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1
Learning step: -5.054275035858154
desired expected reward: 13.560531616210938



action possibilites: [-1.] 
expected returns: [[56.68773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0
 16] -> size -> 25 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: discard_n_cards - action 3
Learning step: -1.275917649269104
desired expected reward: -9.248088836669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[51.672886]
 [57.065147]
 [55.43359 ]
 [59.683323]
 [54.896374]
 [53.773457]
 [60.2403  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 28. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0
 16] -> size -> 25 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1.0
Learning step: -4.5183868408203125
desired expected reward: 52.169342041015625



buy possibilites: [-1] 
expected returns: [[-9.86863]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0
 16] -> size -> 25 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -41 

action type: buy - action 1.0
Learning step: -5.125301361083984
desired expected reward: 51.93984603881836






Player: 1 
cards in hand: [11.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  8. 10.  6.  9.  8.] 
adversary cards in hand: [14. 29.  6.  0.  0.] 
adversary cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.  1. 29.  0.  0.  3.  6.] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1] -> size -> 27 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.] 
cards in discard: [14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0
 16 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [14. 29.  6.  0.  0.] 
adversary cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.  1. 29.  0.  0.  3.  6.] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1] -> size -> 27 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.] 
cards in discard: [14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0
 16 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [14. 29.  6.  0.  0.] 
adversary cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.  1. 29.  0.  0.  3.  6.] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1] -> size -> 27 
adversary victory points: -4
player victory points: 3 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [14. 29.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
expected returns: [[2.3269951 ]
 [0.7323606 ]
 [0.28939557]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29.  6.  0.  0.] 
cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.  1. 29.  0.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  0. 29.  3.  8.] 
adversary cards in discard: [14. 11.  0.  0.  8. 11.] 
adversary owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0
 16 14] -> size -> 26 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1
Learning step: -3.430415391921997
desired expected reward: -13.29904556274414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-2.0075626 ]
 [-0.92153716]
 [-2.5321774 ]
 [-0.3639834 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 29.  6.  0.  0.] 
cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.  1. 29.  0.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  0. 29.  3.  8.] 
adversary cards in discard: [14. 11.  0.  0.  8. 11.] 
adversary owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0
 16 14] -> size -> 26 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action -1.0
Learning step: -3.9853756427764893
desired expected reward: -3.9144814014434814



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 29.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.  8.] 
cards in discard: [14. 11.  0.  0.  8. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0
 16 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  3. 15.  6.  6.] 
adversary cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.  1. 29.  0.  0.  3.  6. 14. 29.  6.  0.
  0.] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1] -> size -> 27 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.] 
cards in discard: [14. 11.  0.  0.  8. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  3. 15.  6.  6.] 
adversary cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.  1. 29.  0.  0.  3.  6. 14. 29.  6.  0.
  0.] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1] -> size -> 27 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.] 
cards in discard: [14. 11.  0.  0.  8. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  3. 15.  6.  6.] 
adversary cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.  1. 29.  0.  0.  3.  6. 14. 29.  6.  0.
  0.] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1] -> size -> 27 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 6.  3. 15.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-15.873835]
 [-15.425428]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 15.  6.  6.] 
cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.  1. 29.  0.  0.  3.  6. 14. 29.  6.  0.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29. 29.  0. 22. 10.] 
adversary cards in discard: [14. 11.  0.  0.  8. 11.  8.  0. 29.  3.] 
adversary owned cards: [ 8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16
 14] -> size -> 25 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1.0
Learning step: -3.7837255001068115
desired expected reward: -4.147711277008057



action possibilites: [-1] 
expected returns: [[29.303093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 6.] 
cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.  1. 29.  0.  0.  3.  6. 14. 29.  6.  0.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29. 29.  0. 22. 10.] 
adversary cards in discard: [14. 11.  0.  0.  8. 11.  8.  0. 29.  3.] 
adversary owned cards: [ 8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16
 14] -> size -> 25 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action 15.0
Learning step: -1.019408941268921
desired expected reward: -16.44483757019043





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[24.33958 ]
 [29.319515]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6.] 
cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.  1. 29.  0.  0.  3.  6. 14. 29.  6.  0.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29. 29.  0. 22. 10.] 
adversary cards in discard: [14. 11.  0.  0.  8. 11.  8.  0. 29.  3.] 
adversary owned cards: [ 8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16
 14] -> size -> 25 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action -1
Learning step: -3.3093559741973877
desired expected reward: 25.993736267089844



buy possibilites: [-1] 
expected returns: [[-6.0031]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6.] 
cards in discard: [ 0.  8. 25.  0.  8.  0. 16. 11.  1. 29.  0.  0.  3.  6. 14. 29.  6.  0.
  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29. 29.  0. 22. 10.] 
adversary cards in discard: [14. 11.  0.  0.  8. 11.  8.  0. 29.  3.] 
adversary owned cards: [ 8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16
 14] -> size -> 25 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action 0.0
Learning step: -5.302048683166504
desired expected reward: 19.03752899169922






Player: 1 
cards in hand: [29. 29.  0. 22. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 22. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 22. 10.] 
cards in discard: [14. 11.  0.  0.  8. 11.  8.  0. 29.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0] -> size -> 28 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1. 29. 29. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 22.  8.] 
cards in discard: [14. 11.  0.  0.  8. 11.  8.  0. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 29  0 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16
 14] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0] -> size -> 28 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1. 29. 29. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 22.] 
cards in discard: [14. 11.  0.  0.  8. 11.  8.  0. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 29 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0] -> size -> 28 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 16.  3.  6.  3. 29.] 
cards in discard: [14. 11.  0.  0.  8. 11.  8.  0. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8. 22. 11.] 
owned cards: [ 8 29 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0] -> size -> 28 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 16.  3.  6.  3. 29.] 
cards in discard: [14. 11.  0.  0.  8. 11.  8.  0. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8. 22. 11.] 
owned cards: [ 8 29 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0] -> size -> 28 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.426796]
 [22.341513]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [3. 8. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16 14] -> size -> 24 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1
Learning step: -2.631153106689453
desired expected reward: -8.634252548217773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.137121]
 [22.00441 ]
 [21.927958]
 [20.913454]
 [23.305824]
 [20.943684]
 [20.968344]
 [18.8067  ]
 [21.15077 ]
 [20.422813]
 [24.390589]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 27. 30. 25. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [3. 8. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16 14] -> size -> 24 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1.0
Learning step: -4.145999431610107
desired expected reward: 19.43840217590332



buy possibilites: [-1] 
expected returns: [[-2.2766986]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 11.  6.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [3. 8. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16 14] -> size -> 24 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -56.0 

action type: buy - action 3.0
Learning step: -3.9476234912872314
desired expected reward: 17.980331420898438






Player: 1 
cards in hand: [3. 8. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 10 11 11 11  8 22 29  3  8  8 29  0  6 29  3  3  0  8  0  0 16 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [8. 6. 6. 6. 3.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0  3] -> size -> 29 
adversary victory points: -3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [8. 6. 6. 6. 3.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0  3] -> size -> 29 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [8. 6. 6. 6. 3.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0  3] -> size -> 29 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [8. 6. 6. 6. 3.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.] 
adversary owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0  3] -> size -> 29 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [8. 6. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-0.27052784]
 [-6.7648144 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 6. 3.] 
cards in discard: [ 3.  1.  0.  0. 11.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 29  8  6  6  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29
  0  0  1  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 10. 11. 29.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0] -> size -> 22 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -2.394381284713745
desired expected reward: -4.671079635620117



action possibilites: [-1] 
expected returns: [[-1.9416133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 3.  1.  0.  0. 11.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 10. 11. 29.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0] -> size -> 22 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: trash_cards_n_from_hand - action 5
Learning step: -0.3964996337890625
desired expected reward: -10.340232849121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-7.3804307 ]
 [ 0.03689218]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 3.  1.  0.  0. 11.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 10. 11. 29.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0] -> size -> 22 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1
Learning step: -0.8323554992675781
desired expected reward: -2.7739686965942383



buy possibilites: [-1] 
expected returns: [[10.777363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 3.  1.  0.  0. 11.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 10. 11. 29.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0] -> size -> 22 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action 0.0
Learning step: -1.7384872436523438
desired expected reward: -9.11893081665039






Player: 1 
cards in hand: [ 3. 10. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 29.  3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 29.  3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[42.545086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29. 11.  0. 29.  8.] 
adversary cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.] 
adversary owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0] -> size -> 22 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1
Learning step: -1.4324291944503784
desired expected reward: 9.34493350982666





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[36.879898]
 [39.34654 ]
 [40.161823]
 [41.039772]
 [37.54762 ]
 [38.74252 ]
 [41.974953]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29. 11.  0. 29.  8.] 
adversary cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.] 
adversary owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0] -> size -> 22 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -3.087043523788452
desired expected reward: 39.42135238647461



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29. 11.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 29.  8.] 
cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29. 16. 11.  0. 15.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1. 11. 29.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  8.] 
cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 27. 30. 24. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29. 16. 11.  0. 15.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.] 
cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 27. 30. 23. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29. 16. 11.  0. 15.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.] 
cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 27. 30. 23. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29. 16. 11.  0. 15.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.] 
cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.  6.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29. 16. 11.  0. 15.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [29. 16. 11.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16. 11. 15.] 
expected returns: [[25.205202]
 [23.341776]
 [22.721077]
 [25.928892]
 [19.680075]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16. 11.  0. 15.] 
cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [16. 14. 22.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.  6.  3.  3. 29. 11.  0. 29.  8.] 
adversary owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -4.420612335205078
desired expected reward: 37.55433654785156



action possibilites: [-1. 11. 15.] 
expected returns: [[17.69365 ]
 [17.592653]
 [12.573359]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15.  0.] 
cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [16. 14. 22.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.  6.  3.  3. 29. 11.  0. 29.  8.] 
adversary owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: discard_n_cards - action 3
Learning step: -2.6121585369110107
desired expected reward: 19.839797973632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[11.558877]
 [15.083731]
 [14.12236 ]
 [16.74848 ]
 [13.73406 ]
 [13.062881]
 [16.799717]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 15.  0.] 
cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  2.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [16. 14. 22.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.  6.  3.  3. 29. 11.  0. 29.  8.] 
adversary owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -2.4076664447784424
desired expected reward: 15.285969734191895



buy possibilites: [-1] 
expected returns: [[44.20279]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 15.  0.] 
cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0. 16. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  1.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [16. 14. 22.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.  6.  3.  3. 29. 11.  0. 29.  8.] 
adversary owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -19 

action type: buy - action 11.0
Learning step: -0.7928611636161804
desired expected reward: 15.955615043640137






Player: 1 
cards in hand: [16. 14. 22.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 22.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14. 22.  0.  0.] 
cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.  6.  3.  3. 29. 11.  0. 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 10 11 11 11 22 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  1.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  8.  0. 25. 29.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0. 16. 11. 29. 11.
  0. 15.  0.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11] -> size -> 28 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.] 
cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.  6.  3.  3. 29. 11.  0. 29.  8.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 22. 30.  8.  0.  7.  1.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  8.  0. 25. 29.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0. 16. 11. 29. 11.
  0. 15.  0.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11] -> size -> 28 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.] 
cards in discard: [ 0.  8.  0.  3. 10. 11. 29.  3.  6.  3.  3. 29. 11.  0. 29.  8.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 22. 30.  8.  0.  7.  1.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  8.  0. 25. 29.] 
adversary cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0. 16. 11. 29. 11.
  0. 15.  0.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11] -> size -> 28 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 6.  8.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 29.] 
expected returns: [[24.257992]
 [20.400286]
 [31.814869]
 [20.016966]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0. 25. 29.] 
cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0. 16. 11. 29. 11.
  0. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 22. 30.  8.  0.  7.  1.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29.  0.  8. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -4.510789394378662
desired expected reward: 39.69200134277344



action possibilites: [-1] 
expected returns: [[54.116302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0. 29.  0. 14.] 
cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0. 16. 11. 29. 11.
  0. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 22. 30.  8.  0.  7.  1.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29.  0.  8. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -36 

action type: take_action - action 25.0
Learning step: -2.1731269359588623
desired expected reward: 29.64175033569336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[41.058598]
 [46.09409 ]
 [44.257668]
 [51.906765]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  0. 29.  0. 14.] 
cards in discard: [ 3.  1.  0.  0. 11.  6.  0.  8.  6.  0.  0.  3.  6.  0. 16. 11. 29. 11.
  0. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 22. 30.  8.  0.  7.  1.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [29.  0.  8. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -3.5194473266601562
desired expected reward: 50.59685516357422






Player: 1 
cards in hand: [29.  0.  8. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8. 29. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 22. 30.  8.  0.  7.  1.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  6.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11] -> size -> 28 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1.  8. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 11.  1.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 22. 30.  8.  0.  7.  1.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  6.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11] -> size -> 28 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29. 11.  1.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 26. 30. 22. 30.  8.  0.  7.  1.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  6.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11] -> size -> 28 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29. 11.  1.] 
cards in discard: [0. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 21. 30.  8.  0.  7.  1.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  6.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11] -> size -> 28 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-13.760859]
 [-15.672614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 30.  8.  0.  7.  1.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 11.  0. 29.  0.] 
adversary cards in discard: [ 0.  3. 29.  8. 29. 11.  1.] 
adversary owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1
  3] -> size -> 25 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -6.280637741088867
desired expected reward: 45.626129150390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-17.074331]
 [-16.498209]
 [-18.185694]
 [-16.236362]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 21. 30.  8.  0.  7.  1.  2.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 11.  0. 29.  0.] 
adversary cards in discard: [ 0.  3. 29.  8. 29. 11.  1.] 
adversary owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1
  3] -> size -> 25 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.020111560821533
desired expected reward: -17.25420570373535



buy possibilites: [-1] 
expected returns: [[-4.9333496]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 29.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 30.  8.  0.  7.  1.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 11.  0. 29.  0.] 
adversary cards in discard: [ 0.  3. 29.  8. 29. 11.  1.] 
adversary owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1
  3] -> size -> 25 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: -2.1517162322998047
desired expected reward: -20.337400436401367






Player: 1 
cards in hand: [ 3. 11.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 29.  0.] 
cards in discard: [ 0.  3. 29.  8. 29. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 30.  8.  0.  7.  1.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  6. 29. 11. 11.] 
adversary cards in discard: [ 8.  6.  6.  0.  0. 29.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8] -> size -> 29 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 29.  0.] 
cards in discard: [ 0.  3. 29.  8. 29. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 21. 30.  8.  0.  7.  1.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  6. 29. 11. 11.] 
adversary cards in discard: [ 8.  6.  6.  0.  0. 29.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8] -> size -> 29 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 29.  0.] 
cards in discard: [ 0.  3. 29.  8. 29. 11.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  7.  1.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  6. 29. 11. 11.] 
adversary cards in discard: [ 8.  6.  6.  0.  0. 29.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8] -> size -> 29 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[-9.124672 ]
 [-9.073421 ]
 [-7.5639677]
 [-7.5639677]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29. 11. 11.] 
cards in discard: [ 8.  6.  6.  0.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  7.  1.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 8. 16. 10. 14.  0.] 
adversary cards in discard: [ 0.  3. 29.  8. 29. 11.  1.  0.  3. 11.  0. 29.  0.] 
adversary owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -3.2901337146759033
desired expected reward: -8.223483085632324



action possibilites: [-1] 
expected returns: [[15.530252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29. 11.] 
cards in discard: [ 8.  6.  6.  0.  0. 29. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  7.  0.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 8. 16. 10. 14.  0.] 
adversary cards in discard: [ 0.  3. 29.  8. 29. 11.  1.  0.  3. 11.  0. 29.  0.] 
adversary owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -38 

action type: gain_card_n - action 4
Learning step: -0.9306852221488953
desired expected reward: -13.328368186950684





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.519346]
 [15.20932 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29. 11.] 
cards in discard: [ 8.  6.  6.  0.  0. 29. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  7.  0.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 8. 16. 10. 14.  0.] 
adversary cards in discard: [ 0.  3. 29.  8. 29. 11.  1.  0.  3. 11.  0. 29.  0.] 
adversary owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -2.80259108543396
desired expected reward: 12.7276611328125






Player: 1 
cards in hand: [ 8. 16. 10. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16. 10. 14.  0.] 
cards in discard: [ 0.  3. 29.  8. 29. 11.  1.  0.  3. 11.  0. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29 10 11 11 11 29  8  8 29  0  6 29  3  3  0  8  0  0 16 14  0  3  3  1
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  7.  0.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [25.  1. 15.  3.  6.] 
adversary cards in discard: [ 8.  6.  6.  0.  0. 29. 11. 11.  0.  6. 29. 11.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8 11] -> size -> 30 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [ 0.  3. 29.  8. 29. 11.  1.  0.  3. 11.  0. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11 11 11 29  8  8 29  6 29  3  3  0  8  0  0 16  0  3  3  1  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  7.  0.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [25.  1. 15.  3.  6.] 
adversary cards in discard: [ 8.  6.  6.  0.  0. 29. 11. 11.  0.  6. 29. 11.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8 11] -> size -> 30 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [ 0.  3. 29.  8. 29. 11.  1.  0.  3. 11.  0. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11 11 11 29  8  8 29  6 29  3  3  0  8  0  0 16  0  3  3  1  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  7.  0.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [25.  1. 15.  3.  6.] 
adversary cards in discard: [ 8.  6.  6.  0.  0. 29. 11. 11.  0.  6. 29. 11.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8 11] -> size -> 30 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [ 0.  3. 29.  8. 29. 11.  1.  0.  3. 11.  0. 29.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11 11 11 29  8  8 29  6 29  3  3  0  8  0  0 16  0  3  3  1  3  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 21. 30.  8.  0.  7.  0.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [25.  1. 15.  3.  6.] 
adversary cards in discard: [ 8.  6.  6.  0.  0. 29. 11. 11.  0.  6. 29. 11.] 
adversary owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8 11] -> size -> 30 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [25.  1. 15.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
expected returns: [[-10.673676]
 [-12.768859]
 [-12.976336]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 15.  3.  6.] 
cards in discard: [ 8.  6.  6.  0.  0. 29. 11. 11.  0.  6. 29. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 21. 30.  8.  0.  7.  0.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  6.  0.  8. 11.] 
adversary cards in discard: [ 0.  3. 29.  8. 29. 11.  1.  0.  3. 11.  0. 29.  0.  0.  8. 16.] 
adversary owned cards: [29 11 11 11 29  8  8 29  6 29  3  3  0  8  0  0 16  0  3  3  1  3  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -4.382350921630859
desired expected reward: 10.826969146728516



action possibilites: [-1] 
expected returns: [[-5.685294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  3.  6.] 
cards in discard: [ 8.  6.  6.  0.  0. 29. 11. 11.  0.  6. 29. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 21. 30.  8.  0.  7.  0.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  6.  0.  8. 11.] 
adversary cards in discard: [ 0.  3. 29.  8. 29. 11.  1.  0.  3. 11.  0. 29.  0.  0.  8. 16.] 
adversary owned cards: [29 11 11 11 29  8  8 29  6 29  3  3  0  8  0  0 16  0  3  3  1  3  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action 15.0
Learning step: -1.785890817642212
desired expected reward: -14.762225151062012





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-8.162445 ]
 [-7.5451813]
 [-6.940124 ]
 [-6.6134844]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  3.  6.] 
cards in discard: [ 8.  6.  6.  0.  0. 29. 11. 11.  0.  6. 29. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 21. 30.  8.  0.  7.  0.  1.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  6.  0.  8. 11.] 
adversary cards in discard: [ 0.  3. 29.  8. 29. 11.  1.  0.  3. 11.  0. 29.  0.  0.  8. 16.] 
adversary owned cards: [29 11 11 11 29  8  8 29  6 29  3  3  0  8  0  0 16  0  3  3  1  3  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -2.2297282218933105
desired expected reward: -7.915022373199463



Player 1 won the game! 



Player 0 bought cards:
Copper: 12 
Silver: 1 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 1 
Workshop: 3 
Chapel: 4 
Witch: 0 
Poacher: 2 
Militia: 1 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [25.  1.  3.  6.] 
cards in discard: [ 8.  6.  6.  0.  0. 29. 11. 11.  0.  6. 29. 11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [11  3 29  8  6  6 15 16 25  8 14  0  6  0  6  0  0 11  0  0 29  0  0  1
  0  3  0 11  8 11  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 21. 30.  8.  0.  7.  0.  0.  9.  3.  7. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  6.  0.  8. 11.] 
adversary cards in discard: [ 0.  3. 29.  8. 29. 11.  1.  0.  3. 11.  0. 29.  0.  0.  8. 16.] 
adversary owned cards: [29 11 11 11 29  8  8 29  6 29  3  3  0  8  0  0 16  0  3  3  1  3  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5 -500   -2  -60    0    0   20    0    0    0    0    0    0    0
    4    0] 
sum of rewards: -543 

action type: buy - action 8.0
Learning step: -26.802993774414062
desired expected reward: -33.74311447143555



