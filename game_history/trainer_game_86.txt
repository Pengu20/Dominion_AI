 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[277.07104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   5  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 510 

action type: buy - action -1.0
Learning step: 24.732648849487305
desired expected reward: 40.0797004699707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[250.68672]
 [268.01926]
 [260.49713]
 [215.62521]
 [276.27097]
 [262.2962 ]
 [256.83722]
 [279.0765 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.076794624328613
desired expected reward: 271.8297424316406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[306.66217]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.125972270965576
desired expected reward: 271.9505920410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[282.72882]
 [299.49625]
 [292.08322]
 [248.84085]
 [289.81445]
 [306.94333]
 [293.9183 ]
 [293.092  ]
 [264.05142]
 [288.2861 ]
 [280.19736]
 [309.2766 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.815970420837402
desired expected reward: 299.0887145996094



buy possibilites: [-1] 
expected returns: [[282.3605]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  3.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 14.0
Learning step: -5.349459171295166
desired expected reward: 258.70196533203125






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[283.87164]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.8369951248168945
desired expected reward: 274.52349853515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[275.21005]
 [279.68744]
 [250.08586]
 [284.04758]
 [291.0962 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.92287015914917
desired expected reward: 275.678466796875



buy possibilites: [-1] 
expected returns: [[277.20197]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 17 

action type: buy - action 3.0
Learning step: -6.897325038909912
desired expected reward: 272.7900390625






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [14.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[278.23123]
 [233.36005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [3. 3. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.4146575927734375
desired expected reward: 269.78729248046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[258.14264]
 [274.6206 ]
 [266.94727]
 [224.122  ]
 [265.11118]
 [280.94482]
 [268.9613 ]
 [268.24088]
 [239.329  ]
 [263.1163 ]
 [255.21684]
 [281.99927]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [3. 3. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -7.414334297180176
desired expected reward: 271.722412109375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [15.  0.  0.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[283.68887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -7.8061723709106445
desired expected reward: 274.1930847167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[259.03146]
 [272.82834]
 [265.9217 ]
 [229.25984]
 [277.68347]
 [268.50723]
 [262.74643]
 [278.42154]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.063173294067383
desired expected reward: 273.8830871582031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 15.  0.  3.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[289.29318]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  0. 29. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -7.490865230560303
desired expected reward: 270.93072509765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[259.78452]
 [275.14767]
 [268.9837 ]
 [228.45137]
 [283.03326]
 [269.44766]
 [265.33917]
 [286.8717 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  0. 29. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.247952461242676
desired expected reward: 279.7615966796875



buy possibilites: [-1] 
expected returns: [[270.96625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  0. 29. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -31.0 

action type: buy - action 0.0
Learning step: -8.442488670349121
desired expected reward: 251.3420867919922






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 8.  0. 29. 15.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 8.  0. 29. 15.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 8.  0. 29. 15.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[242.18501]
 [203.46608]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -8.930413246154785
desired expected reward: 262.03582763671875



action possibilites: [-1] 
expected returns: [[253.47256]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action 14.0
Learning step: -3.9082424640655518
desired expected reward: 198.1486053466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[231.44406]
 [246.5251 ]
 [238.91653]
 [209.07285]
 [196.71992]
 [238.1964 ]
 [251.90352]
 [241.92006]
 [263.48898]
 [241.00313]
 [211.19977]
 [221.73611]
 [235.0948 ]
 [204.59079]
 [226.78914]
 [251.31259]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action -1
Learning step: -6.6989336013793945
desired expected reward: 246.7736358642578






Player: 1 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[236.89743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -7.799106597900391
desired expected reward: 243.5135040283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[215.41402]
 [231.5446 ]
 [224.21663]
 [182.42888]
 [222.15427]
 [237.86082]
 [226.00438]
 [225.12431]
 [196.83618]
 [220.15565]
 [212.42415]
 [238.93898]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -7.237578868865967
desired expected reward: 229.0523681640625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [3. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [3. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[256.53024]
 [216.60265]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  0.  8.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  0.  3.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -6.958905220031738
desired expected reward: 231.98007202148438



action possibilites: [-1] 
expected returns: [[247.34827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  8.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  0.  3.  0. 29.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action 14.0
Learning step: -4.802160739898682
desired expected reward: 211.5477752685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[224.35634]
 [241.33853]
 [232.82585]
 [189.73515]
 [231.61708]
 [246.74971]
 [235.63667]
 [234.56567]
 [203.48972]
 [228.4528 ]
 [219.98053]
 [245.75392]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  8.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  0.  3.  0. 29.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action -1
Learning step: -6.606588840484619
desired expected reward: 240.74168395996094



buy possibilites: [-1] 
expected returns: [[255.32675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  8.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  0.  3.  0. 29.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    4.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 13.5 

action type: buy - action 1.0
Learning step: -5.647076606750488
desired expected reward: 235.6914825439453






Player: 1 
cards in hand: [15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.] 
cards in discard: [ 3.  0.  3.  0.  0.  0.  3.  0. 29.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  8.] 
cards in discard: [ 3.  0.  3.  0.  0.  0.  3.  0. 29.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  8.] 
cards in discard: [ 3.  0.  3.  0.  0.  0.  3.  0. 29.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[244.34305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 1. 14.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -7.859710216522217
desired expected reward: 247.467041015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[220.88876]
 [237.22368]
 [230.33533]
 [201.7115 ]
 [192.2779 ]
 [227.50877]
 [245.70183]
 [231.43869]
 [258.26822]
 [230.72963]
 [204.65694]
 [213.80197]
 [226.95032]
 [198.76039]
 [219.26396]
 [248.83165]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 1. 14.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -7.2989678382873535
desired expected reward: 235.21780395507812



buy possibilites: [-1] 
expected returns: [[236.78284]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 1. 14.  0.  0.  3.  3. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -3.0 

action type: buy - action 16.0
Learning step: -6.197824001312256
desired expected reward: 221.31092834472656






Player: 1 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16] -> size -> 15 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16] -> size -> 15 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16] -> size -> 15 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[223.44624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [10.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -7.357519626617432
desired expected reward: 229.42532348632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[195.99194]
 [205.19745]
 [165.58595]
 [206.97864]
 [221.84053]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [10.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -7.030145168304443
desired expected reward: 216.59750366210938



buy possibilites: [-1] 
expected returns: [[192.3253]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  9.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [10.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -322.0 

action type: buy - action 6.0
Learning step: -20.051977157592773
desired expected reward: 145.5339813232422






Player: 1 
cards in hand: [15.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  3.  0.] 
cards in discard: [10.  0.  8.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0. 14.  0.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6] -> size -> 16 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [10.  0.  8.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8.  9.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0. 14.  0.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6] -> size -> 16 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [10.  0.  8.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 27. 30.  8.  9.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0. 14.  0.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6] -> size -> 16 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [10.  0.  8.  3.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  9.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0. 14.  0.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6] -> size -> 16 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [16.  0.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[235.90405]
 [218.91687]
 [193.44054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 14.  0.] 
cards in discard: [6. 0. 3. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  9.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10.  0.  8.  3.  0.  0.  1. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -5.6171417236328125
desired expected reward: 186.70816040039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[213.9495 ]
 [230.30972]
 [222.56693]
 [180.72243]
 [237.08008]
 [225.32913]
 [219.26929]
 [237.90617]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 14.  0.] 
cards in discard: [6. 0. 3. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8.  9.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10.  0.  8.  3.  0.  0.  1. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -7.856936931610107
desired expected reward: 229.99375915527344



buy possibilites: [-1] 
expected returns: [[171.23654]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 14.  0.] 
cards in discard: [6. 0. 3. 0. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8.  8.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10.  0.  8.  3.  0.  0.  1. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -333.0 

action type: buy - action 6.0
Learning step: -21.525007247924805
desired expected reward: 159.19741821289062






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  0.  8.  3.  0.  0.  1. 15.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  8.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 6.  0.  3.  0.  3.  3.  6. 16.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  0.  8.  3.  0.  0.  1. 15.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8.  8.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 6.  0.  3.  0.  3.  3.  6. 16.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  0.  8.  3.  0.  0.  1. 15.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 27. 30.  8.  8.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 6.  0.  3.  0.  3.  3.  6. 16.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[94.88648]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 6.  0.  3.  0.  3.  3.  6. 16.  0.  0. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  8.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -8.0496244430542
desired expected reward: 163.18692016601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 81.748116]
 [ 95.92786 ]
 [ 89.87756 ]
 [ 64.49519 ]
 [ 55.786945]
 [ 87.576454]
 [101.78882 ]
 [ 91.01085 ]
 [112.541435]
 [ 90.02682 ]
 [ 67.12346 ]
 [ 75.57297 ]
 [ 86.295876]
 [ 61.73726 ]
 [ 79.62059 ]
 [102.24581 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 6.  0.  3.  0.  3.  3.  6. 16.  0.  0. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 27. 30.  8.  8.  9. 10.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -4.287707805633545
desired expected reward: 91.8101577758789



buy possibilites: [-1] 
expected returns: [[168.93494]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 6.  0.  3.  0.  3.  3.  6. 16.  0.  0. 14.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  8.  9. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 17 

action type: buy - action 25.0
Learning step: -0.9760364890098572
desired expected reward: 111.56541442871094






Player: 1 
cards in hand: [ 0.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  8.  9. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 27. 30.  8.  8.  9. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0] -> size -> 19 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 27. 30.  8.  8.  9. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 27. 30.  8.  8.  9. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[161.46292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 8. 29. 10.  0.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -6.522073268890381
desired expected reward: 162.41285705566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[141.98584 ]
 [154.37836 ]
 [149.33069 ]
 [118.234856]
 [159.78336 ]
 [150.5255  ]
 [146.36938 ]
 [161.86366 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 27. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 8. 29. 10.  0.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -6.131276607513428
desired expected reward: 152.7430877685547



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 8. 29. 10.  0.  3.  0.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3.  3. 16.  0.] 
adversary cards in discard: [0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 8. 29. 10.  0.  3.  0.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3.  3. 16.  0.] 
adversary cards in discard: [0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 8. 29. 10.  0.  3.  0.  0. 15.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3.  3. 16.  0.] 
adversary cards in discard: [0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6 25] -> size -> 18 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [14.  3.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
expected returns: [[188.54593]
 [148.2279 ]
 [172.17796]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3. 16.  0.] 
cards in discard: [0. 0. 3. 0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  0  1 16  6  6 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 29. 10.  0.  3.  0.  0. 15.  3.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -6.293946743011475
desired expected reward: 155.56973266601562



action possibilites: [-1] 
expected returns: [[177.23979]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.] 
cards in discard: [ 0.  0.  3.  0.  6. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 29. 10.  0.  3.  0.  0. 15.  3.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3] -> size -> 21 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -18 

action type: gain_card_n - action 10
Learning step: -8.526206970214844
desired expected reward: 223.75582885742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[159.77487]
 [131.19058]
 [180.14647]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.] 
cards in discard: [ 0.  0.  3.  0.  6. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 29. 10.  0.  3.  0.  0. 15.  3.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3] -> size -> 21 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -6.8038177490234375
desired expected reward: 170.43597412109375






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8. 29. 10.  0.  3.  0.  0. 15.  3.  0.  3.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [25.  0.  1.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  0.  6. 15. 16. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15] -> size -> 18 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8. 29. 10.  0.  3.  0.  0. 15.  3.  0.  3.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 26. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [25.  0.  1.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  0.  6. 15. 16. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15] -> size -> 18 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8. 29. 10.  0.  3.  0.  0. 15.  3.  0.  3.  3.  3.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [25.  0.  1.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  0.  6. 15. 16. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15] -> size -> 18 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [25.  0.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[121.52758]
 [128.89568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  1.  0.  0.] 
cards in discard: [ 0.  0.  3.  0.  6. 15. 16. 14.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [10.  3.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3 15] -> size -> 22 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -8.928728103637695
desired expected reward: 171.2177276611328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[100.73186 ]
 [112.43866 ]
 [108.24916 ]
 [ 86.109314]
 [ 78.877266]
 [105.60933 ]
 [117.82459 ]
 [107.95515 ]
 [125.83025 ]
 [107.30086 ]
 [ 88.62493 ]
 [ 95.96188 ]
 [104.99191 ]
 [ 84.157394]
 [ 99.41668 ]
 [119.42966 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  1.  0.  0.] 
cards in discard: [ 0.  0.  3.  0.  6. 15. 16. 14.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 26. 30.  8.  8.  9. 10.  8.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [10.  3.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3 15] -> size -> 22 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -6.089195251464844
desired expected reward: 112.4153823852539



buy possibilites: [-1] 
expected returns: [[126.4336]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  1.  0.  0.] 
cards in discard: [ 0.  0.  3.  0.  6. 15. 16. 14.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 26. 30.  8.  8.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [10.  3.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3 15] -> size -> 22 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -52.0 

action type: buy - action 8.0
Learning step: -5.153000831604004
desired expected reward: 102.80213928222656






Player: 1 
cards in hand: [10.  3.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8.  1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  8.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [0. 1. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3 15] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  8.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [0. 1. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 26. 30.  8.  8.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [0. 1. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 1. 0.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3 15  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 25. 30.  8.  8.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [0. 1. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [0. 1. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[136.89836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  8.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 3.  3. 15.  0.  8.] 
adversary cards in discard: [ 3. 10.  3.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3 15  3] -> size -> 23 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -6.530648708343506
desired expected reward: 119.9029541015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[129.30673]
 [140.7952 ]
 [137.0519 ]
 [107.47339]
 [134.06218]
 [146.0071 ]
 [136.08818]
 [135.44353]
 [117.2505 ]
 [133.45366]
 [128.06696]
 [147.43797]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 25. 30.  8.  8.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 3.  3. 15.  0.  8.] 
adversary cards in discard: [ 3. 10.  3.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3 15  3] -> size -> 23 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -6.71755838394165
desired expected reward: 126.2171630859375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  0.  8.] 
cards in discard: [ 3. 10.  3.  0.  8.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 15  3  8  3  0  0 10  1  0  8  3 15  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  8.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 14. 25.  8.  0.] 
adversary cards in discard: [0. 1. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3. 10.  3.  0.  8.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  8.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 14. 25.  8.  0.] 
adversary cards in discard: [0. 1. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3. 10.  3.  0.  8.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  8.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 14. 25.  8.  0.] 
adversary cards in discard: [0. 1. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  8.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 14. 25.  8.  0.] 
adversary cards in discard: [0. 1. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 14. 25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.  8.] 
expected returns: [[187.14804]
 [146.79878]
 [199.86981]
 [175.57224]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 25.  8.  0.] 
cards in discard: [0. 1. 6. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  8.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 15.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0] -> size -> 23 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -6.461905002593994
desired expected reward: 140.97604370117188



action possibilites: [-1] 
expected returns: [[143.16249]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  0.  6.  3.] 
cards in discard: [0. 1. 6. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  7.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 15.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.  8.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6] -> size -> 24 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action 25.0
Learning step: -8.01736831665039
desired expected reward: 172.7531280517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[116.42211]
 [126.48179]
 [ 85.89107]
 [126.54061]
 [140.15964]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  8.  0.  6.  3.] 
cards in discard: [0. 1. 6. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 25. 30.  8.  7.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 15.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.  8.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6] -> size -> 24 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -6.473495006561279
desired expected reward: 136.68899536132812






Player: 1 
cards in hand: [ 0. 29.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 15.  0.] 
cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.  8.  3.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  7.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [ 0.  1.  6.  0.  3. 25.  0. 14.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.] 
cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.  8.  3.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 25. 30.  8.  7.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [ 0.  1.  6.  0.  3. 25.  0. 14.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.  8.  3.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 25. 30.  8.  7.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [ 0.  1.  6.  0.  3. 25.  0. 14.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.  8.  3.  3.  0.  6.  4.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  7.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [ 0.  1.  6.  0.  3. 25.  0. 14.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[169.45284]
 [159.04759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  0.] 
cards in discard: [ 0.  1.  6.  0.  3. 25.  0. 14.  8.  0.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  7.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.  8.  3.  3.  0.  6.  4. 15. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4] -> size -> 24 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -7.48920202255249
desired expected reward: 132.6704559326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[152.30045]
 [164.12248]
 [159.07996]
 [128.26016]
 [168.11362]
 [159.72368]
 [155.46507]
 [167.60863]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  0.] 
cards in discard: [ 0.  1.  6.  0.  3. 25.  0. 14.  8.  0.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 25. 29.  8.  7.  9. 10.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.  8.  3.  3.  0.  6.  4. 15. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4] -> size -> 24 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -8.973098754882812
desired expected reward: 159.25904846191406



buy possibilites: [-1] 
expected returns: [[80.400375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  0.] 
cards in discard: [ 0.  1.  6.  0.  3. 25.  0. 14.  8.  0.  6.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  9.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.  8.  3.  3.  0.  6.  4. 15. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4] -> size -> 24 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -66 

action type: buy - action 11.0
Learning step: -9.896674156188965
desired expected reward: 158.2169647216797






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.  8.  3.  3.  0.  6.  4. 15. 29.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  9.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  1.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11] -> size -> 20 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.  8.  3.  3.  0.  6.  4. 15. 29.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  9.  7.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  1.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11] -> size -> 20 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3. 10.  3.  0.  8.  1.  0.  0.  8.  3.  3.  0.  6.  4. 15. 29.  0.  0.
  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  9.  6.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  1.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11] -> size -> 20 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[110.634224]
 [ 89.25498 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  9.  6.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 3. 10.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8] -> size -> 25 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -5.939708232879639
desired expected reward: 74.4606704711914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 94.67087 ]
 [106.71918 ]
 [102.610435]
 [ 72.17651 ]
 [ 99.42301 ]
 [112.97089 ]
 [101.34829 ]
 [100.73697 ]
 [ 82.77042 ]
 [ 99.121216]
 [ 93.74626 ]
 [115.68474 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  9.  6.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 3. 10.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8] -> size -> 25 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -7.188662052154541
desired expected reward: 100.25296783447266



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 10.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  9.  6.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 0.  1.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11] -> size -> 20 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  9.  6.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 0.  1.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11] -> size -> 20 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  9.  6.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 0.  1.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11] -> size -> 20 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  9.  5.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 0.  1.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11] -> size -> 20 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[116.35262 ]
 [100.899185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [ 0.  1.  3. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  9.  5.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 6.  1.  8. 15. 29.] 
adversary cards in discard: [ 8. 10.  3.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8] -> size -> 26 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -7.528812408447266
desired expected reward: 108.15591430664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 96.86383 ]
 [109.44781 ]
 [105.79867 ]
 [ 73.419395]
 [115.56865 ]
 [103.88211 ]
 [101.621506]
 [118.61001 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [ 0.  1.  3. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  9.  5.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 6.  1.  8. 15. 29.] 
adversary cards in discard: [ 8. 10.  3.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8] -> size -> 26 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -7.405179500579834
desired expected reward: 106.1245346069336



buy possibilites: [-1] 
expected returns: [[109.354355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [ 0.  1.  3. 15.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  8.  5.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 6.  1.  8. 15. 29.] 
adversary cards in discard: [ 8. 10.  3.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8] -> size -> 26 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -66 

action type: buy - action 11.0
Learning step: -6.617959022521973
desired expected reward: 108.95067596435547






Player: 1 
cards in hand: [ 6.  1.  8. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  8. 15. 29.] 
cards in discard: [ 8. 10.  3.  8.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  8.  5.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [25. 11.  0.  0.  8.] 
adversary cards in discard: [ 0.  1.  3. 15.  0. 11.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11] -> size -> 21 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  8. 15.  4.] 
cards in discard: [ 8. 10.  3.  8.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  8.  5.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [25. 11.  0.  0.  8.] 
adversary cards in discard: [ 0.  1.  3. 15.  0. 11.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11] -> size -> 21 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  8. 15.  4.] 
cards in discard: [ 8. 10.  3.  8.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  8.  5.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [25. 11.  0.  0.  8.] 
adversary cards in discard: [ 0.  1.  3. 15.  0. 11.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11] -> size -> 21 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  8. 15.  4.] 
cards in discard: [ 8. 10.  3.  8.  0.  3.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  8.  4.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [25. 11.  0.  0.  8.] 
adversary cards in discard: [ 0.  1.  3. 15.  0. 11.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11] -> size -> 21 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [25. 11.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.  8.] 
expected returns: [[50.210598]
 [53.83974 ]
 [48.204292]
 [38.636723]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0.  0.  8.] 
cards in discard: [ 0.  1.  3. 15.  0. 11.  0.  0.  0. 16.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  7.  9.  8.  4.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 10.  3.  8.  0.  3.  0.  8. 29.  6.  1.  8. 15.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8  8] -> size -> 27 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -8.534441947937012
desired expected reward: 100.81991577148438



action possibilites: [-1] 
expected returns: [[109.841225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8.  0.  3.] 
cards in discard: [ 0.  1.  3. 15.  0. 11.  0.  0.  0. 16.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 10.  3.  8.  0.  3.  0.  8. 29.  6.  1.  8. 15.  4.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8  8  6] -> size -> 28 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -63 

action type: take_action - action 25.0
Learning step: -3.370558977127075
desired expected reward: 50.469173431396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 99.80672 ]
 [109.43235 ]
 [104.51761 ]
 [ 78.93621 ]
 [111.973145]
 [106.08788 ]
 [101.73909 ]
 [111.5549  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  8.  0.  3.] 
cards in discard: [ 0.  1.  3. 15.  0. 11.  0.  0.  0. 16.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 10.  3.  8.  0.  3.  0.  8. 29.  6.  1.  8. 15.  4.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8  8  6] -> size -> 28 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1
Learning step: -6.28718376159668
desired expected reward: 103.55403900146484



buy possibilites: [-1] 
expected returns: [[130.94907]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  8.  0.  3.] 
cards in discard: [ 0.  1.  3. 15.  0. 11.  0.  0.  0. 16.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 10.  3.  8.  0.  3.  0.  8. 29.  6.  1.  8. 15.  4.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8  8  6] -> size -> 28 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -46 

action type: buy - action 1.0
Learning step: -4.8252644538879395
desired expected reward: 104.60710144042969






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8. 10.  3.  8.  0.  3.  0.  8. 29.  6.  1.  8. 15.  4.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8  8  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [15.  3.  6.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8. 10.  3.  8.  0.  3.  0.  8. 29.  6.  1.  8. 15.  4.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8  8  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [15.  3.  6.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8. 10.  3.  8.  0.  3.  0.  8. 29.  6.  1.  8. 15.  4.  6. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8  8  6 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [15.  3.  6.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [15.  3.  6.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[97.509254]
 [83.23881 ]
 [75.34411 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  6.  6. 14.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  3.  8.  0.  3.  0.  8. 29.  6.  1.  8. 15.  4.  6. 10.  0.  3.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8  8  6 10] -> size -> 29 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1
Learning step: -8.286843299865723
desired expected reward: 122.66222381591797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[83.06533]
 [67.38154]
 [95.85044]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  6.  6. 14.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  3.  8.  0.  3.  0.  8. 29.  6.  1.  8. 15.  4.  6. 10.  0.  3.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8  8  6 10] -> size -> 29 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -6.411354064941406
desired expected reward: 87.43610382080078



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [ 8. 10.  3.  8.  0.  3.  0.  8. 29.  6.  1.  8. 15.  4.  6. 10.  0.  3.
  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4
  8  8  8  6 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [15.  3.  6.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8. 10.  3.  8.  0.  3.  0.  8. 29.  6.  1.  8. 15.  4.  6. 10.  0.  3.
  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4  8  8
  8  6 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [15.  3.  6.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 10.  3.  8.  0.  3.  0.  8. 29.  6.  1.  8. 15.  4.  6. 10.  0.  3.
  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4  8  8
  8  6 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [15.  3.  6.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[35.643738]
 [34.644432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 11.  0.] 
cards in discard: [15.  3.  6.  6. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4  8  8
  8  6 10] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -6.728114604949951
desired expected reward: 79.119140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.065805]
 [34.272907]
 [31.616957]
 [ 8.776331]
 [29.78023 ]
 [37.816906]
 [30.71219 ]
 [30.18609 ]
 [17.381826]
 [29.129618]
 [25.884209]
 [37.986675]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 11.  0.] 
cards in discard: [15.  3.  6.  6. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4  8  8
  8  6 10] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -4.173745632171631
desired expected reward: 29.9425106048584



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4  8  8
  8  6 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 1.  0.  8. 16.  0.] 
adversary cards in discard: [15.  3.  6.  6. 14.  1.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4  8  8
  8  6 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 25. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 1.  0.  8. 16.  0.] 
adversary cards in discard: [15.  3.  6.  6. 14.  1.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4  8  8
  8  6 10  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 1.  0.  8. 16.  0.] 
adversary cards in discard: [15.  3.  6.  6. 14.  1.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  8. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[24.772905]
 [19.252916]
 [18.13528 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8. 16.  0.] 
cards in discard: [15.  3.  6.  6. 14.  1.  0.  3. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [3. 6. 8. 3. 6.] 
adversary cards in discard: [3. 8. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4  8  8
  8  6 10  3] -> size -> 28 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1.0
Learning step: -5.093698024749756
desired expected reward: 32.892982482910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.31442  ]
 [23.641296 ]
 [21.442144 ]
 [ 6.5912952]
 [19.892975 ]
 [26.251476 ]
 [20.940004 ]
 [20.385159 ]
 [10.962903 ]
 [19.23776  ]
 [16.20929  ]
 [26.443335 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  8. 16.  0.] 
cards in discard: [15.  3.  6.  6. 14.  1.  0.  3. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 24. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [3. 6. 8. 3. 6.] 
adversary cards in discard: [3. 8. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4  8  8
  8  6 10  3] -> size -> 28 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -4.437331676483154
desired expected reward: 20.3355712890625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 6. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 3. 6.] 
cards in discard: [3. 8. 0. 0. 3. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  6  4  8  8
  8  6 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [15.  3.  6.  6. 14.  1.  0.  3. 11.  0.  1.  0.  8. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [3. 8. 0. 0. 3. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8
 10  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [15.  3.  6.  6. 14.  1.  0.  3. 11.  0.  1.  0.  8. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [3. 8. 0. 0. 3. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8
 10  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 24. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [15.  3.  6.  6. 14.  1.  0.  3. 11.  0.  1.  0.  8. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[102.19585]
 [102.1746 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [15.  3.  6.  6. 14.  1.  0.  3. 11.  0.  1.  0.  8. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 4. 10.  8. 29.  3.] 
adversary cards in discard: [3. 8. 0. 0. 3. 3. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8
 10  3] -> size -> 26 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1.0
Learning step: -3.7228963375091553
desired expected reward: 22.720441818237305



action possibilites: [-1] 
expected returns: [[108.64993]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [15.  3.  6.  6. 14.  1.  0.  3. 11.  0.  1.  0.  8. 16.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 4. 10.  8. 29.  3.] 
adversary cards in discard: [3. 8. 0. 0. 3. 3. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8
 10  3] -> size -> 26 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -65 

action type: gain_card_n - action 9
Learning step: -6.006293773651123
desired expected reward: 98.01204681396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 97.01756 ]
 [105.648254]
 [102.116196]
 [ 76.38311 ]
 [108.44976 ]
 [102.09004 ]
 [ 99.14197 ]
 [108.79841 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [15.  3.  6.  6. 14.  1.  0.  3. 11.  0.  1.  0.  8. 16.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 24. 29.  8.  6.  9.  8.  4.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 4. 10.  8. 29.  3.] 
adversary cards in discard: [3. 8. 0. 0. 3. 3. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8
 10  3] -> size -> 26 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1
Learning step: -6.797462463378906
desired expected reward: 101.85247039794922



buy possibilites: [-1] 
expected returns: [[43.75607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [15.  3.  6.  6. 14.  1.  0.  3. 11.  0.  1.  0.  8. 16.  0. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 24. 29.  8.  6.  9.  8.  3.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 4. 10.  8. 29.  3.] 
adversary cards in discard: [3. 8. 0. 0. 3. 3. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8
 10  3] -> size -> 26 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -90.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -72.0 

action type: buy - action 8.0
Learning step: -7.7199907302856445
desired expected reward: 94.37004089355469






Player: 1 
cards in hand: [ 4. 10.  8. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 10.  8. 29.  3.] 
cards in discard: [3. 8. 0. 0. 3. 3. 8. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8
 10  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 29.  8.  6.  9.  8.  3.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [11.  1.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8] -> size -> 24 
adversary victory points: 1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 10. 29.] 
cards in discard: [3. 8. 0. 0. 3. 3. 8. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 29.  8.  6.  9.  8.  3.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [11.  1.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8] -> size -> 24 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 10. 29.] 
cards in discard: [3. 8. 0. 0. 3. 3. 8. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 24. 29.  8.  6.  9.  8.  3.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [11.  1.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8] -> size -> 24 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 10. 29.] 
cards in discard: [3. 8. 0. 0. 3. 3. 8. 3. 3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 29.  8.  6.  9.  8.  3.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [11.  1.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8] -> size -> 24 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [11.  1.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[49.118954]
 [50.56892 ]
 [57.988014]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3. 25.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 29.  8.  6.  9.  8.  3.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [15.  8.  8.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  0.  3.  3.  8.  3.  3.  0.  8.  4. 10. 29.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0] -> size -> 26 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -5.198709011077881
desired expected reward: 38.5573616027832



action possibilites: [-1] 
expected returns: [[98.48154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 29.  8.  5.  9.  8.  3.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [15.  8.  8.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  0.  3.  3.  8.  3.  3.  0.  8.  4. 10. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6] -> size -> 27 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -63 

action type: take_action - action 25.0
Learning step: -3.7309398651123047
desired expected reward: 52.20454406738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[83.44804 ]
 [93.60384 ]
 [88.33573 ]
 [55.40541 ]
 [87.67533 ]
 [97.31218 ]
 [90.57311 ]
 [89.64255 ]
 [68.101654]
 [86.425125]
 [81.221886]
 [97.81813 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 24. 29.  8.  5.  9.  8.  3.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [15.  8.  8.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  0.  3.  3.  8.  3.  3.  0.  8.  4. 10. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6] -> size -> 27 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1
Learning step: -6.0873332023620605
desired expected reward: 92.39420318603516



buy possibilites: [-1] 
expected returns: [[88.76971]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  0. 10.  0.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 24. 29.  8.  5.  9.  8.  2.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [15.  8.  8.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  0.  3.  3.  8.  3.  3.  0.  8.  4. 10. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6] -> size -> 27 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -80.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -62.0 

action type: buy - action 8.0
Learning step: -5.631336212158203
desired expected reward: 84.94175720214844






Player: 1 
cards in hand: [15.  8.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8.  0.  3.] 
cards in discard: [ 3.  8.  0.  0.  3.  3.  8.  3.  3.  0.  8.  4. 10. 29.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 29.  8.  5.  9.  8.  2.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 15.  6.  0.] 
adversary cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8
  8] -> size -> 25 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  8.  0.  3.] 
cards in discard: [ 3.  8.  0.  0.  3.  3.  8.  3.  3.  0.  8.  4. 10. 29.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 24. 29.  8.  5.  9.  8.  2.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 15.  6.  0.] 
adversary cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8
  8] -> size -> 25 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  8.  0.  3.] 
cards in discard: [ 3.  8.  0.  0.  3.  3.  8.  3.  3.  0.  8.  4. 10. 29.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  8.  2.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 15.  6.  0.] 
adversary cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8
  8] -> size -> 25 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[20.246363]
 [ 9.905053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  6.  0.] 
cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  8.  2.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 1.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  8.  0.  0.  3.  3.  8.  3.  3.  0.  8.  4. 10. 29.  6.  0. 15.  8.
  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0] -> size -> 28 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1
Learning step: -7.748976230621338
desired expected reward: 81.0207290649414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.012674  ]
 [16.226984  ]
 [ 0.41476178]
 [15.775037  ]
 [21.975021  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  6.  0.] 
cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  8.  2.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 1.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  8.  0.  0.  3.  3.  8.  3.  3.  0.  8.  4. 10. 29.  6.  0. 15.  8.
  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0] -> size -> 28 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -4.328911304473877
desired expected reward: 15.917440414428711



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  0. 10.] 
cards in discard: [ 3.  8.  0.  0.  3.  3.  8.  3.  3.  0.  8.  4. 10. 29.  6.  0. 15.  8.
  8.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  8.  2.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 1. 11. 16.  0.  8.] 
adversary cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.  3.  0. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8
  8] -> size -> 25 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 3.  8.  0.  0.  3.  3.  8.  3.  3.  0.  8.  4. 10. 29.  6.  0. 15.  8.
  8.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  8.  2.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 1. 11. 16.  0.  8.] 
adversary cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.  3.  0. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8
  8] -> size -> 25 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 3.  8.  0.  0.  3.  3.  8.  3.  3.  0.  8.  4. 10. 29.  6.  0. 15.  8.
  8.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  8.  2.  9.  9.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 1. 11. 16.  0.  8.] 
adversary cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.  3.  0. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8
  8] -> size -> 25 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 3.  8.  0.  0.  3.  3.  8.  3.  3.  0.  8.  4. 10. 29.  6.  0. 15.  8.
  8.  0.  3. 23.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  8.  2.  9.  9.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 1. 11. 16.  0.  8.] 
adversary cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.  3.  0. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8
  8] -> size -> 25 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.  8.] 
expected returns: [[50.012306]
 [50.02971 ]
 [43.448006]
 [44.700634]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 16.  0.  8.] 
cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.  3.  0. 15.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  1 16  6  6 25 15  8 11 11  1 10  8
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  8.  2.  9.  9.  9.  9.  7. 10.  7.] 
adversary cards in hand: [23.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23] -> size -> 29 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1.0
Learning step: -3.7111656665802
desired expected reward: 18.263845443725586



action possibilites: [-1] 
expected returns: [[21.765043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.] 
cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.  3.  0. 15.  6.  0. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  8.  2.  8.  9.  9.  9.  7. 10.  7.] 
adversary cards in hand: [23.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23] -> size -> 29 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0  25   0] 
sum of rewards: -29 

action type: gain_card_n - action 8
Learning step: -1.0364197492599487
desired expected reward: 0.4862455129623413





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.370117]
 [10.854553]
 [21.068739]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.] 
cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.  3.  0. 15.  6.  0. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  8.  2.  8.  9.  9.  9.  7. 10.  7.] 
adversary cards in hand: [23.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23] -> size -> 29 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1
Learning step: -3.373431921005249
desired expected reward: 18.391611099243164






Player: 1 
cards in hand: [23.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  8.  2.  8.  9.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 8. 14.  3.  0.  0.] 
adversary cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.  3.  0. 15.  6.  0. 25. 16. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  8.  2.  8.  9.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 8. 14.  3.  0.  0.] 
adversary cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.  3.  0. 15.  6.  0. 25. 16. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  8.  0.  0.] 
cards in discard: [11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  7.  2.  8.  9.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 8. 14.  3.  0.  0.] 
adversary cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.  3.  0. 15.  6.  0. 25. 16. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 8. 14.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[20.88493 ]
 [19.321318]
 [12.689537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  3.  0.  0.] 
cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.  3.  0. 15.  6.  0. 25. 16. 11.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  7.  2.  8.  9.  9.  9.  7. 10.  7.] 
adversary cards in hand: [0. 1. 0. 3. 4.] 
adversary cards in discard: [11. 23.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11] -> size -> 30 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1.0
Learning step: -4.325069904327393
desired expected reward: 16.74367332458496





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.530539 ]
 [22.211391 ]
 [ 7.9588614]
 [21.84768  ]
 [24.009516 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  3.  0.  0.] 
cards in discard: [ 8. 25. 11.  1.  3.  0. 10.  0.  3.  0. 15.  6.  0. 25. 16. 11.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  7.  2.  8.  9.  9.  9.  7. 10.  7.] 
adversary cards in hand: [0. 1. 0. 3. 4.] 
adversary cards in discard: [11. 23.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11] -> size -> 30 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -4.2665839195251465
desired expected reward: 16.61836051940918



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 1. 0. 3. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 4.] 
cards in discard: [11. 23.  0.  8.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  7.  2.  8.  9.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 6. 25.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 4.] 
cards in discard: [11. 23.  0.  8.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  7.  2.  8.  9.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 6. 25.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 4.] 
cards in discard: [11. 23.  0.  8.  0.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 6. 25.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 6. 25.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[34.684624]
 [39.857845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 8. 15.  8. 10.  3.] 
adversary cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29] -> size -> 31 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1.0
Learning step: -4.049382209777832
desired expected reward: 19.96015167236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.845312]
 [30.773623]
 [18.21254 ]
 [31.164412]
 [33.033016]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 8. 15.  8. 10.  3.] 
adversary cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29] -> size -> 31 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -4.722533702850342
desired expected reward: 29.36003875732422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 15.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  8. 10.  3.] 
cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [15. 11. 16. 25.  0.] 
adversary cards in discard: [ 6. 25.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  3.] 
cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [15. 11. 16. 25.  0.] 
adversary cards in discard: [ 6. 25.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10.  3.] 
cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  5.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [15. 11. 16. 25.  0.] 
adversary cards in discard: [ 6. 25.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10.  3.] 
cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  5.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [15. 11. 16. 25.  0.] 
adversary cards in discard: [ 6. 25.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [15. 11. 16. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 16. 25.] 
expected returns: [[23.72868 ]
 [15.650246]
 [23.476915]
 [18.67851 ]
 [27.094784]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 16. 25.  0.] 
cards in discard: [ 6. 25.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  5.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.  0. 15.  8.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0] -> size -> 32 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1.0
Learning step: -4.810584545135498
desired expected reward: 28.222434997558594



action possibilites: [-1] 
expected returns: [[22.983137]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 16.  0.  0. 11.] 
cards in discard: [ 6. 25.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.  0. 15.  8.  8. 10.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6] -> size -> 33 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -53 

action type: take_action - action 25.0
Learning step: -3.4876182079315186
desired expected reward: 23.607160568237305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.280998]
 [23.427792]
 [18.08305 ]
 [22.474339]
 [26.676462]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 16.  0.  0. 11.] 
cards in discard: [ 6. 25.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.  0. 15.  8.  8. 10.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6] -> size -> 33 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1
Learning step: -3.303697347640991
desired expected reward: 19.679439544677734






Player: 1 
cards in hand: [ 0.  0.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 29.] 
cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.  0. 15.  8.  8. 10.  3.
  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [3. 0. 0. 8. 1.] 
adversary cards in discard: [ 6. 25.  0.  6.  0. 25. 15. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.  0. 15.  8.  8. 10.  3.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [3. 0. 0. 8. 1.] 
adversary cards in discard: [ 6. 25.  0.  6.  0. 25. 15. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.  0. 15.  8.  8. 10.  3.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [3. 0. 0. 8. 1.] 
adversary cards in discard: [ 6. 25.  0.  6.  0. 25. 15. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[34.784885]
 [32.087856]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 1.] 
cards in discard: [ 6. 25.  0.  6.  0. 25. 15. 11. 16.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0 16  6  6 25 15  8 11 11  1 10  8  8
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.  0. 15.  8.  8. 10.  3.
  6. 29.  0.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6] -> size -> 33 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -3.7683846950531006
desired expected reward: 22.908069610595703



action possibilites: [-1] 
expected returns: [[14.863632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6. 25.  0.  6.  0. 25. 15. 11. 16.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.  0. 15.  8.  8. 10.  3.
  6. 29.  0.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6] -> size -> 33 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: trash_cards_n_from_hand - action 3
Learning step: -3.852557420730591
desired expected reward: 24.88722801208496





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.392299 ]
 [14.838097 ]
 [ 7.1185465]
 [14.024452 ]
 [17.185375 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6. 25.  0.  6.  0. 25. 15. 11. 16.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.  0. 15.  8.  8. 10.  3.
  6. 29.  0.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6] -> size -> 33 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -3.158534526824951
desired expected reward: 11.705097198486328






Player: 1 
cards in hand: [ 0. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.  0. 15.  8.  8. 10.  3.
  6. 29.  0.  0.  3.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [ 6. 25.  0.  6.  0. 25. 15. 11. 16.  0.  0. 11.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25] -> size -> 23 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.  0. 15.  8.  8. 10.  3.
  6. 29.  0.  0.  3.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  2.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [ 6. 25.  0.  6.  0. 25. 15. 11. 16.  0.  0. 11.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25] -> size -> 23 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [11. 23.  0.  8.  0.  0. 29.  0.  1.  0.  3.  4.  0. 15.  8.  8. 10.  3.
  6. 29.  0.  0.  3.  3.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  1.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [ 6. 25.  0.  6.  0. 25. 15. 11. 16.  0.  0. 11.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25] -> size -> 23 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[33.976063]
 [29.418234]
 [31.313623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  8.] 
cards in discard: [ 6. 25.  0.  6.  0. 25. 15. 11. 16.  0.  0. 11.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  1.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 3. 23.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6  8] -> size -> 34 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -3.8755440711975098
desired expected reward: 13.309831619262695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.697077]
 [27.406652]
 [15.701178]
 [27.548107]
 [29.992443]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  8.] 
cards in discard: [ 6. 25.  0.  6.  0. 25. 15. 11. 16.  0.  0. 11.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  1.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 3. 23.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6  8] -> size -> 34 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -4.6262640953063965
desired expected reward: 25.13810157775879



buy possibilites: [-1] 
expected returns: [[-8.650492]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  8.] 
cards in discard: [ 6. 25.  0.  6.  0. 25. 15. 11. 16.  0.  0. 11.  8.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 3. 23.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6  8] -> size -> 34 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -67 

action type: buy - action 8.0
Learning step: -4.922042369842529
desired expected reward: 22.62607192993164






Player: 1 
cards in hand: [ 3. 23.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  8.  6.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10
  3  0  6  0 23 11 29  0  6  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  6.  8.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8] -> size -> 24 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  6.  8.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8] -> size -> 24 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  6.  8.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8] -> size -> 24 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  8.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[ 0.32332826]
 [-0.71245337]
 [-7.7739787 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  3. 14.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [ 8.  3. 23.] 
adversary owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8] -> size -> 32 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -3.862107992172241
desired expected reward: -12.51259994506836



action possibilites: [-1] 
expected returns: [[17.273989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  3. 29.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.] 
adversary owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8] -> size -> 32 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action 14.0
Learning step: -2.468669891357422
desired expected reward: -10.321975708007812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[11.470507 ]
 [16.869757 ]
 [13.985664 ]
 [-0.6840234]
 [17.799683 ]
 [12.3774185]
 [16.370604 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 24. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  3. 29.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.] 
adversary owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8] -> size -> 32 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: -3.779629945755005
desired expected reward: 13.494359016418457



buy possibilites: [-1] 
expected returns: [[8.420408]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 3.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  3. 29.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.] 
adversary owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8] -> size -> 32 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -47 

action type: buy - action 1.0
Learning step: -3.0040283203125
desired expected reward: 13.865724563598633






Player: 1 
cards in hand: [ 0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.] 
cards in discard: [ 8.  3. 23.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [25. 11. 25.  0. 11.] 
adversary cards in discard: [ 1. 14.  0.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1] -> size -> 25 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 24. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [25. 11. 25.  0. 11.] 
adversary cards in discard: [ 1. 14.  0.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1] -> size -> 25 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 24. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [25. 11. 25.  0. 11.] 
adversary cards in discard: [ 1. 14.  0.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1] -> size -> 25 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [25. 11. 25.  0. 11.] 
adversary cards in discard: [ 1. 14.  0.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1] -> size -> 25 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [25. 11. 25.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 25. 11.] 
expected returns: [[11.367136]
 [11.646482]
 [11.02747 ]
 [11.646482]
 [11.02747 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 25.  0. 11.] 
cards in discard: [ 1. 14.  0.  6.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [8. 0. 8. 8. 6.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -4.912850379943848
desired expected reward: 3.5075578689575195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 6.7709336]
 [ 0.5919955]
 [10.986179 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 11. 25.  0. 11.] 
cards in discard: [ 1. 14.  0.  6.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [8. 0. 8. 8. 6.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -5.133359432220459
desired expected reward: 6.233776569366455



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 8. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 8. 6.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [ 1. 14.  0.  6.  8.  3. 25. 11. 25.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1] -> size -> 25 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 8. 6.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [ 1. 14.  0.  6.  8.  3. 25. 11. 25.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1] -> size -> 25 
adversary victory points: 0
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-5.351875]
 [-7.26112 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [ 1. 14.  0.  6.  8.  3. 25. 11. 25.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [10.  3. 10.  0.  0.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -5.431917667388916
desired expected reward: 5.554261684417725





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[-7.845894 ]
 [-7.188266 ]
 [-6.7115746]
 [-8.412871 ]
 [-6.480322 ]
 [-7.287268 ]
 [-5.9830246]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [ 1. 14.  0.  6.  8.  3. 25. 11. 25.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  7. 10.  7.] 
adversary cards in hand: [10.  3. 10.  0.  0.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -4.6316704750061035
desired expected reward: -9.983551025390625



buy possibilites: [-1] 
expected returns: [[-6.539379]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [ 1. 14.  0.  6.  8.  3. 25. 11. 25.  0. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [10.  3. 10.  0.  0.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -77 

action type: buy - action 10.0
Learning step: -3.632772445678711
desired expected reward: -10.920042037963867






Player: 1 
cards in hand: [10.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  0.  0.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8. 10.  0. 15.] 
adversary cards in discard: [ 1. 14.  0.  6.  8.  3. 25. 11. 25.  0. 11. 10.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10] -> size -> 26 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8. 10.  0. 15.] 
adversary cards in discard: [ 1. 14.  0.  6.  8.  3. 25. 11. 25.  0. 11. 10.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10] -> size -> 26 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3] -> size -> 33 
action values: 3 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8. 10.  0. 15.] 
adversary cards in discard: [ 1. 14.  0.  6.  8.  3. 25. 11. 25.  0. 11. 10.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10] -> size -> 26 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  8.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8. 10.  0. 15.] 
adversary cards in discard: [ 1. 14.  0.  6.  8.  3. 25. 11. 25.  0. 11. 10.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10] -> size -> 26 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8. 10.  0. 15.] 
adversary cards in discard: [ 1. 14.  0.  6.  8.  3. 25. 11. 25.  0. 11. 10.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10] -> size -> 26 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 10.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 15.] 
expected returns: [[14.823936]
 [11.478458]
 [10.294086]
 [ 8.499937]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  0. 15.] 
cards in discard: [ 1. 14.  0.  6.  8.  3. 25. 11. 25.  0. 11. 10.  0.  0.  8.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  0.  8. 29.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25. 10. 10.
  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3 25] -> size -> 34 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -4.13482666015625
desired expected reward: -10.674205780029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 8.469854 ]
 [ 2.0460405]
 [13.375906 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  0. 15.] 
cards in discard: [ 1. 14.  0.  6.  8.  3. 25. 11. 25.  0. 11. 10.  0.  0.  8.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 23. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  0.  8. 29.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25. 10. 10.
  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3 25] -> size -> 34 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -5.259354591369629
desired expected reward: 9.564581871032715



buy possibilites: [-1] 
expected returns: [[29.181587]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  0. 15.] 
cards in discard: [ 1. 14.  0.  6.  8.  3. 25. 11. 25.  0. 11. 10.  0.  0.  8.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 23. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  0.  8. 29.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25. 10. 10.
  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3 25] -> size -> 34 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: -6.016907691955566
desired expected reward: 2.4529542922973633






Player: 1 
cards in hand: [ 0.  3.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 29.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25. 10. 10.
  3.  0.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25. 10. 10.
  3.  0.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3
  0  0 23 11 29  0  6  8  3 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 23. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25. 10. 10.
  3.  0.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0
  0 23 11 29  0  6  8  3 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 23. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25. 10. 10.
  3.  0.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0
  0 23 11 29  0  6  8  3 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 23. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25. 10. 10.
  3.  0.  0.  0.  1.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0
  0 23 11 29  0  6  8  3 25  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 10 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  8. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[13.726896]
 [11.432354]
 [11.031673]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 16.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6  6 25 15  8 11 11 10  8  8 25  8
  1 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [11. 15.  8.  4.  0.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25. 10. 10.
  3.  0.  0.  0.  1.  0.  3. 29.  8.  3.  0.] 
adversary owned cards: [ 0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0
  0 23 11 29  0  6  8  3 25  3] -> size -> 34 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -6.4214653968811035
desired expected reward: 22.760122299194336



action possibilites: [-1] 
expected returns: [[32.779476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [11. 15.  8.  4.  0.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25. 10. 10.
  3.  0.  0.  0.  1.  0.  3. 29.  8.  3.  0.] 
adversary owned cards: [ 0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0
  0 23 11 29  0  6  8  3 25  3] -> size -> 34 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -59 

action type: gain_card_n - action 1
Learning step: -1.9821484088897705
desired expected reward: -6.588418960571289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[29.977137]
 [32.44048 ]
 [24.891548]
 [34.63248 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [11. 15.  8.  4.  0.] 
adversary cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25. 10. 10.
  3.  0.  0.  0.  1.  0.  3. 29.  8.  3.  0.] 
adversary owned cards: [ 0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0
  0 23 11 29  0  6  8  3 25  3] -> size -> 34 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1
Learning step: -4.062704563140869
desired expected reward: 28.716772079467773






Player: 1 
cards in hand: [11. 15.  8.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  8.  4.  0.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25. 10. 10.
  3.  0.  0.  0.  1.  0.  3. 29.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0
  0 23 11 29  0  6  8  3 25  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [11.  0. 14.  0.  0.] 
adversary cards in discard: [ 3. 16.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3] -> size -> 27 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  8.  4.  0.] 
cards in discard: [ 8.  3. 23.  0.  3.  3.  3. 29.  0.  3.  8.  0.  8.  8.  6. 25. 10. 10.
  3.  0.  0.  0.  1.  0.  3. 29.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0
  0 23 11 29  0  6  8  3 25  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [11.  0. 14.  0.  0.] 
adversary cards in discard: [ 3. 16.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3] -> size -> 27 
adversary victory points: 2
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [11.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[13.589224 ]
 [14.083984 ]
 [ 6.0570817]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 14.  0.  0.] 
cards in discard: [ 3. 16.  0.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 23.  8.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0
  0 23 11 29  0  6  8  3 25  3] -> size -> 34 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -5.601010799407959
desired expected reward: 29.03147315979004



action possibilites: [-1] 
expected returns: [[5.733766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.] 
cards in discard: [ 3. 16.  0.  8.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 23.  8.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0
  0 23 11 29  0  6  8  3 25  3] -> size -> 34 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -47 

action type: gain_card_n - action 9
Learning step: -3.033498764038086
desired expected reward: 13.2166748046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[-1.2268355]
 [ 4.399175 ]
 [ 2.3420343]
 [-3.1324627]
 [ 7.4894605]
 [-0.2609563]
 [ 7.748812 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.] 
cards in discard: [ 3. 16.  0.  8.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 23.  8.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0
  0 23 11 29  0  6  8  3 25  3] -> size -> 34 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1
Learning step: -3.3296287059783936
desired expected reward: 2.404137372970581






Player: 1 
cards in hand: [ 8. 23.  8.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23.  8.  6.  8.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  8  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0
  0 23 11 29  0  6  8  3 25  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 8.  0. 15. 11.  0.] 
adversary cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 8.  0. 15. 11.  0.] 
adversary cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
adversary victory points: 2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  8.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 8.  0. 15. 11.  0.] 
adversary cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
adversary victory points: 2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  8.] 
cards in discard: [0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 8.  0. 15. 11.  0.] 
adversary cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
adversary victory points: 2
player victory points: 11 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 15. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 11.] 
expected returns: [[8.400932 ]
 [4.274894 ]
 [2.3663917]
 [7.517259 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15. 11.  0.] 
cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 29.  8.] 
adversary cards in discard: [ 0.  8. 23.  8.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1.0
Learning step: -4.883678913116455
desired expected reward: 2.8650894165039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 2.710022 ]
 [ 4.8621173]
 [-0.6522472]
 [ 9.760786 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15. 11.  0.] 
cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 29.  8.] 
adversary cards in discard: [ 0.  8. 23.  8.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: take_action - action -1.0
Learning step: -4.921825885772705
desired expected reward: 3.4790987968444824



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  8.] 
cards in discard: [ 0.  8. 23.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [25.  6. 10.  3.  8.] 
adversary cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.  8.  0. 15. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
adversary victory points: 2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  8.] 
cards in discard: [ 0.  8. 23.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [25.  6. 10.  3.  8.] 
adversary cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.  8.  0. 15. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
adversary victory points: 2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  8.] 
cards in discard: [ 0.  8. 23.  8.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [25.  6. 10.  3.  8.] 
adversary cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.  8.  0. 15. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
adversary victory points: 2
player victory points: 11 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [25.  6. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.  8.] 
expected returns: [[15.446117]
 [19.51646 ]
 [ 9.986799]
 [11.054972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6. 10.  3.  8.] 
cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.  8.  0. 15. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0] -> size -> 34 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1.0
Learning step: -4.769354343414307
desired expected reward: 4.991418361663818





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.289814 ]
 [ 1.2475591]
 [16.037788 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6. 10.  3.  8.] 
cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.  8.  0. 15. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0] -> size -> 34 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: take_action - action -1.0
Learning step: -5.15314245223999
desired expected reward: 10.292964935302734



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  3.  8. 25. 10.] 
adversary cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.  8.  0. 15. 11.  0. 25.  6.
 10.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
adversary victory points: 2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  3.  8. 25. 10.] 
adversary cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.  8.  0. 15. 11.  0. 25.  6.
 10.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
adversary victory points: 2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 0.  3.  8. 25. 10.] 
adversary cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.  8.  0. 15. 11.  0. 25.  6.
 10.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
adversary victory points: 2
player victory points: 11 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  8. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 10.] 
expected returns: [[-13.4067  ]
 [-19.746037]
 [ -6.85119 ]
 [-22.755106]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 25. 10.] 
cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.  8.  0. 15. 11.  0. 25.  6.
 10.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 21. 29.  8.  4.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10] -> size -> 35 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1.0
Learning step: -5.718917369842529
desired expected reward: 10.318868637084961



action possibilites: [-1] 
expected returns: [[-0.7557416]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 10.  1.  0.] 
cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.  8.  0. 15. 11.  0. 25.  6.
 10.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 21. 29.  8.  3.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6] -> size -> 36 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20   0   0   0   0   0   0   0   0   3] 
sum of rewards: -70 

action type: take_action - action 25.0
Learning step: -3.1744449138641357
desired expected reward: -10.025625228881836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-5.711359 ]
 [-6.4484377]
 [-5.081587 ]
 [-3.59082  ]
 [-6.066111 ]
 [-5.208488 ]
 [-6.183256 ]
 [-3.6672351]
 [-4.7131476]
 [-4.1796293]
 [-3.3494658]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 10.  1.  0.] 
cards in discard: [ 3. 16.  0.  8.  0. 15. 11.  0. 14.  0.  0.  8.  0. 15. 11.  0. 25.  6.
 10.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 26. 30. 21. 29.  8.  3.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6] -> size -> 36 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1
Learning step: -3.7077252864837646
desired expected reward: -4.463466644287109






Player: 1 
cards in hand: [0. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 21. 29.  8.  3.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 21. 29.  8.  3.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 20. 29.  8.  3.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
adversary victory points: 2
player victory points: 11 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-4.56466 ]
 [-4.581111]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1
 10  0  3 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 20. 29.  8.  3.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 0. 29. 25.  3.  3.] 
adversary cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6  3] -> size -> 37 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1.0
Learning step: -4.585336685180664
desired expected reward: -7.9348039627075195



action possibilites: [-1] 
expected returns: [[13.64049]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 20. 29.  8.  3.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 0. 29. 25.  3.  3.] 
adversary cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6  3] -> size -> 37 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: trash_cards_n_from_hand - action 6
Learning step: -2.7685775756835938
desired expected reward: -14.258803367614746





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 8.31472   ]
 [ 0.88500285]
 [12.065252  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 20. 29.  8.  3.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 0. 29. 25.  3.  3.] 
adversary cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6  3] -> size -> 37 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1
Learning step: -4.124115943908691
desired expected reward: 9.516373634338379






Player: 1 
cards in hand: [ 0. 29. 25.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  3.  3.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 20. 29.  8.  3.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 0.  6. 11. 15.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3
 15] -> size -> 25 
adversary victory points: 2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 25.  3.  3.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 20. 29.  8.  3.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 0.  6. 11. 15.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3
 15] -> size -> 25 
adversary victory points: 2
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 11. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[-16.945164]
 [-17.00441 ]
 [-16.490948]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11. 15.  0.] 
cards in discard: [8. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 20. 29.  8.  3.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [15. 10. 10.  0. 11.] 
adversary cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.  0. 29. 25.  3.  3.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6  3] -> size -> 37 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1.0
Learning step: -5.6284284591674805
desired expected reward: 6.436827659606934



action possibilites: [-1] 
expected returns: [[-10.517181]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.] 
cards in discard: [8. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 20. 29.  8.  3.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [15. 10. 10.  0. 11.] 
adversary cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.  0. 29. 25.  3.  3.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6  3] -> size -> 37 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action 15.0
Learning step: -3.0620903968811035
desired expected reward: -19.55301856994629





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-14.025314]
 [-10.495112]
 [-12.962138]
 [-18.259834]
 [-12.546888]
 [-10.449029]
 [-11.503107]
 [-12.549109]
 [-13.773223]
 [-13.513017]
 [-11.918285]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.] 
cards in discard: [8. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 26. 30. 20. 29.  8.  3.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [15. 10. 10.  0. 11.] 
adversary cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.  0. 29. 25.  3.  3.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6  3] -> size -> 37 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1
Learning step: -3.390655517578125
desired expected reward: -13.9078369140625



buy possibilites: [-1] 
expected returns: [[10.785788]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.] 
cards in discard: [8. 3. 6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 26. 30. 20. 29.  8.  2.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [15. 10. 10.  0. 11.] 
adversary cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.  0. 29. 25.  3.  3.] 
adversary owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6  3] -> size -> 37 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1. -100.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -384.0 

action type: buy - action 6.0
Learning step: -18.044328689575195
desired expected reward: -36.304168701171875






Player: 1 
cards in hand: [15. 10. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10.  0. 11.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.  0. 29. 25.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 20. 29.  8.  2.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6] -> size -> 25 
adversary victory points: 1
player victory points: 11 


action possibilites: [-1. 15. 10. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0. 11.  3.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.  0. 29. 25.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0
 23 11 29  0  8  3 25  3  0  0 10  6  3] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 20. 29.  8.  2.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6] -> size -> 25 
adversary victory points: 1
player victory points: 11 


action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.  0. 29. 25.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0 23
 11 29  0  8  3 25  3  0  0 10  6  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 20. 29.  8.  2.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6] -> size -> 25 
adversary victory points: 1
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.  0. 29. 25.  3.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0 23
 11 29  0  8  3 25  3  0  0 10  6  3  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 20. 29.  8.  1.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6] -> size -> 25 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.  0. 29. 25.  3.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0 23
 11 29  0  8  3 25  3  0  0 10  6  3  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 20. 29.  8.  1.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6] -> size -> 25 
adversary victory points: 1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 0.  8. 23.  8.  0.  0.  3.  0. 29.  8. 10.  0.  1.  0.  3.  3.  6.  3.
  0.  3.  0.  3.  8.  0. 29. 25.  3.  3.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0 23
 11 29  0  8  3 25  3  0  0 10  6  3  6  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 19. 29.  8.  1.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6] -> size -> 25 
adversary victory points: 1
player victory points: 11 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-11.857659]
 [-18.001038]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [ 8.  3.  6. 15.  6. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 29.  8.  1.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [1. 8. 0. 8. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0 23
 11 29  0  8  3 25  3  0  0 10  6  3  6  3] -> size -> 38 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -104 

action type: buy - action -1
Learning step: -6.045314788818359
desired expected reward: 4.740472793579102





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[-18.472748]
 [-14.734555]
 [-13.244131]
 [-22.553926]
 [-11.96415 ]
 [-15.842791]
 [-11.338242]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [ 8.  3.  6. 15.  6. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 19. 29.  8.  1.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [1. 8. 0. 8. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0 23
 11 29  0  8  3 25  3  0  0 10  6  3  6  3] -> size -> 38 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -104 

action type: take_action - action -1.0
Learning step: -4.91473913192749
desired expected reward: -16.772403717041016



buy possibilites: [-1] 
expected returns: [[-5.100452]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 26. 30. 19. 29.  8.  1.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [1. 8. 0. 8. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0 23
 11 29  0  8  3 25  3  0  0 10  6  3  6  3] -> size -> 38 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1. -100.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -134.0 

action type: buy - action 0.0
Learning step: -5.891122817993164
desired expected reward: -24.36386489868164






Player: 1 
cards in hand: [1. 8. 0. 8. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 8. 4.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  4  8  8  8 10  3  0  0 23
 11 29  0  8  3 25  3  0  0 10  6  3  6  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 19. 29.  8.  1.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 3. 11. 25. 10.  0.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 19. 29.  8.  1.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 3. 11. 25. 10.  0.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 19. 29.  8.  1.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 3. 11. 25. 10.  0.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8.] 
cards in discard: [3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 18. 29.  8.  1.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 3. 11. 25. 10.  0.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10.] 
expected returns: [[-15.648497]
 [-14.784718]
 [-17.089825]
 [ -9.938694]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 25. 10.  0.] 
cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 18. 29.  8.  1.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 3. 23. 15.  0. 10.] 
adversary cards in discard: [3. 8. 1. 0. 8.] 
adversary owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3] -> size -> 38 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -4.225131511688232
desired expected reward: -9.325583457946777



action possibilites: [-1. 11. 25.  8.] 
expected returns: [[-13.033741]
 [-14.680585]
 [-16.091406]
 [-16.870174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 25.  0.  8.] 
cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 18. 29.  8.  1.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 3. 23. 15.  0. 10.] 
adversary cards in discard: [3. 8. 1. 0. 8.] 
adversary owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3] -> size -> 38 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action 10.0
Learning step: -3.0235934257507324
desired expected reward: -12.962287902832031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-16.007898]
 [-12.041658]
 [-12.878534]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 25.  0.  8.] 
cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 18. 29.  8.  1.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 3. 23. 15.  0. 10.] 
adversary cards in discard: [3. 8. 1. 0. 8.] 
adversary owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3] -> size -> 38 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -2.8396973609924316
desired expected reward: -15.873432159423828



buy possibilites: [-1] 
expected returns: [[-0.92827725]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 25.  0.  8.] 
cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [ 3. 23. 15.  0. 10.] 
adversary cards in discard: [3. 8. 1. 0. 8.] 
adversary owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3] -> size -> 38 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -90.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -375.0 

action type: buy - action 6.0
Learning step: -18.168804168701172
desired expected reward: -30.210464477539062






Player: 1 
cards in hand: [ 3. 23. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 15. 10.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23. 15.  0. 10.] 
cards in discard: [3. 8. 1. 0. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [15.  8. 16. 25. 14.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.  6. 10.  3. 11. 25.
  0.  8.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 10.  6.] 
cards in discard: [3. 8. 1. 0. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [15.  8. 16. 25. 14.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.  6. 10.  3. 11. 25.
  0.  8.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  6. 10.] 
cards in discard: [3. 8. 1. 0. 8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3] -> size -> 38 
action values: 2 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [15.  8. 16. 25. 14.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.  6. 10.  3. 11. 25.
  0.  8.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  6. 10.] 
cards in discard: [3. 8. 1. 0. 8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3] -> size -> 38 
action values: 0 
buys: 2 
player value: 2 
card supply: [18. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [15.  8. 16. 25. 14.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.  6. 10.  3. 11. 25.
  0.  8.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 9 


buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  6. 10.] 
cards in discard: [3. 8. 1. 0. 8. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [15.  8. 16. 25. 14.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.  6. 10.  3. 11. 25.
  0.  8.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  6. 10.] 
cards in discard: [3. 8. 1. 0. 8. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [15.  8. 16. 25. 14.] 
adversary cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.  6. 10.  3. 11. 25.
  0.  8.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [15.  8. 16. 25. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 16. 25. 14.] 
expected returns: [[ -4.5677714]
 [-18.953741 ]
 [-18.298328 ]
 [-17.82051  ]
 [ -7.5221367]
 [-24.913988 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 16. 25. 14.] 
cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.  6. 10.  3. 11. 25.
  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.] 
adversary owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 40 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -4.944009304046631
desired expected reward: -5.872286796569824



action possibilites: [-1] 
expected returns: [[0.26206446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16. 25. 14.] 
cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.  6. 10.  3. 11. 25.
  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.] 
adversary owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 40 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 15.0
Learning step: -2.7964165210723877
desired expected reward: -21.750158309936523





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-4.059436  ]
 [-0.21032524]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16. 25. 14.] 
cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.  6. 10.  3. 11. 25.
  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.] 
adversary owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 40 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: -3.7924137115478516
desired expected reward: -3.5303492546081543



buy possibilites: [-1] 
expected returns: [[-30.088318]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16. 25. 14.] 
cards in discard: [ 8.  3.  6. 15.  6. 11.  0.  0.  0.  8.  3.  0.  0.  6. 10.  3. 11. 25.
  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.] 
adversary owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 40 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -105 

action type: buy - action 0.0
Learning step: -5.616359710693359
desired expected reward: -11.828910827636719






Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  3  3  0  0 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11
 29  0  8  3 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [15.  3. 11. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0] -> size -> 28 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3  3 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3
 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [15.  3. 11. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0] -> size -> 28 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3  3 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3
 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [15.  3. 11. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0] -> size -> 28 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [15.  3. 11. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10.] 
expected returns: [[4.7349815]
 [3.5245059]
 [4.7674828]
 [3.8458898]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 11. 10.  1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [29.  3.  8.  8.  3.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.] 
adversary owned cards: [29  3  3 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3
 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -2.6453304290771484
desired expected reward: -32.73365020751953



action possibilites: [-1. 15. 11.  8.] 
expected returns: [[-10.029435]
 [-10.714085]
 [-10.352013]
 [-12.075624]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 11.  1.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  5. 10.  6.] 
adversary cards in hand: [29.  3.  8.  8.  3.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.] 
adversary owned cards: [29  3  3 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3
 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action 10.0
Learning step: -3.677706241607666
desired expected reward: 0.1681978702545166



action possibilites: [-1. 15.  8.] 
expected returns: [[-11.337678]
 [-10.985842]
 [-11.943204]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  1.  8.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4. 10.  6.] 
adversary cards in hand: [29.  3.  8.  8.  3.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.] 
adversary owned cards: [29  3  3 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3
 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  40   0   0   0   0   0   0   0   9   0] 
sum of rewards: -36 

action type: gain_card_n - action 7
Learning step: -1.5338157415390015
desired expected reward: -11.912590980529785



action possibilites: [-1] 
expected returns: [[-15.772301]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 8.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 11. 15.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4. 10.  6.] 
adversary cards in hand: [29.  3.  8.  8.  3.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.] 
adversary owned cards: [29  3  3 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3
 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 15.0
Learning step: -1.0555847883224487
desired expected reward: -12.041425704956055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-13.413977 ]
 [-13.426378 ]
 [-15.9547415]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 8.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 11. 15.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4. 10.  6.] 
adversary cards in hand: [29.  3.  8.  8.  3.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.] 
adversary owned cards: [29  3  3 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3
 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -0.7740681767463684
desired expected reward: -16.546369552612305



buy possibilites: [-1] 
expected returns: [[-17.861994]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 8.] 
cards in discard: [10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 11. 15.] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4. 10.  6.] 
adversary cards in hand: [29.  3.  8.  8.  3.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.] 
adversary owned cards: [29  3  3 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3
 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -80.   0.   0.  60. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -55.0 

action type: buy - action 0.0
Learning step: -2.481196165084839
desired expected reward: -15.895172119140625






Player: 1 
cards in hand: [29.  3.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8.  8.  3.] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  3 10  1  0  8  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3
 25  3  0  0 10  6  3  6  3  3  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.085238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0. 10. 11. 15.  3.  1.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  6. 10.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0] -> size -> 33 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -3.173818349838257
desired expected reward: -21.035812377929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -9.2962055]
 [-13.050043 ]
 [-11.46702  ]
 [ -7.3898096]
 [ -9.895446 ]
 [-13.506775 ]
 [-15.719878 ]
 [-10.3989   ]
 [ -7.042019 ]
 [ -7.693754 ]
 [ -9.197026 ]
 [ -6.366564 ]
 [ -8.429821 ]
 [-14.0874405]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0. 10. 11. 15.  3.  1.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  6. 10.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0] -> size -> 33 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -3.2386181354522705
desired expected reward: -17.323856353759766



buy possibilites: [-1] 
expected returns: [[-18.619616]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10  0 22] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 3.  0.  0.  6. 10.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0] -> size -> 33 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: -25 

action type: buy - action 22.0
Learning step: -1.3506133556365967
desired expected reward: -7.717177391052246






Player: 1 
cards in hand: [ 3.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  6. 10.] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 3.  0. 11.  8.  8.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10  0 22] -> size -> 31 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 3.  0. 11.  8.  8.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10  0 22] -> size -> 31 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 3.  0. 11.  8.  8.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10  0 22] -> size -> 31 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 3.  0. 11.  8.  8.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10  0 22] -> size -> 31 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[-10.012989]
 [ -9.243861]
 [ -8.245525]
 [ -8.245525]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  8.  8.] 
cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  0 16  6 25 15  8 11 11 10  8  8 25  8  1 10  0  3 15
  6  0  6  0 10  0 22] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [11.  3.  0. 29.  0.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.  0.
 10.  3.  0.  0.  6.  3.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0] -> size -> 34 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -3.013374090194702
desired expected reward: -21.63298988342285



action possibilites: [-1] 
expected returns: [[-15.925849]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0
  6  0 10  0 22] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [11.  3.  0. 29.  0.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.  0.
 10.  3.  0.  0.  6.  3.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0] -> size -> 34 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: trash_cards_n_from_hand - action 7
Learning step: -2.8097665309906006
desired expected reward: -8.781071662902832





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-15.306459]
 [-15.619561]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0
  6  0 10  0 22] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [11.  3.  0. 29.  0.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.  0.
 10.  3.  0.  0.  6.  3.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0] -> size -> 34 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -2.3001022338867188
desired expected reward: -18.2259521484375






Player: 1 
cards in hand: [11.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 29.  0.] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.  0.
 10.  3.  0.  0.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 8.  6. 16.  6. 10.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.  8.  3. 11.] 
adversary owned cards: [ 0  0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0
  6  0 10  0 22] -> size -> 29 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 29.  0.] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.  0.
 10.  3.  0.  0.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 18. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 8.  6. 16.  6. 10.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.  8.  3. 11.] 
adversary owned cards: [ 0  0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0
  6  0 10  0 22] -> size -> 29 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 29.  0.] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.  0.
 10.  3.  0.  0.  6.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 8.  6. 16.  6. 10.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.  8.  3. 11.] 
adversary owned cards: [ 0  0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0
  6  0 10  0 22] -> size -> 29 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 8.  6. 16.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
expected returns: [[ -6.0537977]
 [-10.824667 ]
 [-10.588674 ]
 [ -9.396074 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 16.  6. 10.] 
cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.  8.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0
  6  0 10  0 22] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 25.  0.  3.  3.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.  0.
 10.  3.  0.  0.  6.  3.  3. 11.  3.  0. 29.  0.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3] -> size -> 35 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -3.6456139087677
desired expected reward: -19.265172958374023





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-15.310169]
 [ -8.685072]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 16.  6. 10.] 
cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.  8.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0
  6  0 10  0 22] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 26. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 25.  0.  3.  3.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.  0.
 10.  3.  0.  0.  6.  3.  3. 11.  3.  0. 29.  0.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3] -> size -> 35 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -4.029928207397461
desired expected reward: -13.185726165771484



buy possibilites: [-1] 
expected returns: [[-29.402506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 16.  6. 10.] 
cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.  8.  3. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0
  6  0 10  0 22  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 25.  0.  3.  3.] 
adversary cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.  0.
 10.  3.  0.  0.  6.  3.  3. 11.  3.  0. 29.  0.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3] -> size -> 35 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -115 

action type: buy - action 0.0
Learning step: -5.646048069000244
desired expected reward: -20.956214904785156






Player: 1 
cards in hand: [ 3. 25.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  3.  3.] 
cards in discard: [ 3.  8.  1.  0.  8.  0.  0. 23. 10.  3. 15.  0.  6. 10.  8.  8.  3.  0.
 10.  3.  0.  0.  6.  3.  3. 11.  3.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [14. 15. 25.  0.  6.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.  8.  3. 11.  0.
  8.  6. 16.  6. 10.] 
adversary owned cards: [ 0  0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0
  6  0 10  0 22  0] -> size -> 30 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [14. 15. 25.  0.  6.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.  8.  3. 11.  0.
  8.  6. 16.  6. 10.] 
adversary owned cards: [ 0  0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0
  6  0 10  0 22  0] -> size -> 30 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 26. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [14. 15. 25.  0.  6.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.  8.  3. 11.  0.
  8.  6. 16.  6. 10.] 
adversary owned cards: [ 0  0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0
  6  0 10  0 22  0] -> size -> 30 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [14. 15. 25.  0.  6.] 
adversary cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.  8.  3. 11.  0.
  8.  6. 16.  6. 10.] 
adversary owned cards: [ 0  0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0
  6  0 10  0 22  0] -> size -> 30 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [14. 15. 25.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 25.] 
expected returns: [[-16.844812]
 [-14.30327 ]
 [-15.09067 ]
 [-18.851835]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 15. 25.  0.  6.] 
cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.  8.  3. 11.  0.
  8.  6. 16.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0
  6  0 10  0 22  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 23.  0.  0.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -3.1268489360809326
desired expected reward: -32.529354095458984



action possibilites: [-1] 
expected returns: [[-9.274963]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 25.  6.] 
cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.  8.  3. 11.  0.
  8.  6. 16.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 25. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 23.  0.  0.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action 15.0
Learning step: -2.704153537750244
desired expected reward: -17.794822692871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-10.689728]
 [-12.369674]
 [-10.059461]
 [-11.05917 ]
 [-10.594404]
 [ -9.798227]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 25.  6.] 
cards in discard: [10.  0. 10. 11. 15.  3.  1.  8. 22.  0.  0.  0.  0.  0.  8.  3. 11.  0.
  8.  6. 16.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 25. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 23.  0.  0.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: -3.019017457962036
desired expected reward: -12.293980598449707






Player: 1 
cards in hand: [ 3. 23.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  0.  0.  0.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [25.  0.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0] -> size -> 29 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1] -> size -> 36 
action values: 1 
buys: 1 
player value: 1 
card supply: [12. 25. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [25.  0.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0] -> size -> 29 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1] -> size -> 36 
action values: 0 
buys: 2 
player value: 4 
card supply: [12. 25. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [25.  0.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0] -> size -> 29 
adversary victory points: 0
player victory points: 8 


buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 25. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  6.] 
adversary cards in hand: [25.  0.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0] -> size -> 29 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1  0 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [25.  0.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0] -> size -> 29 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-14.975754]
 [-17.046741]
 [-17.046741]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [3. 3. 8. 3. 0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1  0 15] -> size -> 38 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -4.114675521850586
desired expected reward: -13.912901878356934





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-13.397074]
 [-12.993094]
 [-15.520808]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 25. 30. 17. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [3. 3. 8. 3. 0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1  0 15] -> size -> 38 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -3.806037664413452
desired expected reward: -18.781780242919922



buy possibilites: [-1] 
expected returns: [[-12.063822]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  3. 25.] 
cards in discard: [3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [3. 3. 8. 3. 0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1  0 15] -> size -> 38 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -66 

action type: buy - action 3.0
Learning step: -2.921781539916992
desired expected reward: -15.914871215820312






Player: 1 
cards in hand: [3. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 3. 0.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1  0 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [15. 14.  6. 11.  8.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25.] 
adversary owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0  3] -> size -> 30 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3. 0.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1  0 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [15. 14.  6. 11.  8.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25.] 
adversary owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0  3] -> size -> 30 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3. 0.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1  0 15  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [15. 14.  6. 11.  8.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25.] 
adversary owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0  3] -> size -> 30 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [15. 14.  6. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 11.  8.] 
expected returns: [[-5.733944]
 [-5.48846 ]
 [-5.64403 ]
 [-6.233287]
 [-8.014766]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  6. 11.  8.] 
cards in discard: [ 3. 25.  0.  0.  3. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [10.  8.  8.  6.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1  0 15  0] -> size -> 39 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1
Learning step: -3.2296788692474365
desired expected reward: -15.293500900268555



action possibilites: [-1] 
expected returns: [[-13.241257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 11.  8.] 
cards in discard: [ 3. 25.  0.  0.  3. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [10.  8.  8.  6.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1  0 15  0] -> size -> 39 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action 15.0
Learning step: -2.7235054969787598
desired expected reward: -8.21196174621582





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-14.543968]
 [-13.568799]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6. 11.  8.] 
cards in discard: [ 3. 25.  0.  0.  3. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [10.  8.  8.  6.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.] 
adversary owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1  0 15  0] -> size -> 39 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1
Learning step: -2.3494622707366943
desired expected reward: -15.590719223022461






Player: 1 
cards in hand: [10.  8.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  6.  0.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  0  3 15  3  0  8  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0
  0 10  6  3  6  3  3  0  0  0  3  1  0 15  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [15.  0.  1.  3.  8.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.] 
adversary owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0  3] -> size -> 30 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  1  3 15  3  0  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10
  3  6  3  3  0  0  0  3  1  0 15  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [15.  0.  1.  3.  8.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.] 
adversary owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0  3] -> size -> 30 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  1  3 15  3  0  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10
  3  6  3  3  0  0  0  3  1  0 15  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [15.  0.  1.  3.  8.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.] 
adversary owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0  3] -> size -> 30 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  1  3 15  3  0  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10
  3  6  3  3  0  0  0  3  1  0 15  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [15.  0.  1.  3.  8.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.] 
adversary owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0  3] -> size -> 30 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [15.  0.  1.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[ -9.039243]
 [ -8.676261]
 [-10.373298]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  3.  8.] 
cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6
  0 10  0 22  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 3.  3.  0. 10. 15.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.] 
adversary owned cards: [ 3 10  1  3 15  3  0  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10
  3  6  3  3  0  0  0  3  1  0 15  0  0] -> size -> 37 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -3.7255446910858154
desired expected reward: -17.29435157775879



action possibilites: [-1] 
expected returns: [[-13.828577]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 8.] 
cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 3.  3.  0. 10. 15.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.] 
adversary owned cards: [ 3 10  1  3 15  3  0  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10
  3  6  3  3  0  0  0  3  1  0 15  0  0] -> size -> 37 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action 15.0
Learning step: -3.0773303508758545
desired expected reward: -11.753589630126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-11.223743 ]
 [-11.35829  ]
 [-10.855618 ]
 [ -9.198802 ]
 [-11.575701 ]
 [-11.531312 ]
 [-10.702933 ]
 [-11.897265 ]
 [ -8.71905  ]
 [-10.176925 ]
 [-11.325383 ]
 [ -6.8319235]
 [-10.804347 ]
 [-13.45984  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8.] 
cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 25. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 3.  3.  0. 10. 15.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.] 
adversary owned cards: [ 3 10  1  3 15  3  0  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10
  3  6  3  3  0  0  0  3  1  0 15  0  0] -> size -> 37 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1
Learning step: -2.711561679840088
desired expected reward: -16.540138244628906



buy possibilites: [-1] 
expected returns: [[-10.491473]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8.] 
cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 24. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 3.  3.  0. 10. 15.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.] 
adversary owned cards: [ 3 10  1  3 15  3  0  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10
  3  6  3  3  0  0  0  3  1  0 15  0  0] -> size -> 37 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -80.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -59.5 

action type: buy - action 1.0
Learning step: -2.64314341545105
desired expected reward: -14.001433372497559






Player: 1 
cards in hand: [ 3.  3.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10. 15.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  3 15  3  0  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10
  3  6  3  3  0  0  0  3  1  0 15  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 0.  6. 10.  3.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.] 
adversary owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1] -> size -> 30 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 15.  3.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 10  1  3 15  3  0  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10
  3  6  3  3  0  0  0  3  1  0 15  0  0] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 0.  6. 10.  3.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.] 
adversary owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1] -> size -> 30 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3 10  1  3 15  3  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10  3
  6  3  3  0  0  0  3  1  0 15  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 3 
card supply: [ 9. 24. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 0.  6. 10.  3.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.] 
adversary owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1] -> size -> 30 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3 10  1  3 15  3  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10  3
  6  3  3  0  0  0  3  1  0 15  0  0] -> size -> 36 
action values: 1 
buys: 1 
player value: 3 
card supply: [ 9. 24. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 0.  6. 10.  3.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.] 
adversary owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1] -> size -> 30 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3 10  1  3 15  3  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10  3
  6  3  3  0  0  0  3  1  0 15  0  0  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 0.  6. 10.  3.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.] 
adversary owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1] -> size -> 30 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-19.633224]
 [-19.550138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  3.  0.] 
cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 8. 10.  0.  1. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.  1. 10. 15.  3.  3.  3.] 
adversary owned cards: [ 3 10  1  3 15  3  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10  3
  6  3  3  0  0  0  3  1  0 15  0  0  1] -> size -> 37 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -4.115835189819336
desired expected reward: -14.607308387756348





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-21.918854]
 [-21.466051]
 [-21.618355]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  3.  0.] 
cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 30. 16. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 8. 10.  0.  1. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.  1. 10. 15.  3.  3.  3.] 
adversary owned cards: [ 3 10  1  3 15  3  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10  3
  6  3  3  0  0  0  3  1  0 15  0  0  1] -> size -> 37 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -3.59375262260437
desired expected reward: -25.429941177368164



buy possibilites: [-1] 
expected returns: [[-13.877714]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  3.  0.] 
cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 15. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 8. 10.  0.  1. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.  1. 10. 15.  3.  3.  3.] 
adversary owned cards: [ 3 10  1  3 15  3  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10  3
  6  3  3  0  0  0  3  1  0 15  0  0  1] -> size -> 37 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -65 

action type: buy - action 3.0
Learning step: -2.4889461994171143
desired expected reward: -23.954998016357422






Player: 1 
cards in hand: [ 8. 10.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  1. 11.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.  1. 10. 15.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  3 15  3  8  8 10  3  0  0 23 11 29  0  8  3 25  3  0  0 10  3
  6  3  3  0  0  0  3  1  0 15  0  0  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 15. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [10. 16. 10. 11.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.  3.  0.
  6. 10.  3.  0.] 
adversary owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3] -> size -> 31 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.  1. 10. 15.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 15. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [10. 16. 10. 11.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.  3.  0.
  6. 10.  3.  0.] 
adversary owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3] -> size -> 31 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.  1. 10. 15.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 23. 30. 15. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [10. 16. 10. 11.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.  3.  0.
  6. 10.  3.  0.] 
adversary owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3] -> size -> 31 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 1. 25.  3.  0.  3.  3.  0.  0.  0. 15. 23.  3.  0.  0.  0.  6.  0.  3.
  3.  8.  3.  0.  0.  8. 10.  1. 10. 15.  3.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 23. 30. 15. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [10. 16. 10. 11.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.  3.  0.
  6. 10.  3.  0.] 
adversary owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3] -> size -> 31 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [10. 16. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 10. 11.] 
expected returns: [[-16.335743]
 [-14.069791]
 [-15.341279]
 [-14.069791]
 [-17.112198]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16. 10. 11.  0.] 
cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.  3.  0.
  6. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 15. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [10.  0.  3.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0] -> size -> 36 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1
Learning step: -3.2894904613494873
desired expected reward: -17.167203903198242



action possibilites: [-1. 16. 10. 11.] 
expected returns: [[-26.782204]
 [-27.180151]
 [-25.900124]
 [-26.28523 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10. 11.  0.  6.] 
cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.  3.  0.
  6. 10.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 15. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [10.  0.  3.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0] -> size -> 36 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action 10.0
Learning step: -2.537395715713501
desired expected reward: -16.607187271118164



action possibilites: [-1. 16. 11.] 
expected returns: [[-9.3099  ]
 [-8.089615]
 [-8.234757]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.  6.  0.] 
cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.  3.  0.
  6. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3] -> size -> 31 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 15. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [10.  0.  3.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0] -> size -> 36 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  40   0   0   0   0   0   0   0   0   1] 
sum of rewards: -32 

action type: take_action - action 10.0
Learning step: -0.49282246828079224
desired expected reward: -26.3929500579834





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-7.609088 ]
 [-7.0136538]
 [-8.550147 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  0.  6.  0.] 
cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.  3.  0.
  6. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 23. 30. 15. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [10.  0.  3.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0] -> size -> 36 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -1.351387619972229
desired expected reward: -10.661291122436523



buy possibilites: [-1] 
expected returns: [[-1.3190358]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  0.  6.  0.] 
cards in discard: [ 3. 25.  0.  0.  3. 25. 15. 14.  6. 11.  8.  1. 15.  1.  3.  8.  3.  0.
  6. 10.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [10.  0.  3.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0] -> size -> 36 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  40   0   0   0   0   0   0   0   8   0] 
sum of rewards: -14 

action type: buy - action 3.0
Learning step: -0.37899547815322876
desired expected reward: -7.3926520347595215






Player: 1 
cards in hand: [10.  0.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 3. 25. 10. 22.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3  3] -> size -> 32 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 23. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 3. 25. 10. 22.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3  3] -> size -> 32 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3. 29.] 
cards in discard: [0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 23. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 3. 25. 10. 22.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3  3] -> size -> 32 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 10. 22.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 22.  8.] 
expected returns: [[-7.6767626]
 [-8.817505 ]
 [-7.179747 ]
 [-6.068981 ]
 [-8.03725  ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 10. 22.  8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 0.  6. 15.  1.  3.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0] -> size -> 37 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: buy - action -1
Learning step: -3.189591407775879
desired expected reward: -4.508626937866211



action possibilites: [-1. 25. 22.  8.] 
expected returns: [[-16.541988]
 [-16.773262]
 [-13.872237]
 [-15.1261  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 22.  8.  6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 14  3  0 16  6 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0
 10  0 22  0  3  1  3  3] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 0.  6. 15.  1.  3.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0] -> size -> 37 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action 10.0
Learning step: -2.0749266147613525
desired expected reward: -9.254683494567871



action possibilites: [-1. 25.] 
expected returns: [[ -9.713373]
 [-11.297806]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 0.  6. 15.  1.  3.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0] -> size -> 37 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.0016584396362304688
desired expected reward: -15.541853904724121



action possibilites: [-1] 
expected returns: [[11.829222]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8. 25.] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 0.  6. 15.  1.  3.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0] -> size -> 37 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action 25.0
Learning step: 1.2810477018356323
desired expected reward: -10.016754150390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.053849]
 [11.524254]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8. 25.] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 23. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 0.  6. 15.  1.  3.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0] -> size -> 37 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action -1
Learning step: 0.10206003487110138
desired expected reward: 11.931282043457031






Player: 1 
cards in hand: [ 0.  6. 15.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  1.  3.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 8.  3.  3.  3. 11.] 
adversary cards in discard: [10.  8. 25.  3.  3. 16.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3] -> size -> 30 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  1.  3.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 23. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 8.  3.  3.  3. 11.] 
adversary cards in discard: [10.  8. 25.  3.  3. 16.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3] -> size -> 30 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  1.  3.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 8.  3.  3.  3. 11.] 
adversary cards in discard: [10.  8. 25.  3.  3. 16.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3] -> size -> 30 
adversary victory points: 4
player victory points: 9 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[7.5700855]
 [5.2932577]
 [6.9202147]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3.  3. 11.] 
cards in discard: [10.  8. 25.  3.  3. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  4.  9.  5.] 
adversary cards in hand: [ 3.  0.  3. 10.  1.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0  1] -> size -> 38 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: buy - action -1.0
Learning step: -2.9683449268341064
desired expected reward: 8.55591106414795



action possibilites: [-1] 
expected returns: [[-16.126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3.] 
cards in discard: [10.  8. 25.  3.  3. 16. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 3.  0.  3. 10.  1.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0  1] -> size -> 38 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -22 

action type: gain_card_n - action 7
Learning step: -1.6479486227035522
desired expected reward: 2.999721050262451





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-14.36959 ]
 [-16.130796]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 3.] 
cards in discard: [10.  8. 25.  3.  3. 16. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 22. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 3.  0.  3. 10.  1.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0  1] -> size -> 38 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1
Learning step: -1.0782619714736938
desired expected reward: -17.204261779785156



buy possibilites: [-1] 
expected returns: [[-17.796194]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 3.] 
cards in discard: [10.  8. 25.  3.  3. 16. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 3.  0.  3. 10.  1.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0  1] -> size -> 38 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action 0.0
Learning step: -2.7319347858428955
desired expected reward: -17.101524353027344






Player: 1 
cards in hand: [ 3.  0.  3. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  1.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  3.  9.  5.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0] -> size -> 32 
adversary victory points: 4
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0  1] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  3.  9.  5.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0] -> size -> 32 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 22. 30. 14. 29.  8.  0.  9.  7.  0.  7.  8.  9.  9.  3.  9.  5.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0] -> size -> 32 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0  1 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 22. 30. 14. 29.  8.  0.  9.  6.  0.  7.  8.  9.  9.  3.  9.  5.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0] -> size -> 32 
adversary victory points: 4
player victory points: 9 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-21.780844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 14. 29.  8.  0.  9.  6.  0.  7.  8.  9.  9.  3.  9.  5.] 
adversary cards in hand: [15.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0  1 11] -> size -> 39 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: buy - action -1
Learning step: -2.150259494781494
desired expected reward: -19.946453094482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-26.018467]
 [-23.266157]
 [-21.099989]
 [-25.185595]
 [-21.74892 ]
 [-26.220373]
 [-26.591242]
 [-23.416794]
 [-24.326   ]
 [-21.86063 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 22. 30. 14. 29.  8.  0.  9.  6.  0.  7.  8.  9.  9.  3.  9.  5.] 
adversary cards in hand: [15.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0  1 11] -> size -> 39 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: take_action - action -1.0
Learning step: -1.9724037647247314
desired expected reward: -23.75324821472168



buy possibilites: [-1] 
expected returns: [[-15.199129]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 14. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [15.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0  1 11] -> size -> 39 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -19 

action type: buy - action 29.0
Learning step: 0.01903829537332058
desired expected reward: -26.20133399963379






Player: 1 
cards in hand: [15.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  0.  0.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0  0 23 29  0  8  3 25  3  0  0 10  3  6  3
  3  0  0  0  3  1  0 15  0  0  1  0  0  1 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 14. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [11.  6.  8.  0.  0.] 
adversary cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.  0.  3.  6.  1.
  0.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29] -> size -> 33 
adversary victory points: 4
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 22. 30. 14. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [11.  6.  8.  0.  0.] 
adversary cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.  0.  3.  6.  1.
  0.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29] -> size -> 33 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 6. 22. 30. 14. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [11.  6.  8.  0.  0.] 
adversary cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.  0.  3.  6.  1.
  0.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29] -> size -> 33 
adversary victory points: 4
player victory points: 9 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [11.  6.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[-11.978655]
 [-12.4598  ]
 [-13.520593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  8.  0.  0.] 
cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.  0.  3.  6.  1.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 14. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11] -> size -> 38 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: buy - action -1
Learning step: -2.0681755542755127
desired expected reward: -17.267305374145508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-11.670553]
 [-10.778012]
 [-11.429511]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  8.  0.  0.] 
cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.  0.  3.  6.  1.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 22. 30. 14. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11] -> size -> 38 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: take_action - action -1.0
Learning step: -2.200145721435547
desired expected reward: -14.178796768188477



buy possibilites: [-1] 
expected returns: [[-23.213533]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  8.  0.  0.] 
cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.  0.  3.  6.  1.
  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 13. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11] -> size -> 38 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -32 

action type: buy - action 3.0
Learning step: -1.583404302597046
desired expected reward: -12.361410140991211






Player: 1 
cards in hand: [10.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 13. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [25.  0.  0.  1. 15.] 
adversary cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.  0.  3.  6.  1.
  0.  3. 11.  6.  8.  0.  0.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3] -> size -> 34 
adversary victory points: 5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 22. 30. 13. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [25.  0.  0.  1. 15.] 
adversary cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.  0.  3.  6.  1.
  0.  3. 11.  6.  8.  0.  0.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3] -> size -> 34 
adversary victory points: 5
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 13. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [25.  0.  0.  1. 15.] 
adversary cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.  0.  3.  6.  1.
  0.  3. 11.  6.  8.  0.  0.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3] -> size -> 34 
adversary victory points: 5
player victory points: 9 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
expected returns: [[ 6.233717 ]
 [ 6.852854 ]
 [-2.9141736]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  1. 15.] 
cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.  0.  3.  6.  1.
  0.  3. 11.  6.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 13. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 3.  8. 23. 25.  0.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11  1] -> size -> 39 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: buy - action -1
Learning step: -0.7293475270271301
desired expected reward: -23.942880630493164



action possibilites: [-1] 
expected returns: [[-30.868528]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 15. 10. 10.] 
cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.  0.  3.  6.  1.
  0.  3. 11.  6.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 13. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 3.  8. 23. 25.  0.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11  1] -> size -> 39 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action 25.0
Learning step: -2.0371854305267334
desired expected reward: 4.815682411193848





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-30.902092]
 [-31.010813]
 [-30.50504 ]
 [-30.975698]
 [-30.853827]
 [-31.164062]
 [-30.372631]
 [-30.7492  ]
 [-30.578184]
 [-30.648462]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 15. 10. 10.] 
cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.  0.  3.  6.  1.
  0.  3. 11.  6.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 21. 30. 13. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 3.  8. 23. 25.  0.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11  1] -> size -> 39 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1
Learning step: -0.14510928094387054
desired expected reward: -31.01363754272461



buy possibilites: [-1] 
expected returns: [[-6.7604923]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 15. 10. 10.] 
cards in discard: [10.  8. 25.  3.  3. 16. 10.  0. 11.  8.  3.  3.  3. 29.  0.  3.  6.  1.
  0.  3. 11.  6.  8.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 20. 30. 13. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 3.  8. 23. 25.  0.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11  1] -> size -> 39 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    5.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -15.5 

action type: buy - action 1.0
Learning step: 0.6234292984008789
desired expected reward: -30.387378692626953






Player: 1 
cards in hand: [ 3.  8. 23. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 23. 25.  0.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1. 10.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 20. 30. 13. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [11.  1. 10. 15. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1] -> size -> 35 
adversary victory points: 5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 23. 25.  0.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1. 10.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 20. 30. 13. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [11.  1. 10. 15. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1] -> size -> 35 
adversary victory points: 5
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 23. 25.  0.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1. 10.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11  1  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 20. 30. 13. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [11.  1. 10. 15. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1] -> size -> 35 
adversary victory points: 5
player victory points: 9 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [11.  1. 10. 15. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15. 14.] 
expected returns: [[-1.0893462]
 [-2.2132168]
 [-2.4318383]
 [-2.157739 ]
 [-1.9649725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 10. 15. 14.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 20. 30. 13. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [0. 3. 3. 8. 8.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1. 10.  0.  3.  0.  0.  0.  3.  8. 23. 25.  0.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11  1  0] -> size -> 40 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: buy - action -1
Learning step: -1.697750449180603
desired expected reward: -8.458242416381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[0.20734477]
 [1.1171386 ]
 [2.3525836 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 10. 15. 14.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 20. 30. 13. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [0. 3. 3. 8. 8.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1. 10.  0.  3.  0.  0.  0.  3.  8. 23. 25.  0.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11  1  0] -> size -> 40 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: take_action - action -1.0
Learning step: -1.9069918394088745
desired expected reward: -2.9963197708129883



buy possibilites: [-1] 
expected returns: [[-13.577234]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 10. 15. 14.] 
cards in discard: [3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [0. 3. 3. 8. 8.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1. 10.  0.  3.  0.  0.  0.  3.  8. 23. 25.  0.] 
adversary owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11  1  0] -> size -> 40 
adversary victory points: 9
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -30   0   0   0   0   0   0   0  -1   0   0   8   0] 
sum of rewards: -22 

action type: buy - action 3.0
Learning step: -1.4613455533981323
desired expected reward: -0.3441883325576782






Player: 1 
cards in hand: [0. 3. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 8.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1. 10.  0.  3.  0.  0.  0.  3.  8. 23. 25.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3
  0  0  0  3  1  0 15  0  0  1  0  0  1 11  1  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 0. 10. 10. 15.  1.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3] -> size -> 36 
adversary victory points: 6
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1. 10.  0.  3.  0.  0.  0.  3.  8. 23. 25.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 0. 10. 10. 15.  1.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3] -> size -> 36 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 0. 10.  0.  3.  3. 29.  1.  0.  6. 15.  1.  3. 11. 10.  3.  0.  3.  1.
  0. 15.  3.  0.  0.  1. 10.  0.  3.  0.  0.  0.  3.  8. 23. 25.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 0. 10. 10. 15.  1.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3] -> size -> 36 
adversary victory points: 6
player victory points: 7 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15.] 
expected returns: [[-13.577235]
 [-10.913396]
 [-10.913396]
 [ -9.647766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 15.  1.] 
cards in discard: [ 3. 11.  1. 10. 15. 14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [15.  6.  3.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0] -> size -> 38 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: buy - action -1
Learning step: -0.00884027499705553
desired expected reward: -13.586074829101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-11.410542 ]
 [-13.851757 ]
 [-11.7127075]
 [-14.457792 ]
 [-11.558462 ]
 [-14.518782 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 15.  1.] 
cards in discard: [ 3. 11.  1. 10. 15. 14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [15.  6.  3.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0] -> size -> 38 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: take_action - action -1.0
Learning step: -5.4025651479605585e-05
desired expected reward: -14.51883602142334



buy possibilites: [-1] 
expected returns: [[-20.914766]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 15.  1.] 
cards in discard: [ 3. 11.  1. 10. 15. 14.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [15.  6.  3.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0] -> size -> 38 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6. -10.   0.   0.   0. -30.   0.   0.   0.  -2.   0.   0.
   0.   0.] 
sum of rewards: -41.0 

action type: buy - action 0.0
Learning step: -1.9500551223754883
desired expected reward: -13.360596656799316






Player: 1 
cards in hand: [15.  6.  3.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3.  0. 23.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 8. 29. 25.  6.  0.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0] -> size -> 37 
adversary victory points: 6
player victory points: 7 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [23.] 
owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 4. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 8. 29. 25.  6.  0.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0] -> size -> 37 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [23.] 
owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0] -> size -> 38 
action values: 0 
buys: 2 
player value: 2 
card supply: [ 4. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 8. 29. 25.  6.  0.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0] -> size -> 37 
adversary victory points: 6
player victory points: 7 


buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  3.  0.  3.] 
cards in discard: [0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [23.] 
owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 8. 29. 25.  6.  0.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0] -> size -> 37 
adversary victory points: 6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  3.  0.  3.] 
cards in discard: [0. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [23.] 
owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 8. 29. 25.  6.  0.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0] -> size -> 37 
adversary victory points: 6
player victory points: 7 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 25.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 25.] 
expected returns: [[-18.422697]
 [-17.236666]
 [-16.886457]
 [-20.521433]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 25.  6.  0.] 
cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 0. 29. 10.  3. 10.] 
adversary cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3.] 
adversary owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 40 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: buy - action -1
Learning step: 0.1981646567583084
desired expected reward: -20.716602325439453



action possibilites: [-1. 25. 11.] 
expected returns: [[-17.317438]
 [-18.830574]
 [-17.191313]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6. 11.] 
cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 0. 29. 10.  3. 10.] 
adversary cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3.] 
adversary owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 40 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 11 

action type: discard_n_cards - action 3
Learning step: 0.9303105473518372
desired expected reward: -14.562294960021973





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-17.303303]
 [-17.375174]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6. 11.] 
cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0] -> size -> 37 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 2. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 0. 29. 10.  3. 10.] 
adversary cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3.] 
adversary owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 40 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 11 

action type: take_action - action -1.0
Learning step: 1.0260887145996094
desired expected reward: -16.291351318359375



buy possibilites: [-1] 
expected returns: [[-9.874973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6. 11.] 
cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 0. 29. 10.  3. 10.] 
adversary cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3.] 
adversary owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 40 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6. -10.   0.   0.  20. -30.   0.   0.   0.  -3.   0.   0.
   0.   0.] 
sum of rewards: -22.0 

action type: buy - action 0.0
Learning step: -0.45702171325683594
desired expected reward: -17.760324478149414






Player: 1 
cards in hand: [ 0. 29. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  3. 10.] 
cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.  0. 29. 25.  6.
 11.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0  0] -> size -> 38 
adversary victory points: 6
player victory points: 7 


action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 10.  3.] 
cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.  0. 29. 25.  6.
 11.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0  0] -> size -> 38 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 10.  3.] 
cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.  0. 29. 25.  6.
 11.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0  0] -> size -> 38 
adversary victory points: 6
player victory points: 7 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-38.50975 ]
 [-43.102997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 3.] 
cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.  0. 29. 25.  6.
 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 0.  1.  0. 15.  8.] 
adversary cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3. 10.  0. 29.  3. 10.  3.] 
adversary owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 40 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: buy - action -1
Learning step: -0.8520506024360657
desired expected reward: -10.72702407836914





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-42.711372]
 [-37.59052 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 3.] 
cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.  0. 29. 25.  6.
 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 0.  1.  0. 15.  8.] 
adversary cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3. 10.  0. 29.  3. 10.  3.] 
adversary owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 40 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: take_action - action -1.0
Learning step: 0.5970019698143005
desired expected reward: -37.912750244140625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  1.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 15.  8.] 
cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3. 10.  0. 29.  3. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10 15  3  8  8 10  3  0 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0
  0  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.  0. 29. 25.  6.
 11.  3.  3.  0.  8.  3.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0  0] -> size -> 38 
adversary victory points: 6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8.] 
cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3. 10.  0. 29.  3. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 15  3  8  8 10  3 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0  0
  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.  0. 29. 25.  6.
 11.  3.  3.  0.  8.  3.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0  0] -> size -> 38 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8.] 
cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3. 10.  0. 29.  3. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 15  3  8  8 10  3 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0  0
  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 1. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.  0. 29. 25.  6.
 11.  3.  3.  0.  8.  3.] 
adversary owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0  0] -> size -> 38 
adversary victory points: 6
player victory points: 7 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-23.490444]
 [-23.123579]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 3.] 
cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.  0. 29. 25.  6.
 11.  3.  3.  0.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  0 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10
  0  0  3  1  3  3 10  0 29  3  1  3  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 1.  0. 10. 25.  8.] 
adversary cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3. 10.  0. 29.  3. 10.  3. 15.  1.  0.  8.] 
adversary owned cards: [10 15  3  8  8 10  3 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0  0
  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 39 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: buy - action -1.0
Learning step: 0.9069026112556458
desired expected reward: -36.68361282348633



action possibilites: [-1] 
expected returns: [[-4.941214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.  0. 29. 25.  6.
 11.  3.  3.  0.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10  0  0  3
  1  3  3 10  0 29  3  1  3  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 1.  0. 10. 25.  8.] 
adversary cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3. 10.  0. 29.  3. 10.  3. 15.  1.  0.  8.] 
adversary owned cards: [10 15  3  8  8 10  3 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0  0
  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 39 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.2195906639099121
desired expected reward: -17.395769119262695





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.2856627]
 [-5.0503225]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.  0. 29. 25.  6.
 11.  3.  3.  0.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10  0  0  3
  1  3  3 10  0 29  3  1  3  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 1.  0. 10. 25.  8.] 
adversary cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3. 10.  0. 29.  3. 10.  3. 15.  1.  0.  8.] 
adversary owned cards: [10 15  3  8  8 10  3 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0  0
  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 39 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1
Learning step: -0.4244597554206848
desired expected reward: -5.365674018859863



Player 1 won the game! 



Player 0 bought cards:
Copper: 10 
Silver: 5 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 1 
Workshop: 2 
Chapel: 4 
Witch: 1 
Poacher: 1 
Militia: 1 
Market: 0 
Village: 1 
Library: 1 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [3.] 
cards in discard: [ 3. 11.  1. 10. 15. 14.  0.  0. 10. 10. 15.  1.  8.  0.  0. 29. 25.  6.
 11.  3.  3.  0.  8.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 16 25 15 11 11 10  8  8 25  8  1 10  0  3 15  6  0  6  0 10  0  0  3
  1  3  3 10  0 29  3  1  3  0  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 12. 29.  8.  0.  9.  6.  0.  7.  7.  9.  9.  3.  9.  5.] 
adversary cards in hand: [ 1.  0. 10. 25.  8.] 
adversary cards in discard: [ 0.  0. 23. 15.  6.  3.  0.  3. 10.  0. 29.  3. 10.  3. 15.  1.  0.  8.] 
adversary owned cards: [10 15  3  8  8 10  3 23 29  0  8  3 25  3  0  0 10  3  6  3  3  0  0  0
  3  1  0 15  0  0  1  0  0  1 11  1  0  0  0] -> size -> 39 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[  -5 -500    4  -30    0    0   20  -30    0    0    0   -1    0    0
    0    0] 
sum of rewards: -542 

action type: buy - action 0.0
Learning step: -26.78571891784668
desired expected reward: -33.071380615234375



