 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.802698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.52139949798584
desired expected reward: -3.141420364379883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.056948]
 [19.436226]
 [17.81    ]
 [20.890696]
 [20.972046]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.184974670410156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.974787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.972043991088867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.265831]
 [22.185951]
 [21.64511 ]
 [20.556135]
 [20.018885]
 [21.720184]
 [23.47886 ]
 [23.099579]
 [24.474052]
 [23.764359]
 [21.849043]
 [21.389765]
 [22.55874 ]
 [20.469648]
 [22.769165]
 [23.180931]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.2064266204834



buy possibilites: [-1] 
expected returns: [[26.207157]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  0.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 45 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 24.474050521850586






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  0.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.696302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.207157135009766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.254028]
 [25.17415 ]
 [24.63331 ]
 [23.007084]
 [26.467058]
 [26.08778 ]
 [25.54694 ]
 [26.169128]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.97040367126465



buy possibilites: [-1] 
expected returns: [[26.104107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 26.467058181762695






Player: 1 
cards in hand: [ 3.  3.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.736181]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 25.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 25.096540451049805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.017431]
 [18.937548]
 [18.396708]
 [16.770483]
 [20.230457]
 [19.851177]
 [19.310339]
 [19.932528]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 25.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.862600326538086



buy possibilites: [-1] 
expected returns: [[20.839693]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 25.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 20.23045539855957






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11. 14.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11. 14.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[27.883364]
 [28.181295]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.839693069458008



action possibilites: [-1] 
expected returns: [[28.030329]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 29.32304573059082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.13085 ]
 [27.050966]
 [26.510128]
 [24.883902]
 [28.343876]
 [27.964598]
 [27.423758]
 [28.045946]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.03032875061035



buy possibilites: [-1] 
expected returns: [[26.82952]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 28.343875885009766






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.895384]
 [25.193316]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 14. 11.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.829519271850586



action possibilites: [-1] 
expected returns: [[27.67527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 14. 11.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 25.858800888061523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.826128]
 [26.205406]
 [24.579182]
 [27.65988 ]
 [27.741226]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 14. 11.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.675270080566406






Player: 1 
cards in hand: [ 3.  3.  0. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 14. 11.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 14.] 
cards in discard: [ 0.  3.  0.  0.  3.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 14.] 
cards in discard: [ 0.  3.  0.  0.  3.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11.  3. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[29.112467]
 [29.410395]
 [30.405588]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.741226196289062



action possibilites: [-1] 
expected returns: [[29.046427]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.532007217407227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.554718]
 [28.474836]
 [27.933994]
 [26.307772]
 [28.009068]
 [29.767744]
 [29.388464]
 [30.053238]
 [28.137928]
 [28.847628]
 [29.05805 ]
 [29.469814]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.04642677307129



buy possibilites: [-1] 
expected returns: [[30.784563]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.  0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 30.053241729736328






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 10. 11.  3.] 
adversary cards in discard: [29. 25. 11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 10. 11.  3.] 
adversary cards in discard: [29. 25. 11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [10.  0. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[31.039333]
 [30.428375]
 [30.428375]
 [31.333954]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 11.  3.] 
cards in discard: [29. 25. 11.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.784563064575195



action possibilites: [-1] 
expected returns: [[26.8597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3.] 
cards in discard: [29. 25. 11.  3.  0.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.934221267700195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.074701]
 [23.8502  ]
 [26.955288]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  3.] 
cards in discard: [29. 25. 11.  3.  0.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.859699249267578






Player: 1 
cards in hand: [ 3.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  0.] 
cards in discard: [6. 3. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  0.] 
cards in discard: [6. 3. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  0.] 
cards in discard: [6. 3. 3. 0. 0. 0. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[28.252382]
 [27.630194]
 [28.550314]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14. 11.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0.  1.  3.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.955286026000977



action possibilites: [-1] 
expected returns: [[28.064287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14. 11.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0.  1.  3.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 29.216764450073242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.340506]
 [26.719784]
 [25.093557]
 [28.174255]
 [28.255602]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14. 11.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0.  1.  3.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.064287185668945






Player: 1 
cards in hand: [ 0.  0.  3. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14. 11.] 
cards in discard: [ 6.  3.  3.  0.  0.  0.  1.  3.  0.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3. 25. 10.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 6.  3.  3.  0.  0.  0.  1.  3.  0.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 6.  3.  3.  0.  0.  0.  1.  3.  0.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 6.  3.  3.  0.  0.  0.  1.  3.  0.  0. 29.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[24.463308]
 [23.841118]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.] 
cards in discard: [10. 11. 10.  3.  0.  0. 25. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  0.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 79  0] 
sum of rewards: 74 

action type: discard_down_to_3_cards - action 8
Learning step: 0
desired expected reward: 27.670917510986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.632402]
 [21.4065  ]
 [24.547499]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [10. 11. 10.  3.  0.  0. 25. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  0.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.578079223632812



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  0.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29. 11.  0.  0.  3.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0. 25. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29. 11.  0.  0.  3.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0. 25. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.  1.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1 16  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6.  9.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29. 11.  0.  0.  3.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0. 25. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[26.497574]
 [27.070469]
 [26.790154]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  0.  3.] 
cards in discard: [10. 11. 10.  3.  0.  0. 25. 10.  3. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6.  9.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [ 8. 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1 16  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.54749870300293



action possibilites: [-1. 11.] 
expected returns: [[30.401493]
 [30.694075]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [10. 11. 10.  3.  0.  0. 25. 10.  3. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6.  9.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [ 8. 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1 16  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.10978889465332



action possibilites: [-1] 
expected returns: [[36.77782]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 11. 10.  3.  0.  0. 25. 10.  3. 10.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6.  9.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [ 8. 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1 16  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.225364685058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[35.182537]
 [36.102657]
 [35.561817]
 [33.93559 ]
 [35.636887]
 [37.39556 ]
 [37.01629 ]
 [37.68106 ]
 [35.76575 ]
 [36.47545 ]
 [36.68587 ]
 [37.097637]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 11. 10.  3.  0.  0. 25. 10.  3. 10.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6.  9.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [ 8. 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1 16  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.7778205871582



buy possibilites: [-1] 
expected returns: [[37.748466]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 11. 10.  3.  0.  0. 25. 10.  3. 10.  0. 10. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6.  9.  9.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [ 8. 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1 16  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 37.681060791015625






Player: 1 
cards in hand: [ 3. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  0.] 
cards in discard: [ 8. 14.  0.  0.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14 11  0 29  6  1 16  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6.  9.  9.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 14.  0.  0.  3.  1. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6.  9.  9.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 14.  0.  0.  3.  1. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  6.  9.  9.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 14.  0.  0.  3.  1. 14.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9.  9.  6.  9.  9.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[29.538727]
 [29.836657]
 [30.122154]
 [29.836657]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9.  9.  6.  9.  9.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  6.] 
adversary cards in discard: [ 8. 14.  0.  0.  3.  1. 14.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.74846649169922



action possibilites: [-1. 11. 11.] 
expected returns: [[35.71278]
 [36.01071]
 [36.01071]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  9.  9.  6.  9.  9.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  6.] 
adversary cards in discard: [ 8. 14.  0.  0.  3.  1. 14.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 30.182092666625977



action possibilites: [-1] 
expected returns: [[34.20172]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  9.  9.  6.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  6.] 
adversary cards in discard: [ 8. 14.  0.  0.  3.  1. 14.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.55380630493164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.377808]
 [33.297928]
 [32.757088]
 [31.130861]
 [34.590836]
 [34.211555]
 [33.670715]
 [34.292904]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  9.  9.  6.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  6.] 
adversary cards in discard: [ 8. 14.  0.  0.  3.  1. 14.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.20172119140625



buy possibilites: [-1] 
expected returns: [[35.20263]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  6.] 
adversary cards in discard: [ 8. 14.  0.  0.  3.  1. 14.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 18  0] 
sum of rewards: 53 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 34.59083557128906






Player: 1 
cards in hand: [ 0.  3.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  6.] 
cards in discard: [ 8. 14.  0.  0.  3.  1. 14.  1. 16.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 25.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  6.] 
cards in discard: [ 8. 14.  0.  0.  3.  1. 14.  1. 16.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  9.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 25.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 25.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10.] 
expected returns: [[35.146175]
 [35.444107]
 [36.4393  ]
 [34.523987]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  0. 10.] 
cards in discard: [10. 11. 29. 11.  0. 11.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.20262908935547



action possibilites: [-1] 
expected returns: [[28.145227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10. 29. 10.] 
cards in discard: [10. 11. 29. 11.  0. 11.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0. 29.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 36.462364196777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.793888]
 [27.166336]
 [25.569387]
 [28.594606]
 [28.674475]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10. 29. 10.] 
cards in discard: [10. 11. 29. 11.  0. 11.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0. 29.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.145227432250977






Player: 1 
cards in hand: [ 6.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29.  0.  3.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0. 11.  0.  3. 25.  0. 11.  0. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0. 11.  0.  3. 25.  0. 11.  0. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0. 11.  0.  3. 25.  0. 11.  0. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [6. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0. 11.  0.  3. 25.  0. 11.  0. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[34.100815]
 [33.478622]
 [33.478622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10. 10.] 
cards in discard: [10. 11. 29. 11.  0. 11.  0.  3. 25.  0. 11.  0. 10. 29. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  8.  0.  1.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.674474716186523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.308132]
 [32.687412]
 [31.061184]
 [34.14188 ]
 [34.223232]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10. 10.] 
cards in discard: [10. 11. 29. 11.  0. 11.  0.  3. 25.  0. 11.  0. 10. 29. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  8.  0.  1.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.10081481933594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  0.  8.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  0.  1.] 
cards in discard: [ 6.  3. 29.  6.  0.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  0 29  6  1 16  8 14  1  6  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11. 11. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [ 6.  3. 29.  6.  0.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11. 11. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 6.  3. 29.  6.  0.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11. 11. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [11. 11. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[30.445076]
 [30.743006]
 [30.743006]
 [29.822886]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 1. 14.  0.  0. 16.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  0.  3.  3.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 34.223228454589844



action possibilites: [-1] 
expected returns: [[33.80097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 1. 14.  0.  0. 16.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  0.  3.  3.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.3818416595459





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.95642 ]
 [30.709475]
 [33.87152 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 1. 14.  0.  0. 16.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  0.  3.  3.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.800968170166016






Player: 1 
cards in hand: [ 1. 14.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0.  0. 16.] 
cards in discard: [ 6.  3. 29.  6.  0.  0.  3.  3.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  0.  0.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10] -> size -> 24 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  0.  0. 16.] 
cards in discard: [ 6.  3. 29.  6.  0.  0.  3.  3.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8.  8.  9.  5.  9.  9.  7.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  0.  0.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10] -> size -> 24 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  0.  0. 16.] 
cards in discard: [ 6.  3. 29.  6.  0.  0.  3.  3.  8. 14. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  7.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  0.  0.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10] -> size -> 24 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[27.158335]
 [26.536146]
 [27.741762]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  0.  0.] 
cards in discard: [10. 11. 11. 10.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  7.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.87152099609375



action possibilites: [-1. 10.] 
expected returns: [[32.782646]
 [32.160454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [10. 11. 11. 10.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  7.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.787126541137695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[31.169067]
 [32.089188]
 [31.548346]
 [29.92212 ]
 [31.623419]
 [33.382095]
 [33.002815]
 [33.66759 ]
 [31.752281]
 [32.46197 ]
 [32.6724  ]
 [33.084164]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [10. 11. 11. 10.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  7.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.78264617919922



buy possibilites: [-1] 
expected returns: [[39.746605]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [10. 11. 11. 10.  3.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  6.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 33.6675910949707






Player: 1 
cards in hand: [ 0.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  6.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 11.  0.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0. 29. 29.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  6.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 11.  0.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0. 29. 29.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  6.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 11.  0.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0. 29. 29.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[31.301603]
 [31.853024]
 [30.713585]
 [31.583231]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 11.  0.] 
cards in discard: [10. 11. 11. 10.  3.  0. 29. 29.  0. 10.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  6.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 1. 14. 29. 14.  6.] 
adversary cards in discard: [ 0.  0.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.746604919433594



action possibilites: [-1. 10. 11.] 
expected returns: [[35.74743 ]
 [35.159412]
 [36.02906 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.  0.] 
cards in discard: [10. 11. 11. 10.  3.  0. 29. 29.  0. 10.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  6.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 1. 14. 29. 14.  6.] 
adversary cards in discard: [ 0.  0.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.853023529052734



action possibilites: [-1] 
expected returns: [[35.857582]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10. 11. 11. 10.  3.  0. 29. 29.  0. 10.  0.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  6.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 14. 29. 14.  6.] 
adversary cards in discard: [ 0.  0.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.540225982666016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[34.22792 ]
 [35.114143]
 [34.593224]
 [33.04693 ]
 [34.665546]
 [36.35942 ]
 [35.994118]
 [36.634403]
 [34.789642]
 [35.4732  ]
 [35.67586 ]
 [36.072445]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10. 11. 11. 10.  3.  0. 29. 29.  0. 10.  0.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  6.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 14. 29. 14.  6.] 
adversary cards in discard: [ 0.  0.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.857582092285156



buy possibilites: [-1] 
expected returns: [[38.19802]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10. 11. 11. 10.  3.  0. 29. 29.  0. 10.  0.  0.  3. 10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 14. 29. 14.  6.] 
adversary cards in discard: [ 0.  0.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 36.6343994140625






Player: 1 
cards in hand: [ 1. 14. 29. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14. 29. 14.  6.] 
cards in discard: [ 0.  0.  3.  0. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 10. 10. 11. 25.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0. 29. 29.  0. 10.  0.  0.  3. 10. 29. 29. 11.  0.
 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 14. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14. 14.  6. 16.] 
cards in discard: [ 0.  0.  3.  0. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 10. 10. 11. 25.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0. 29. 29.  0. 10.  0.  0.  3. 10. 29. 29. 11.  0.
 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14. 14.  6. 16.] 
cards in discard: [ 0.  0.  3.  0. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  8.  8.  5.  9.  9.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 10. 10. 11. 25.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0. 29. 29.  0. 10.  0.  0.  3. 10. 29. 29. 11.  0.
 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14. 14.  6. 16.] 
cards in discard: [ 0.  0.  3.  0. 11.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  8.  8.  5.  9.  9.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 10. 10. 11. 25.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0. 29. 29.  0. 10.  0.  0.  3. 10. 29. 29. 11.  0.
 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 10. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 25.] 
expected returns: [[30.097116]
 [29.47962 ]
 [29.47962 ]
 [30.39505 ]
 [31.390238]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 11. 25.] 
cards in discard: [10. 11. 11. 10.  3.  0. 29. 29.  0. 10.  0.  0.  3. 10. 29. 29. 11.  0.
 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  8.  8.  5.  9.  9.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11.  0.  3. 29.  1. 14. 14.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0  3] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.198020935058594



action possibilites: [-1] 
expected returns: [[36.966476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 11. 11. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  7.  8.  5.  9.  9.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11.  0.  3. 29.  1. 14. 14.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.390241622924805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.235302]
 [33.988354]
 [37.1504  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10. 11. 11. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  7.  8.  5.  9.  9.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11.  0.  3. 29.  1. 14. 14.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.96647644042969






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  0. 11.  0.  3. 29.  1. 14. 14.  6. 16.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  7.  8.  5.  9.  9.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [29. 11.  3. 10.  0.] 
adversary cards in discard: [25.  3. 10. 10. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  0. 11.  0.  3. 29.  1. 14. 14.  6. 16.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  7.  8.  5.  9.  9.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [29. 11.  3. 10.  0.] 
adversary cards in discard: [25.  3. 10. 10. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  0. 11.  0.  3. 29.  1. 14. 14.  6. 16.  6. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0  3  6 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [29. 11.  3. 10.  0.] 
adversary cards in discard: [25.  3. 10. 10. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29. 11.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[35.344193]
 [35.917084]
 [35.636772]
 [34.733227]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3. 10.  0.] 
cards in discard: [25.  3. 10. 10. 11. 11. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0  3  6 11] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.1504020690918



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[41.354847]
 [41.65277 ]
 [40.741646]
 [40.741646]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  0. 10.] 
cards in discard: [25.  3. 10. 10. 11. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0  3  6 11] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.911415100097656



action possibilites: [-1] 
expected returns: [[36.261868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 10.] 
cards in discard: [25.  3. 10. 10. 11. 11. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0  3  6 11] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.19361114501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[34.4804  ]
 [34.85285 ]
 [33.2559  ]
 [36.3011  ]
 [36.382454]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 10.] 
cards in discard: [25.  3. 10. 10. 11. 11. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0  3  6 11] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.26186752319336






Player: 1 
cards in hand: [ 0.  6.  3. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 16.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  0 29  6 16  8 14  1  6  3 16  0  3  6 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10] -> size -> 28 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10] -> size -> 28 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10] -> size -> 28 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10] -> size -> 28 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[28.406609]
 [27.81859 ]
 [28.958033]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  3.  0.] 
cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 1. 11. 11.  3.  3.] 
adversary cards in discard: [ 0.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 36.382450103759766



action possibilites: [-1. 10.] 
expected returns: [[29.170761]
 [28.582743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 1. 11. 11.  3.  3.] 
adversary cards in discard: [ 0.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.958030700683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.428812]
 [28.298456]
 [27.787292]
 [26.253654]
 [27.85824 ]
 [29.520458]
 [29.161978]
 [29.790249]
 [27.980011]
 [28.650806]
 [28.849659]
 [29.238829]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 1. 11. 11.  3.  3.] 
adversary cards in discard: [ 0.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 29.17076301574707



buy possibilites: [-1] 
expected returns: [[30.90333]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  4.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 1. 11. 11.  3.  3.] 
adversary cards in discard: [ 0.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 29.790252685546875






Player: 1 
cards in hand: [ 1. 11. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 11.  3.  3.] 
cards in discard: [ 0.  8.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  4.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  0.  0.] 
adversary cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10. 29. 29.  0. 10.
  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29] -> size -> 29 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 11.  3.  3.] 
cards in discard: [ 0.  8.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8.  7.  8.  4.  9.  9.  4.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  0.  0.] 
adversary cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10. 29. 29.  0. 10.
  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29] -> size -> 29 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 11.  3.  3.] 
cards in discard: [ 0.  8.  0. 16.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  9.  4.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  0.  0.] 
adversary cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10. 29. 29.  0. 10.
  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29] -> size -> 29 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[26.24907 ]
 [25.66699 ]
 [26.798227]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  0.  0.] 
cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10. 29. 29.  0. 10.
  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  9.  4.  8. 10.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.903329849243164



action possibilites: [-1. 10. 29.] 
expected returns: [[23.594097]
 [22.989073]
 [24.161406]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 29.] 
cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10. 29. 29.  0. 10.
  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  9.  4.  8. 10.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 26.798227310180664



action possibilites: [-1. 10. 10.] 
expected returns: [[25.750822]
 [25.162806]
 [25.162806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 10.] 
cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10. 29. 29.  0. 10.
  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  9.  4.  8. 10.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 24.161401748657227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[24.03255 ]
 [24.902197]
 [24.391027]
 [23.36808 ]
 [22.865437]
 [24.461979]
 [26.168161]
 [25.795712]
 [27.145407]
 [26.448475]
 [24.583754]
 [24.149658]
 [25.264616]
 [23.287138]
 [25.471228]
 [25.875576]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 10.] 
cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10. 29. 29.  0. 10.
  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  9.  4.  8. 10.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.750823974609375



buy possibilites: [-1] 
expected returns: [[27.326479]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 10.] 
cards in discard: [25.  3. 10. 10. 11. 11. 10. 10. 29. 11.  3. 10.  0. 10. 29. 29.  0. 10.
  3.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  8.  4.  8. 10.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 50  0] 
sum of rewards: 85 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 27.14540672302246






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  8.  4.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  8.  4.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 11.] 
expected returns: [[37.27333 ]
 [37.856762]
 [36.651146]
 [36.651146]
 [37.571266]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 10. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  0. 14.] 
adversary cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3
 10] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.326478958129883



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[37.79474 ]
 [37.172554]
 [37.172554]
 [37.172554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10.] 
cards in discard: [11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  0. 14.] 
adversary cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3
 10] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.28133010864258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[35.928333]
 [36.307613]
 [34.68138 ]
 [37.762077]
 [37.843433]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 10.] 
cards in discard: [11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  0. 14.] 
adversary cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3
 10] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.794742584228516






Player: 1 
cards in hand: [ 0.  6. 29.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  0. 14.] 
cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3. 10.  3.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 11. 25.  0.] 
adversary cards in discard: [11. 29.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 14.] 
cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3. 10.  3.  3.  0.  0.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 11. 25.  0.] 
adversary cards in discard: [11. 29.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3. 10.  3.  3.  0.  0.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11. 25.  0.] 
adversary cards in discard: [11. 29.  0. 10. 10. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3. 10.  3.  3.  0.  0.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11. 25.  0.] 
adversary cards in discard: [11. 29.  0. 10. 10. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 0.  8.  0. 16.  3.  1. 11. 11.  3.  3. 10.  3.  3.  0.  0.  0. 16. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3
 10 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [11. 25.  0.] 
adversary cards in discard: [11. 29.  0. 10. 10. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[29.854322]
 [30.146906]
 [31.12415 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0.] 
cards in discard: [11. 29.  0. 10. 10. 10. 11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  7.  8.  4.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [16.  8.  0.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3
 10 15] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 204   0] 
sum of rewards: 199 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 25.49894142150879



action possibilites: [-1] 
expected returns: [[39.08719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 29.] 
cards in discard: [11. 29.  0. 10. 10. 10. 11.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  6.  8.  4.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [16.  8.  0.  6. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3
 10 15  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.1241512298584





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.35762 ]
 [36.133118]
 [39.238205]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10. 29.] 
cards in discard: [11. 29.  0. 10. 10. 10. 11.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 26. 30.  8.  6.  8.  4.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [16.  8.  0.  6. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3
 10 15  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.087188720703125






Player: 1 
cards in hand: [16.  8.  0.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0.  6. 14.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29 16  8 14  1  6  3 16  0  3  6 11  0  3
 10 15  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  6.  8.  4.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 10.  0. 25.] 
adversary cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  6.  8.  4.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 10.  0. 25.] 
adversary cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 26. 30.  8.  6.  8.  4.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 10.  0. 25.] 
adversary cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [6. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  6.  8.  4.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 10.  0. 25.] 
adversary cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  0. 10.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25.] 
expected returns: [[26.169039]
 [25.586962]
 [25.586962]
 [27.378855]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0. 25.] 
cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  6.  8.  4.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 39.23820877075195



action possibilites: [-1] 
expected returns: [[36.40873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0. 11.  3.] 
cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  4.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 27.378854751586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[34.65724 ]
 [35.027847]
 [33.48152 ]
 [36.482315]
 [36.563667]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0. 11.  3.] 
cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  4.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.408729553222656






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 6.  0.  8.  0. 14.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  4.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [29. 10. 10. 10.  3.] 
adversary cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29. 25. 10.  0. 10.  0.
 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 6.  0.  8.  0. 14.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  4.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [29. 10. 10. 10.  3.] 
adversary cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29. 25. 10.  0. 10.  0.
 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 6.  0.  8.  0. 14.  6. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0  6 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [29. 10. 10. 10.  3.] 
adversary cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29. 25. 10.  0. 10.  0.
 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29. 10. 10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 10.] 
expected returns: [[22.686865]
 [23.226013]
 [22.111902]
 [22.111902]
 [22.111902]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 10.  3.] 
cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29. 25. 10.  0. 10.  0.
 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 29.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0  6 11] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 36.56366729736328



action possibilites: [-1. 10. 10. 10. 29.] 
expected returns: [[23.467052]
 [22.884972]
 [22.884972]
 [22.884972]
 [24.0134  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 29.] 
cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29. 25. 10.  0. 10.  0.
 11.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 29.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0  6 11] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.767423629760742



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[27.049974]
 [26.467894]
 [26.467894]
 [27.595804]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.] 
cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29. 25. 10.  0. 10.  0.
 11.  3.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 29.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0  6 11] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.536218643188477



action possibilites: [-1. 10.] 
expected returns: [[33.636475]
 [33.031452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29. 25. 10.  0. 10.  0.
 11.  3.  3. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 29.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0  6 11] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 26.119138717651367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[31.879316]
 [32.774048]
 [32.248123]
 [30.696196]
 [32.3211  ]
 [34.03127 ]
 [33.662457]
 [34.30886 ]
 [32.44641 ]
 [33.341152]
 [33.741554]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29. 25. 10.  0. 10.  0.
 11.  3.  3. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  4.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 29.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0  6 11] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.636474609375



buy possibilites: [-1] 
expected returns: [[33.715157]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [11. 29.  0. 10. 10. 10. 11.  0. 25. 11.  0. 10. 29. 25. 10.  0. 10.  0.
 11.  3.  3. 10. 10. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  3.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 29.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0  6 11] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 32  0] 
sum of rewards: 87 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 34.308860778808594






Player: 1 
cards in hand: [ 0. 15.  0.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  6. 29.] 
cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15
  6  0  6 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  3.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29] -> size -> 31 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.] 
cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  3.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29] -> size -> 31 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29.] 
cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  3.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29] -> size -> 31 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29.] 
cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  3.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 29. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29] -> size -> 31 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[38.043297]
 [38.626724]
 [37.421112]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  3.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.71515655517578



action possibilites: [-1. 10. 10.] 
expected returns: [[42.291496]
 [41.669308]
 [41.669308]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  3.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.04832077026367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[40.53833 ]
 [41.45845 ]
 [40.917614]
 [39.29138 ]
 [42.751354]
 [42.372086]
 [42.45343 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  3.  9.  8.  3.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 42.29149627685547



buy possibilites: [-1] 
expected returns: [[44.41977]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [ 3. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  2.  9.  8.  3.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 42.75135803222656






Player: 1 
cards in hand: [ 3.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 11.  0.] 
cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  2.  9.  8.  3.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  0. 10. 11.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  2.  9.  8.  3.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  0. 10. 11.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  5.  8.  2.  9.  8.  3.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  0. 10. 11.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29. 14.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15 14  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 26. 30.  8.  5.  8.  2.  9.  8.  3.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  0. 10. 11.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[37.084793]
 [36.47383 ]
 [36.47383 ]
 [37.37738 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10. 11.] 
cards in discard: [ 3. 11. 29.  0. 10.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  5.  8.  2.  9.  8.  3.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10. 14.  0. 11.  1.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29. 14.
  0. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15 14  0] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.419769287109375



action possibilites: [-1] 
expected returns: [[39.415813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  5.  8.  2.  9.  8.  3.  7. 10.  0. 10.  7.] 
adversary cards in hand: [10. 14.  0. 11.  1.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29. 14.
  0. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15 14  0] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 37.908470153808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[37.669895]
 [38.042347]
 [36.4454  ]
 [39.47062 ]
 [39.550484]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 26. 30.  8.  5.  8.  2.  9.  8.  3.  7. 10.  0. 10.  7.] 
adversary cards in hand: [10. 14.  0. 11.  1.] 
adversary cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29. 14.
  0. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15 14  0] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.41581344604492






Player: 1 
cards in hand: [10. 14.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0. 11.  1.] 
cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29. 14.
  0. 11.  3.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15 14  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  5.  8.  2.  9.  8.  3.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 29. 25. 29.  3.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0.  1.] 
cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29. 14.
  0. 11.  3.  3.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15 14  0 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  5.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 29. 25. 29.  3.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  1.] 
cards in discard: [ 6.  0.  8.  0. 14.  6. 11.  3.  3.  0.  0.  0. 15. 15.  0.  6. 29. 14.
  0. 11.  3.  3.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15 14  0 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 26. 30.  8.  5.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 29. 25. 29.  3.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[26.158491]
 [26.69774 ]
 [27.35372 ]
 [26.69774 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25. 29.  3.] 
cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  5.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [11. 14.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15 14  0 29] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 39.55048370361328



action possibilites: [-1] 
expected returns: [[33.075363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  3.  3.  0.] 
cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  4.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [11. 14.  0.  0. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15 14  0 29  6] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 27.35371971130371





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.221186]
 [31.571749]
 [30.068615]
 [32.9161  ]
 [32.991264]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29.  3.  3.  0.] 
cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 26. 30.  8.  4.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [11. 14.  0.  0. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15 14  0 29  6] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.07536315917969






Player: 1 
cards in hand: [11. 14.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  0.  0. 16.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6
  0  6 11 15 14  0 29  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  4.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0. 29. 29. 11.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10. 25.  0. 29. 29.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [6. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  4.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0. 29. 29. 11.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10. 25.  0. 29. 29.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [6. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 26. 30.  8.  4.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0. 29. 29. 11.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10. 25.  0. 29. 29.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [6. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 26. 30.  8.  4.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0. 29. 29. 11.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10. 25.  0. 29. 29.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10.  0. 29. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29. 11.] 
expected returns: [[23.4262  ]
 [22.844118]
 [23.97203 ]
 [23.97203 ]
 [23.704956]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 29. 11.] 
cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10. 25.  0. 29. 29.  3.
  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  4.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [14. 10.  0. 14.  0.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.99126434326172



action possibilites: [-1. 29. 11. 25.] 
expected returns: [[21.410116]
 [21.949265]
 [21.685453]
 [22.605124]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 25.] 
cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10. 25.  0. 29. 29.  3.
  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  4.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [14. 10.  0. 14.  0.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.495363235473633



action possibilites: [-1] 
expected returns: [[26.455202]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 10. 10.] 
cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10. 25.  0. 29. 29.  3.
  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [14. 10.  0. 14.  0.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.60512351989746





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.564798]
 [24.937244]
 [23.340296]
 [26.365519]
 [26.445385]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11. 10. 10.] 
cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10. 25.  0. 29. 29.  3.
  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 26. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [14. 10.  0. 14.  0.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.455202102661133






Player: 1 
cards in hand: [14. 10.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0. 14.  0.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [11. 29. 10. 10. 11.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10. 25.  0. 29. 29.  3.
  3.  0. 10. 29. 25.  0. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1. 14. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 14.  0.  3.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [11. 29. 10. 10. 11.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10. 25.  0. 29. 29.  3.
  3.  0. 10. 29. 25.  0. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 14.  0.  3.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 26. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [11. 29. 10. 10. 11.] 
adversary cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10. 25.  0. 29. 29.  3.
  3.  0. 10. 29. 25.  0. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11. 29. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 10. 11.] 
expected returns: [[26.603477]
 [26.896059]
 [27.17637 ]
 [25.992517]
 [25.992517]
 [26.896059]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10. 10. 11.] 
cards in discard: [ 3. 11. 29.  0. 10.  0. 10. 15. 11. 10.  0.  0. 10. 25.  0. 29. 29.  3.
  3.  0. 10. 29. 25.  0. 29. 11. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [29.  3.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.445384979248047



action possibilites: [-1. 11. 10. 10. 11.] 
expected returns: [[38.728283]
 [39.026215]
 [38.1061  ]
 [38.1061  ]
 [39.026215]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 11.] 
cards in discard: [29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  7.] 
adversary cards in hand: [29.  3.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 25.626432418823242



action possibilites: [-1] 
expected returns: [[36.75302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [29. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [29.  3.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 39.37877655029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.905323]
 [33.65838 ]
 [36.820427]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11.] 
cards in discard: [29. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [29.  3.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.753021240234375






Player: 1 
cards in hand: [29.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0. 11.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11. 11. 10. 25.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11. 11. 10. 25.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 25. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11. 11. 10. 25.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6  3  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11. 11. 10. 25.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10. 25.] 
expected returns: [[37.54085 ]
 [37.833435]
 [37.833435]
 [36.92989 ]
 [38.810677]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 10. 25.] 
cards in discard: [29. 15. 29. 11. 10. 10. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  3.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  3.  3. 15.  1.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3. 11. 29.
  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6  3  3] -> size -> 36 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 36.8204231262207



action possibilites: [-1] 
expected returns: [[28.206236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 10. 29.  0.] 
cards in discard: [29. 15. 29. 11. 10. 10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  2.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  3.  3. 15.  1.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3. 11. 29.
  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6  3  3  6] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 38.81067657470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.470556]
 [26.829037]
 [25.298862]
 [28.203722]
 [28.280571]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11. 10. 29.  0.] 
cards in discard: [29. 15. 29. 11. 10. 10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 24. 30.  8.  2.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  3.  3. 15.  1.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3. 11. 29.
  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6  3  3  6] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.206235885620117






Player: 1 
cards in hand: [ 8.  3.  3. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 15.  1.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3. 11. 29.
  3.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0
  6 11 15 14  0 29  6  0  0  6  3  3  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  2.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29.  3. 25. 10.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3. 11. 29.
  3.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11
 15 14  0 29  6  0  0  6  3  3  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  2.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29.  3. 25. 10.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3. 11. 29.
  3.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11
 15 14  0 29  6  0  0  6  3  3  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 24. 30.  8.  2.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29.  3. 25. 10.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10.] 
expected returns: [[28.039606]
 [28.58544 ]
 [29.249424]
 [27.457525]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 25. 10.] 
cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  2.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  6.  6. 29.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3. 11. 29.
  3.  0.  0.  6.  8. 15.  1.] 
adversary owned cards: [ 0  0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11
 15 14  0 29  6  0  0  6  3  3  6] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.28057289123535



action possibilites: [-1] 
expected returns: [[23.109446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 10. 10.  0.] 
cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  6.  6. 29.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3. 11. 29.
  3.  0.  0.  6.  8. 15.  1.  6.] 
adversary owned cards: [ 0  0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11
 15 14  0 29  6  0  0  6  3  3  6  6] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.24942398071289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.520105]
 [21.859648]
 [20.403734]
 [23.16179 ]
 [23.234608]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 10. 10.  0.] 
cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  6.  6. 29.] 
adversary cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3. 11. 29.
  3.  0.  0.  6.  8. 15.  1.  6.] 
adversary owned cards: [ 0  0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11
 15 14  0 29  6  0  0  6  3  3  6  6] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.109445571899414






Player: 1 
cards in hand: [ 0. 11.  6.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  6. 29.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3. 11. 29.
  3.  0.  0.  6.  8. 15.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11
 15 14  0 29  6  0  0  6  3  3  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [10.  3. 10. 10. 11.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  6.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3. 11. 29.
  3.  0.  0.  6.  8. 15.  1.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11
 15 14  0 29  6  0  0  6  3  3  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  6.] 
adversary cards in hand: [10.  3. 10. 10. 11.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3. 11. 29.
  3.  0.  0.  6.  8. 15.  1.  6.  6. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11
 15 14  0 29  6  0  0  6  3  3  6  6 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  5.] 
adversary cards in hand: [10.  3. 10. 10. 11.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [ 6.  0.  0. 16. 11.  0.  0.  6. 10. 14.  0. 14.  0.  3.  3.  3. 11. 29.
  3.  0.  0.  6.  8. 15.  1.  6.  6. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11
 15 14  0 29  6  0  0  6  3  3  6  6 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  5.] 
adversary cards in hand: [10.  3. 10. 10. 11.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [10.  3. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 11.] 
expected returns: [[23.592512]
 [23.01755 ]
 [23.01755 ]
 [23.01755 ]
 [23.867847]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 10. 11.] 
cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  5.] 
adversary cards in hand: [ 6. 15.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11
 15 14  0 29  6  0  0  6  3  3  6  6 15] -> size -> 37 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 23.23460578918457



action possibilites: [-1] 
expected returns: [[20.752676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 10.] 
cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 6. 15.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11
 15 14  0 29  6  0  0  6  3  3  6  6 15] -> size -> 37 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 24.368741989135742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.976784]
 [17.810158]
 [20.768454]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10. 10.] 
cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 6. 15.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11
 15 14  0 29  6  0  0  6  3  3  6  6 15] -> size -> 37 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.752676010131836






Player: 1 
cards in hand: [ 6. 15.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11
 15 14  0 29  6  0  0  6  3  3  6  6 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  0.  3. 29.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0. 15. 11. 10.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  0.  3. 29.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0. 15. 11. 10.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  0.  3. 29.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0. 15. 11. 10.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  3.] 
adversary cards in hand: [10.  0.  0.  3. 29.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0. 15. 11. 10.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[21.996626]
 [21.428675]
 [22.529188]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3. 29.] 
cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0. 15. 11. 10.  3. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 6. 29.  0. 11.  6.] 
adversary cards in discard: [15. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15] -> size -> 37 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.76845359802246



action possibilites: [-1. 10.] 
expected returns: [[22.351921]
 [21.776958]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0. 15. 11. 10.  3. 10. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 6. 29.  0. 11.  6.] 
adversary cards in discard: [15. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15] -> size -> 37 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.088403701782227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[20.595057]
 [21.4439  ]
 [20.944094]
 [19.460966]
 [21.013466]
 [22.63868 ]
 [22.288189]
 [22.902493]
 [21.132524]
 [21.98282 ]
 [22.363342]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0. 15. 11. 10.  3. 10. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  2.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 6. 29.  0. 11.  6.] 
adversary cards in discard: [15. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15] -> size -> 37 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.351919174194336



buy possibilites: [-1] 
expected returns: [[23.077261]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [29. 15. 29. 11. 10. 10. 11. 25.  0. 11. 11. 10. 29.  0. 25.  0. 29.  3.
 10. 10.  0. 15. 11. 10.  3. 10. 10.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 6. 29.  0. 11.  6.] 
adversary cards in discard: [15. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15] -> size -> 37 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0 32  0] 
sum of rewards: 46 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 22.902490615844727






Player: 1 
cards in hand: [ 6. 29.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0. 11.  6.] 
cards in discard: [15. 15.  6.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  7. 10.  0. 10.  3.] 
adversary cards in hand: [15. 11. 10. 29. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29] -> size -> 36 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  0. 11.  6.] 
cards in discard: [15. 15.  6.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  7. 10.  0. 10.  3.] 
adversary cards in hand: [15. 11. 10. 29. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29] -> size -> 36 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  0. 11.  6.] 
cards in discard: [15. 15.  6.  3.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  7. 10.  0. 10.  3.] 
adversary cards in hand: [15. 11. 10. 29. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29] -> size -> 36 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [15. 11. 10. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10. 29. 15.] 
expected returns: [[33.241024]
 [32.82926 ]
 [33.538956]
 [32.618835]
 [33.824455]
 [32.82926 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 10. 29. 15.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 6.  0.  0. 11.  6.] 
adversary cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0] -> size -> 38 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.077260971069336



action possibilites: [-1. 15. 11. 10. 15.] 
expected returns: [[41.210327]
 [40.79856 ]
 [41.508255]
 [40.588135]
 [40.79856 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 10. 15.] 
cards in discard: [3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 6.  0.  0. 11.  6.] 
adversary cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0] -> size -> 38 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 32.24604415893555



action possibilites: [-1] 
expected returns: [[38.96628]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 15.] 
cards in discard: [ 3. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  7. 10.  0. 10.  2.] 
adversary cards in hand: [ 6.  0.  0. 11.  6.] 
adversary cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0] -> size -> 38 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -2  0  0 16  0] 
sum of rewards: 49 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.049095153808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.116943]
 [35.87    ]
 [39.032043]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 15.] 
cards in discard: [ 3. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  7. 10.  0. 10.  2.] 
adversary cards in hand: [ 6.  0.  0. 11.  6.] 
adversary cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0] -> size -> 38 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.96628189086914






Player: 1 
cards in hand: [ 6.  0.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.  6.] 
cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  7. 10.  0. 10.  2.] 
adversary cards in hand: [10.  0. 11. 10. 10.] 
adversary cards in discard: [ 3. 15. 29. 11. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15] -> size -> 37 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  6. 10.  0. 10.  2.] 
adversary cards in hand: [10.  0. 11. 10. 10.] 
adversary cards in discard: [ 3. 15. 29. 11. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15] -> size -> 37 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  6. 10.  0. 10.  2.] 
adversary cards in hand: [10.  0. 11. 10. 10.] 
adversary cards in discard: [ 3. 15. 29. 11. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15] -> size -> 37 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  6. 10.  0. 10.  2.] 
adversary cards in hand: [10.  0. 11. 10. 10.] 
adversary cards in discard: [ 3. 15. 29. 11. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15] -> size -> 37 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [10.  0. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 10.] 
expected returns: [[31.737978]
 [31.127018]
 [32.03056 ]
 [31.127018]
 [31.127018]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10. 10.] 
cards in discard: [ 3. 15. 29. 11. 15. 10. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  6. 10.  0. 10.  2.] 
adversary cards in hand: [ 6.  0. 29. 10.  0.] 
adversary cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0] -> size -> 40 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 39.03204345703125



action possibilites: [-1] 
expected returns: [[33.11353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [ 6.  0. 29. 10.  0.] 
adversary cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0] -> size -> 40 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0 16  0] 
sum of rewards: 28 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.56165313720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.441843]
 [30.27038 ]
 [33.251858]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [ 6.  0. 29. 10.  0.] 
adversary cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0] -> size -> 40 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.113529205322266






Player: 1 
cards in hand: [ 6.  0. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29. 10.  0.] 
cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [25. 10. 10. 25.  0.] 
adversary cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  3.] 
cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [25. 10. 10. 25.  0.] 
adversary cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0] -> size -> 40 
action values: 2 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [25. 10. 10. 25.  0.] 
adversary cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [25. 10. 10. 25.  0.] 
adversary cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [25. 10. 10. 25.  0.] 
adversary cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [25. 10. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10. 25.] 
expected returns: [[22.820154]
 [23.989983]
 [22.25757 ]
 [22.25757 ]
 [23.989983]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 10. 25.  0.] 
cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  1.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [14. 11.  0.  3.  0.] 
adversary cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.  1. 29. 10.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0  1] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.25185775756836



action possibilites: [-1] 
expected returns: [[24.504366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 25.  0.  0. 29.] 
cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  0.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [14. 11.  0.  3.  0.] 
adversary cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.  1. 29. 10.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0  1  6] -> size -> 42 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 23.989980697631836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[22.876558]
 [23.2161  ]
 [24.530783]
 [24.604345]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 25.  0.  0. 29.] 
cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 24. 30.  8.  0.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [14. 11.  0.  3.  0.] 
adversary cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.  1. 29. 10.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0  1  6] -> size -> 42 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.504365921020508






Player: 1 
cards in hand: [14. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  0.  3.  0.] 
cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.  1. 29. 10.  6.  0.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0  1  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  0.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [10. 11. 11.  0. 29.] 
adversary cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10. 25. 10. 10. 25.  0.
  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0.] 
cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.  1. 29. 10.  6.  0.  3.  0.  6.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0  1  6  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  0.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [10. 11. 11.  0. 29.] 
adversary cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10. 25. 10. 10. 25.  0.
  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.] 
cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.  1. 29. 10.  6.  0.  3.  0.  6.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0  1  6  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 24. 30.  8.  0.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [10. 11. 11.  0. 29.] 
adversary cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10. 25. 10. 10. 25.  0.
  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.] 
cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.  1. 29. 10.  6.  0.  3.  0.  6.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0  1  6  1  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  0.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [10. 11. 11.  0. 29.] 
adversary cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10. 25. 10. 10. 25.  0.
  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10. 11. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 29.] 
expected returns: [[21.788   ]
 [21.21304 ]
 [22.063337]
 [22.063337]
 [22.327154]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0. 29.] 
cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10. 25. 10. 10. 25.  0.
  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  0.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  0. 14.  6.  1.] 
adversary cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.  1. 29. 10.  6.  0.  3.  0.  6.  1.  3. 11. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0  1  6  1  3] -> size -> 44 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.604345321655273



action possibilites: [-1. 10. 11.] 
expected returns: [[23.823742]
 [23.225836]
 [24.110033]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.] 
cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10. 25. 10. 10. 25.  0.
  0. 29. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 23. 30.  8.  0.  8.  2.  9.  8.  1.  6. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  0. 14.  6.  1.] 
adversary cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.  1. 29. 10.  6.  0.  3.  0.  6.  1.  3. 11. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0  1  6  1  3] -> size -> 44 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.868558883666992



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 0 
Witch: 2 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  3.] 
cards in discard: [ 3. 15. 29. 11. 15. 10. 15. 15. 11. 10.  0. 10. 10. 25. 10. 10. 25.  0.
  0. 29. 11.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 11 11 10 11 10 29 10 10 10 29 10 11 10
 29 10 29 10 29 25 29 11 15 15 15 29 15 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 23. 30.  8.  0.  8.  2.  9.  8.  1.  6. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0. 14.  6.  1.] 
adversary cards in discard: [15. 15.  6.  3.  0.  0.  6. 29.  0. 11.  6. 14.  0. 11.  6.  0.  0.  6.
  0.  1. 29. 10.  6.  0.  3.  0.  6.  1.  3. 11. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0 11  0 29  8 14  1  3 16  0  3  6 11  0  3 10 15  6  0  6 11 15
 14  0 29  6  0  0  6  3  3  6  6 15 15  0 14  0  1  6  1  3] -> size -> 44 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5 500   0   0   0   0  40   0   0   0   0  -4   0   0  16   0] 
sum of rewards: 547 

action type: gain_card_n - action 8
Learning step: 15.697633743286133
desired expected reward: 39.44320297241211



