 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[110.625046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -450        0        0       20        0
        0        0        0        0        0        0       27        0] 
sum of rewards: -3000408 

action type: buy - action 11.0
Learning step: -120015.6796875
desired expected reward: -120031.734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[104.79968 ]
 [107.443016]
 [ 90.80769 ]
 [112.48319 ]
 [109.58167 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 111.28857421875



buy possibilites: [-1] 
expected returns: [[107.64421]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 112.48318481445312






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[113.574455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 107.64421081542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[108.35987 ]
 [115.744835]
 [110.86685 ]
 [100.561584]
 [ 96.164696]
 [113.5155  ]
 [117.99039 ]
 [115.48338 ]
 [128.02399 ]
 [119.97471 ]
 [102.648964]
 [108.00018 ]
 [110.605415]
 [100.83654 ]
 [109.9411  ]
 [113.304245]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.02949523925781



buy possibilites: [-1] 
expected returns: [[109.132774]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  3.  0.  3.  3.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 128.0239715576172






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[99.82644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.13277435302734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 94.35067 ]
 [101.61619 ]
 [ 96.95174 ]
 [ 82.17207 ]
 [ 99.32425 ]
 [104.0352  ]
 [101.28993 ]
 [106.00676 ]
 [ 88.989174]
 [ 96.63553 ]
 [ 96.12309 ]
 [100.46832 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 101.09553527832031



buy possibilites: [-1] 
expected returns: [[135.61797]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 106.00675201416016






Player: 1 
cards in hand: [29.  1.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 25.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 25.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  3.  3.  0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 25.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[112.15557]
 [114.37256]
 [126.08797]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 25.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 29.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 135.6179656982422



action possibilites: [-1] 
expected returns: [[100.359436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9. 10. 10.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 29.  1.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 127.15744018554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 93.62566 ]
 [101.45206 ]
 [ 96.3364  ]
 [ 80.01723 ]
 [103.856415]
 [101.14567 ]
 [ 96.03001 ]
 [ 99.25788 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8.  9. 10. 10.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 29.  1.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.35943603515625



buy possibilites: [-1] 
expected returns: [[135.34212]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9. 10.  9.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 29.  1.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 103.85641479492188






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1. 29.  1.  3.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9. 10.  9.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1. 29.  1.  3.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8.  9. 10.  9.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1. 29.  1.  3.  3.  0.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[108.410576]
 [109.31621 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 135.3421173095703



action possibilites: [-1] 
expected returns: [[127.12628]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 117.25543212890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[117.48401 ]
 [124.84743 ]
 [120.224945]
 [105.54391 ]
 [127.2348  ]
 [124.49385 ]
 [119.87137 ]
 [124.58493 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.12628173828125



buy possibilites: [-1] 
expected returns: [[121.917145]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9. 10.  7.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 127.23480224609375






Player: 1 
cards in hand: [1. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9. 10.  7.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  0.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11] -> size -> 14 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 28. 30. 30. 30.  8.  9. 10.  7.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  0.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11] -> size -> 14 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 29.  8.  9. 10.  7.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  0.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11] -> size -> 14 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[106.46431]
 [122.8381 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  0.  3.] 
cards in discard: [11.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8.  9. 10.  7.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [4. 1. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 121.91714477539062



action possibilites: [-1] 
expected returns: [[104.0328]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 11.  0.] 
cards in discard: [11.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8.  8. 10.  7.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [4. 1. 1. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 124.18356323242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[102.83195 ]
 [111.56928 ]
 [105.60348 ]
 [ 88.54267 ]
 [114.58656 ]
 [111.176544]
 [105.323875]
 [109.82662 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 11.  0.] 
cards in discard: [11.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 29.  8.  8. 10.  7.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [4. 1. 1. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 104.03279876708984



buy possibilites: [-1] 
expected returns: [[122.68682]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 11.  0.] 
cards in discard: [11.  8.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8.  8. 10.  6.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [4. 1. 1. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: -21 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 114.5865707397461






Player: 1 
cards in hand: [ 3.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [4. 1. 1. 0. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8.  8. 10.  6.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11] -> size -> 15 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [4. 1. 1. 0. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 29.  8.  8. 10.  6.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11] -> size -> 15 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [4. 1. 1. 0. 0. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 30. 29.  8.  8. 10.  6.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11] -> size -> 15 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11. 11. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 29.] 
expected returns: [[106.05592]
 [108.40314]
 [108.40314]
 [108.40314]
 [109.9864 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 29.  8.  8. 10.  6.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3.  6.] 
adversary cards in discard: [ 4.  1.  1.  0.  0.  0.  6.  0.  3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.68682098388672



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[87.86235]
 [91.83617]
 [91.83617]
 [91.83617]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 29.  8.  8. 10.  6.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3.  6.] 
adversary cards in discard: [ 4.  1.  1.  0.  0.  0.  6.  0.  3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 110.41645812988281



action possibilites: [-1] 
expected returns: [[101.635574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 29.  8.  8. 10.  6.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3.  6.] 
adversary cards in discard: [ 4.  1.  1.  0.  0.  0.  6.  0.  3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 97.11050415039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 96.28444 ]
 [102.76156 ]
 [ 98.78135 ]
 [ 85.475845]
 [105.04552 ]
 [102.42716 ]
 [ 98.45311 ]
 [103.04605 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 29.  8.  8. 10.  6.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3.  6.] 
adversary cards in discard: [ 4.  1.  1.  0.  0.  0.  6.  0.  3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.63557434082031



buy possibilites: [-1] 
expected returns: [[130.37744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 29.  8.  8. 10.  5.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3.  6.] 
adversary cards in discard: [ 4.  1.  1.  0.  0.  0.  6.  0.  3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 29 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 105.04550170898438






Player: 1 
cards in hand: [ 3.  0. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.  6.] 
cards in discard: [ 4.  1.  1.  0.  0.  0.  6.  0.  3.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 29.  8.  8. 10.  5.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  0.  8.] 
adversary cards in discard: [10. 11. 29. 11. 11. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11] -> size -> 17 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  3.  6.] 
cards in discard: [ 4.  1.  1.  0.  0.  0.  6.  0.  3.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 30. 29.  8.  8. 10.  5.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  0.  8.] 
adversary cards in discard: [10. 11. 29. 11. 11. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11] -> size -> 17 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  3.  6.] 
cards in discard: [ 4.  1.  1.  0.  0.  0.  6.  0.  3.  0.  0.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 29.  8.  8. 10.  5.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  0.  8.] 
adversary cards in discard: [10. 11. 29. 11. 11. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11] -> size -> 17 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 25.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[112.73218 ]
 [124.765686]
 [113.78519 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  0.  8.] 
cards in discard: [10. 11. 29. 11. 11. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  8. 10.  5.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 130.37744140625



action possibilites: [-1] 
expected returns: [[92.9095]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 3. 0.] 
cards in discard: [10. 11. 29. 11. 11. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  5.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 1. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 124.13392639160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 91.49903 ]
 [ 98.763855]
 [ 94.00985 ]
 [ 77.82657 ]
 [101.14417 ]
 [ 98.43752 ]
 [ 93.70998 ]
 [ 97.550766]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 3. 0.] 
cards in discard: [10. 11. 29. 11. 11. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  5.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 1. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.90950012207031



buy possibilites: [-1] 
expected returns: [[116.43121]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 3. 0.] 
cards in discard: [10. 11. 29. 11. 11. 11.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  4.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 1. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 101.14415740966797






Player: 1 
cards in hand: [0. 0. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 1. 0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  4.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11] -> size -> 18 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1. 0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  4.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11] -> size -> 18 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1. 0.] 
cards in discard: [ 6. 22.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  4.  9.  9.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11] -> size -> 18 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[110.14159]
 [112.0174 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  4.  9.  9.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [29.  3.  0.  6.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 116.43121337890625



action possibilites: [-1] 
expected returns: [[111.699875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  4.  9.  9.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  3.  0.  6.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 114.98699951171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[107.9075  ]
 [113.463394]
 [109.899254]
 [ 99.58191 ]
 [115.23268 ]
 [113.24093 ]
 [109.67678 ]
 [112.37736 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  4.  9.  9.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  3.  0.  6.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 111.69987487792969



buy possibilites: [-1] 
expected returns: [[109.483185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  9.  9.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  3.  0.  6.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 115.232666015625






Player: 1 
cards in hand: [29.  3.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  6.  0.] 
cards in discard: [ 6. 22.  0.  0.  6.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  9.  9.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  0. 10.  3.  0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11] -> size -> 20 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [ 6. 22.  0.  0.  6.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  9.  9.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  0. 10.  3.  0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11] -> size -> 20 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [ 6. 22.  0.  0.  6.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  9.  9.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  0. 10.  3.  0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11] -> size -> 20 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[133.7435 ]
 [137.20264]
 [128.83353]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  3.  0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  9.  9.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.  4.  1.] 
adversary cards in discard: [ 6. 22.  0.  0.  6.  1.  0. 29.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.48318481445312



action possibilites: [-1] 
expected returns: [[115.19491]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  9.  9.  8. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.  4.  1.] 
adversary cards in discard: [ 6. 22.  0.  0.  6.  1.  0. 29.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 139.33184814453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[112.888985]
 [115.48021 ]
 [100.46559 ]
 [119.98211 ]
 [118.41187 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  9.  9.  8. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.  4.  1.] 
adversary cards in discard: [ 6. 22.  0.  0.  6.  1.  0. 29.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.19490814208984



buy possibilites: [-1] 
expected returns: [[134.27982]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  8.  9.  8. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.  4.  1.] 
adversary cards in discard: [ 6. 22.  0.  0.  6.  1.  0. 29.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 119.98212432861328






Player: 1 
cards in hand: [ 3. 11.  0.  4.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  4.  1.] 
cards in discard: [ 6. 22.  0.  0.  6.  1.  0. 29.  3.  0.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  8.  9.  8. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 8.  0. 11.  0. 11.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  8. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  4.  1.] 
cards in discard: [ 6. 22.  0.  0.  6.  1.  0. 29.  3.  0.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  8.  9.  8. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 8.  0. 11.  0. 11.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  8. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  4.  1.] 
cards in discard: [ 6. 22.  0.  0.  6.  1.  0. 29.  3.  0.  6.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  7.  9.  8. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 8.  0. 11.  0. 11.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  8. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[110.69574]
 [112.25433]
 [115.07208]
 [115.07208]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0. 11.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  8. 11.  0. 10.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  7.  9.  8. 10. 10.  7.  9. 10.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.27981567382812



action possibilites: [-1] 
expected returns: [[163.71373]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  8. 11.  0. 10.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  7.  9.  8. 10. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 119.65980529785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[159.29738]
 [162.00633]
 [146.19797]
 [166.2901 ]
 [166.58023]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  8. 11.  0. 10.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  7.  9.  8. 10. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.71372985839844






Player: 1 
cards in hand: [29.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  7.  9.  8. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11. 11. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10] -> size -> 23 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  7.  9.  8. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11. 11. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10] -> size -> 23 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  3.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  6.  9.  8. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11. 11. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10] -> size -> 23 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29. 25.] 
expected returns: [[114.87764]
 [117.56474]
 [117.56474]
 [119.04383]
 [125.23245]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 29. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  3.  6.  9.  8. 10. 10.  6.  9. 10.] 
adversary cards in hand: [6. 0. 1. 0. 3.] 
adversary cards in discard: [ 8. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8  8] -> size -> 23 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 166.58023071289062



action possibilites: [-1] 
expected returns: [[115.88123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 29. 11. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8. 10. 10.  6.  9. 10.] 
adversary cards in hand: [6. 0. 1. 0. 3.] 
adversary cards in discard: [ 8. 29.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8  8  6] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 122.75486755371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[114.7974 ]
 [105.02872]
 [118.54658]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11. 29. 11. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8. 10. 10.  6.  9. 10.] 
adversary cards in hand: [6. 0. 1. 0. 3.] 
adversary cards in discard: [ 8. 29.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8  8  6] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.88123321533203






Player: 1 
cards in hand: [6. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 0. 3.] 
cards in discard: [ 8. 29.  0.  0.  0.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8  8  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 10.  3. 11.  8.] 
adversary cards in discard: [25.  0. 11. 11. 29. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10] -> size -> 23 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 3.] 
cards in discard: [ 8. 29.  0.  0.  0.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8  8  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 10.  3. 11.  8.] 
adversary cards in discard: [25.  0. 11. 11. 29. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10] -> size -> 23 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 3.] 
cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8  8  6
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 10.  3. 11.  8.] 
adversary cards in discard: [25.  0. 11. 11. 29. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10] -> size -> 23 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
expected returns: [[114.100655]
 [110.20325 ]
 [117.0099  ]
 [114.48679 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11.  8.] 
cards in discard: [25.  0. 11. 11. 29. 11. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8.  9. 10.  6.  9. 10.] 
adversary cards in hand: [11.  4.  6.  1.  8.] 
adversary cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8  8  6
 14] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 118.54657745361328



action possibilites: [-1] 
expected returns: [[90.98001]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  8.] 
cards in discard: [25.  0. 11. 11. 29. 11. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11.  4.  6.  1.  8.] 
adversary cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8  8  6
 14] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 121.43821716308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[84.47106]
 [74.49332]
 [91.71776]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.] 
cards in discard: [25.  0. 11. 11. 29. 11. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11.  4.  6.  1.  8.] 
adversary cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8  8  6
 14] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.98001098632812






Player: 1 
cards in hand: [11.  4.  6.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  4.  6.  1.  8.] 
cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  6 11  4  6  0  0  6 22  8  8  6
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 11. 10.] 
adversary cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  4.  6.] 
cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 11. 10.] 
adversary cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  4.  6.] 
cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 11. 10.] 
adversary cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  4.  6.] 
cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 11. 10.] 
adversary cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[96.24675]
 [89.97062]
 [96.75084]
 [89.97062]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11. 10.] 
cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8.  9. 10.  5.  9. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.  0.  8. 11.  4.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 91.71774291992188



action possibilites: [-1] 
expected returns: [[98.29587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.  0.  8. 11.  4.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 101.01115417480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 94.84654 ]
 [ 97.1375  ]
 [ 85.03593 ]
 [100.711555]
 [100.42925 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 30. 29.  8.  6. 10.  3.  6.  9.  8.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.  0.  8. 11.  4.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 98.29586791992188



buy possibilites: [-1] 
expected returns: [[106.46156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.  0.  8. 11.  4.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 100.7115478515625






Player: 1 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.  0.  8. 11.  4.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0.  3.  0.  8.] 
adversary cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8. 10.  8. 11.  0.  0.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.  0.  8. 11.  4.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0.  3.  0.  8.] 
adversary cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8. 10.  8. 11.  0.  0.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 8. 29.  0.  0.  0.  3.  6. 14.  6.  0.  1.  0.  3.  0.  8. 11.  4.  6.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0.  3.  0.  8.] 
adversary cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8. 10.  8. 11.  0.  0.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[106.746895]
 [108.3413  ]
 [105.77879 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  8.] 
cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8. 10.  8. 11.  0.  0.
 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  8.  0. 22.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.46156311035156



action possibilites: [-1] 
expected returns: [[90.93204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8. 10.  8. 11.  0.  0.
 10. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  3.  9. 10.] 
adversary cards in hand: [ 0.  8.  0. 22.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 112.2900390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[83.320244]
 [85.669815]
 [73.801994]
 [89.01672 ]
 [90.491066]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [25.  0. 11. 11. 29. 11. 10. 10. 11.  0. 10.  3.  8. 10.  8. 11.  0.  0.
 10. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  3.  9. 10.] 
adversary cards in hand: [ 0.  8.  0. 22.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.93203735351562






Player: 1 
cards in hand: [ 0.  8.  0. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 22.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  3.  9. 10.] 
adversary cards in hand: [10. 11. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10] -> size -> 27 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  8.  4.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [22. 14.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  3.  9. 10.] 
adversary cards in hand: [10. 11. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10] -> size -> 27 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29.  8.  4.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [22. 14.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  3.  9. 10.] 
adversary cards in hand: [10. 11. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10] -> size -> 27 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29.  8.  4.  0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [22. 14.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  2.  9. 10.] 
adversary cards in hand: [10. 11. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10] -> size -> 27 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10. 11. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 10.] 
expected returns: [[90.38342 ]
 [86.516914]
 [93.78452 ]
 [86.516914]
 [86.516914]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  2.  9. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10] -> size -> 27 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 90.49107360839844



action possibilites: [-1] 
expected returns: [[99.65068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  0.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  1.  9. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10] -> size -> 27 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 96.16677856445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 91.38512]
 [ 79.3757 ]
 [100.13171]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  0.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  1.  9. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10] -> size -> 27 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.65068054199219






Player: 1 
cards in hand: [1. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  1.  9. 10.] 
adversary cards in hand: [ 0. 10. 11.  0. 11.] 
adversary cards in discard: [10. 11. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10] -> size -> 28 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  1.  9. 10.] 
adversary cards in hand: [ 0. 10. 11.  0. 11.] 
adversary cards in discard: [10. 11. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10] -> size -> 28 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0. 10. 11.  0. 11.] 
adversary cards in discard: [10. 11. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10] -> size -> 28 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[103.9272 ]
 [ 99.29312]
 [105.84152]
 [105.84152]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0. 11.] 
cards in discard: [10. 11. 10. 10. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  0.  9. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0. 10.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 100.13169860839844



action possibilites: [-1] 
expected returns: [[133.98174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [10. 11. 10. 10. 10.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  0.  9.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0. 10.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 110.02081298828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[130.97214 ]
 [133.07976 ]
 [121.271805]
 [136.4207  ]
 [136.0043  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [10. 11. 10. 10. 10.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  5.  9.  8.  9. 10.  0.  9.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0. 10.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 133.9817352294922



buy possibilites: [-1] 
expected returns: [[116.01936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [10. 11. 10. 10. 10.  0. 15.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0. 10.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 136.4207000732422






Player: 1 
cards in hand: [6. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0. 10.  1.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10.  8.  0. 10. 11.] 
adversary cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8] -> size -> 30 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0. 10.  1.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10.  8.  0. 10. 11.] 
adversary cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8] -> size -> 30 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0. 10.  1.  3.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10.  8.  0. 10. 11.] 
adversary cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8] -> size -> 30 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10.  8.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 11.] 
expected returns: [[151.1893 ]
 [145.4106 ]
 [150.68225]
 [145.4106 ]
 [153.94835]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 10. 11.] 
cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  9.] 
adversary cards in hand: [11.  0.  6.  6.  3.] 
adversary cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0. 10.  1.  3.  0.  0.  0.  0.
  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0] -> size -> 29 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 116.01936340332031



action possibilites: [-1] 
expected returns: [[91.50794]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 10.] 
cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  8.] 
adversary cards in hand: [11.  0.  6.  6.  3.] 
adversary cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0. 10.  1.  3.  0.  0.  0.  0.
  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0] -> size -> 29 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 159.24008178710938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[86.80727 ]
 [74.575806]
 [92.75133 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 10.] 
cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  8.] 
adversary cards in hand: [11.  0.  6.  6.  3.] 
adversary cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0. 10.  1.  3.  0.  0.  0.  0.
  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0] -> size -> 29 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.50794219970703






Player: 1 
cards in hand: [11.  0.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  6.  3.] 
cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0. 10.  1.  3.  0.  0.  0.  0.
  6.  0.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  8.] 
adversary cards in hand: [11. 10. 29.  8.  8.] 
adversary cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11. 15. 11. 10.  8.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15] -> size -> 31 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  6.  3.] 
cards in discard: [10. 22. 14.  8.  0.  0.  3. 29.  8.  4.  0. 10.  1.  3.  0.  0.  0.  0.
  6.  0.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  8.] 
adversary cards in hand: [11. 10. 29.  8.  8.] 
adversary cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11. 15. 11. 10.  8.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15] -> size -> 31 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11. 10. 29.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.  8.  8.] 
expected returns: [[118.0318 ]
 [119.05066]
 [110.90742]
 [121.06925]
 [115.73372]
 [115.73372]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  8.  8.] 
cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11. 15. 11. 10.  8.  0.
 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 1.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0] -> size -> 29 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.75132751464844



action possibilites: [-1. 11. 10.  8. 11.] 
expected returns: [[ 97.606064]
 [100.05615 ]
 [ 92.26573 ]
 [ 97.064896]
 [100.05615 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8. 11.] 
cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11. 15. 11. 10.  8.  0.
 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 1.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0] -> size -> 29 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 116.21669006347656



action possibilites: [-1] 
expected returns: [[138.84239]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.] 
cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11. 15. 11. 10.  8.  0.
 10.  8. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 1.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0] -> size -> 29 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 104.85530090332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[129.91254]
 [120.2457 ]
 [138.5679 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.] 
cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11. 15. 11. 10.  8.  0.
 10.  8. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 1.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0] -> size -> 29 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 138.84239196777344






Player: 1 
cards in hand: [ 1.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 3. 25.  3.  0.  0.] 
adversary cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11. 15. 11. 10.  8.  0.
 10.  8. 15. 29. 11. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  3.  4.  9.  8.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 3. 25.  3.  0.  0.] 
adversary cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11. 15. 11. 10.  8.  0.
 10.  8. 15. 29. 11. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 10.  0.] 
cards in discard: [11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  2.  4.  9.  8.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 3. 25.  3.  0.  0.] 
adversary cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11. 15. 11. 10.  8.  0.
 10.  8. 15. 29. 11. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[124.70032]
 [133.82408]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3.  0.  0.] 
cards in discard: [10. 11. 10. 10. 10.  0. 15.  8. 11.  0. 10.  0. 11. 15. 11. 10.  8.  0.
 10.  8. 15. 29. 11. 10.  8. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  6. 10.  2.  4.  9.  8.  9. 10.  0.  9.  7.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [11.  1.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 138.56793212890625



action possibilites: [-1] 
expected returns: [[64.19939]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  2.  4.  9.  8.  9. 10.  0.  9.  7.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [11.  1.  3.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 133.82406616210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[59.970184]
 [65.057495]
 [61.885414]
 [51.177864]
 [66.95076 ]
 [64.77406 ]
 [65.47801 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  2.  4.  9.  8.  9. 10.  0.  9.  7.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [11.  1.  3.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.19938659667969



buy possibilites: [-1] 
expected returns: [[101.55516]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 11.  0.] 
cards in discard: [11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  7.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [11.  1.  3.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 66.95075988769531






Player: 1 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [11.  1.  3.  0. 10.  0.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  7.] 
adversary cards in hand: [10. 11.  0. 10.  8.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11] -> size -> 33 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [11.  1.  3.  0. 10.  0.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  7.] 
adversary cards in hand: [10. 11.  0. 10.  8.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11] -> size -> 33 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  6.] 
adversary cards in hand: [10. 11.  0. 10.  8.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11] -> size -> 33 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10. 11.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.  8.] 
expected returns: [[146.72478]
 [141.66875]
 [147.96605]
 [141.66875]
 [145.35773]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10.  8.] 
cards in discard: [11. 25.  3.  3.  0.  0. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 3.  6. 10. 14.  8.] 
adversary cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 101.55516052246094



action possibilites: [-1] 
expected returns: [[154.32683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8.] 
cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 3.  6. 10. 14.  8.] 
adversary cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 151.9868927001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[147.38235]
 [138.80435]
 [154.32584]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  8.] 
cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 3.  6. 10. 14.  8.] 
adversary cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 154.3268280029297






Player: 1 
cards in hand: [ 3.  6. 10. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10. 14.  8.] 
cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.  6.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [11. 15. 11. 11. 10.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15] -> size -> 34 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 14.  8.  6.] 
cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.  6.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [11. 15. 11. 11. 10.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15] -> size -> 34 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 14.  8.  6.] 
cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.  6.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15] -> size -> 32 
action values: 2 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [11. 15. 11. 11. 10.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15] -> size -> 34 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11. 15. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11. 11. 10.] 
expected returns: [[155.78506]
 [156.95163]
 [150.29755]
 [156.95163]
 [156.95163]
 [150.57129]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 11. 11. 10.] 
cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [22.  8.  4.  0.  0.] 
adversary cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.  6.  0.  0.  0.  0. 10.  3.  6. 14.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 154.3258514404297



action possibilites: [-1] 
expected returns: [[165.48018]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 11. 10.] 
cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  4.] 
adversary cards in hand: [22.  8.  4.  0.  0.] 
adversary cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.  6.  0.  0.  0.  0. 10.  3.  6. 14.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 160.77658081054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[156.86371]
 [143.52121]
 [166.13272]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 11. 10.] 
cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  4.] 
adversary cards in hand: [22.  8.  4.  0.  0.] 
adversary cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.  6.  0.  0.  0.  0. 10.  3.  6. 14.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 165.4801788330078






Player: 1 
cards in hand: [22.  8.  4.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  8.  4.  0.  0.] 
cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.  6.  0.  0.  0.  0. 10.  3.  6. 14.  8.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15.  0.  8.  8.  0.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15. 11. 15. 11.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 4. 0. 0. 0. 0. 0.] 
cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.  6.  0.  0.  0.  0. 10.  3.  6. 14.  8.
  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15.  0.  8.  8.  0.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15. 11. 15. 11.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 4. 0. 0. 0. 0. 0.] 
cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.  6.  0.  0.  0.  0. 10.  3.  6. 14.  8.
  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  8.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15.  0.  8.  8.  0.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15. 11. 15. 11.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 4. 0. 0. 0. 0. 0.] 
cards in discard: [11.  1.  3.  0. 10.  0.  6. 15.  6.  0.  0.  0.  0. 10.  3.  6. 14.  8.
  6. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15.  0.  8.  8.  0.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15. 11. 15. 11.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [15.  0.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
expected returns: [[152.82437]
 [145.89024]
 [151.55075]
 [151.55075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.  8.  0.] 
cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15. 11. 15. 11.
 11. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 6. 29.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 166.1327362060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[145.3573 ]
 [148.743  ]
 [130.16933]
 [153.49712]
 [154.77072]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  8.  8.  0.] 
cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15. 11. 15. 11.
 11. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 6. 29.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 152.8243408203125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6. 29.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [10. 10. 29. 10.  0.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15. 11. 15. 11.
 11. 10. 15.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 0.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [10. 10. 29. 10.  0.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15. 11. 15. 11.
 11. 10. 15.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 0.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [10. 10. 29. 10.  0.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15. 11. 15. 11.
 11. 10. 15.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10. 10. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 10.] 
expected returns: [[151.38805]
 [144.84952]
 [144.84952]
 [153.14804]
 [144.84952]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29. 10.  0.] 
cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15. 11. 15. 11.
 11. 10. 15.  0.  8.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [10.  0.  6.  0.  1.] 
adversary cards in discard: [ 0. 29.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 154.77073669433594



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[157.7612 ]
 [151.05508]
 [151.05508]
 [151.05508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  0.] 
cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15. 11. 15. 11.
 11. 10. 15.  0.  8.  8.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [10.  0.  6.  0.  1.] 
adversary cards in discard: [ 0. 29.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 149.1002197265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[147.21748]
 [150.10353]
 [136.52606]
 [154.3886 ]
 [156.31087]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  0.] 
cards in discard: [11. 25.  3.  3.  0.  0. 11.  0. 15. 11. 10.  0. 10.  8. 15. 11. 15. 11.
 11. 10. 15.  0.  8.  8.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [10.  0.  6.  0.  1.] 
adversary cards in discard: [ 0. 29.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 157.76121520996094






Player: 1 
cards in hand: [10.  0.  6.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  0.  1.] 
cards in discard: [ 0. 29.  6.  6.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15. 15.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  0.  1.] 
cards in discard: [ 0. 29.  6.  6.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15. 15.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [15. 15.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.  8. 10. 10.] 
expected returns: [[130.30931]
 [125.90376]
 [125.90376]
 [129.94432]
 [126.25954]
 [126.25954]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  8. 10. 10.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [22. 10.  4.  0.  8.] 
adversary cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 156.3108673095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[124.286606]
 [114.13091 ]
 [130.33359 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  8. 10. 10.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [22. 10.  4.  0.  8.] 
adversary cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 130.30929565429688



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [22. 10.  4.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 10.  4.  0.  8.] 
cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 0.  3.  0. 10. 25.] 
adversary cards in discard: [15. 15.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  4.  0.  8.  0.  0.  3.] 
cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 0.  3.  0. 10. 25.] 
adversary cards in discard: [15. 15.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  4.  0.  8.  0.  0.  3.] 
cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 0.  3.  0. 10. 25.] 
adversary cards in discard: [15. 15.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  4.  0.  8.  0.  0.  3.] 
cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 0.  3.  0. 10. 25.] 
adversary cards in discard: [15. 15.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[111.40387]
 [106.23556]
 [119.9057 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 25.] 
cards in discard: [15. 15.  8. 10. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 30. 29.  8.  5. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29  1] -> size -> 34 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 130.33355712890625



action possibilites: [-1] 
expected returns: [[113.653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 10.  0.] 
cards in discard: [15. 15.  8. 10. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 30. 29.  8.  4. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29  1  6] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 119.90570068359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[106.72612 ]
 [114.195694]
 [109.629135]
 [ 94.59123 ]
 [116.71125 ]
 [113.808266]
 [114.59982 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10. 10.  0.] 
cards in discard: [15. 15.  8. 10. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 30. 29.  8.  4. 10.  1.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29  1  6] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 113.65299987792969



buy possibilites: [-1] 
expected returns: [[123.36477]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10. 10.  0.] 
cards in discard: [15. 15.  8. 10. 10. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29  1  6] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 116.71124267578125






Player: 1 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29  1  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15.  8.  3.  8. 29.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29  1  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15.  8.  3.  8. 29.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29  1  6  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15.  8.  3.  8. 29.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [15.  8.  3.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8. 29.] 
expected returns: [[169.0612 ]
 [162.75507]
 [166.93542]
 [166.93542]
 [171.21884]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  3.  8. 29.] 
cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [11.  6. 29.  8.  0.] 
adversary cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.  1.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29  1  6  1] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 123.3647689819336



action possibilites: [-1. 15.  8.] 
expected returns: [[161.57617]
 [155.27115]
 [160.77066]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.] 
cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [11.  6. 29.  8.  0.] 
adversary cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.  1.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29  1  6  1] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 167.35218811035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[152.89838]
 [155.98895]
 [140.65126]
 [160.67557]
 [161.48106]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.] 
cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [11.  6. 29.  8.  0.] 
adversary cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.  1.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29  1  6  1] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 161.57614135742188






Player: 1 
cards in hand: [11.  6. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 29.  8.  0.] 
cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.  1.  3.  0.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29  1  6  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15. 11. 11. 11. 11.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  8.] 
cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.  1.  3.  0.  0.  6.  0.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 11  4  6  0  0  6 22  8  8  6 14
  0  0 10 10  0 11  6 15 29  1  6  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15. 11. 11. 11. 11.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.  1.  3.  0.  0.  6.  0.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15. 11. 11. 11. 11.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.  1.  3.  0.  0.  6.  0.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15. 11. 11. 11. 11.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 29.  6.  6.  3.  0. 10.  0.  6.  0.  1.  1. 22. 11. 10.  4.  0.  8.
  0.  0.  3.  6.  1.  3.  0.  0.  6.  0.  0. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [15. 11. 11. 11. 11.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [15. 11. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11. 11. 11.] 
expected returns: [[115.4253  ]
 [109.4991  ]
 [116.920494]
 [116.920494]
 [116.920494]
 [116.920494]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 11. 11. 11.] 
cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 161.48104858398438



action possibilites: [-1] 
expected returns: [[109.71152]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 11. 11.] 
cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 114.43305969238281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[100.72538]
 [ 90.01586]
 [109.85024]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 11. 11.] 
cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 25. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 109.71151733398438






Player: 1 
cards in hand: [ 0.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [10.  0. 11. 10.  0.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1. 11. 15. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1] -> size -> 37 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  4.] 
adversary cards in hand: [10.  0. 11. 10.  0.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1. 11. 15. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1] -> size -> 37 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  0. 11. 10.  0.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1. 11. 15. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1] -> size -> 37 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[137.92715]
 [133.3971 ]
 [139.04263]
 [133.3971 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.  0.] 
cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1. 11. 15. 11. 11. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [29. 11.  1. 29.  1.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15] -> size -> 36 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 109.85025024414062



action possibilites: [-1] 
expected returns: [[129.61255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1. 11. 15. 11. 11. 11.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [29. 11.  1. 29.  1.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15] -> size -> 36 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 42 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 137.10867309570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[122.86228]
 [125.36485]
 [112.58214]
 [128.75844]
 [130.1274 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1. 11. 15. 11. 11. 11.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 24. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [29. 11.  1. 29.  1.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15] -> size -> 36 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.612548828125






Player: 1 
cards in hand: [29. 11.  1. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  1. 29.  1.] 
cards in discard: [15.  0.  0.  0.  0. 14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  8. 11. 15. 11.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1. 11. 15. 11. 11. 11.  1. 11. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1] -> size -> 38 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 29.  1.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  8. 11. 15. 11.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1. 11. 15. 11. 11. 11.  1. 11. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1] -> size -> 38 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1. 29.  1.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 23. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  8. 11. 15. 11.] 
adversary cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1. 11. 15. 11. 11. 11.  1. 11. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1] -> size -> 38 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [10.  8. 11. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 15. 11.] 
expected returns: [[137.66862]
 [134.17456]
 [136.84322]
 [138.61067]
 [133.95184]
 [138.61067]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11. 15. 11.] 
cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1. 11. 15. 11. 11. 11.  1. 11. 10.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 10.  8.  1. 15.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 130.1273956298828



action possibilites: [-1] 
expected returns: [[129.40991]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 15. 11.] 
cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1. 11. 15. 11. 11. 11.  1. 11. 10.  0. 10.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 10.  8.  1. 15.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 137.07879638671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[122.72315]
 [114.94777]
 [129.40991]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 15. 11.] 
cards in discard: [15. 15.  8. 10. 10. 11. 25.  0.  3.  0. 10. 10.  0.  3.  8. 29. 15.  8.
  0.  1. 11. 15. 11. 11. 11.  1. 11. 10.  0. 10.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 22. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 10.  8.  1. 15.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.409912109375






Player: 1 
cards in hand: [ 0. 10.  8.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  1. 15.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 10. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1] -> size -> 39 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  1. 15.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 22. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 10. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1] -> size -> 39 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[91.46257 ]
 [86.76472 ]
 [93.479576]
 [86.76472 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [22.  3.  0.  0. 10.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 129.409912109375



action possibilites: [-1] 
expected returns: [[61.4049]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [22.  3.  0.  0. 10.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 22 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 91.20672607421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[54.615795]
 [56.783966]
 [46.963722]
 [60.02424 ]
 [61.58625 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 21. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [22.  3.  0.  0. 10.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.40489959716797






Player: 1 
cards in hand: [22.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0.  0. 10.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10. 10. 15.  0. 15.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  6.  3.  6.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10. 10. 15.  0. 15.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  6.  3.  6.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 21. 30. 30. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10. 10. 15.  0. 15.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  6.  3.  6.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 29. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10. 10. 15.  0. 15.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [10. 10. 15.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15. 15.] 
expected returns: [[95.984146]
 [91.81573 ]
 [91.81573 ]
 [91.55031 ]
 [91.55031 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15.  0. 15.] 
cards in discard: [ 1. 11.  0. 10. 10.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 29. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.  3.
 22.  3.  0.  0. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1  3] -> size -> 38 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 61.58624267578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[90.64084 ]
 [81.80432 ]
 [96.759155]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15.  0. 15.] 
cards in discard: [ 1. 11.  0. 10. 10.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 21. 30. 29. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.  3.
 22.  3.  0.  0. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1  3] -> size -> 38 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 95.98414611816406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.  3.
 22.  3.  0.  0. 10.  6.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0
 10 10  0 11  6 15 29  1  6  1  0 15  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 29. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 8. 25. 10.  1.  8.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.  3.
 22.  3.  0.  0. 10.  6.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 29. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 8. 25. 10.  1.  8.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.  3.
 22.  3.  0.  0. 10.  6.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 21. 30. 29. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 8. 25. 10.  1.  8.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.  3.
 22.  3.  0.  0. 10.  6.  3.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 21. 30. 29. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 8. 25. 10.  1.  8.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 8. 25. 10.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 10.  8.] 
expected returns: [[134.01872]
 [133.0848 ]
 [144.58844]
 [129.64449]
 [133.0848 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 10.  1.  8.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 29. 29.  8.  4. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 4. 6. 0. 6.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.  3.
 22.  3.  0.  0. 10.  6.  3.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0] -> size -> 36 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 96.75914764404297



action possibilites: [-1] 
expected returns: [[95.35134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  1.  8. 15.  3.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 29. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 4. 6. 0. 6.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.  3.
 22.  3.  0.  0. 10.  6.  3.  6.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 144.58843994140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[88.173454]
 [90.7204  ]
 [77.903145]
 [94.084724]
 [95.89966 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  1.  8. 15.  3.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 21. 30. 29. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 4. 6. 0. 6.] 
adversary cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.  3.
 22.  3.  0.  0. 10.  6.  3.  6.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.3513412475586






Player: 1 
cards in hand: [0. 4. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 6. 0. 6.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.  3.
 22.  3.  0.  0. 10.  6.  3.  6.  0.  8.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 29. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 29.  1. 10. 11.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 6. 0. 6.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.  3.
 22.  3.  0.  0. 10.  6.  3.  6.  0.  8.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 21. 30. 29. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 29.  1. 10. 11.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 6. 0. 6.] 
cards in discard: [15.  0.  0.  0.  0. 14.  1. 11. 29.  1. 29.  1.  0. 10.  8.  1. 15.  3.
 22.  3.  0.  0. 10.  6.  3.  6.  0.  8.  0.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 28. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 29.  1. 10. 11.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [11. 29.  1. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 11.] 
expected returns: [[115.64408 ]
 [117.257324]
 [118.619385]
 [111.78667 ]
 [117.257324]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  1. 10. 11.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 28. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 95.89967346191406



action possibilites: [-1. 11. 11.] 
expected returns: [[120.17243]
 [121.23518]
 [121.23518]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 11.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 21. 30. 28. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 115.40513610839844



action possibilites: [-1] 
expected returns: [[100.264114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 20. 30. 28. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 119.23976135253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[91.37996]
 [98.39049]
 [94.10788]
 [80.65456]
 [97.96748]
 [99.35942]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 20. 30. 28. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.26411437988281






Player: 1 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 20. 30. 28. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 11.  8. 10. 11.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1] -> size -> 41 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 20. 30. 28. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 11.  8. 10. 11.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1] -> size -> 41 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 20. 30. 27. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 11.  8. 10. 11.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1] -> size -> 41 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [11. 11.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 10. 11.] 
expected returns: [[76.769585]
 [77.688705]
 [77.688705]
 [75.41838 ]
 [72.29089 ]
 [77.688705]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8. 10. 11.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 20. 30. 27. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  8.  4.  1. 15.] 
adversary cards in discard: [3. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3] -> size -> 39 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 99.35943603515625



action possibilites: [-1] 
expected returns: [[87.21995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 10. 11.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 19. 30. 27. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  8.  4.  1. 15.] 
adversary cards in discard: [3. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3] -> size -> 39 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 75.75459289550781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[81.49826]
 [73.58893]
 [87.21997]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 10. 11.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 19. 30. 27. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  8.  4.  1. 15.] 
adversary cards in discard: [3. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3] -> size -> 39 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.2199478149414






Player: 1 
cards in hand: [10.  8.  4.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  4.  1. 15.] 
cards in discard: [3. 0. 0. 0. 6. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 19. 30. 27. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11.  8.  0.  0. 11.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  4.  1. 15.] 
cards in discard: [3. 0. 0. 0. 6. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 19. 30. 27. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11.  8.  0.  0. 11.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  4.  1. 15.] 
cards in discard: [3. 0. 0. 0. 6. 0. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 19. 30. 26. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11.  8.  0.  0. 11.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11.  8.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[113.25773]
 [114.93384]
 [113.26657]
 [114.93384]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  0. 11.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 19. 30. 26. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 6.  0.  6. 11. 14.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3] -> size -> 40 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.2199478149414



action possibilites: [-1] 
expected returns: [[96.54903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 26. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 6.  0.  6. 11. 14.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3] -> size -> 40 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -80   0   0  27   0] 
sum of rewards: -68 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 113.47572326660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[92.91236]
 [94.33126]
 [87.03935]
 [96.57433]
 [96.54903]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 18. 30. 26. 29.  8.  3. 10.  0.  4.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 6.  0.  6. 11. 14.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3] -> size -> 40 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.54902648925781



buy possibilites: [-1] 
expected returns: [[101.55779]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.  1.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 26. 29.  8.  3. 10.  0.  3.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 6.  0.  6. 11. 14.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3] -> size -> 40 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -90   0   0  16   0] 
sum of rewards: -89 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 96.5743408203125






Player: 1 
cards in hand: [ 6.  0.  6. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 11. 14.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 26. 29.  8.  3. 10.  0.  3.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0.  1.  0. 10. 15.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.  1.  8. 11.  8.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8] -> size -> 44 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 11.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 18. 30. 26. 29.  8.  3. 10.  0.  3.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 1. 0.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.  1.  8. 11.  8.  0.
  0. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8] -> size -> 44 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 11.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 18. 30. 26. 29.  8.  3. 10.  0.  3.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 1. 0.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.  1.  8. 11.  8.  0.
  0. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8] -> size -> 44 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 11.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 18. 30. 25. 29.  8.  3. 10.  0.  3.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 1. 0.] 
adversary cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.  1.  8. 11.  8.  0.
  0. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8] -> size -> 44 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[77.69386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.  1.  8. 11.  8.  0.
  0. 11. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 25. 29.  8.  3. 10.  0.  3.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 1. 29.  6.  0.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3] -> size -> 41 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0 -90   0   0 773   0] 
sum of rewards: 618 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 94.59916687011719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[72.05444 ]
 [75.88091 ]
 [73.77175 ]
 [66.10734 ]
 [74.712944]
 [75.56738 ]
 [78.214325]
 [69.620255]
 [73.446686]
 [77.69387 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.  1.  8. 11.  8.  0.
  0. 11. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 18. 30. 25. 29.  8.  3. 10.  0.  3.  9.  7.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 1. 29.  6.  0.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3] -> size -> 41 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 77.69386291503906



buy possibilites: [-1] 
expected returns: [[82.47606]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 1. 11.  0. 10. 10.  0. 10. 10. 15.  0. 15. 25.  8. 10.  1.  8. 15.  3.
 10. 15.  1. 29. 11.  1. 11.  1. 11. 11.  8. 10. 11.  1.  8. 11.  8.  0.
  0. 11. 10. 15. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 25. 29.  8.  3. 10.  0.  3.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 1. 29.  6.  0.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3] -> size -> 41 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0 -100    0    0
  128    0] 
sum of rewards: -37 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 78.21432495117188






Player: 1 
cards in hand: [ 1. 29.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  6.  0.  3.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 25. 29.  8.  3. 10.  0.  3.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 3.  0. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  6.  0.  3.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 18. 30. 25. 29.  8.  3. 10.  0.  3.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 3.  0. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  6.  0.  3.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 3.  0. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[100.89276 ]
 [ 97.06592 ]
 [100.553314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [8. 3. 6. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8] -> size -> 42 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.47605895996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 95.71738 ]
 [ 87.49321 ]
 [101.410645]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [8. 3. 6. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8] -> size -> 42 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 100.89276123046875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 3. 0.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [29.  1. 11. 15.  8.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 3. 0.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [29.  1. 11. 15.  8.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 3. 0.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [29.  1. 11. 15.  8.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [29.  1. 11. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 15.  8.] 
expected returns: [[101.00016]
 [105.0996 ]
 [103.32562]
 [ 96.47617]
 [100.6888 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 11. 15.  8.] 
cards in discard: [ 3.  0. 10.  8.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 3.  0. 10.  1. 15.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.  0.  8.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.41065216064453



action possibilites: [-1. 11.  8. 11.] 
expected returns: [[89.136215]
 [88.461136]
 [85.76361 ]
 [88.461136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 11.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 3.  0. 10.  1. 15.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.  0.  8.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 101.05105590820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[81.61139]
 [73.64498]
 [90.31842]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 11.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
action values: 1 
buys: 1 
player value: 1 
card supply: [22. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 3.  0. 10.  1. 15.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.  0.  8.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 89.13619995117188






Player: 1 
cards in hand: [ 3.  0. 10.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  1. 15.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.  0.  8.  3.  6.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 10. 15.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 15. 22.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 15. 22.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.  0.  8.  3.  6.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0
 11  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 10. 15.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 22.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.  0.  8.  3.  6.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 3 
card supply: [22. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 10. 15.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.  0.  8.  3.  6.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15. 22. 29.] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 10. 15.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.  0.  8.  3.  6.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15. 22. 29.] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 9 
card supply: [22. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 10. 15.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  6.  0.  3. 10.  8.  4.  1. 15.  3. 14.  6.  0.  6. 11.
  8.  1. 29.  6.  0.  3.  0.  8.  3.  6.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15. 22. 29.] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 9 
card supply: [21. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 10. 15.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [11. 10. 15.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15. 11.] 
expected returns: [[97.32791]
 [97.87946]
 [92.88514]
 [92.75473]
 [97.87946]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 15.  0. 11.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 29.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 90.31840515136719



action possibilites: [-1] 
expected returns: [[51.90993]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0. 11.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 17. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 29.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: -128 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 95.97819519042969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[48.368935]
 [44.444973]
 [52.79799 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0. 11.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 17. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 29.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.90993118286133






Player: 1 
cards in hand: [ 0. 29.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  1.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 17. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  8. 11. 15. 15.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1] -> size -> 46 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0.] 
cards in discard: [0. 0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 17. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  8. 11. 15. 15.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1] -> size -> 46 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [0. 0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 17. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  8. 11. 15. 15.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1] -> size -> 46 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [10.  8. 11. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 15. 15.] 
expected returns: [[90.869934]
 [85.85098 ]
 [88.9601  ]
 [91.19787 ]
 [85.66701 ]
 [85.66701 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11. 15. 15.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 17. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 6. 11.  6.  3. 10.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 52.79798889160156



action possibilites: [-1] 
expected returns: [[82.02567]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 15. 15.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 6. 11.  6.  3. 10.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: -138 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 89.29049682617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.88461]
 [66.40883]
 [81.58855]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 15. 15.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 16. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 6. 11.  6.  3. 10.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.02567291259766






Player: 1 
cards in hand: [ 6. 11.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6.  3. 10.] 
cards in discard: [ 0.  0. 29.  3.  1.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 1. 25. 10.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1] -> size -> 47 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6.  3. 10.] 
cards in discard: [ 0.  0. 29.  3.  1.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 1. 25. 10.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1] -> size -> 47 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  6.  3. 10.] 
cards in discard: [ 0.  0. 29.  3.  1.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
action values: 2 
buys: 1 
player value: 0 
card supply: [21. 16. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 1. 25. 10.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1] -> size -> 47 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 1. 25. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11.] 
expected returns: [[115.4083  ]
 [118.23123 ]
 [109.991684]
 [113.72715 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 10.  0. 11.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 29.  8.  3. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 81.58855438232422



action possibilites: [-1] 
expected returns: [[68.1623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0. 11. 10. 10.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 29.  8.  2. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 118.23124694824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[61.601425]
 [64.6729  ]
 [63.217636]
 [57.25227 ]
 [64.33034 ]
 [68.16231 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0. 11. 10. 10.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 16. 30. 25. 29.  8.  2. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 68.16230010986328






Player: 1 
cards in hand: [0. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 29.  8.  2. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0.  0.  1. 15. 10.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1] -> size -> 47 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 16. 30. 25. 29.  8.  2. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0.  0.  1. 15. 10.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1] -> size -> 47 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  1. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[85.23925 ]
 [81.213104]
 [81.331116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 15. 10.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 29.  8.  2. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 6. 14.  3.  4.  0.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 68.16230010986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[80.01216 ]
 [83.42783 ]
 [81.53425 ]
 [73.57039 ]
 [82.4304  ]
 [83.22472 ]
 [85.380844]
 [77.34826 ]
 [81.21311 ]
 [85.23924 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 15. 10.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 16. 30. 25. 29.  8.  2. 10.  0.  2.  9.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 6. 14.  3.  4.  0.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.23927307128906



buy possibilites: [-1] 
expected returns: [[99.88189]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 15. 10.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 29.  8.  2. 10.  0.  2.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 6. 14.  3.  4.  0.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0    0    0    0    0 -130    0    0
  128    0] 
sum of rewards: -37 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 85.38084411621094






Player: 1 
cards in hand: [ 6. 14.  3.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  3.  4.  0.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 29.  8.  2. 10.  0.  2.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11.  0.  1.  8.  1.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10. 29.  0.  0.  1. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29] -> size -> 48 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  3.  4.  0.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 16. 30. 25. 29.  8.  2. 10.  0.  2.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11.  0.  1.  8.  1.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10. 29.  0.  0.  1. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29] -> size -> 48 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [11.  0.  1.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[109.76645 ]
 [110.037674]
 [108.13928 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  8.  1.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10. 29.  0.  0.  1. 15. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 29.  8.  2. 10.  0.  2.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [29.  0.  1.  0.  8.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 99.88188934326172



action possibilites: [-1] 
expected returns: [[70.256325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 1.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10. 29.  0.  0.  1. 15. 10.
  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 25. 29.  8.  2. 10.  0.  2.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [29.  0.  1.  0.  8.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: -128 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 108.44586181640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[62.88266 ]
 [67.39243 ]
 [65.01048 ]
 [59.387882]
 [58.012012]
 [66.00164 ]
 [66.98064 ]
 [74.26577 ]
 [70.200455]
 [60.58004 ]
 [63.761612]
 [59.890045]
 [64.69207 ]
 [70.25632 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 1.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10. 29.  0.  0.  1. 15. 10.
  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 15. 30. 25. 29.  8.  2. 10.  0.  2.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [29.  0.  1.  0.  8.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.2563247680664



buy possibilites: [-1] 
expected returns: [[77.72941]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 1.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10. 29.  0.  0.  1. 15. 10.
  1. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 25. 29.  8.  2. 10.  0.  2.  8.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [29.  0.  1.  0.  8.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -150    0    0
  250    0] 
sum of rewards: 85 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 74.26577758789062






Player: 1 
cards in hand: [29.  0.  1.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  0.  8.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 25. 29.  8.  2. 10.  0.  2.  8.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11.  1.  1. 10.  8.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10. 29.  0.  0.  1. 15. 10.
  1. 25. 11.  0.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25] -> size -> 50 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  0.  8.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 15. 30. 25. 29.  8.  2. 10.  0.  2.  8.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11.  1.  1. 10.  8.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10. 29.  0.  0.  1. 15. 10.
  1. 25. 11.  0.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25] -> size -> 50 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  0.  8.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 25. 29.  8.  2. 10.  0.  2.  8.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [11.  1.  1. 10.  8.] 
adversary cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10. 29.  0.  0.  1. 15. 10.
  1. 25. 11.  0.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25] -> size -> 50 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [11.  1.  1. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[103.57522 ]
 [102.688896]
 [ 98.50101 ]
 [100.78319 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  1. 10.  8.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10. 29.  0.  0.  1. 15. 10.
  1. 25. 11.  0.  1.  8.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 25. 29.  8.  2. 10.  0.  2.  8.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  8.  1. 15.  0.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15. 29.  0.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15] -> size -> 45 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.72940826416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[ 96.959496]
 [101.12503 ]
 [ 98.842834]
 [ 89.39038 ]
 [ 99.85288 ]
 [100.78319 ]
 [103.72058 ]
 [ 93.93404 ]
 [ 98.49704 ]
 [103.57521 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1. 10.  8.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10. 29.  0.  0.  1. 15. 10.
  1. 25. 11.  0.  1.  8.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 15. 30. 25. 29.  8.  2. 10.  0.  2.  8.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  8.  1. 15.  0.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15. 29.  0.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15] -> size -> 45 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 103.57524108886719



buy possibilites: [-1] 
expected returns: [[120.902405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1. 10.  8.] 
cards in discard: [ 3.  0. 10.  8.  3.  1. 15. 29. 11.  8. 11.  1. 11. 10. 15.  0. 11.  1.
 11. 10.  8. 15. 15. 25.  1. 10.  0. 11. 10. 10. 29.  0.  0.  1. 15. 10.
  1. 25. 11.  0.  1.  8.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 25. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  8.  1. 15.  0.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15. 29.  0.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15] -> size -> 45 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0    0    0    0    0 -160    0    0
  128    0] 
sum of rewards: -67 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 103.72059631347656






Player: 1 
cards in hand: [ 0.  8.  1. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1. 15.  0.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15. 29.  0.  1.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11
  6 15 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 25. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  8. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15. 29.  0.  1.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 25. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  8. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15. 29.  0.  1.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 15. 30. 25. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  8. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15. 29.  0.  1.  0.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  8. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [10.  8. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 29.] 
expected returns: [[115.870926]
 [110.624115]
 [113.22502 ]
 [115.29579 ]
 [116.41298 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11. 29.  0.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [22.  0.  8.  3.  6.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15. 29.  0.  1.  0.  8.  3.  8.  1. 15.] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3] -> size -> 44 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 120.90240478515625



action possibilites: [-1.  8.  8.] 
expected returns: [[113.29271]
 [110.76271]
 [110.76271]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [10. 11.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [22.  0.  8.  3.  6.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15. 29.  0.  1.  0.  8.  3.  8.  1. 15.] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3] -> size -> 44 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 113.57675170898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[106.39835 ]
 [108.505554]
 [ 98.904236]
 [110.38885 ]
 [112.91885 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [10. 11.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [22.  0.  8.  3.  6.] 
adversary cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15. 29.  0.  1.  0.  8.  3.  8.  1. 15.] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3] -> size -> 44 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 113.292724609375






Player: 1 
cards in hand: [22.  0.  8.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  8.  3.  6.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15. 29.  0.  1.  0.  8.  3.  8.  1. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  0. 29.  0. 15.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 6. 1. 3. 0.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15. 29.  0.  1.  0.  8.  3.  8.  1. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  0. 29.  0. 15.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 6. 1. 3. 0.] 
cards in discard: [ 0.  0. 29.  3.  1.  0. 10.  6. 11.  6.  3. 10.  6.  0.  3.  3.  0.  6.
  6. 14.  3.  4.  0. 15. 29.  0.  1.  0.  8.  3.  8.  1. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  0. 29.  0. 15.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 29.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 15.] 
expected returns: [[87.010635]
 [86.78708 ]
 [90.06555 ]
 [83.012794]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  0. 15.] 
cards in discard: [10. 11. 29.  8.  0.  8.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [3. 4. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3] -> size -> 44 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 112.91886901855469



action possibilites: [-1. 15. 15.] 
expected returns: [[118.9003 ]
 [115.20082]
 [115.20082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 15.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [3. 4. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3] -> size -> 44 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 87.08930969238281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[114.61046 ]
 [116.16054 ]
 [109.29463 ]
 [118.0072  ]
 [119.519615]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 15.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [3. 4. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3] -> size -> 44 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 118.90029907226562






Player: 1 
cards in hand: [3. 4. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 4. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  1. 10.  1.  1.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  1. 10.  1.  1.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4. 0. 6. 0.] 
cards in discard: [0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  1. 10.  1.  1.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 8.  1. 10.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[111.877396]
 [110.38838 ]
 [107.69752 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 10.  1.  1.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  6.  0.  0. 14.] 
adversary cards in discard: [0. 3. 4. 0. 6. 0.] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0] -> size -> 45 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 119.51962280273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[108.66414 ]
 [112.62103 ]
 [106.3375  ]
 [110.294395]
 [104.6936  ]
 [102.95025 ]
 [111.41233 ]
 [112.38871 ]
 [119.483246]
 [115.03604 ]
 [105.94716 ]
 [108.92767 ]
 [105.088005]
 [109.90407 ]
 [113.56675 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 10.  1.  1.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29] -> size -> 51 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 15. 30. 24. 29.  8.  2. 10.  0.  2.  8.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  6.  0.  0. 14.] 
adversary cards in discard: [0. 3. 4. 0. 6. 0.] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0] -> size -> 45 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 111.87741088867188



buy possibilites: [-1] 
expected returns: [[139.69261]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 10.  1.  1.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 15. 30. 24. 29.  8.  2. 10.  0.  2.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  6.  0.  0. 14.] 
adversary cards in discard: [0. 3. 4. 0. 6. 0.] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0] -> size -> 45 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.   -60.     0.     0.     0.     0.     0.     0.
    0.  -170.     0.     0.    62.5    0. ] 
sum of rewards: -172.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 119.48326110839844






Player: 1 
cards in hand: [10.  6.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  0. 14.] 
cards in discard: [0. 3. 4. 0. 6. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 24. 29.  8.  2. 10.  0.  2.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 1. 15. 11.  3. 11.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25] -> size -> 52 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  0. 14.] 
cards in discard: [0. 3. 4. 0. 6. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 15. 30. 24. 29.  8.  2. 10.  0.  2.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 1. 15. 11.  3. 11.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25] -> size -> 52 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  0. 14.] 
cards in discard: [0. 3. 4. 0. 6. 0. 8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 24. 29.  8.  2. 10.  0.  1.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 1. 15. 11.  3. 11.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25] -> size -> 52 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 1. 15. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11.] 
expected returns: [[126.85025]
 [123.46536]
 [127.43288]
 [127.43288]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 11.  3. 11.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 24. 29.  8.  2. 10.  0.  1.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 1. 10. 15.  8.  3.] 
adversary cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8] -> size -> 46 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 139.69261169433594



action possibilites: [-1] 
expected returns: [[127.24736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  3. 11.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 24. 29.  8.  2. 10.  0.  1.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 1. 10. 15.  8.  3.] 
adversary cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8] -> size -> 46 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0 -180    0    0
   27    0] 
sum of rewards: -198 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 126.06427001953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[122.950096]
 [124.57503 ]
 [115.92682 ]
 [126.96265 ]
 [127.24736 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  3. 11.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 14. 30. 24. 29.  8.  2. 10.  0.  1.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 1. 10. 15.  8.  3.] 
adversary cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8] -> size -> 46 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.24736022949219






Player: 1 
cards in hand: [ 1. 10. 15.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 15.  8.  3.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 24. 29.  8.  2. 10.  0.  1.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [11.  1. 29.  0. 15.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  8.  3.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 24. 29.  8.  2. 10.  0.  1.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [11.  1. 29.  0. 15.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  8.  3.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 14. 30. 24. 29.  8.  2. 10.  0.  1.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [11.  1. 29.  0. 15.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  8.  3.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [11.  1. 29.  0. 15.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [11.  1. 29.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15.] 
expected returns: [[72.78322]
 [71.74153]
 [72.65706]
 [67.81632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29.  0. 15.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 3.  0. 15.  0.  1.] 
adversary cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3] -> size -> 47 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 127.24736022949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[66.31529 ]
 [70.245224]
 [68.12865 ]
 [61.42627 ]
 [69.92819 ]
 [72.78321 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 29.  0. 15.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 3.  0. 15.  0.  1.] 
adversary cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.] 
adversary owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3] -> size -> 47 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 72.78321075439453



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 15.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0.  1.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15
 29  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  1. 10. 10.  1.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29
  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  1. 10. 10.  1.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29
  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  1. 10. 10.  1.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29
  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  3.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  1. 10. 10.  1.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [10.  1. 10. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[93.10924]
 [90.8845 ]
 [90.8845 ]
 [90.8845 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 10. 10.  1.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  3.  9. 10.  0.  9.  2.] 
adversary cards in hand: [29.  0.  3.  6.  8.] 
adversary cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.] 
adversary owned cards: [ 0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29
  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29] -> size -> 47 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 72.78321075439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[89.81611 ]
 [92.99523 ]
 [91.042366]
 [84.38133 ]
 [92.02624 ]
 [92.83737 ]
 [94.86406 ]
 [87.52195 ]
 [90.70108 ]
 [93.109245]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 10. 10.  1.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  3.  9. 10.  0.  9.  2.] 
adversary cards in hand: [29.  0.  3.  6.  8.] 
adversary cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.] 
adversary owned cards: [ 0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29
  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29] -> size -> 47 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 93.10923767089844



buy possibilites: [-1] 
expected returns: [[119.882805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 10. 10.  1.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1 29] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  2.  9. 10.  0.  9.  2.] 
adversary cards in hand: [29.  0.  3.  6.  8.] 
adversary cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.] 
adversary owned cards: [ 0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29
  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29] -> size -> 47 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -90    0    0    0    0    0    0    0 -190    0    0
  128    0] 
sum of rewards: -157 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 94.86405944824219






Player: 1 
cards in hand: [29.  0.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  6.  8.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29  1  4  6  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29
  1  6  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  2.  9. 10.  0.  9.  2.] 
adversary cards in hand: [25. 15.  0.  1. 10.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15. 29. 10.  1. 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1 29] -> size -> 54 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  1  4  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29  1  6
  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  2.  9. 10.  0.  9.  2.] 
adversary cards in hand: [25. 15.  0.  1. 10.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15. 29. 10.  1. 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1 29] -> size -> 54 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  1  4  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29  1  6
  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  2.  9. 10.  0.  9.  2.] 
adversary cards in hand: [25. 15.  0.  1. 10.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15. 29. 10.  1. 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1 29] -> size -> 54 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [25. 15.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 10.] 
expected returns: [[65.42493 ]
 [72.449265]
 [62.744545]
 [63.05732 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15.  0.  1. 10.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15. 29. 10.  1. 10. 10.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1 29] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 23. 29.  8.  2. 10.  0.  1.  7.  2.  9. 10.  0.  9.  2.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.  8. 29.  3.] 
adversary owned cards: [ 3  3 29  1  4  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29  1  6
  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29] -> size -> 45 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 119.88280487060547



action possibilites: [-1] 
expected returns: [[42.14595]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1. 10.  8. 29.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15. 29. 10.  1. 10. 10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1 29] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 23. 29.  8.  1. 10.  0.  1.  7.  2.  9. 10.  0.  9.  2.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.  8. 29.  3.  6.] 
adversary owned cards: [ 3  3 29  1  4  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29  1  6
  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29  6] -> size -> 46 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 72.44924926757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[36.045773]
 [37.68801 ]
 [37.24009 ]
 [34.274174]
 [37.392365]
 [42.145943]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1. 10.  8. 29.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15. 29. 10.  1. 10. 10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1 29] -> size -> 54 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 14. 30. 23. 29.  8.  1. 10.  0.  1.  7.  2.  9. 10.  0.  9.  2.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.  8. 29.  3.  6.] 
adversary owned cards: [ 3  3 29  1  4  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29  1  6
  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29  6] -> size -> 46 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.14595031738281






Player: 1 
cards in hand: [3. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.  8. 29.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  4  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29  1  6
  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 23. 29.  8.  1. 10.  0.  1.  7.  2.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 1. 11.  1. 25. 11.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15. 29. 10.  1. 10. 10.  1. 25.
 15.  0.  1. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1 29] -> size -> 54 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.  8. 29.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  4  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29  1  6
  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 14. 30. 23. 29.  8.  1. 10.  0.  1.  7.  2.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 1. 11.  1. 25. 11.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15. 29. 10.  1. 10. 10.  1. 25.
 15.  0.  1. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1 29] -> size -> 54 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.  8. 29.  3.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  4  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29  1  6
  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29  6  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 14. 30. 23. 29.  8.  1. 10.  0.  1.  7.  2.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 1. 11.  1. 25. 11.] 
adversary cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15. 29. 10.  1. 10. 10.  1. 25.
 15.  0.  1. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1 29] -> size -> 54 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 1. 11.  1. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11.] 
expected returns: [[78.6607 ]
 [80.48197]
 [86.19383]
 [80.48197]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  1. 25. 11.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15. 29. 10.  1. 10. 10.  1. 25.
 15.  0.  1. 10.  8. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1 29] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 14. 30. 23. 29.  8.  1. 10.  0.  1.  7.  2.  9. 10.  0.  9.  2.] 
adversary cards in hand: [22.  3.  3.  0.  6.] 
adversary cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.  8. 29.  3.  6.  0.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 3  3 29  1  4  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29  1  6
  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29  6  0] -> size -> 47 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 42.14595031738281



Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 5 
Witch: 3 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1. 11.  1. 11. 10.  3.] 
cards in discard: [10. 11. 29.  8.  0.  8.  8.  0. 29.  0. 15. 15. 25.  8.  1. 10.  1.  1.
  1. 11.  1. 15.  3. 11. 11.  1. 29.  0. 15. 29. 10.  1. 10. 10.  1. 25.
 15.  0.  1. 10.  8. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 11 10 11 11 10 11 10  8 10 10
 10  8 10 10 15  8 15 15 11 15 15 11  1  1  1  1  1  1  1  8 29  1  1 29
  1 25 29 25  1 29] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 14. 30. 23. 29.  8.  0. 10.  0.  1.  7.  2.  9. 10.  0.  9.  2.] 
adversary cards in hand: [22.  3.  3.  0.  6.] 
adversary cards in discard: [ 0.  3.  4.  0.  6.  0.  8. 10.  6.  0.  0. 14.  3. 15.  1. 10.  8.  3.
 29. 15.  3.  0.  1.  8. 29.  3.  6.  0.  3.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 3  3 29  1  4  0  0  6 22  8  8  6 14  0  0 10 10  0 11  6 15 29  1  6
  1  0 15  1  3  0  6  3  3  3  3  8  0  0  6 15  3  0  8  3 29  6  0  6] -> size -> 48 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0       20        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000075 

action type: take_action - action 25.0
Learning step: -120006.4453125
desired expected reward: -119920.25



