 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[62.346786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000125 

action type: buy - action -1.0
Learning step: -119995.390625
desired expected reward: -120235.671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 46.69642 ]
 [ 88.405685]
 [ 61.170975]
 [-15.667871]
 [ 88.5353  ]
 [ 72.874306]
 [ 46.923695]
 [ 60.923386]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 62.948829650878906



buy possibilites: [-1] 
expected returns: [[62.52427]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 88.53529357910156






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[66.584526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.524269104003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 54.754314]
 [ 96.51743 ]
 [ 69.904106]
 [-11.074932]
 [ 84.953316]
 [ 96.68834 ]
 [ 81.407455]
 [112.11788 ]
 [ 13.818236]
 [ 54.913193]
 [ 55.12045 ]
 [ 69.355446]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 66.88148498535156



buy possibilites: [-1] 
expected returns: [[57.50628]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 112.11788177490234






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16.  0.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[50.043636]
 [90.04943 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.50627899169922



action possibilites: [-1. 11.] 
expected returns: [[59.82392]
 [82.57991]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 90.5280532836914



action possibilites: [-1] 
expected returns: [[55.04518]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 99.50357055664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 44.748863 ]
 [ 80.8551   ]
 [ 57.78781  ]
 [-13.328353 ]
 [ 70.65317  ]
 [ 80.98723  ]
 [ 67.58719  ]
 [ 95.218254 ]
 [  9.5099535]
 [ 44.95127  ]
 [ 45.184795 ]
 [ 57.713837 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.04518127441406



buy possibilites: [-1] 
expected returns: [[48.049744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 95.21822357177734






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[40.550903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.04974365234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 32.28296   ]
 [ 67.4589    ]
 [ 44.790134  ]
 [-17.96783   ]
 [ 57.57617   ]
 [ 67.74281   ]
 [ 54.417007  ]
 [ 81.09402   ]
 [ -0.32233286]
 [ 32.565285  ]
 [ 32.862064  ]
 [ 45.35215   ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 40.53178405761719



buy possibilites: [-1] 
expected returns: [[49.64953]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 81.0940170288086






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.  3.  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[45.94204]
 [82.71855]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.64952850341797



action possibilites: [-1. 10.] 
expected returns: [[48.134758]
 [34.9767  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 82.46431732177734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 36.780907]
 [ 73.30022 ]
 [ 50.065563]
 [-22.2113  ]
 [ 73.56884 ]
 [ 60.00329 ]
 [ 37.01746 ]
 [ 50.175518]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 48.13474655151367



buy possibilites: [-1] 
expected returns: [[58.35575]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 73.56883239746094






Player: 1 
cards in hand: [ 0.  3.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [11. 29.  0.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11] -> size -> 16 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [11. 29.  0.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11] -> size -> 16 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 16.  0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [11. 29.  0.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11] -> size -> 16 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[52.077023]
 [72.67921 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [11. 29.  0.  3.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [ 8.  0.  3.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.355751037597656



action possibilites: [-1] 
expected returns: [[70.42795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [11. 29.  0.  3.  0.  3. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [ 8.  0.  3.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 92.17827606201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[57.113564]
 [94.68678 ]
 [70.97834 ]
 [ 5.181445]
 [95.04159 ]
 [81.17682 ]
 [57.46836 ]
 [71.81648 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [11. 29.  0.  3.  0.  3. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [ 8.  0.  3.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.42794799804688



buy possibilites: [-1] 
expected returns: [[55.35753]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [11. 29.  0.  3.  0.  3. 10. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [ 8.  0.  3.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 95.04155731201172






Player: 1 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [ 8.  0.  3.  3. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [ 8.  0.  3.  3. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [ 8.  0.  3.  3. 16.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  8. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11. 29. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[11.302024]
 [34.10955 ]
 [47.810043]
 [47.810043]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  8. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.35752868652344



action possibilites: [-1. 11. 29. 10.] 
expected returns: [[42.122063]
 [63.977135]
 [78.21249 ]
 [28.367058]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  8. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 46.663780212402344



action possibilites: [-1. 11. 10.] 
expected returns: [[80.29476]
 [98.38006]
 [67.79155]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  8. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 78.21247100830078



action possibilites: [-1] 
expected returns: [[85.7152]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  8. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 22 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 117.61833953857422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 76.50056 ]
 [103.88424 ]
 [ 86.819115]
 [ 34.16717 ]
 [ 96.55848 ]
 [104.37836 ]
 [ 94.05979 ]
 [114.58802 ]
 [ 51.37555 ]
 [ 76.99469 ]
 [ 77.46496 ]
 [ 88.79602 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  8. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.71520233154297



buy possibilites: [-1] 
expected returns: [[125.09495]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [10. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  8. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 114.58799743652344






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  8. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 29.  3.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  8. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 29.  3.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  5.  8. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 29.  3.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [11.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[126.7927 ]
 [143.77824]
 [154.59915]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  3.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  5.  8. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8. 11.  0.  3.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.0949478149414



action possibilites: [-1. 11.] 
expected returns: [[145.75694]
 [163.74983]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  5.  8. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8. 11.  0.  3.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 151.74411010742188



action possibilites: [-1] 
expected returns: [[134.4615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  5.  8. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 11.  0.  3.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 183.00413513183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[126.82021]
 [160.05707]
 [139.1756 ]
 [ 77.50273]
 [160.47127]
 [148.11592]
 [127.23446]
 [140.44368]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  5.  8. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 11.  0.  3.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.4615020751953



buy possibilites: [-1] 
expected returns: [[127.65484]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  4.  8. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 11.  0.  3.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 29 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 160.4712677001953






Player: 1 
cards in hand: [ 3.  8. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  0.  3.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 11  3  8  8 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  4.  8. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 11.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3. 10. 11. 29. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  3  8  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  4.  8. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 11.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3. 10. 11. 29. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  3  8  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  4.  8. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 11.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3. 10. 11. 29. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0.  3.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  3  8  8 11  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  4.  8. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 11.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3. 10. 11. 29. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[ 89.66224]
 [ 81.24363]
 [107.99119]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3. 10. 11. 29. 11.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  4.  8. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  8.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3  3  8  8 11  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 127.65483856201172



action possibilites: [-1] 
expected returns: [[74.22248]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3. 10. 11. 29. 11.  0.  3.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  4.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  8.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3  3  8  8 11  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 123.87918853759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[64.58758 ]
 [90.29711 ]
 [73.69742 ]
 [28.157284]
 [90.33902 ]
 [80.712585]
 [64.622795]
 [73.00802 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3. 10. 11. 29. 11.  0.  3.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  4.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  8.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3  3  8  8 11  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.22248077392578



buy possibilites: [-1] 
expected returns: [[63.170784]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 10.  3. 10. 11. 29. 11.  0.  3.  0.  3. 10.
 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  3.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  8.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3  3  8  8 11  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 90.33899688720703






Player: 1 
cards in hand: [ 0.  0.  3. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 16.  8.] 
cards in discard: [11.  0.  3.  3.  0.  0.  0.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  3  8  8 11  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  3.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11.  0.  3.  3.  0.  0.  0.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  3.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0.  3.  3.  0.  0.  0.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  3.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0.  3.  3.  0.  0.  0.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  3.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [10.  0. 10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[55.908432]
 [43.52916 ]
 [43.52916 ]
 [82.807816]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  3.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.17078399658203



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[ 74.76313 ]
 [ 63.39382 ]
 [ 63.39382 ]
 [100.382545]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  3.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 82.71992492675781



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[101.30643]
 [ 91.32928]
 [ 91.32928]
 [115.51202]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  3.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 100.3825454711914



action possibilites: [-1] 
expected returns: [[112.41845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  3.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 131.72183227539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[103.30624 ]
 [127.843895]
 [112.598404]
 [ 63.984375]
 [128.33557 ]
 [119.043365]
 [103.79791 ]
 [114.643364]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  3.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  3.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.41844940185547



buy possibilites: [-1] 
expected returns: [[143.00792]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  3.] 
cards in discard: [10. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  2.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 128.33554077148438






Player: 1 
cards in hand: [ 0.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  2.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 29.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  2.  8. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 29.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  2.  8. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 29.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  2.  8. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 29.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[117.983406]
 [135.01305 ]
 [145.78114 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 29.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  2.  8. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 143.00791931152344



action possibilites: [-1. 11. 11.] 
expected returns: [[118.17211]
 [135.13516]
 [135.13516]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 11.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  2.  8. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 142.1207275390625



action possibilites: [-1] 
expected returns: [[107.61837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  2.  8. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 153.001708984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 97.90846 ]
 [122.58114 ]
 [107.09659 ]
 [ 58.694862]
 [115.9275  ]
 [122.90653 ]
 [113.71839 ]
 [132.05719 ]
 [ 74.43852 ]
 [ 98.23613 ]
 [ 98.56207 ]
 [108.12652 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  2.  8. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.61837005615234



buy possibilites: [-1] 
expected returns: [[82.60263]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  2.  8. 10.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 132.0571746826172






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29. 10. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  2.  8. 10.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11. 29. 10.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29. 29. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29. 10. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  2.  8. 10.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11. 29. 10.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29. 29. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29. 10. 11.  0.  0.  3.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  2.  8. 10.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11. 29. 10.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29. 29. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11. 11. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29. 10.] 
expected returns: [[59.85505]
 [72.95011]
 [72.95011]
 [80.49594]
 [52.424  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29. 10.  0.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29. 29. 11.  0.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  2.  8. 10.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [29. 10.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.60263061523438



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[55.83358 ]
 [68.945465]
 [68.945465]
 [48.300114]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29. 29. 11.  0.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  2.  8. 10.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [29. 10.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 80.49593353271484



action possibilites: [-1] 
expected returns: [[65.0441]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29. 29. 11.  0.  0.  0. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  2.  8. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [29. 10.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 82.61470794677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[58.029472]
 [79.996506]
 [66.0218  ]
 [22.7309  ]
 [80.08261 ]
 [72.10379 ]
 [58.107773]
 [65.69465 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29. 29. 11.  0.  0.  0. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  2.  8. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [29. 10.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.04409790039062



buy possibilites: [-1] 
expected returns: [[62.87877]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29. 29. 11.  0.  0.  0. 11. 10.
 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  8. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [29. 10.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 80.08260345458984






Player: 1 
cards in hand: [29. 10.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  8.  8.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  8. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 10. 10.  0.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29. 29. 11.  0.  0.  0. 11. 10.
 11. 29. 11. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 29.  8.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  8.  3. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  8. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 10. 10.  0.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29. 29. 11.  0.  0.  0. 11. 10.
 11. 29. 11. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  8.  3. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1] -> size -> 16 
action values: 2 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  8. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 10. 10.  0.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29. 29. 11.  0.  0.  0. 11. 10.
 11. 29. 11. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[46.018303]
 [37.32618 ]
 [37.32618 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.  3.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29. 29. 11.  0.  0.  0. 11. 10.
 11. 29. 11. 11. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  8. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10. 29.  8.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.87876892089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.461533]
 [ 9.354169]
 [44.959846]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0.  3.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 10.  3. 10. 29. 29. 11.  0.  0.  0. 11. 10.
 11. 29. 11. 11. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  8. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10. 29.  8.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 46.018287658691406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 29.  8.  8.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  8. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 29.  8.  8.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  8. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 29.  8.  8.  3. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  8. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 95.114494]
 [109.5425  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  8. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [10. 29.  8.  8.  3. 11. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 44.95984649658203



action possibilites: [-1] 
expected returns: [[105.14173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  8. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [10. 29.  8.  8.  3. 11. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 49 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 122.32913970947266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 96.926056]
 [106.49861 ]
 [ 55.459972]
 [113.39016 ]
 [107.65164 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  8. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [10. 29.  8.  8.  3. 11. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.14173126220703



buy possibilites: [-1] 
expected returns: [[120.4967]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [15.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [10. 29.  8.  8.  3. 11. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 113.39014434814453






Player: 1 
cards in hand: [3. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [10. 29.  8.  8.  3. 11. 10.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 11. 10.  3. 11.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8] -> size -> 32 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [10. 29.  8.  8.  3. 11. 10.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  1.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 11. 10.  3. 11.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8] -> size -> 32 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [10. 29.  8.  8.  3. 11. 10.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 11. 10.  3. 11.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8] -> size -> 32 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [11. 11. 10.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10. 11.] 
expected returns: [[57.510834]
 [72.81605 ]
 [72.81605 ]
 [48.3925  ]
 [72.81605 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.  3. 11.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10 11] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 120.49669647216797



action possibilites: [-1] 
expected returns: [[67.41594]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3. 11.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10 11] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 72.13468170166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[58.034203]
 [25.931564]
 [67.47158 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3. 11.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10 11] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.41593933105469






Player: 1 
cards in hand: [ 1. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 10. 11. 29.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1] -> size -> 33 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 10. 11. 29.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1] -> size -> 33 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  3.  0.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10 11  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 10. 11. 29.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1] -> size -> 33 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10.  0. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 29.] 
expected returns: [[ 8.683272 ]
 [ 0.2530074]
 [ 0.2530074]
 [22.963898 ]
 [31.840088 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 11. 29.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 3.  1. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10 11  3] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 67.47156524658203



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[16.756943]
 [ 8.769495]
 [31.185852]
 [ 8.769495]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 3.  1. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10 11  3] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.740509033203125



action possibilites: [-1] 
expected returns: [[3.6831493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 27. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 3.  1. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10 11  3] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 31.069103240966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -3.9187822]
 [-34.96229  ]
 [  3.5047703]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 27. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 3.  1. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10 11  3] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.6831493377685547






Player: 1 
cards in hand: [10.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  8.] 
cards in discard: [ 3.  1. 10.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  8 11  0  0 29 10  1 10 11  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 10. 29. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  1. 10.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 10. 29. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  1. 10.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 27. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 10. 29. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  1. 10.  3.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 10. 29. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 10.] 
expected returns: [[65.13463 ]
 [90.18626 ]
 [56.857067]
 [90.18626 ]
 [56.857067]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 29. 10.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11. 11.] 
adversary cards in discard: [ 3.  1. 10.  3.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 3.504746437072754



action possibilites: [-1. 10. 29. 10.] 
expected returns: [[ 92.76108 ]
 [ 84.257225]
 [117.97581 ]
 [ 84.257225]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11. 11.] 
adversary cards in discard: [ 3.  1. 10.  3.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 80.6561508178711



action possibilites: [-1. 10.] 
expected returns: [[98.81853 ]
 [89.213036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.  0.  0. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11. 11.] 
adversary cards in discard: [ 3.  1. 10.  3.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 108.32759857177734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 89.51724 ]
 [ 98.9838  ]
 [ 50.273785]
 [106.48067 ]
 [ 98.797905]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.  0.  0. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1] -> size -> 34 
action values: 1 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8. 10.  9.  0.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11. 11.] 
adversary cards in discard: [ 3.  1. 10.  3.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 98.81852722167969



buy possibilites: [-1] 
expected returns: [[80.197914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.  0.  0. 10. 11.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  9.  0.  6. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11. 11.] 
adversary cards in discard: [ 3.  1. 10.  3.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: -9 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 106.4806900024414






Player: 1 
cards in hand: [ 0.  0.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11. 11.] 
cards in discard: [ 3.  1. 10.  3.  3.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  9.  0.  6. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 10. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.  0.  0. 10. 11.  8. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8] -> size -> 35 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 3.  1. 10.  3.  3.  0.  0.  8.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  0.  6. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 10. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.  0.  0. 10. 11.  8. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8] -> size -> 35 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 3.  1. 10.  3.  3.  0.  0.  8.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  0.  6. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 10. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.  0.  0. 10. 11.  8. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8] -> size -> 35 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 3.  1. 10.  3.  3.  0.  0.  8.  0.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  0.  5. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 10. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.  0.  0. 10. 11.  8. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8] -> size -> 35 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 10.] 
expected returns: [[46.28354]
 [72.59532]
 [62.71614]
 [36.68652]
 [36.68652]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 10. 10.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.  0.  0. 10. 11.  8. 29. 29. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  0.  5. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.19791412353516



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[-36.289898]
 [-21.68175 ]
 [-43.291824]
 [-10.177679]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.  0.  0. 10. 11.  8. 29. 29. 10.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  0.  5. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 62.44915771484375



action possibilites: [-1.] 
expected returns: [[-13.8341675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.  0.  0. 10. 11.  8. 29. 29. 10.  0. 10. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  0.  5. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -21.84640121459961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[-19.29615   ]
 [  0.38775063]
 [-12.1031275 ]
 [-47.008186  ]
 [ -6.694765  ]
 [-12.1656475 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.  0.  0. 10. 11.  8. 29. 29. 10.  0. 10. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  0.  5. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -13.83416748046875



buy possibilites: [-1] 
expected returns: [[22.212246]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.  8. 11.  0.  0.  3.  3.  1. 11. 11. 10.  3. 11.  0. 10.  1. 29. 11.
 10. 10.  0.  0. 10. 11.  8. 29. 29. 10.  0. 10. 11. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  0.  5. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 0.3877573013305664






Player: 1 
cards in hand: [ 0.  3.  8.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  3. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  0.  5. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 15.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1] -> size -> 36 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  0.  5. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 15.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1] -> size -> 36 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8] -> size -> 19 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  0.  5. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 15.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1] -> size -> 36 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [0. 3. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 27. 30.  8.  9.  9.  0.  5. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 15.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1] -> size -> 36 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 15.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[56.221634]
 [45.53869 ]
 [45.94718 ]
 [70.71415 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15.  0. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  9.  9.  0.  5. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [ 0.  3.  0. 29.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.21224594116211



action possibilites: [-1] 
expected returns: [[41.739765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15.  0.] 
cards in discard: [1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 30.  8.  9.  9.  0.  5. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [ 0.  3.  0. 29.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: -8 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 69.6832504272461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.615128]
 [40.054646]
 [-2.361082]
 [45.974384]
 [41.680714]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15.  0.] 
cards in discard: [1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 27. 30.  8.  9.  9.  0.  5. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [ 0.  3.  0. 29.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.73976516723633



buy possibilites: [-1] 
expected returns: [[46.817513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15.  0.] 
cards in discard: [1. 8.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 30.  8.  9.  9.  0.  4. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [ 0.  3.  0. 29.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -30   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 45.974388122558594






Player: 1 
cards in hand: [ 0. 10.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  8.] 
cards in discard: [ 0.  3.  0. 29.  8.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 30.  8.  9.  9.  0.  4. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 11. 29.  1. 10.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8] -> size -> 38 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  8.] 
cards in discard: [ 0.  3.  0. 29.  8.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 27. 30.  8.  9.  9.  0.  4. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 11. 29.  1. 10.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8] -> size -> 38 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  8.] 
cards in discard: [ 0.  3.  0. 29.  8.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 27. 30.  8.  9.  9.  0.  4. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 11. 29.  1. 10.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8] -> size -> 38 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [29. 11. 29.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29. 10.] 
expected returns: [[17.692757]
 [41.00623 ]
 [31.65918 ]
 [41.00623 ]
 [ 9.000924]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 29.  1. 10.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  9.  9.  0.  4. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 11.  3. 11.  0.] 
adversary cards in discard: [ 0.  3.  0. 29.  8.  3.  3.  0.  0. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.81751251220703



action possibilites: [-1. 11. 29. 10.] 
expected returns: [[63.105034]
 [74.68012 ]
 [82.77539 ]
 [53.97857 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 27. 30.  8.  9.  9.  0.  4. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 11.  3. 11.  0.] 
adversary cards in discard: [ 0.  3.  0. 29.  8.  3.  3.  0.  0. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 47.385536193847656



action possibilites: [-1. 11.] 
expected returns: [[65.66961]
 [76.18058]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 27. 30.  8.  9.  9.  0.  4. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 11.  3. 11.  0.] 
adversary cards in discard: [ 0.  3.  0. 29.  8.  3.  3.  0.  0. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 74.26860046386719



action possibilites: [-1] 
expected returns: [[64.53134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 24. 30. 27. 30.  8.  9.  9.  0.  4. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 11.  3. 11.  0.] 
adversary cards in discard: [ 0.  3.  0. 29.  8.  3.  3.  0.  0. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 75.88978576660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[55.690388]
 [63.96441 ]
 [17.280506]
 [69.95918 ]
 [64.761925]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 30. 27. 30.  8.  9.  9.  0.  4. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 11.  3. 11.  0.] 
adversary cards in discard: [ 0.  3.  0. 29.  8.  3.  3.  0.  0. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.53134155273438



buy possibilites: [-1] 
expected returns: [[64.42518]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 11.  3. 11.  0.] 
adversary cards in discard: [ 0.  3.  0. 29.  8.  3.  3.  0.  0. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0 -50   0   0  16   0] 
sum of rewards: -9 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 69.95919036865234






Player: 1 
cards in hand: [ 1. 11.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3. 11.  0.] 
cards in discard: [ 0.  3.  0. 29.  8.  3.  3.  0.  0. 10.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 29. 10.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8] -> size -> 40 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3. 11.  0.] 
cards in discard: [ 0.  3.  0. 29.  8.  3.  3.  0.  0. 10.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 27. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 29. 10.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8] -> size -> 40 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3. 11.  0.] 
cards in discard: [ 0.  3.  0. 29.  8.  3.  3.  0.  0. 10.  0.  3.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 29. 10.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8] -> size -> 40 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[21.298012]
 [33.932434]
 [42.483665]
 [13.219058]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 29. 10.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0  3] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.42517852783203



action possibilites: [-1. 10. 29.] 
expected returns: [[40.42636 ]
 [31.820705]
 [65.16485 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0  3] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 48.562774658203125



action possibilites: [-1.] 
expected returns: [[61.361496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 24. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0  3] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 55.69139862060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[54.7986  ]
 [75.80064 ]
 [62.48123 ]
 [20.620869]
 [68.24552 ]
 [62.47252 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0  3] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 61.36149597167969



buy possibilites: [-1] 
expected returns: [[69.624985]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0  3] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0 -60   0   0  54   0] 
sum of rewards: -31 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 75.8006362915039






Player: 1 
cards in hand: [10.  3.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8.  6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  8  8 11  0  0 29  1 10 11  3  0  6  8  0  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 11.  1.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1] -> size -> 41 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 11.  1.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1] -> size -> 41 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 23. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 11.  1.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1] -> size -> 41 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 11.  1.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1] -> size -> 41 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-10.67363  ]
 [-21.338928 ]
 [  5.1165104]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11.  1.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [0. 8. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.62498474121094



action possibilites: [-1] 
expected returns: [[-7.187792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  1.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [0. 8. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: -58 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 4.7580671310424805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[-15.542062  ]
 [  9.40187   ]
 [ -6.521911  ]
 [-54.46983   ]
 [  0.41986609]
 [ -7.1877766 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  1.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 22. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [0. 8. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.18779182434082



buy possibilites: [-1] 
expected returns: [[-13.021126]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  1.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [0. 8. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -80   0   0  54   0] 
sum of rewards: -41 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 9.401850700378418






Player: 1 
cards in hand: [0. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [0. 8. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 11. 10. 11.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.  1. 11.  0.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [0. 8. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 11. 10. 11.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.  1. 11.  0.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [0. 8. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 21. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 11. 10. 11.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.  1. 11.  0.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 11. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 11.] 
expected returns: [[19.519146 ]
 [24.983906 ]
 [33.192196 ]
 [10.9818125]
 [33.192196 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11. 10. 11.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.  1. 11.  0.  3. 10.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 29. 11.  3. 11.] 
adversary cards in discard: [0. 8. 0. 6. 8. 0. 3. 8.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.021125793457031



action possibilites: [-1] 
expected returns: [[1.8211002]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 11.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.  1. 11.  0.  3. 10.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 20. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 29. 11.  3. 11.] 
adversary cards in discard: [0. 8. 0. 6. 8. 0. 3. 8.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -90   0   0  27   0] 
sum of rewards: -78 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 32.966835021972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -6.335889 ]
 [-40.381813 ]
 [  1.8211069]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10. 11.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.  1. 11.  0.  3. 10.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 20. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 29. 11.  3. 11.] 
adversary cards in discard: [0. 8. 0. 6. 8. 0. 3. 8.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.8211002349853516






Player: 1 
cards in hand: [ 1. 29. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 11.  3. 11.] 
cards in discard: [0. 8. 0. 6. 8. 0. 3. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 20. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 29. 10.  8.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.  1. 11.  0.  3. 10.  1.  1. 11.  3.  8. 10.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1] -> size -> 44 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 11.  3. 11.] 
cards in discard: [0. 8. 0. 6. 8. 0. 3. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 20. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 29. 10.  8.] 
adversary cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.  1. 11.  0.  3. 10.  1.  1. 11.  3.  8. 10.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1] -> size -> 44 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  0. 29. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.  8.] 
expected returns: [[-43.662525]
 [-52.10103 ]
 [-20.17101 ]
 [-52.10103 ]
 [-38.285156]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 10.  8.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.  1. 11.  0.  3. 10.  1.  1. 11.  3.  8. 10.
 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 20. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  6.  8.  0.  3.  8.  1. 29. 11.  3. 11.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 1.8211002349853516



action possibilites: [-1. 10. 10.] 
expected returns: [[-43.470215]
 [-51.206406]
 [-51.206406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.  1. 11.  0.  3. 10.  1.  1. 11.  3.  8. 10.
 11. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 20. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  6.  8.  0.  3.  8.  1. 29. 11.  3. 11.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -30.23562240600586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-51.46834 ]
 [-44.562954]
 [-80.54136 ]
 [-39.602066]
 [-43.470215]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.  1. 11.  0.  3. 10.  1.  1. 11.  3.  8. 10.
 11. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 20. 30. 26. 30.  8.  9.  9.  0.  3. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  6.  8.  0.  3.  8.  1. 29. 11.  3. 11.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -43.47020721435547



buy possibilites: [-1] 
expected returns: [[-37.173634]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [ 1.  8. 11.  0. 10. 15.  0.  1.  0. 10.  1.  1.  8. 29. 29. 11.  0. 11.
  3. 10.  1. 29. 29.  0.  1.  1. 11.  0.  3. 10.  1.  1. 11.  3.  8. 10.
 11. 10.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 20. 30. 26. 30.  8.  9.  9.  0.  2. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  6.  8.  0.  3.  8.  1. 29. 11.  3. 11.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -100    0    0
   16    0] 
sum of rewards: -99 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -39.60206604003906






Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 0.  8.  0.  6.  8.  0.  3.  8.  1. 29. 11.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 20. 30. 26. 30.  8.  9.  9.  0.  2. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  3.  1.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8] -> size -> 45 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 0.  8.  0.  6.  8.  0.  3.  8.  1. 29. 11.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 20. 30. 26. 30.  8.  9.  9.  0.  2. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  3.  1.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8] -> size -> 45 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  1.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[29.540573]
 [42.70116 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  1.  1. 11.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 20. 30. 26. 30.  8.  9.  9.  0.  2. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -37.17363357543945



action possibilites: [-1] 
expected returns: [[38.84223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 1.] 
cards in discard: [1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 19. 30. 26. 30.  8.  9.  9.  0.  2. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: -98 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 42.213035583496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[31.447212 ]
 [52.275093 ]
 [18.508354 ]
 [39.3362   ]
 [11.014916 ]
 [-1.9239626]
 [46.728123 ]
 [44.806316 ]
 [81.79575  ]
 [60.48278  ]
 [11.435136 ]
 [34.184788 ]
 [13.356952 ]
 [32.26299  ]
 [41.096634 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 1.] 
cards in discard: [1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 19. 30. 26. 30.  8.  9.  9.  0.  2. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.84223175048828



buy possibilites: [-1] 
expected returns: [[67.192245]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 1.] 
cards in discard: [ 1. 25.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 19. 30. 26. 30.  8.  9.  9.  0.  2.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.    20.     0.     0.     0.
    0.  -120.     0.     0.    62.5    0. ] 
sum of rewards: -72.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 81.79571533203125






Player: 1 
cards in hand: [ 8. 29.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 19. 30. 26. 30.  8.  9.  9.  0.  2.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 29. 11.  1. 11.] 
adversary cards in discard: [ 1. 25. 11.  1.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25] -> size -> 47 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 19. 30. 26. 30.  8.  9.  9.  0.  2.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 29. 11.  1. 11.] 
adversary cards in discard: [ 1. 25. 11.  1.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25] -> size -> 47 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  1.  0.  0.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 19. 30. 26. 30.  8.  9.  9.  0.  1.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 29. 11.  1. 11.] 
adversary cards in discard: [ 1. 25. 11.  1.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25] -> size -> 47 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 11.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11. 11.] 
expected returns: [[44.05242 ]
 [48.80755 ]
 [66.107185]
 [57.376297]
 [57.376297]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 11.  1. 11.] 
cards in discard: [ 1. 25. 11.  1.  3.  1.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 19. 30. 26. 30.  8.  9.  9.  0.  1.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3.  6. 11.  3.] 
adversary cards in discard: [ 8.  8. 29.  1.  0.  0.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.19224548339844



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[40.96742 ]
 [54.056656]
 [54.056656]
 [54.056656]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.] 
cards in discard: [ 1. 25. 11.  1.  3.  1.  1.  8.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 19. 30. 26. 30.  8.  9.  9.  0.  1.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3.  6. 11.  3.] 
adversary cards in discard: [ 8.  8. 29.  1.  0.  0.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 56.9973030090332



action possibilites: [-1] 
expected returns: [[10.612599]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.] 
cards in discard: [ 1. 25. 11.  1.  3.  1.  1.  8.  1.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 18. 30. 26. 30.  8.  9.  9.  0.  1.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3.  6. 11.  3.] 
adversary cards in discard: [ 8.  8. 29.  1.  0.  0.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: -98 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 53.658973693847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[  1.506484 ]
 [-32.88364  ]
 [ 10.2211275]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.] 
cards in discard: [ 1. 25. 11.  1.  3.  1.  1.  8.  1.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 18. 30. 26. 30.  8.  9.  9.  0.  1.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3.  6. 11.  3.] 
adversary cards in discard: [ 8.  8. 29.  1.  0.  0.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.61259937286377






Player: 1 
cards in hand: [ 3.  3.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 11.  3.] 
cards in discard: [ 8.  8. 29.  1.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 26. 30.  8.  9.  9.  0.  1.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 10.  0. 10.] 
adversary cards in discard: [ 1. 25. 11.  1.  3.  1.  1.  8.  1.  1. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25  1] -> size -> 48 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 3.] 
cards in discard: [ 8.  8. 29.  1.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 26. 30.  8.  9.  9.  0.  1.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 10.  0. 10.] 
adversary cards in discard: [ 1. 25. 11.  1.  3.  1.  1.  8.  1.  1. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25  1] -> size -> 48 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 3.] 
cards in discard: [ 8.  8. 29.  1.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 18. 30. 26. 30.  8.  9.  9.  0.  1.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 10.  0. 10.] 
adversary cards in discard: [ 1. 25. 11.  1.  3.  1.  1.  8.  1.  1. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25  1] -> size -> 48 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 3.] 
cards in discard: [ 8.  8. 29.  1.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0  8  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 18. 30. 26. 30.  8.  9.  9.  0.  1.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 10.  0. 10.] 
adversary cards in discard: [ 1. 25. 11.  1.  3.  1.  1.  8.  1.  1. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25  1] -> size -> 48 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10. 29. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 10.] 
expected returns: [[36.128445]
 [27.638218]
 [59.484634]
 [27.638218]
 [27.638218]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  0. 10.] 
cards in discard: [ 1. 25. 11.  1.  3.  1.  1.  8.  1.  1. 29. 11. 11. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 18. 30. 26. 30.  8.  9.  9.  0.  1.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [ 8.  8. 29.  1.  0.  0.  0.  0. 11.  3.  3.  6.  3.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0  8  0  0] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.221123695373535



action possibilites: [-1. 10. 10.] 
expected returns: [[55.397377]
 [47.59762 ]
 [47.59762 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [ 1. 25. 11.  1.  3.  1.  1.  8.  1.  1. 29. 11. 11. 11. 10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 18. 30. 26. 30.  8.  9.  9.  0.  1.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [ 8.  8. 29.  1.  0.  0.  0.  0. 11.  3.  3.  6.  3.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0  8  0  0] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 50.621673583984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[47.011982]
 [55.418125]
 [ 6.989888]
 [61.88172 ]
 [55.00564 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 1. 25. 11.  1.  3.  1.  1.  8.  1.  1. 29. 11. 11. 11. 10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 18. 30. 26. 30.  8.  9.  9.  0.  1.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [ 8.  8. 29.  1.  0.  0.  0.  0. 11.  3.  3.  6.  3.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0  8  0  0] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 55.397396087646484



Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 3 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 6 
Witch: 1 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10. 10.  0.] 
cards in discard: [ 1. 25. 11.  1.  3.  1.  1.  8.  1.  1. 29. 11. 11. 11. 10.  0.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 11 10 11 10 29 10 11 10 11
 10 11 10 29 10 11 15  8  1  1  8  1  1  8  1  8  1  1  1  1  8  1 25  1
  8] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 18. 30. 26. 30.  8.  9.  9.  0.  0.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [ 8.  8. 29.  1.  0.  0.  0.  0. 11.  3.  3.  6.  3.] 
adversary owned cards: [ 0  3  3  3  8  8 11  0  0 29  1 11  3  0  6  8  0  0  3  0  8  0  0] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0       20        0
        0        0        0     -140        0        0        8        0] 
sum of rewards: -3000147 

action type: buy - action 8.0
Learning step: -120008.359375
desired expected reward: -119946.4765625



