 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[72.79156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000095 

action type: buy - action -1
Learning step: -300007.71875
desired expected reward: -300025.34375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[69.1762  ]
 [71.671196]
 [70.49875 ]
 [68.56772 ]
 [71.094795]
 [73.27816 ]
 [71.9556  ]
 [76.933174]
 [71.34712 ]
 [70.78316 ]
 [73.84212 ]
 [68.48102 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 72.91520690917969



buy possibilites: [-1] 
expected returns: [[45.4102]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 76.93316650390625






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  0.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[73.17258]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 45.41019821166992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[74.200905]
 [76.557945]
 [75.44951 ]
 [73.623955]
 [78.07772 ]
 [76.829124]
 [75.720695]
 [73.542046]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 73.3996810913086



buy possibilites: [-1] 
expected returns: [[67.62264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 78.07772064208984






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3. 29.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[46.977226]
 [53.77889 ]
 [50.84359 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.62264251708984



action possibilites: [-1. 11.] 
expected returns: [[34.48014 ]
 [38.098473]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 53.316749572753906



action possibilites: [-1] 
expected returns: [[38.986755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 38.4581184387207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[41.3304  ]
 [43.266476]
 [42.354183]
 [40.85174 ]
 [42.812042]
 [44.518604]
 [43.494823]
 [47.425583]
 [43.01616 ]
 [42.58252 ]
 [44.95224 ]
 [40.784462]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.98675537109375



buy possibilites: [-1] 
expected returns: [[37.964973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 103 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 47.42558288574219






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 3.  0.  3.  0.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  3 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[68.1906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  3 11] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.96497344970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[67.48335]
 [69.52583]
 [68.56702]
 [66.98778]
 [70.83932]
 [69.75566]
 [68.79685]
 [66.91679]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  3 11] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 65.81208038330078



buy possibilites: [-1] 
expected returns: [[75.854515]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  3 11] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: -11 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 70.83932495117188






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  3 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [11.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[36.25016 ]
 [40.285263]
 [38.186867]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [16. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.8545150756836



action possibilites: [-1] 
expected returns: [[38.90847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [16. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.31781005859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[40.921165]
 [42.01202 ]
 [40.41172 ]
 [43.255135]
 [40.340046]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [16. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.908470153808594



buy possibilites: [-1] 
expected returns: [[39.23906]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [16. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 43.25514221191406






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  0.] 
cards in discard: [16. 15.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  0.] 
cards in discard: [16. 15.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  0.] 
cards in discard: [16. 15.  3.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[77.84005]
 [82.31727]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.23905944824219



action possibilites: [-1] 
expected returns: [[52.875237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 79.26878356933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[60.46644 ]
 [62.969017]
 [61.792618]
 [59.880127]
 [64.586464]
 [63.255478]
 [62.07908 ]
 [59.801582]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.87523651123047



buy possibilites: [-1] 
expected returns: [[33.62905]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 64.58646392822266






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0. 29.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0. 10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0. 29.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0. 10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0. 29.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0. 10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3.  0. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[2.6624532]
 [6.200831 ]
 [6.200831 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0. 29.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3. 16.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10  0] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.629051208496094



action possibilites: [-1. 29.] 
expected returns: [[44.18995 ]
 [51.354584]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3. 16.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10  0] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 0.992828369140625



action possibilites: [-1.] 
expected returns: [[44.723362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3. 16.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10  0] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.354583740234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[46.527534]
 [48.531918]
 [47.589825]
 [46.980297]
 [46.0409  ]
 [48.068302]
 [49.823288]
 [48.76099 ]
 [52.30615 ]
 [52.75891 ]
 [48.27166 ]
 [49.58336 ]
 [47.8189  ]
 [47.57898 ]
 [50.276047]
 [45.97305 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3. 16.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10  0] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 44.72336196899414



buy possibilites: [-1] 
expected returns: [[46.97132]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3. 16.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10  0] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 7.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 52.7589111328125






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 15.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3. 16.] 
cards in discard: [0. 3. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  3 11 16 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  6.  9. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  0. 11.  3.] 
adversary cards in discard: [29. 29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.] 
cards in discard: [0. 3. 3. 3. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  0. 11.  3.] 
adversary cards in discard: [29. 29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.] 
cards in discard: [0. 3. 3. 3. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  0. 11.  3.] 
adversary cards in discard: [29. 29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.] 
cards in discard: [0. 3. 3. 3. 0. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  0. 11.  3.] 
adversary cards in discard: [29. 29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[46.368187]
 [49.618053]
 [49.618053]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11.  3.] 
cards in discard: [29. 29. 29.  3.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0.  0.  6.  0. 16.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.97132110595703



action possibilites: [-1] 
expected returns: [[5.9041543]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [29. 29. 29.  3.  0.  0.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0.  0.  6.  0. 16.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.172142028808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[10.533167]
 [11.15943 ]
 [10.24198 ]
 [11.854448]
 [10.201992]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [29. 29. 29.  3.  0.  0.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  9. 10.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0.  0.  6.  0. 16.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.904154300689697



buy possibilites: [-1] 
expected returns: [[19.248022]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [29. 29. 29.  3.  0.  0.  3.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  8. 10.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0.  0.  6.  0. 16.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 11.854446411132812






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.  0.] 
cards in discard: [ 0.  3.  3.  3.  0.  0.  6.  0. 16.  0. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  8. 10.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10. 11.  8. 10.  0.] 
adversary cards in discard: [29. 29. 29.  3.  0.  0.  3.  0. 10.  8. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6.  8. 10.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10. 11.  8. 10.  0.] 
adversary cards in discard: [29. 29. 29.  3.  0.  0.  3.  0. 10.  8. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  6.  8. 10.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10. 11.  8. 10.  0.] 
adversary cards in discard: [29. 29. 29.  3.  0.  0.  3.  0. 10.  8. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  6.  8. 10.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10. 11.  8. 10.  0.] 
adversary cards in discard: [29. 29. 29.  3.  0.  0.  3.  0. 10.  8. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 11.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8. 10.] 
expected returns: [[-1.4383876 ]
 [-0.7463188 ]
 [-0.00427103]
 [-0.39602113]
 [-0.7463188 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8. 10.  0.] 
cards in discard: [29. 29. 29.  3.  0.  0.  3.  0. 10.  8. 11.  0.  0. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  6.  8. 10.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 15.  0.] 
adversary cards in discard: [ 0. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.248022079467773



action possibilites: [-1] 
expected returns: [[-15.137514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.  0.] 
cards in discard: [29. 29. 29.  3.  0.  0.  3.  0. 10.  8. 11.  0.  0. 11.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  6.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 15.  0.] 
adversary cards in discard: [ 0. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -0.32538866996765137





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-15.240955]
 [-15.357056]
 [-15.373205]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.  0.] 
cards in discard: [29. 29. 29.  3.  0.  0.  3.  0. 10.  8. 11.  0.  0. 11.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  6.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 15.  0.] 
adversary cards in discard: [ 0. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -15.137514114379883



buy possibilites: [-1] 
expected returns: [[-14.434856]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.  0.] 
cards in discard: [29. 29. 29.  3.  0.  0.  3.  0. 10.  8. 11.  0.  0. 11.  3. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  6.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 15.  0.] 
adversary cards in discard: [ 0. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -15.24095344543457






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 15.  0.] 
cards in discard: [ 0. 10. 11.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  6.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0. 10. 11.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  6.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0. 10. 11.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  6.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0. 10. 11.  0.  0.  0.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0] -> size -> 24 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[25.528296]
 [29.001097]
 [27.194399]
 [27.194399]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [16.  0.  3.  3.  0.] 
adversary cards in discard: [ 0. 10. 11.  0.  0.  0.  3.  8. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.434856414794922



action possibilites: [-1] 
expected returns: [[14.735037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 10.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [16.  0.  3.  3.  0.] 
adversary cards in discard: [ 0. 10. 11.  0.  0.  0.  3.  8. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 24.46748924255371





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.199697]
 [19.802721]
 [19.746767]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 10.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [16.  0.  3.  3.  0.] 
adversary cards in discard: [ 0. 10. 11.  0.  0.  0.  3.  8. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.735036849975586



buy possibilites: [-1] 
expected returns: [[18.690783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 10.] 
cards in discard: [10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [16.  0.  3.  3.  0.] 
adversary cards in discard: [ 0. 10. 11.  0.  0.  0.  3.  8. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 20.1997013092041






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [16.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  3.  0.] 
cards in discard: [ 0. 10. 11.  0.  0.  0.  3.  8. 15.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 10.] 
adversary cards in discard: [10.  0. 11.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  3.  0.] 
cards in discard: [ 0. 10. 11.  0.  0.  0.  3.  8. 15.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 10.] 
adversary cards in discard: [10.  0. 11.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  3.  0.] 
cards in discard: [ 0. 10. 11.  0.  0.  0.  3.  8. 15.  6.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 10.] 
adversary cards in discard: [10.  0. 11.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 9.358887]
 [12.672106]
 [10.26153 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0. 10.] 
cards in discard: [10.  0. 11.  3. 10.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.69078254699707



action possibilites: [-1. 10. 10.] 
expected returns: [[-4.521701 ]
 [-3.6767805]
 [-3.6767805]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 10.] 
cards in discard: [10.  0. 11.  3. 10.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 9.672649383544922



action possibilites: [-1. 10.  8.] 
expected returns: [[-2.3432407]
 [-1.5183966]
 [-1.1002169]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  8.] 
cards in discard: [10.  0. 11.  3. 10.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0
 10  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -3.6767797470092773



action possibilites: [-1. 10.] 
expected returns: [[29.508848]
 [30.879572]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [10.  0. 11.  3. 10.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 0.27527475357055664



action possibilites: [-1. 29.] 
expected returns: [[26.85909 ]
 [31.350195]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [10.  0. 11.  3. 10.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.  8. 10.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 30.87957191467285



action possibilites: [-1. 29.] 
expected returns: [[13.926617]
 [18.034151]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [10.  0. 11.  3. 10.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10.  8. 10. 29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.350194931030273



action possibilites: [-1.] 
expected returns: [[12.121008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  0. 11.  3. 10.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10.  8. 10. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 18.034154891967773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[13.569569]
 [14.66243 ]
 [14.147224]
 [13.309828]
 [14.405222]
 [15.369711]
 [14.792051]
 [16.994928]
 [14.521246]
 [14.276848]
 [15.614105]
 [13.273676]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  0. 11.  3. 10.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10.  8. 10. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.121007919311523



buy possibilites: [-1] 
expected returns: [[-3.2908878]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  0. 11.  3. 10.  0. 10. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10.  8. 10. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0 120   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 16.99492835998535






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 15.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.  6.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [10.  0. 11.  3. 10.  0. 10. 29. 29. 10.  8. 10. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29] -> size -> 24 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  6.  3.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [10.  0. 11.  3. 10.  0. 10. 29. 29. 10.  8. 10. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29] -> size -> 24 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  6.  3.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3] -> size -> 19 
action values: 2 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [10.  0. 11.  3. 10.  0. 10. 29. 29. 10.  8. 10. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29] -> size -> 24 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  6.  3.  3.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [10.  0. 11.  3. 10.  0. 10. 29. 29. 10.  8. 10. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29] -> size -> 24 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-9.819292]
 [-9.33729 ]
 [-9.075991]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  8.] 
cards in discard: [10.  0. 11.  3. 10.  0. 10. 29. 29. 10.  8. 10. 29. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  3. 15.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -3.2908878326416016



action possibilites: [-1] 
expected returns: [[0.21358871]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [10.  0. 11.  3. 10.  0. 10. 29. 29. 10.  8. 10. 29. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  3. 15.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: -8.548450469970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 0.02810192]
 [-0.12480879]
 [-0.14625835]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [10.  0. 11.  3. 10.  0. 10. 29. 29. 10.  8. 10. 29. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  3. 15.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.21358871459960938



buy possibilites: [-1] 
expected returns: [[-9.621902]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [10.  0. 11.  3. 10.  0. 10. 29. 29. 10.  8. 10. 29. 29.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  3. 15.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 0.028101444244384766






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  3. 15.  6.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  3. 15.  6.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  3. 15.  6.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  3. 15.  6.  3.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [10.  0.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[-11.645704 ]
 [-11.0978775]
 [-10.50828  ]
 [-10.50828  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [ 0. 10.  3. 15.  6.  3.  3. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.621902465820312



action possibilites: [-1] 
expected returns: [[-14.975796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [ 0. 10.  3. 15.  6.  3.  3. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -11.412660598754883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-13.355011]
 [-12.997038]
 [-13.522331]
 [-12.597792]
 [-13.545818]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  9.  9.  6.  7. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [ 0. 10.  3. 15.  6.  3.  3. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -14.97579574584961



buy possibilites: [-1] 
expected returns: [[-6.146554]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  9.  9.  6.  6. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [ 0. 10.  3. 15.  6.  3.  3. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -12.59779167175293






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [ 0. 10.  3. 15.  6.  3.  3. 10.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  9.  9.  6.  6. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29.  0. 29.  3.  0.] 
adversary cards in discard: [10.  8. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 0. 10.  3. 15.  6.  3.  3. 10.  8.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  6.  6. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29.  0. 29.  3.  0.] 
adversary cards in discard: [10.  8. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 0. 10.  3. 15.  6.  3.  3. 10.  8.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  6.  6. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29.  0. 29.  3.  0.] 
adversary cards in discard: [10.  8. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [29.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-11.969357]
 [ -9.766115]
 [ -9.766115]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3.  0.] 
cards in discard: [10.  8. 11. 10.  0.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  6.  6. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.146553993225098



action possibilites: [-1. 29.] 
expected returns: [[-7.0861464]
 [-4.6828637]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [10.  8. 11. 10.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  6.  6. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -11.124929428100586



action possibilites: [-1. 10.] 
expected returns: [[-11.876177]
 [-11.203346]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [10.  8. 11. 10.  0.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  6.  6. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -4.682863235473633



action possibilites: [-1.  8.] 
expected returns: [[-8.85788  ]
 [-7.9380155]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [10.  8. 11. 10.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  3 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8] -> size -> 24 
action values: 2 
buys: 0 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  6.  6. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -11.203346252441406



action possibilites: [-1.] 
expected returns: [[-8.440399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  8. 11. 10.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 10.  8.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  6.  6. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 5
Learning step: 0
desired expected reward: -7.576424598693848





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-7.2806487]
 [-6.643779 ]
 [-6.9443502]
 [-7.4392333]
 [-6.211755 ]
 [-6.56726  ]
 [-6.867831 ]
 [-7.4613442]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  8. 11. 10.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 10.  8.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  6.  6. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -8.440399169921875



buy possibilites: [-1] 
expected returns: [[10.036886]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  8. 11. 10.  0.  0. 11. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 10.  8.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  5.  6. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
   54    0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -6.21175479888916






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  5.  6. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29.  0. 10. 10.  8.] 
adversary cards in discard: [10.  8. 11. 10.  0.  0. 11. 11. 29. 29. 10.  8.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11] -> size -> 22 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  5.  6. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29.  0. 10. 10.  8.] 
adversary cards in discard: [10.  8. 11. 10.  0.  0. 11. 11. 29. 29. 10.  8.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11] -> size -> 22 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  5.  5. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29.  0. 10. 10.  8.] 
adversary cards in discard: [10.  8. 11. 10.  0.  0. 11. 11. 29. 29. 10.  8.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11] -> size -> 22 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [29.  0. 10. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.  8.] 
expected returns: [[-8.513102 ]
 [-6.7087593]
 [-8.056208 ]
 [-8.056208 ]
 [-7.8065424]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 10.  8.] 
cards in discard: [10.  8. 11. 10.  0.  0. 11. 11. 29. 29. 10.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  5.  5. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.036886215209961



action possibilites: [-1. 10. 10.  8. 11.] 
expected returns: [[-7.3815575]
 [-6.9246106]
 [-6.9246106]
 [-6.6933823]
 [-6.434911 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  8. 11.] 
cards in discard: [10.  8. 11. 10.  0.  0. 11. 11. 29. 29. 10.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  5.  5. 10.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -6.912528991699219



action possibilites: [-1] 
expected returns: [[-3.0565305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  8.] 
cards in discard: [10.  8. 11. 10.  0.  0. 11. 11. 29. 29. 10.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  5.  5. 10.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -58 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -6.203339576721191





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-3.1957421]
 [-2.9372704]
 [-3.3180494]
 [-2.6468284]
 [-3.3350651]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  8.] 
cards in discard: [10.  8. 11. 10.  0.  0. 11. 11. 29. 29. 10.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  5.  5. 10.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.056530475616455



buy possibilites: [-1] 
expected returns: [[-10.495003]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  8.] 
cards in discard: [10.  8. 11. 10.  0.  0. 11. 11. 29. 29. 10.  8.  0. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  5.  4. 10.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -69 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -2.646829128265381






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  0.  0.] 
cards in discard: [ 8.  3.  3.  0.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  5.  4. 10.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  0.  0.] 
cards in discard: [ 8.  3.  3.  0.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  5.  4. 10.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  0.  0.] 
cards in discard: [ 8.  3.  3.  0.  0. 11. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  4.  4. 10.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [11.  0. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 29.] 
expected returns: [[-6.5423656]
 [-4.9698114]
 [-5.7845397]
 [-5.7845397]
 [-3.7808352]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 10. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  4.  4. 10.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 16.  3. 10.  3.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8 11] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.495002746582031



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[-7.6829634]
 [-6.5139832]
 [-7.1349206]
 [-7.1349206]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  0.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  4.  4. 10.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 16.  3. 10.  3.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8 11] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -8.612351417541504



action possibilites: [-1] 
expected returns: [[-9.182568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [ 0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  4.  4. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 16.  3. 10.  3.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8 11] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -21 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -6.159806728363037





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-7.785043 ]
 [-7.4267683]
 [-7.9534097]
 [-7.026076 ]
 [-7.976964 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  4.  4. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 16.  3. 10.  3.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8 11] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.182567596435547



buy possibilites: [-1] 
expected returns: [[4.3703275]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 0. 15.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 16.  3. 10.  3.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8 11] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -69 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -7.02607536315918






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3. 10.  3.] 
cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16 10  0  6  0  0  8  3  0 10  0  8 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 11.  8.  8.  0.] 
adversary cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8] -> size -> 26 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 11.  8.  8.  0.] 
adversary cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8] -> size -> 26 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 11.  8.  8.  0.] 
adversary cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8] -> size -> 26 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 11.  8.  8.  0.] 
adversary cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8] -> size -> 26 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [10. 11.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.  8.] 
expected returns: [[-13.111601]
 [-12.736176]
 [-12.333626]
 [-12.546064]
 [-12.546064]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  8.  0.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  6. 10.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.  0.  0. 16.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.370327472686768



action possibilites: [-1] 
expected returns: [[-6.989438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  0.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6. 10.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.  0.  0. 16.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -12.11014175415039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-7.007272 ]
 [-7.1453495]
 [-7.1645613]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  8.  0.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6. 10.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.  0.  0. 16.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.989438056945801



buy possibilites: [-1] 
expected returns: [[-0.31720543]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  8.  0.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6. 10.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.  0.  0. 16.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -105.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -7.007270812988281






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  0.  0.] 
cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.  0.  0. 16.  8.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11.  8. 10. 10.  0.] 
adversary cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0] -> size -> 28 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0.  0.] 
cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.  0.  0. 16.  8.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11.  8. 10. 10.  0.] 
adversary cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0] -> size -> 28 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0.  0.] 
cards in discard: [ 8.  3.  3.  0.  0. 11. 11.  0.  3. 15.  0.  0.  0.  0. 16.  8.  3.  3.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11.  8. 10. 10.  0.] 
adversary cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0] -> size -> 28 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [11.  8. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10. 10.] 
expected returns: [[-12.616615]
 [-11.838501]
 [-12.05094 ]
 [-12.241049]
 [-12.241049]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 10. 10.  0.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.31720542907714844



action possibilites: [-1] 
expected returns: [[-14.210075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.  0.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -11.649360656738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-14.226522]
 [-14.342726]
 [-14.358877]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.  0.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -14.210075378417969



buy possibilites: [-1] 
expected returns: [[-11.907782]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.  0.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -105.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.226520538330078






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 29. 29. 11. 10.] 
adversary cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0. 15.  0. 11.
  8. 10. 10.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0] -> size -> 30 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 29. 29. 11. 10.] 
adversary cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0. 15.  0. 11.
  8. 10. 10.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0] -> size -> 30 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 29. 29. 11. 10.] 
adversary cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0. 15.  0. 11.
  8. 10. 10.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0] -> size -> 30 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [29. 29. 29. 11. 10.] 
adversary cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0. 15.  0. 11.
  8. 10. 10.  0.] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0] -> size -> 30 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [29. 29. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 11. 10.] 
expected returns: [[-13.384605]
 [-12.025991]
 [-12.025991]
 [-12.025991]
 [-12.606688]
 [-13.009237]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 11. 10.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0. 15.  0. 11.
  8. 10. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -11.907781600952148



action possibilites: [-1. 29. 11. 10. 10.] 
expected returns: [[-9.022676 ]
 [-7.6419272]
 [-8.234948 ]
 [-8.642611 ]
 [-8.642611 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10. 10.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0. 15.  0. 11.
  8. 10. 10.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -12.86790657043457



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[-16.496616]
 [-15.835579]
 [-16.176664]
 [-16.176664]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0. 15.  0. 11.
  8. 10. 10.  0. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -8.499368667602539



action possibilites: [-1] 
expected returns: [[-17.557566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0. 15.  0. 11.
  8. 10. 10.  0. 29.  8. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -1 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -15.679798126220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-17.509882]
 [-17.295444]
 [-17.611284]
 [-17.046635]
 [-17.625399]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0. 15.  0. 11.
  8. 10. 10.  0. 29.  8. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  4.  3. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: -17.557565689086914



buy possibilites: [-1] 
expected returns: [[-12.304001]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [ 0. 15.  8. 29. 11. 10. 10.  0. 15.  0. 11. 10.  8.  8.  0. 15.  0. 11.
  8. 10. 10.  0. 29.  8. 15.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0 15  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  4.  2. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -49 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -17.0466365814209






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  4.  2. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [15.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0 15  8] -> size -> 32 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  4.  2. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [15.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0 15  8] -> size -> 32 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [15.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0 15  8] -> size -> 32 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [15.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
expected returns: [[-13.008291]
 [-12.141222]
 [-12.442701]
 [-12.632811]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8
 15  8 15  0 15  0 15  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [11.  3.  0. 16.  8.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.304000854492188



action possibilites: [-1] 
expected returns: [[-12.232731]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8 15
  8 15  0 15  0 15  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [11.  3.  0. 16.  8.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -12.170343399047852





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[-12.023787 ]
 [-11.534158 ]
 [-11.765385 ]
 [-12.14596  ]
 [-11.650471 ]
 [-11.216472 ]
 [-11.474943 ]
 [-10.506355 ]
 [-11.597252 ]
 [-11.107552 ]
 [-12.1629505]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8 15
  8 15  0 15  0 15  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [11.  3.  0. 16.  8.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.232730865478516



buy possibilites: [-1] 
expected returns: [[-11.630326]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.] 
cards in discard: [29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8 15
  8 15  0 15  0 15  8 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [11.  3.  0. 16.  8.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
  128    0] 
sum of rewards: 23 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -10.506355285644531






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [11.  3.  0. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 16.  8.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10. 29.  0. 15.  8.] 
adversary cards in discard: [29. 15.  8.  0. 10.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8 15
  8 15  0 15  0 15  8 29] -> size -> 32 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 16.  8.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10. 29.  0. 15.  8.] 
adversary cards in discard: [29. 15.  8.  0. 10.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8 15
  8 15  0 15  0 15  8 29] -> size -> 32 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 29.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 15.  8.] 
expected returns: [[-12.397652]
 [-11.962785]
 [-10.82099 ]
 [-11.392803]
 [-11.742605]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 15.  8.] 
cards in discard: [29. 15.  8.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8 15
  8 15  0 15  0 15  8 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3. 11.  3.  0. 16.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -11.630326271057129



action possibilites: [-1. 10. 15.  8.] 
expected returns: [[-12.900772]
 [-12.465979]
 [-11.896215]
 [-12.245798]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.  8.] 
cards in discard: [29. 15.  8.  0. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10  0 10  0 29  0 10  8 11 10  8 15
  8 15  0 15  0 15  8 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3. 11.  3.  0. 16.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -11.798986434936523



action possibilites: [-1] 
expected returns: [[-12.374872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.] 
cards in discard: [29. 15.  8.  0. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3. 11.  3.  0. 16.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -11.896217346191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[-12.241716]
 [-11.775644]
 [-11.995821]
 [-12.357979]
 [-11.886398]
 [-11.473138]
 [-11.719263]
 [-10.797205]
 [-11.835724]
 [-11.369419]
 [-12.374149]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.] 
cards in discard: [29. 15.  8.  0. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3. 11.  3.  0. 16.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.374872207641602



buy possibilites: [-1] 
expected returns: [[-12.416094]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  4.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3. 11.  3.  0. 16.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
  128    0] 
sum of rewards: 43 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -10.79720401763916






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3. 11.  3.  0. 16.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0
 14 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  4.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10.  8.  8.  0. 11.] 
adversary cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29] -> size -> 32 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3. 11.  3.  0. 16.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  4.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10.  8.  8.  0. 11.] 
adversary cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29] -> size -> 32 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3. 11.  3.  0. 16.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  2. 10.  4.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10.  8.  8.  0. 11.] 
adversary cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29] -> size -> 32 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0. 11. 11.  0.  0.  0.  3. 11.  3.  0. 16.  8.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10.  8.  8.  0. 11.] 
adversary cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29] -> size -> 32 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [10.  8.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8. 11.] 
expected returns: [[-15.502932]
 [-15.046761]
 [-14.815533]
 [-14.815533]
 [-14.558157]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  0. 11.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 8. 11.  8.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.416093826293945



action possibilites: [-1] 
expected returns: [[-17.5691]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  0.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 8. 11.  8.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -14.32917594909668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-17.4708  ]
 [-17.571068]
 [-17.585005]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  8.  0.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 8. 11.  8.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -17.56909942626953



buy possibilites: [-1] 
expected returns: [[-12.960516]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  8.  0.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 8. 11.  8.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -105.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -17.470802307128906






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  8.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8.  3.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11.  8. 10.  8. 29.] 
adversary cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0] -> size -> 34 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  8.  3.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11.  8. 10.  8. 29.] 
adversary cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0] -> size -> 34 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  8.  3.  6.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11.  8. 10.  8. 29.] 
adversary cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0] -> size -> 34 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [11.  8. 10.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.  8. 29.] 
expected returns: [[-11.47168 ]
 [-10.693648]
 [-10.906088]
 [-11.096196]
 [-10.906088]
 [-10.109846]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 10.  8. 29.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.960515975952148



action possibilites: [-1. 11. 10.  8. 15.] 
expected returns: [[-8.46809  ]
 [-7.6803365]
 [-8.087999 ]
 [-7.89553  ]
 [-7.5896277]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8. 15.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -10.954866409301758



action possibilites: [-1] 
expected returns: [[-15.643581]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -7.589627742767334





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-15.56934 ]
 [-15.669607]
 [-15.683544]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  8.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -15.64358139038086



buy possibilites: [-1] 
expected returns: [[-12.716721]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  8.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.
  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -15.569339752197266






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 10. 10. 10. 10.] 
adversary cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.
  8.  0. 29. 15. 11. 10.  8.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0] -> size -> 35 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 10. 10. 10. 10.] 
adversary cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.
  8.  0. 29. 15. 11. 10.  8.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0] -> size -> 35 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 10. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 10. 10.] 
expected returns: [[-13.806219]
 [-12.152557]
 [-13.349728]
 [-13.349728]
 [-13.349728]
 [-13.349728]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 10. 10.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.
  8.  0. 29. 15. 11. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3.  3. 14.  0.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.716720581054688



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[-16.791977]
 [-16.41728 ]
 [-16.41728 ]
 [-16.41728 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  0.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.
  8.  0. 29. 15. 11. 10.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3.  3. 14.  0.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -13.177715301513672



action possibilites: [-1. 10. 10.] 
expected returns: [[-16.815815]
 [-16.441128]
 [-16.441128]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.
  8.  0. 29. 15. 11. 10.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0] -> size -> 35 
action values: 2 
buys: 0 
player value: 1 
card supply: [14. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3.  3. 14.  0.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -16.417278289794922



action possibilites: [-1. 10. 29.] 
expected returns: [[-18.134434]
 [-17.760647]
 [-16.804655]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 29.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.
  8.  0. 29. 15. 11. 10.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0] -> size -> 35 
action values: 3 
buys: 0 
player value: 1 
card supply: [14. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3.  3. 14.  0.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -16.441125869750977



action possibilites: [-1. 10.] 
expected returns: [[-19.003408]
 [-19.010803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.
  8.  0. 29. 15. 11. 10.  8. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 10. 10. 29.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0] -> size -> 35 
action values: 3 
buys: 0 
player value: 2 
card supply: [14. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3.  3. 14.  0.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -17.62353515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[-19.00389 ]
 [-19.015818]
 [-19.008934]
 [-19.003408]
 [-19.012266]
 [-18.92447 ]
 [-19.017561]
 [-18.57245 ]
 [-19.013966]
 [-18.870682]
 [-19.003408]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.
  8.  0. 29. 15. 11. 10.  8. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 10. 10. 29.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  4.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3.  3. 14.  0.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -19.003408432006836



buy possibilites: [-1] 
expected returns: [[-18.918299]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [29. 15.  8.  0. 10. 11. 29. 29. 15. 10.  8. 15.  0. 11. 10.  8.  8.  0.
  8.  0. 29. 15. 11. 10.  8. 10. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 10. 10. 29.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3.  3. 14.  0.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0  -10    0    0
  128    0] 
sum of rewards: 73 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -18.572450637817383






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 14.  0.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  0. 29. 29. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0 29] -> size -> 36 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  0. 29.] 
adversary cards in discard: [29. 15.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0 29] -> size -> 36 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 30. 30. 27. 30.  8.  9.  9.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  0. 29.] 
adversary cards in discard: [29. 15.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0 29] -> size -> 36 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  0. 29.] 
adversary cards in discard: [29. 15.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0 29] -> size -> 36 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[-11.584169]
 [-11.018549]
 [-10.222567]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.] 
cards in discard: [29. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0. 15. 10.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0 16] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0  -10    0    0
  944    0] 
sum of rewards: 809 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: -10.4273681640625



action possibilites: [-1.  8.] 
expected returns: [[-9.694862]
 [-9.129095]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [29. 15. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10  0 29  0 10  8 11 10  8 15  8
 15  0 15  0 15  8 29 29 15  0  0 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 30. 30. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0. 15. 10.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0 16] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -11.067327499389648



action possibilites: [-1] 
expected returns: [[-12.625536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29. 15. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10 29  0 10  8 11 10  8 15  8 15
  0 15  0 15  8 29 29 15  0  0 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 30. 30. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0. 15. 10.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0 16] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -9.522018432617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-12.669413]
 [-12.785671]
 [-12.801842]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29. 15. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10 29  0 10  8 11 10  8 15  8 15
  0 15  0 15  8 29 29 15  0  0 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 30. 30. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0. 15. 10.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0 16] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.62553596496582



buy possibilites: [-1] 
expected returns: [[-8.647112]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29. 15. 29.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10 29  0 10  8 11 10  8 15  8 15
  0 15  0 15  8 29 29 15  0  0 29  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 30. 30. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0. 15. 10.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0 16] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   40.    0.    0.    0.    0.  -10.
    0.    0.    0.    0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -12.669412612915039






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15. 10.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10 29  0 10  8 11 10  8 15  8 15
  0 15  0 15  8 29 29 15  0  0 29  0] -> size -> 36 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14
 11  8  0 16] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10 29  0 10  8 11 10  8 15  8 15
  0 15  0 15  8 29 29 15  0  0 29  0] -> size -> 36 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11
  8  0 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 3 
card supply: [13. 30. 30. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10 29  0 10  8 11 10  8 15  8 15
  0 15  0 15  8 29 29 15  0  0 29  0] -> size -> 36 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11
  8  0 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [13. 30. 30. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10 29  0 10  8 11 10  8 15  8 15
  0 15  0 15  8 29 29 15  0  0 29  0] -> size -> 36 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.  2.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11
  8  0 16  2] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.] 
adversary owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10 29  0 10  8 11 10  8 15  8 15
  0 15  0 15  8 29 29 15  0  0 29  0] -> size -> 36 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-9.268534]
 [-8.815498]
 [-8.815498]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [29. 15. 29.  0. 29.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10 29  0 10  8 11 10  8 15  8 15
  0 15  0 15  8 29 29 15  0  0 29  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11. 11.  3.  0.  8.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.  2.
 10. 15.  0.  0.  0.] 
adversary owned cards: [ 0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11
  8  0 16  2] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.647111892700195



action possibilites: [-1. 10.  8.] 
expected returns: [[-6.9417367]
 [-6.50661  ]
 [-6.286431 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [29. 15. 29.  0. 29.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 11 10 29 11 10  8 10 11 29 10  8 10 10 29  0 10  8 11 10  8 15  8 15
  0 15  0 15  8 29 29 15  0  0 29  0] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11. 11.  3.  0.  8.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.  2.
 10. 15.  0.  0.  0.] 
adversary owned cards: [ 0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11
  8  0 16  2] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -8.815499305725098



action possibilites: [-1.] 
expected returns: [[-5.580216]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29. 15. 29.  0. 29.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [29 11 29 11 10  8 10 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0
 15  8 29 29 15  0  0 29  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11. 11.  3.  0.  8.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.  2.
 10. 15.  0.  0.  0.] 
adversary owned cards: [ 0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11
  8  0 16  2] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: trash_cards_n_from_hand - action 5
Learning step: 0
desired expected reward: -6.161931991577148





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.8783503]
 [-6.0164356]
 [-6.03566  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 15. 29.  0. 29.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [29 11 29 11 10  8 10 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0
 15  8 29 29 15  0  0 29  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11. 11.  3.  0.  8.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.  2.
 10. 15.  0.  0.  0.] 
adversary owned cards: [ 0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11
  8  0 16  2] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.580215930938721



buy possibilites: [-1] 
expected returns: [[-14.269289]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 15. 29.  0. 29.  8.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [29 11 29 11 10  8 10 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0
 15  8 29 29 15  0  0 29  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11. 11.  3.  0.  8.] 
adversary cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.  2.
 10. 15.  0.  0.  0.] 
adversary owned cards: [ 0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11
  8  0 16  2] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.878351211547852






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [11. 11.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0.  8.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.  2.
 10. 15.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  3 11 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11
  8  0 16  2] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10. 10. 10.  8. 29.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.] 
adversary owned cards: [29 11 29 11 10  8 10 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0
 15  8 29 29 15  0  0 29  0  0] -> size -> 34 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.  2.
 10. 15.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10. 10. 10.  8. 29.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.] 
adversary owned cards: [29 11 29 11 10  8 10 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0
 15  8 29 29 15  0  0 29  0  0] -> size -> 34 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.  2.
 10. 15.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10. 10. 10.  8. 29.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.] 
adversary owned cards: [29 11 29 11 10  8 10 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0
 15  8 29 29 15  0  0 29  0  0] -> size -> 34 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [ 0.  8. 11.  8.  3.  6.  0.  0.  0. 16.  3. 16. 14.  0.  3.  3.  0.  2.
 10. 15.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10. 10. 10.  8. 29.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.] 
adversary owned cards: [29 11 29 11 10  8 10 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0
 15  8 29 29 15  0  0 29  0  0] -> size -> 34 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [10. 10. 10.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.  8. 29.] 
expected returns: [[-8.666721 ]
 [-8.20216  ]
 [-8.20216  ]
 [-8.20216  ]
 [-7.9408627]
 [-6.700756 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  8. 29.] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29 11 10  8 10 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0
 15  8 29 29 15  0  0 29  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  8.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.269289016723633



action possibilites: [-1. 10. 10. 10. 29.] 
expected returns: [[-12.504744]
 [-12.051798]
 [-12.051798]
 [-12.051798]
 [-10.861654]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 29.] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11 29 11 10  8 10 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0
 15  8 29 29 15  0  0 29  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  8.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -8.007680892944336



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[-5.119142 ]
 [-4.5978007]
 [-4.5978007]
 [-4.3194494]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 11 29 11 10  8 10 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0
 15  8 29 29 15  0  0 29  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 2 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  8.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -11.880894660949707



action possibilites: [-1] 
expected returns: [[-13.697168]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0 15  8
 29 29 15  0  0 29  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  8.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -4.162361145019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-13.873676]
 [-13.661484]
 [-13.974073]
 [-13.422596]
 [-13.988028]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0 15  8
 29 29 15  0  0 29  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  3.  1. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  8.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: -13.697168350219727



buy possibilites: [-1] 
expected returns: [[-13.90807]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0 15  8
 29 29 15  0  0 29  0  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  3.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  8.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -49 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -13.422595977783203






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 16. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  3.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15. 11. 10.  8.  0.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8.] 
adversary owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0 15  8
 29 29 15  0  0 29  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1.  8. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 16. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  3.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15. 11. 10.  8.  0.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8.] 
adversary owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0 15  8
 29 29 15  0  0 29  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 16. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  3.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15. 11. 10.  8.  0.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8.] 
adversary owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0 15  8
 29 29 15  0  0 29  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [15. 11. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10.  8.] 
expected returns: [[-13.757441]
 [-12.753393]
 [-12.856586]
 [-13.322748]
 [-13.102568]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 10.  8.  0.] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15  0 15  8
 29 29 15  0  0 29  0  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  3.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 6. 11.  3.  0.  8.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.908069610595703



action possibilites: [-1] 
expected returns: [[-16.36527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8.] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  3.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 6. 11.  3.  0.  8.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -12.753395080566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
expected returns: [[-16.236452]
 [-15.75107 ]
 [-15.980412]
 [-16.357227]
 [-15.437929]
 [-16.37406 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  8.] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  3.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 6. 11.  3.  0.  8.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -16.365270614624023



buy possibilites: [-1] 
expected returns: [[-12.34362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  8.] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 6. 11.  3.  0.  8.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -51 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -15.437929153442383






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 6. 11.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  0.  8.] 
cards in discard: [10.  3.  8.  0. 16. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  8. 11. 29.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8. 11. 15.
 11. 10.  8.] 
adversary owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11] -> size -> 33 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.  0.  8.] 
cards in discard: [10.  3.  8.  0. 16. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  8. 11. 29.] 
adversary cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8. 11. 15.
 11. 10.  8.] 
adversary owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11] -> size -> 33 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0.  8. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 29.] 
expected returns: [[-15.345461 ]
 [-15.025286 ]
 [-14.8629055]
 [-14.671162 ]
 [-14.062046 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 11. 29.] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8. 11. 15.
 11. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.343620300292969



action possibilites: [-1. 10.  8. 29.] 
expected returns: [[-14.427399]
 [-14.107031]
 [-13.944639]
 [-13.153103]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29.] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8. 11. 15.
 11. 10.  8.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: -14.471940994262695



action possibilites: [-1. 10.] 
expected returns: [[-15.9508  ]
 [-15.630747]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8. 11. 15.
 11. 10.  8.  0. 11.  8. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -13.986261367797852



action possibilites: [-1. 15.] 
expected returns: [[-15.669031]
 [-14.804443]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8. 11. 15.
 11. 10.  8.  0. 11.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11] -> size -> 33 
action values: 2 
buys: 0 
player value: 2 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -15.630744934082031



action possibilites: [-1.] 
expected returns: [[-19.003408]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8. 11. 15.
 11. 10.  8.  0. 11.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 10. 15.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -45 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -14.804443359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-19.003408]
 [-18.960367]
 [-19.003408]
 [-19.003408]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8. 11. 15.
 11. 10.  8.  0. 11.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 10. 15.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11] -> size -> 33 
action values: 1 
buys: 1 
player value: 2 
card supply: [11. 30. 29. 27. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -19.003408432006836



buy possibilites: [-1] 
expected returns: [[-14.682978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29. 15. 29.  0. 29.  8.  0. 10.  8.  0.  8. 10.  8. 29. 29.  8. 11. 15.
 11. 10.  8.  0. 11.  8. 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 10. 15.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 26. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.] 
adversary owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -18.96036720275879






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  3 16  0  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0
 16  2  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 26. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 11. 15. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11  3] -> size -> 34 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 26. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 11. 15. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 30. 29. 26. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 11. 15. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11. 15. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10. 11.] 
expected returns: [[-15.084349]
 [-14.307571]
 [-14.218754]
 [-14.709227]
 [-14.307571]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15. 10. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0  0 29  0  0  8 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 26. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [0. 0. 0. 2. 3.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.682977676391602



action possibilites: [-1] 
expected returns: [[-16.850769]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0 29  0  0  8 11  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 30. 29. 26. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [0. 0. 0. 2. 3.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -14.218755722045898





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
expected returns: [[-16.749516]
 [-16.40638 ]
 [-16.568651]
 [-16.835085]
 [-16.18825 ]
 [-16.846985]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0 29  0  0  8 11  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 30. 29. 26. 30.  8.  9.  8.  2.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [0. 0. 0. 2. 3.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -16.85076904296875



buy possibilites: [-1] 
expected returns: [[-11.830212]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11.] 
cards in discard: [11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0 29  0  0  8 11  3 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 26. 30.  8.  9.  8.  1.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [0. 0. 0. 2. 3.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -16.188247680664062






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 2. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 2. 3.] 
cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 29. 26. 30.  8.  9.  8.  1.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 29. 15. 29.  8.] 
adversary cards in discard: [11. 15. 11. 10. 11.] 
adversary owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0 29  0  0  8 11  3 11] -> size -> 34 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 2. 3.] 
cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [11. 30. 29. 26. 30.  8.  9.  8.  1.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 29. 15. 29.  8.] 
adversary cards in discard: [11. 15. 11. 10. 11.] 
adversary owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0 29  0  0  8 11  3 11] -> size -> 34 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 2. 3.] 
cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.  8.  0.  0.  2.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0  2] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 30. 28. 26. 30.  8.  9.  8.  1.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 29. 15. 29.  8.] 
adversary cards in discard: [11. 15. 11. 10. 11.] 
adversary owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0 29  0  0  8 11  3 11] -> size -> 34 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [29. 29. 15. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 15. 29.  8.] 
expected returns: [[-7.7930346]
 [-6.2128725]
 [-6.2128725]
 [-6.787966 ]
 [-6.2128725]
 [-7.137809 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 15. 29.  8.] 
cards in discard: [11. 15. 11. 10. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0 29  0  0  8 11  3 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 28. 26. 30.  8.  9.  8.  1.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [16.  0.  3. 14.  0.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.  8.  0.  0.  2.  0.  0.  0.
  2.  3.] 
adversary owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0  2] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -11.830211639404297



action possibilites: [-1. 29. 29. 15.] 
expected returns: [[-15.807751]
 [-14.462231]
 [-14.462231]
 [-14.943373]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 15.] 
cards in discard: [11. 15. 11. 10. 11.  8. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0 29  0  0  8 11  3 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 30. 28. 26. 30.  8.  9.  8.  1.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [16.  0.  3. 14.  0.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.  8.  0.  0.  2.  0.  0.  0.
  2.  3.] 
adversary owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0  2] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: -7.09047269821167



action possibilites: [-1. 29.] 
expected returns: [[-17.095499]
 [-15.757935]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [11. 15. 11. 10. 11.  8. 15. 15. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0 29  0  0  8 11  3 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 2 
card supply: [11. 30. 28. 26. 30.  8.  9.  8.  1.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [16.  0.  3. 14.  0.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.  8.  0.  0.  2.  0.  0.  0.
  2.  3.] 
adversary owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0  2] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -15.29149055480957



action possibilites: [-1.] 
expected returns: [[-16.134756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11. 15. 11. 10. 11.  8. 15. 15. 29.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0 29  0  0  8 11  3 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 3 
card supply: [11. 30. 28. 26. 30.  8.  9.  8.  1.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [16.  0.  3. 14.  0.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.  8.  0.  0.  2.  0.  0.  0.
  2.  3.] 
adversary owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0  2] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -16.98129653930664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
expected returns: [[-16.009607]
 [-15.520422]
 [-15.75165 ]
 [-16.131552]
 [-15.204536]
 [-16.148516]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11. 15. 11. 10. 11.  8. 15. 15. 29.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0 29  0  0  8 11  3 11] -> size -> 34 
action values: 1 
buys: 1 
player value: 3 
card supply: [11. 30. 28. 26. 30.  8.  9.  8.  1.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [16.  0.  3. 14.  0.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.  8.  0.  0.  2.  0.  0.  0.
  2.  3.] 
adversary owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0  2] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.134756088256836



Player 1 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 0 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 7 
Witch: 0 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [] 
cards in discard: [11. 15. 11. 10. 11.  8. 15. 15. 29.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [29 11 29 11  8 11 29 10  8 10 10 29 10  8 11 10  8 15  8 15 15 15  8 29
 29 15  0 29  0  0  8 11  3 11 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 28. 26. 30.  8.  9.  8.  0.  0. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [16.  0.  3. 14.  0.] 
adversary cards in discard: [10.  3.  8.  0. 16. 11.  6. 11.  3.  0.  8.  8.  0.  0.  2.  0.  0.  0.
  2.  3.] 
adversary owned cards: [ 3  3 15  3 16  6  0  0  8  3  0 10  0  8 11  0  0  0 14 11  8  0 16  2
  0  2] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0       60        0
        0        0        0        0        0        0       27        0] 
sum of rewards: -2999978 

action type: buy - action 11.0
Learning step: -299996.28125
desired expected reward: -300011.5



