 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.857506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     180       0       0       0       0       0
       0       0     -60       0    -300       0       0] 
sum of rewards: 2999815 

action type: buy - action 6.0
Learning step: 119996.2734375
desired expected reward: 119904.3515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 23.384924  ]
 [ 42.91109   ]
 [ 35.69441   ]
 [-23.90194   ]
 [ 45.182472  ]
 [ 43.509632  ]
 [ 31.667671  ]
 [ 50.792984  ]
 [ -0.61565065]
 [ 37.5209    ]
 [ 29.148731  ]
 [ 28.92442   ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 29.594024658203125



buy possibilites: [-1] 
expected returns: [[46.645233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 50.79298782348633






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.04829]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.645233154296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 18.599419]
 [ 36.937412]
 [ 30.872803]
 [-52.05796 ]
 [ 39.05095 ]
 [ 26.692947]
 [ 33.5371  ]
 [ 24.708843]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.091203689575195



buy possibilites: [-1] 
expected returns: [[34.379883]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 39.05095291137695






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.960117]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.3798828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 16.864405]
 [ 35.465546]
 [ 27.553486]
 [-22.834139]
 [ 34.477818]
 [ 23.98586 ]
 [ 28.710213]
 [ 21.260965]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 20.384042739868164



buy possibilites: [-1] 
expected returns: [[13.125101]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 35.46554946899414






Player: 1 
cards in hand: [ 3.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.910267]
 [37.880703]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  3. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.125101089477539



action possibilites: [-1] 
expected returns: [[17.789185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  3. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 39.183998107910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 11.699955]
 [ 31.65519 ]
 [ 23.920706]
 [-61.073853]
 [ 31.806759]
 [ 20.000547]
 [ 25.655373]
 [ 16.969175]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  3. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.7891845703125



buy possibilites: [-1] 
expected returns: [[33.264683]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  3. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 31.806777954101562






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3. 29.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [11.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[27.653343]
 [41.535862]
 [48.80202 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.26468276977539



action possibilites: [-1. 11.] 
expected returns: [[27.55075 ]
 [39.230885]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 48.16194152832031



action possibilites: [-1] 
expected returns: [[39.30359]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.71181869506836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 35.86917 ]
 [ 54.596134]
 [ 47.442677]
 [-11.465197]
 [ 55.986855]
 [ 54.625294]
 [ 42.8582  ]
 [ 59.910633]
 [ 10.023157]
 [ 48.141575]
 [ 38.1463  ]
 [ 40.294952]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.3035888671875



buy possibilites: [-1] 
expected returns: [[44.382145]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 59.910640716552734






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-9.1978855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.382144927978516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-11.7320175 ]
 [  5.2748933 ]
 [ -1.762228  ]
 [-66.211914  ]
 [  7.8955617 ]
 [  4.7162766 ]
 [ -4.5820017 ]
 [ 12.557381  ]
 [-32.887695  ]
 [  0.25285673]
 [ -7.5273495 ]
 [ -6.993507  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -8.562589645385742



buy possibilites: [-1] 
expected returns: [[25.231056]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 12.557394027709961






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 3. 0. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 3. 0. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8.  3.  0.  0.  0.  3. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[39.318478]
 [44.16152 ]
 [49.86796 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  1.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.231056213378906



action possibilites: [-1] 
expected returns: [[37.380707]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  3.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 54.468170166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[34.179363 ]
 [50.64826  ]
 [41.26154  ]
 [-3.2666626]
 [47.19206  ]
 [40.75459  ]
 [41.986275 ]
 [38.624413 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  3.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.380706787109375



buy possibilites: [-1] 
expected returns: [[30.539883]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  3.] 
cards in discard: [10.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 50.64826583862305






Player: 1 
cards in hand: [ 0.  3. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [10.  1. 11.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [10.  1. 11.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16] -> size -> 15 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [10.  1. 11.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [10.  1. 11.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 16.] 
cards in discard: [15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [10.  1. 11.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[39.731777]
 [59.06091 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [10.  1. 11.  0. 10.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [15. 10. 29.  0.  3.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.53988265991211



action possibilites: [-1. 29.] 
expected returns: [[62.639683]
 [77.06706 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [10.  1. 11.  0. 10.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [15. 10. 29.  0.  3.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 57.25338363647461



action possibilites: [-1.] 
expected returns: [[43.730953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  1. 11.  0. 10.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [15. 10. 29.  0.  3.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 77.0670394897461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[40.280216 ]
 [57.067707 ]
 [38.07923  ]
 [49.855293 ]
 [25.116016 ]
 [ 2.7378592]
 [58.656963 ]
 [55.936172 ]
 [46.977654 ]
 [66.21815  ]
 [61.85007  ]
 [17.977018 ]
 [50.9473   ]
 [50.86264  ]
 [31.382084 ]
 [41.74911  ]
 [44.323776 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  1. 11.  0. 10.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [15. 10. 29.  0.  3.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 43.730953216552734



buy possibilites: [-1] 
expected returns: [[70.46711]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  1. 11.  0. 10.  1.  3. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [15. 10. 29.  0.  3.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 97.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 66.2181625366211






Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [15. 10. 29.  0.  3.  0.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0 10  8 16 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 29. 11.] 
adversary cards in discard: [10.  1. 11.  0. 10.  1.  3. 25. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25] -> size -> 21 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15. 10. 29.  0.  3.  0.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29  0 10  8 16 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 29. 11.] 
adversary cards in discard: [10.  1. 11.  0. 10.  1.  3. 25. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15. 10. 29.  0.  3.  0.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29  0 10  8 16 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 29. 11.] 
adversary cards in discard: [10.  1. 11.  0. 10.  1.  3. 25. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25] -> size -> 21 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[54.973938]
 [61.609478]
 [71.28874 ]
 [67.428154]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 29. 11.] 
cards in discard: [10.  1. 11.  0. 10.  1.  3. 25. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [15. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  0 10  8 16 15] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.46710968017578



action possibilites: [-1. 10. 11.] 
expected returns: [[62.714787]
 [68.58981 ]
 [74.00781 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11.  0.] 
cards in discard: [10.  1. 11.  0. 10.  1.  3. 25. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [15. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  0 10  8 16 15] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 70.78688049316406



action possibilites: [-1] 
expected returns: [[116.18903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10.  1. 11.  0. 10.  1.  3. 25. 29. 29.  0.  0.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [15. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  0 10  8 16 15] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 76.6822280883789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[100.57014 ]
 [119.59189 ]
 [110.94361 ]
 [ 50.974262]
 [121.66078 ]
 [110.64522 ]
 [114.803894]
 [115.45649 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10.  1. 11.  0. 10.  1.  3. 25. 29. 29.  0.  0.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [15. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  0 10  8 16 15] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 116.18903350830078



buy possibilites: [-1] 
expected returns: [[141.33253]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10.  1. 11.  0. 10.  1.  3. 25. 29. 29.  0.  0.  0.  3.  0. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  7.  9.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [15. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  0 10  8 16 15] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 121.66080474853516






Player: 1 
cards in hand: [15. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  0 10  8 16 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  7.  9.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  7.  9.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  7.  9.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  7.  9.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 82.3521  ]
 [ 98.26178 ]
 [102.357666]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 29. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  7.  9.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [29. 15. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 141.33253479003906



action possibilites: [-1] 
expected returns: [[44.836044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 29. 10.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  7.  9.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [29. 15. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 101.66064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[37.69979  ]
 [52.987305 ]
 [46.27102  ]
 [ 1.3820214]
 [52.925495 ]
 [44.206593 ]
 [47.893665 ]
 [44.526413 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 29. 10.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  7.  9.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [29. 15. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.83604431152344



buy possibilites: [-1] 
expected returns: [[21.929764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 29. 10.  3.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  9.  9.  7.  9.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [29. 15. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 52.9873161315918






Player: 1 
cards in hand: [ 8. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.  0.] 
cards in discard: [29. 15. 29.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  9.  9.  7.  9.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1] -> size -> 24 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.  0.] 
cards in discard: [29. 15. 29.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 30. 30.  8.  9.  9.  7.  9.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1] -> size -> 24 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.  0.] 
cards in discard: [29. 15. 29.  3.  0.  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 30. 30.  8.  9.  9.  7.  8.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1] -> size -> 24 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[40.568386]
 [50.762104]
 [46.54572 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.  0.] 
cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  9.  9.  7.  8.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 29.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.929763793945312



action possibilites: [-1] 
expected returns: [[66.0831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  9.  9.  7.  8.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 29.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 52.274410247802734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[63.908085]
 [79.79926 ]
 [74.586136]
 [31.089134]
 [80.14043 ]
 [69.54398 ]
 [75.52649 ]
 [67.62239 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 30. 30.  8.  9.  9.  7.  8.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 29.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.08309936523438



buy possibilites: [-1] 
expected returns: [[65.951324]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 29.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 80.14044952392578






Player: 1 
cards in hand: [ 8. 29.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10.  0. 11. 11.] 
adversary cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10.  0. 11. 11.] 
adversary cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0. 16.  3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10.  0. 11. 11.] 
adversary cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10. 10.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 11.] 
expected returns: [[66.45884 ]
 [68.337944]
 [68.337944]
 [72.99069 ]
 [72.99069 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 11. 11.] 
cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10. 11. 11.  0.  0. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 10. 29. 15.  3.] 
adversary cards in discard: [ 0.  8. 29.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 65.95132446289062



action possibilites: [-1] 
expected returns: [[50.808887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 11.] 
cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10. 11. 11.  0.  0. 10.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 10. 29. 15.  3.] 
adversary cards in discard: [ 0.  8. 29.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 75.36395263671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.761135]
 [ 5.839828]
 [51.672077]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 11.] 
cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10. 11. 11.  0.  0. 10.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 10. 29. 15.  3.] 
adversary cards in discard: [ 0.  8. 29.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.80888748168945






Player: 1 
cards in hand: [ 8. 10. 29. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 29. 15.  3.] 
cards in discard: [ 0.  8. 29.  0. 16.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  1.  3.  0. 29.] 
adversary cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10. 11. 11.  0.  0. 10.  0. 10. 11. 10.
 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 29. 15.  3.] 
cards in discard: [ 0.  8. 29.  0. 16.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  1.  3.  0. 29.] 
adversary cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10. 11. 11.  0.  0. 10.  0. 10. 11. 10.
 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 29. 15.  3.] 
cards in discard: [ 0.  8. 29.  0. 16.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  1.  3.  0. 29.] 
adversary cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10. 11. 11.  0.  0. 10.  0. 10. 11. 10.
 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29.  1.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[80.45238]
 [92.03374]
 [92.03374]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  0. 29.] 
cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10. 11. 11.  0.  0. 10.  0. 10. 11. 10.
 10.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 51.672061920166016



action possibilites: [-1. 29.] 
expected returns: [[83.854706]
 [98.35943 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 29.  0.] 
cards in discard: [ 1. 25.  3.  1.  0. 29. 10.  3. 10. 11. 11.  0.  0. 10.  0. 10. 11. 10.
 10.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 92.03372192382812



action possibilites: [-1.] 
expected returns: [[53.376637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 98.35942840576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[46.894897]
 [62.765026]
 [43.494843]
 [55.314133]
 [28.96754 ]
 [ 5.902099]
 [66.42846 ]
 [63.518307]
 [54.57038 ]
 [75.29258 ]
 [68.699234]
 [22.24696 ]
 [55.69728 ]
 [57.800022]
 [36.23916 ]
 [46.162064]
 [54.519497]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 7 
card supply: [27. 27. 30. 30. 30.  8.  9.  9.  6.  8.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 53.37663650512695



buy possibilites: [-1] 
expected returns: [[57.931534]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 30. 30.  8.  9.  9.  6.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 157.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 75.29258728027344






Player: 1 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8.  9.  9.  6.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 25.  1.  3.] 
adversary cards in discard: [25. 29. 29.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25] -> size -> 28 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 30. 30.  8.  9.  9.  6.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 25.  1.  3.] 
adversary cards in discard: [25. 29. 29.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25] -> size -> 28 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  9.  9.  6.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 25.  1.  3.] 
adversary cards in discard: [25. 29. 29.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25] -> size -> 28 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [10.  0. 25.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[36.26827 ]
 [42.43355 ]
 [57.009636]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25.  1.  3.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  9.  9.  6.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 10.  0. 16.  8.] 
adversary cards in discard: [3. 3. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0  3] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.93153381347656



action possibilites: [-1] 
expected returns: [[59.40347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  3. 11. 11.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  6.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 10.  0. 16.  8.] 
adversary cards in discard: [3. 3. 0. 0. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 56.7450065612793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[48.16625  ]
 [65.86932  ]
 [57.724438 ]
 [ 4.4472623]
 [66.85627  ]
 [57.281403 ]
 [61.587917 ]
 [58.11209  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  3. 11. 11.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  6.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 10.  0. 16.  8.] 
adversary cards in discard: [3. 3. 0. 0. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.40346908569336



buy possibilites: [-1] 
expected returns: [[52.489853]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  3. 11. 11.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  5.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 10.  0. 16.  8.] 
adversary cards in discard: [3. 3. 0. 0. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 66.85626983642578






Player: 1 
cards in hand: [ 8. 10.  0. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 16.  8.] 
cards in discard: [3. 3. 0. 0. 6. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10  8 16 15 29  6  8  0  0  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  5.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  0. 10.] 
adversary cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11] -> size -> 29 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [3. 3. 0. 0. 6. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  5.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  0. 10.] 
adversary cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11] -> size -> 29 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [3. 3. 0. 0. 6. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  5.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  0. 10.] 
adversary cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11] -> size -> 29 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[81.88939]
 [84.23339]
 [84.23339]
 [84.23339]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0. 10.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  5.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 15. 29.] 
adversary cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.48985290527344



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[71.715515]
 [77.08921 ]
 [77.08921 ]
 [89.689064]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10. 29.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  5.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 15. 29.] 
adversary cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 84.2333755493164



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[107.74631 ]
 [110.255554]
 [110.255554]
 [115.00929 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10. 11.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11] -> size -> 29 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  5.  8.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 15. 29.] 
adversary cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 89.6890869140625



action possibilites: [-1. 10. 10.] 
expected returns: [[107.976494]
 [110.19154 ]
 [110.19154 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  5.  8.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 15. 29.] 
adversary cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 116.31959533691406



action possibilites: [-1. 10. 10.] 
expected returns: [[139.74002]
 [144.66168]
 [144.66168]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 29. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10] -> size -> 30 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  5.  8.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 15. 29.] 
adversary cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 110.19151306152344



action possibilites: [-1. 10. 10.] 
expected returns: [[134.00916]
 [138.26619]
 [138.26619]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29. 11. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10] -> size -> 30 
action values: 3 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  5.  8.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 15. 29.] 
adversary cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 144.66171264648438



action possibilites: [-1. 10. 11.] 
expected returns: [[133.81958]
 [136.66876]
 [141.7282 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29. 11. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10] -> size -> 30 
action values: 4 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  5.  8.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 15. 29.] 
adversary cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 138.26620483398438



action possibilites: [-1. 10.] 
expected returns: [[113.0301 ]
 [117.92816]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29. 11. 10. 10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11] -> size -> 31 
action values: 3 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  4.  8.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 15. 29.] 
adversary cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0 140   0   0   0   0   0   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 142.5015411376953



action possibilites: [-1.] 
expected returns: [[99.9488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 29. 11. 10. 10. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11] -> size -> 31 
action values: 4 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  4.  8.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 15. 29.] 
adversary cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0 160   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 117.92818450927734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 92.015915]
 [107.40502 ]
 [103.200806]
 [ 74.95052 ]
 [ 51.712177]
 [113.707184]
 [112.41054 ]
 [ 99.97195 ]
 [123.942764]
 [117.5169  ]
 [ 70.81791 ]
 [106.804016]
 [107.43737 ]
 [ 86.351845]
 [ 95.583336]
 [102.14226 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 29. 11. 10. 10. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  4.  8.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 15. 29.] 
adversary cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0 160   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 99.94879913330078



buy possibilites: [-1] 
expected returns: [[96.70596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [25. 29. 29.  1.  3.  0.  0.  0. 11. 25. 10.  0.  1.  3. 11. 11. 10. 11.
 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 29. 11. 10. 10. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  4.  8.  7.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 15. 29.] 
adversary cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0 160   0   0   0   0   0   0   0 250   0] 
sum of rewards: 465 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 123.9427490234375






Player: 1 
cards in hand: [ 3.  0. 29. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 15. 29.] 
cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  4.  8.  7.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25] -> size -> 32 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 15. 29.] 
cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  8.  9.  4.  8.  7.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25] -> size -> 32 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 15. 29.] 
cards in discard: [ 3.  3.  0.  0.  6.  0.  6.  8. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  4.  8.  7.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25] -> size -> 32 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[37.7011]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  4.  8.  7.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.70596313476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 30.277775]
 [ 46.136303]
 [ 38.950233]
 [-11.081984]
 [ 47.55605 ]
 [ 38.171303]
 [ 41.821655]
 [ 38.324543]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  4.  8.  7.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.397735595703125



buy possibilites: [-1] 
expected returns: [[60.468365]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  3.  8.  7.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 109 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 47.55604934692383






Player: 1 
cards in hand: [ 3.  3. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  3.  8.  7.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  1.  1.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11] -> size -> 33 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  3.  8.  7.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  1.  1.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11] -> size -> 33 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[85.2983  ]
 [94.454346]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1.  1.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  3.  8.  7.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6. 29.  0.  8. 29.] 
adversary cards in discard: [ 3.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.46836471557617



action possibilites: [-1] 
expected returns: [[71.69873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  3.  8.  7.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 6. 29.  0.  8. 29.] 
adversary cards in discard: [ 3.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 94.58341979980469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[62.742413]
 [78.27964 ]
 [59.957767]
 [71.70591 ]
 [45.61897 ]
 [22.279743]
 [83.39321 ]
 [79.76591 ]
 [70.68696 ]
 [92.90785 ]
 [86.67325 ]
 [39.69784 ]
 [74.6046  ]
 [74.76818 ]
 [54.163372]
 [64.076584]
 [73.36806 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  3.  8.  7.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 6. 29.  0.  8. 29.] 
adversary cards in discard: [ 3.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.69873046875



buy possibilites: [-1] 
expected returns: [[68.83922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10. 25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  3.  8.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 6. 29.  0.  8. 29.] 
adversary cards in discard: [ 3.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 137.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 92.90786743164062






Player: 1 
cards in hand: [ 6. 29.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  8. 29.] 
cards in discard: [ 3.  3. 15.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  3.  8.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 25. 11. 10. 25.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 29.  0.] 
cards in discard: [ 3.  3. 15.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  3.  8.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 25. 11. 10. 25.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.] 
cards in discard: [ 3.  3. 15.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  3.  8.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 25. 11. 10. 25.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  0.] 
cards in discard: [ 3.  3. 15.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  3.  8.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 25. 11. 10. 25.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  0.] 
cards in discard: [ 3.  3. 15.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  3.  7.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 25. 11. 10. 25.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 25. 11. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11. 10. 25.] 
expected returns: [[108.66712 ]
 [115.37856 ]
 [124.521576]
 [115.37856 ]
 [110.11043 ]
 [124.521576]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 11. 10. 25.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  8.  9.  3.  7.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [ 3.  3. 15.  0.  0.  8. 29.  8.  6. 29.  0.] 
adversary owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 68.83921813964844



action possibilites: [-1] 
expected returns: [[122.38237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 25. 10.  0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [ 3.  3. 15.  0.  0.  8. 29.  8.  6. 29.  0.  6.] 
adversary owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 124.52157592773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[113.78548 ]
 [ 79.05497 ]
 [121.704544]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 10. 25. 10.  0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [ 3.  3. 15.  0.  0.  8. 29.  8.  6. 29.  0.  6.] 
adversary owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.38236999511719






Player: 1 
cards in hand: [10.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  6.  3.] 
cards in discard: [ 3.  3. 15.  0.  0.  8. 29.  8.  6. 29.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10. 29. 10. 29. 10.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  6.  3.] 
cards in discard: [ 3.  3. 15.  0.  0.  8. 29.  8.  6. 29.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10. 29. 10. 29. 10.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  6.  3.] 
cards in discard: [ 3.  3. 15.  0.  0.  8. 29.  8.  6. 29.  0.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10. 29. 10. 29. 10.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10. 29. 10. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 29. 10.] 
expected returns: [[87.76522]
 [90.0376 ]
 [99.91357]
 [90.0376 ]
 [99.91357]
 [90.0376 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10. 29. 10.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 121.70454406738281



action possibilites: [-1. 10. 10. 29. 10. 11.] 
expected returns: [[ 97.148186]
 [ 96.919205]
 [ 96.919205]
 [107.08106 ]
 [ 96.919205]
 [101.616516]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29. 10. 11.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 99.91357421875



action possibilites: [-1. 10. 10. 10. 11.] 
expected returns: [[107.05968 ]
 [106.045006]
 [106.045006]
 [106.045006]
 [110.810936]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 11.  3.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 107.08104705810547



action possibilites: [-1] 
expected returns: [[97.87849]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  3.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 113.37353515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[88.013504]
 [96.11991 ]
 [51.205833]
 [94.36017 ]
 [98.524086]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  3.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 97.87848663330078






Player: 1 
cards in hand: [3. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  1. 29.  0. 11.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0. 10. 29. 29. 11. 10. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10] -> size -> 36 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  1. 29.  0. 11.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0. 10. 29. 29. 11. 10. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10] -> size -> 36 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  1. 29.  0. 11.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0. 10. 29. 29. 11. 10. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10] -> size -> 36 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10.  1. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[116.511925]
 [117.92992 ]
 [129.25296 ]
 [121.89975 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 29.  0. 11.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0. 10. 29. 29. 11. 10. 10. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  8.] 
adversary cards in discard: [3. 3. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3  3] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 98.52411651611328



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[151.2597 ]
 [152.58836]
 [157.70496]
 [157.70496]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 11.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0. 10. 29. 29. 11. 10. 10. 10.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  8.] 
adversary cards in discard: [3. 3. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3  3] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 122.60704040527344



action possibilites: [-1] 
expected returns: [[108.96413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0. 10. 29. 29. 11. 10. 10. 10.  3.  1. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  8. 10.  0.  8.] 
adversary cards in discard: [3. 3. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3  3] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 158.7442169189453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[100.317856]
 [108.69153 ]
 [ 66.33191 ]
 [106.38433 ]
 [108.9641  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.] 
cards in discard: [11.  3.  0.  0.  3.  0. 10. 25. 11.  0.  0.  1.  1. 25. 11. 11. 10. 25.
 10.  0. 10. 29. 29. 11. 10. 10. 10.  3.  1. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  8. 10.  0.  8.] 
adversary cards in discard: [3. 3. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3  3] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.96412658691406






Player: 1 
cards in hand: [ 0.  8. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.  8.] 
cards in discard: [3. 3. 6. 0. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  0 10 15 29  6  8  0  0  3  6  0  8  6  3  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29. 11. 10. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15] -> size -> 37 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [3. 3. 6. 0. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29. 11. 10. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15] -> size -> 37 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [3. 3. 6. 0. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29. 11. 10. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15] -> size -> 37 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29. 11. 10. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 10. 25.] 
expected returns: [[100.223335]
 [114.44528 ]
 [109.566864]
 [103.85122 ]
 [103.85122 ]
 [121.30648 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10. 10. 25.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  3.  7.  6.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  3.  3.] 
adversary cards in discard: [ 3.  3.  6.  0.  3.  0.  8. 10.  0.] 
adversary owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 108.96412658691406



action possibilites: [-1] 
expected returns: [[70.85753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  3.  7.  6.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  3.  3.] 
adversary cards in discard: [ 3.  3.  6.  0.  3.  0.  8. 10.  0.  6.] 
adversary owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 120.88497924804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[65.94861 ]
 [30.847889]
 [73.824135]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11. 10. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  3.  7.  6.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  3.  3.] 
adversary cards in discard: [ 3.  3.  6.  0.  3.  0.  8. 10.  0.  6.] 
adversary owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.85752868652344






Player: 1 
cards in hand: [ 6.  0. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15.  3.  3.] 
cards in discard: [ 3.  3.  6.  0.  3.  0.  8. 10.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  3.  7.  6.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1. 11. 10.  1.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15] -> size -> 37 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15.  3.  3.] 
cards in discard: [ 3.  3.  6.  0.  3.  0.  8. 10.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  3.  7.  6.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1. 11. 10.  1.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15] -> size -> 37 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 11. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[73.07216]
 [80.21025]
 [75.23927]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11. 10.  1.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  3.  7.  6.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 73.82412719726562



action possibilites: [-1] 
expected returns: [[74.755455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.  1.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  3.  7.  6.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 83.28974914550781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[66.59583 ]
 [80.52845 ]
 [73.744225]
 [51.905575]
 [31.387234]
 [81.94795 ]
 [79.54478 ]
 [72.21521 ]
 [88.3257  ]
 [84.581085]
 [45.476   ]
 [74.00736 ]
 [56.9506  ]
 [66.38215 ]
 [73.62587 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.  1.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  3.  7.  6.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.75545501708984



buy possibilites: [-1] 
expected returns: [[118.81045]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.  1.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -40   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 88.32569885253906






Player: 1 
cards in hand: [ 0.  6.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0. 25. 25.  0.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25] -> size -> 39 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0. 25. 25.  0.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25] -> size -> 39 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10.  0. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 25.] 
expected returns: [[101.108246]
 [102.46031 ]
 [117.25946 ]
 [117.25946 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25. 25.  0.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [15.  0.  8.  3.  6.] 
adversary cards in discard: [ 0.  6.  0. 29. 29.] 
adversary owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 118.8104476928711



action possibilites: [-1] 
expected returns: [[112.39967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25.  0.  3. 11.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  5.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [15.  0.  8.  3.  6.] 
adversary cards in discard: [ 0.  6.  0. 29. 29.  6.] 
adversary owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 117.25948333740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[106.708336]
 [114.82117 ]
 [ 72.93081 ]
 [111.57036 ]
 [112.821106]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25.  0.  3. 11.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8.  5.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [15.  0.  8.  3.  6.] 
adversary cards in discard: [ 0.  6.  0. 29. 29.  6.] 
adversary owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.39967346191406



buy possibilites: [-1] 
expected returns: [[133.10687]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25.  0.  3. 11.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  5.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [15.  0.  8.  3.  6.] 
adversary cards in discard: [ 0.  6.  0. 29. 29.  6.] 
adversary owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 71 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 114.82115173339844






Player: 1 
cards in hand: [15.  0.  8.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.  3.  6.] 
cards in discard: [ 0.  6.  0. 29. 29.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29  0 10 15 29  6  0  0  3  6  0  8  6  3  3  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  5.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 29. 11.  3.  0.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3] -> size -> 40 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0.  6.  0. 29. 29.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  5.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 29. 11.  3.  0.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  6.  0. 29. 29.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  5.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 29. 11.  3.  0.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  6.  0. 29. 29.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  5.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 29. 11.  3.  0.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[87.97232 ]
 [98.49556 ]
 [93.702835]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 11.  3.  0.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  5.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 6. 10.  3.  0.  3.] 
adversary cards in discard: [ 0.  6.  0. 29. 29.  6.  0.  8.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0] -> size -> 18 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 133.10687255859375



action possibilites: [-1. 11. 25.] 
expected returns: [[120.26245 ]
 [125.528595]
 [135.66183 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 25.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  5.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 6. 10.  3.  0.  3.] 
adversary cards in discard: [ 0.  6.  0. 29. 29.  6.  0.  8.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0] -> size -> 18 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 93.19283294677734



action possibilites: [-1] 
expected returns: [[94.440735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 10. 11.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 6. 10.  3.  0.  3.] 
adversary cards in discard: [ 0.  6.  0. 29. 29.  6.  0.  8.  6.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 135.6618194580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[80.36545 ]
 [88.78544 ]
 [40.16501 ]
 [88.775536]
 [94.561   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 10. 11.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 6. 10.  3.  0.  3.] 
adversary cards in discard: [ 0.  6.  0. 29. 29.  6.  0.  8.  6.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.44073486328125






Player: 1 
cards in hand: [ 6. 10.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  0.  3.] 
cards in discard: [ 0.  6.  0. 29. 29.  6.  0.  8.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10.  0. 15. 11.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.  1. 29. 25. 11.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3] -> size -> 40 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  0.  3.] 
cards in discard: [ 0.  6.  0. 29. 29.  6.  0.  8.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10.  0. 15. 11.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.  1. 29. 25. 11.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3] -> size -> 40 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  0.  3.] 
cards in discard: [ 0.  6.  0. 29. 29.  6.  0.  8.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10.  0. 15. 11.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.  1. 29. 25. 11.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3] -> size -> 40 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10. 10.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15. 11.] 
expected returns: [[59.763912]
 [57.570385]
 [57.570385]
 [49.479176]
 [62.132282]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 15. 11.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.  1. 29. 25. 11.  3.  0. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0] -> size -> 20 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 94.5610122680664



action possibilites: [-1] 
expected returns: [[80.7405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 15.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.  1. 29. 25. 11.  3.  0. 10. 11. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0] -> size -> 20 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -60   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 65.01191711425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[69.576706]
 [34.018948]
 [80.74048 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 15.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.  1. 29. 25. 11.  3.  0. 10. 11. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0] -> size -> 20 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.7405014038086






Player: 1 
cards in hand: [3. 0. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 10. 29. 11.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.  1. 29. 25. 11.  3.  0. 10. 11. 15. 11. 10. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15] -> size -> 41 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 10. 29. 11.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.  1. 29. 25. 11.  3.  0. 10. 11. 15. 11. 10. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15] -> size -> 41 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 3.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 10. 29. 11.] 
adversary cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.  1. 29. 25. 11.  3.  0. 10. 11. 15. 11. 10. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15] -> size -> 41 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[61.893414]
 [64.7894  ]
 [74.55844 ]
 [69.5128  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 29. 11.] 
cards in discard: [25. 29. 11. 10. 10. 10.  0. 15. 25. 11.  0.  1. 10.  1.  3. 25. 10.  0.
 25.  0.  3. 11.  1. 29. 25. 11.  3.  0. 10. 11. 15. 11. 10. 10.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [0. 3. 0. 6. 3. 3.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.7405014038086



action possibilites: [-1. 10. 11.] 
expected returns: [[71.05547]
 [69.84833]
 [74.49407]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [0. 3. 0. 6. 3. 3.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 68.50920104980469



action possibilites: [-1] 
expected returns: [[101.58448]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 3. 15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  5.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [0. 3. 0. 6. 3. 3.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 209 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 79.5527572631836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[ 94.48837 ]
 [109.27902 ]
 [101.42875 ]
 [ 54.43884 ]
 [109.425385]
 [102.055954]
 [103.40477 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 3. 15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  3.  7.  5.  5. 10. 10.  0. 10.  5.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [0. 3. 0. 6. 3. 3.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.58448028564453



buy possibilites: [-1] 
expected returns: [[88.30019]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 3. 15. 11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  2.  7.  5.  5. 10. 10.  0. 10.  5.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [0. 3. 0. 6. 3. 3.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -80   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 109.42535400390625






Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [0. 3. 0. 6. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  2.  7.  5.  5. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10. 11.  0. 11. 10.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11] -> size -> 43 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [0. 3. 0. 6. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  2.  7.  5.  5. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10. 11.  0. 11. 10.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11] -> size -> 43 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 0.  3.  0.  6.  3.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  1.  7.  5.  5. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10. 11.  0. 11. 10.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11] -> size -> 43 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10. 11.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[88.092224]
 [88.53798 ]
 [94.03809 ]
 [94.03809 ]
 [88.53798 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 11. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  1.  7.  5.  5. 10. 10.  0. 10.  5.] 
adversary cards in hand: [29.  8.  6.  6. 10.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  3. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11] -> size -> 22 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.3001937866211



action possibilites: [-1] 
expected returns: [[92.97012]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  1.  7.  5.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [29.  8.  6.  6. 10.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  3. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11] -> size -> 22 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -90   0   0  64   0] 
sum of rewards: 169 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 96.70398712158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[85.06533 ]
 [48.154537]
 [94.08783 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  1.  7.  5.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [29.  8.  6.  6. 10.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  3. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11] -> size -> 22 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.97012329101562






Player: 1 
cards in hand: [29.  8.  6.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  6.  6. 10.] 
cards in discard: [ 0.  3.  0.  6.  3.  3. 11.  0.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  1.  7.  5.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [1. 0. 1. 3. 3.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15] -> size -> 44 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  6.  6. 10.] 
cards in discard: [ 0.  3.  0.  6.  3.  3. 11.  0.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  1.  7.  5.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [1. 0. 1. 3. 3.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15] -> size -> 44 
adversary victory points: 4
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[74.305984]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 3. 3.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  1.  7.  5.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  0. 29.  6.  3.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  3. 11.  0.  0.  0.  0.  6. 29.  8.  6.  6. 10.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11] -> size -> 22 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 94.08782958984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[66.94427 ]
 [81.09295 ]
 [74.60487 ]
 [50.916523]
 [28.93391 ]
 [82.97625 ]
 [80.82467 ]
 [72.59854 ]
 [89.83398 ]
 [85.69644 ]
 [44.88518 ]
 [75.10971 ]
 [57.602005]
 [67.13242 ]
 [75.67608 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 3.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  1.  7.  5.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  0. 29.  6.  3.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  3. 11.  0.  0.  0.  0.  6. 29.  8.  6.  6. 10.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11] -> size -> 22 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 74.30598449707031



buy possibilites: [-1] 
expected returns: [[86.344475]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 3.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  0. 29.  6.  3.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  3. 11.  0.  0.  0.  0.  6. 29.  8.  6.  6. 10.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11] -> size -> 22 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  180    0    0    0    0    0    0    0 -100    0    0
  250    0] 
sum of rewards: 325 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 89.833984375






Player: 1 
cards in hand: [ 6.  0. 29.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29.  6.  3.] 
cards in discard: [ 0.  3.  0.  6.  3.  3. 11.  0.  0.  0.  0.  6. 29.  8.  6.  6. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 25. 15. 25.  0.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 25. 15. 25.  0.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 25. 15. 25.  0.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 15. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 25.] 
expected returns: [[ 96.60376]
 [110.1776 ]
 [ 87.16911]
 [110.1776 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 15. 25.  0.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  4.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 3. 29.  6.  0.  6.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11] -> size -> 22 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 86.34447479248047



action possibilites: [-1] 
expected returns: [[92.46682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 25.  0. 10. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  3.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 3. 29.  6.  0.  6.  6.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6] -> size -> 23 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 110.17759704589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[84.84782 ]
 [47.572754]
 [92.46684 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 25.  0. 10. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  3.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 3. 29.  6.  0.  6.  6.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6] -> size -> 23 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.4668197631836






Player: 1 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 3. 29.  6.  0.  6.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  3.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 25.  1. 10.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
adversary victory points: 4
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 3. 29.  6.  0.  6.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  3.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 25.  1. 10.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 3. 29.  6.  0.  6.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 26. 30.  8.  3.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 25.  1. 10.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 3. 29.  6.  0.  6.  6.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 26. 30.  8.  3.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 25.  1. 10.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10.] 
expected returns: [[76.72731]
 [88.66202]
 [96.70244]
 [73.94489]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  1. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  3.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  3.  6.  0. 29.] 
adversary cards in discard: [ 3. 29.  6.  0.  6.  6.  6.  0. 10.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0] -> size -> 24 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.4668197631836



action possibilites: [-1] 
expected returns: [[75.06144]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1. 10. 15. 11.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  2.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  3.  6.  0. 29.] 
adversary cards in discard: [ 3. 29.  6.  0.  6.  6.  6.  0. 10.  0.  3.  0.  0.  6.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6] -> size -> 25 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 96.70243072509766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[68.16248 ]
 [82.970955]
 [75.47824 ]
 [29.20332 ]
 [82.80714 ]
 [75.025566]
 [75.06142 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1. 10. 15. 11.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 26. 30.  8.  2.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  3.  6.  0. 29.] 
adversary cards in discard: [ 3. 29.  6.  0.  6.  6.  6.  0. 10.  0.  3.  0.  0.  6.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6] -> size -> 25 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.06143951416016



buy possibilites: [-1] 
expected returns: [[78.22777]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1. 10. 15. 11.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  2.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  3.  6.  0. 29.] 
adversary cards in discard: [ 3. 29.  6.  0.  6.  6.  6.  0. 10.  0.  3.  0.  0.  6.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6] -> size -> 25 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -110    0    0
   54    0] 
sum of rewards: 169 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 82.9709701538086






Player: 1 
cards in hand: [ 8.  3.  6.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  6.  0. 29.] 
cards in discard: [ 3. 29.  6.  0.  6.  6.  6.  0. 10.  0.  3.  0.  0.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  2.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 10. 11. 10. 10.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.  1. 25.  0. 29.  1. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1] -> size -> 46 
adversary victory points: 4
player victory points: -4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 6.] 
cards in discard: [ 3. 29.  6.  0.  6.  6.  6.  0. 10.  0.  3.  0.  0.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 26. 30.  8.  2.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 10. 11. 10. 10.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.  1. 25.  0. 29.  1. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1] -> size -> 46 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 6.] 
cards in discard: [ 3. 29.  6.  0.  6.  6.  6.  0. 10.  0.  3.  0.  0.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6] -> size -> 25 
action values: 1 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 26. 30.  8.  2.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 10. 11. 10. 10.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.  1. 25.  0. 29.  1. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1] -> size -> 46 
adversary victory points: 4
player victory points: -4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 10.] 
expected returns: [[39.49172 ]
 [40.607906]
 [45.56625 ]
 [40.607906]
 [40.607906]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.  1. 25.  0. 29.  1. 10. 15. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  2.  9.  1.  7.  4.  5. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.22776794433594



action possibilites: [-1] 
expected returns: [[71.4435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.  1. 25.  0. 29.  1. 10. 15. 11. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  2.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -120    0    0
   64    0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 47.288448333740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[65.35411 ]
 [30.869396]
 [71.44349 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.  1. 25.  0. 29.  1. 10. 15. 11. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 26. 30.  8.  2.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.44349670410156






Player: 1 
cards in hand: [ 0.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  2.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [25. 29. 11. 11. 25.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.  1. 25.  0. 29.  1. 10. 15. 11. 15.
 11.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15] -> size -> 47 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 26. 30.  8.  2.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [25. 29. 11. 11. 25.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.  1. 25.  0. 29.  1. 10. 15. 11. 15.
 11.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15] -> size -> 47 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  2.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [25. 29. 11. 11. 25.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.  1. 25.  0. 29.  1. 10. 15. 11. 15.
 11.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15] -> size -> 47 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [25. 29. 11. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11. 11. 25.] 
expected returns: [[41.324024]
 [59.665424]
 [55.695755]
 [51.053406]
 [51.053406]
 [59.665424]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 11. 11. 25.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 10.  0. 15. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  3.  3. 25.  3. 15. 25.  0. 10. 10.  1. 25.  0. 29.  1. 10. 15. 11. 15.
 11.  0. 10. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  2.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [3. 0. 6. 3. 6.] 
adversary cards in discard: [ 3.  0.  0. 11.  0.  3.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3] -> size -> 26 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 71.44349670410156



action possibilites: [-1] 
expected returns: [[75.705376]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11. 25.  1. 15.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [3. 0. 6. 3. 6.] 
adversary cards in discard: [ 3.  0.  0. 11.  0.  3.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6] -> size -> 27 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 59.66543197631836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[69.759186]
 [77.61725 ]
 [40.098686]
 [75.041756]
 [76.93239 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11. 11. 25.  1. 15.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 25. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [3. 0. 6. 3. 6.] 
adversary cards in discard: [ 3.  0.  0. 11.  0.  3.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6] -> size -> 27 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.70537567138672



buy possibilites: [-1] 
expected returns: [[87.905396]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11. 11. 25.  1. 15.] 
cards in discard: [3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [3. 0. 6. 3. 6.] 
adversary cards in discard: [ 3.  0.  0. 11.  0.  3.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6] -> size -> 27 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -130    0    0
   16    0] 
sum of rewards: 141 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 77.61725616455078






Player: 1 
cards in hand: [3. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [ 3.  0.  0. 11.  0.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [15. 10.  0.  0. 15.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [ 3.  0.  0. 11.  0.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [15. 10.  0.  0. 15.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [15. 10.  0.  0. 15.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [15. 10.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 15.] 
expected returns: [[63.643124]
 [55.600376]
 [64.09299 ]
 [55.600376]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  0. 15.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [ 6.  6.  0. 29. 10.] 
adversary cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0] -> size -> 28 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.9053955078125



action possibilites: [-1. 15. 15. 15.] 
expected returns: [[75.94086]
 [67.04739]
 [67.04739]
 [67.04739]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 15. 15.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [ 6.  6.  0. 29. 10.] 
adversary cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0] -> size -> 28 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 64.09300231933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[66.75972 ]
 [73.5934  ]
 [30.979729]
 [72.87431 ]
 [75.67991 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 15. 15.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [ 6.  6.  0. 29. 10.] 
adversary cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0] -> size -> 28 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 75.94087219238281






Player: 1 
cards in hand: [ 6.  6.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 29. 10.] 
cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [29.  1. 10. 10. 10.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1. 29. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 29. 29.] 
cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [29.  1. 10. 10. 10.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 29. 29.] 
cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [29.  1. 10. 10. 10.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 29. 29.] 
cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [29.  1. 10. 10. 10.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29.  1. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 10.] 
expected returns: [[55.898853]
 [67.12183 ]
 [56.29141 ]
 [56.29141 ]
 [56.29141 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 10. 10. 10.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.  0. 10.  6.  6.  0.
 29. 29.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 75.67991638183594



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[87.99624]
 [88.01378]
 [88.01378]
 [88.01378]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10. 10.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.  0. 10.  6.  6.  0.
 29. 29.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.12533187866211



action possibilites: [-1. 10. 10.] 
expected returns: [[91.463196]
 [90.96648 ]
 [90.96648 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10.  0.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
action values: 2 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.  0. 10.  6.  6.  0.
 29. 29.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 88.01380920410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[ 84.052605]
 [ 97.84206 ]
 [ 90.32458 ]
 [ 47.837223]
 [100.002884]
 [ 96.71552 ]
 [ 90.278824]
 [102.52278 ]
 [ 62.31824 ]
 [ 82.99763 ]
 [ 92.40684 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  0.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  5. 10. 10.  0. 10.  3.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.  0. 10.  6.  6.  0.
 29. 29.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 91.46320343017578



buy possibilites: [-1] 
expected returns: [[87.01121]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  0.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.  0. 10.  6.  6.  0.
 29. 29.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -140    0    0
  128    0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 102.52278900146484






Player: 1 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.  0. 10.  6.  6.  0.
 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [10. 11. 15.  0.  0.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29] -> size -> 49 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.  0. 10.  6.  6.  0.
 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 24. 30.  8.  1.  9.  1.  7.  4.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [10. 11. 15.  0.  0.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29] -> size -> 49 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 3.  0.  0. 11.  0.  3.  6.  0.  3.  0.  6.  3.  6.  0. 10.  6.  6.  0.
 29. 29.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  1.  9.  1.  7.  4.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [10. 11. 15.  0.  0.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29] -> size -> 49 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [10. 11. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
expected returns: [[115.740234]
 [114.52017 ]
 [119.224525]
 [106.150505]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15.  0.  0.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  1.  9.  1.  7.  4.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [0. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0  1] -> size -> 30 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.0112075805664



action possibilites: [-1] 
expected returns: [[110.49263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  0.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29 15] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  1.  9.  1.  7.  4.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0  1] -> size -> 30 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -150    0    0
   64    0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 122.23680114746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[101.99087 ]
 [109.04746 ]
 [ 65.776405]
 [108.0892  ]
 [110.492645]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.  0.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29 15] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 24. 30.  8.  1.  9.  1.  7.  4.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0  1] -> size -> 30 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.49263000488281






Player: 1 
cards in hand: [0. 6. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  1.  9.  1.  7.  4.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10. 25.  0.  3. 25.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0. 15. 11. 10. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29 15] -> size -> 50 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 24. 30.  8.  1.  9.  1.  7.  4.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10. 25.  0.  3. 25.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0. 15. 11. 10. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29 15] -> size -> 50 
adversary victory points: 5
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [10. 25.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 25.] 
expected returns: [[71.94147]
 [71.73791]
 [85.75273]
 [85.75273]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  0.  3. 25.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0. 15. 11. 10. 15.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29 15] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  1.  9.  1.  7.  4.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [0. 6. 6. 6. 8.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0  1] -> size -> 30 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 110.49263000488281



action possibilites: [-1] 
expected returns: [[51.541798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 25. 10.  1.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0. 15. 11. 10. 15.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29 15] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  0.  9.  1.  7.  4.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [0. 6. 6. 6. 8. 6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0  1  6] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 85.75273132324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[43.184593]
 [56.312836]
 [50.20996 ]
 [54.984867]
 [48.537655]
 [51.541817]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 25. 10.  1.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0. 15. 11. 10. 15.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29 15] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 24. 30.  8.  0.  9.  1.  7.  4.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [0. 6. 6. 6. 8. 6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0  1  6] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.54179763793945



buy possibilites: [-1] 
expected returns: [[19.122784]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 25. 10.  1.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0. 15. 11. 10. 15.  0.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29 15  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 24. 30.  8.  0.  9.  1.  7.  4.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [0. 6. 6. 6. 8. 6.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0  1  6] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -160    0    0
   54    0] 
sum of rewards: 179 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 56.31283187866211






Player: 1 
cards in hand: [0. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [0. 6. 6. 6. 8. 6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0  1  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 24. 30.  8.  0.  9.  1.  7.  4.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 25. 10.  0.  3.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0. 15. 11. 10. 15.  0.  0.  1. 25. 10.  0.  3. 25. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29 15  1] -> size -> 51 
adversary victory points: 5
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [0. 6. 6. 6. 8. 6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0  1  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 30. 24. 30.  8.  0.  9.  1.  7.  4.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 25. 10.  0.  3.] 
adversary cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0. 15. 11. 10. 15.  0.  0.  1. 25. 10.  0.  3. 25. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29 15  1] -> size -> 51 
adversary victory points: 5
player victory points: -5 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 5 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 0 
Witch: 6 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11. 25. 10.  0.  3.] 
cards in discard: [ 3. 25. 29. 11. 11. 25.  1. 15. 10. 15.  0.  0. 15. 15. 10. 29. 29. 10.
  1. 10. 10.  0. 15. 11. 10. 15.  0.  0.  1. 25. 10.  0.  3. 25. 10.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1 10 11 10 29 29 10  1 25 10 11  1
 10 11 10 25 11 10 11 25 11 10 25 10 15 15 25  3 15 15 11 15 25  1 15  3
 29 15  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 24. 30.  8.  0.  9.  0.  7.  4.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 0.  6.  6.  6.  8.  6. 11.] 
adversary owned cards: [ 3 29  0 10 29  6  0  0  3  6  0  8  6  3  3  6  6  0  6  0  0 11  6  0
  6  3  6  0  0  1  6 11] -> size -> 32 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[     -5 3000000       0     300       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000295 

action type: buy - action -1
Learning step: 120011.0390625
desired expected reward: 120030.1640625



