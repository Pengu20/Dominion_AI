 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[320.1356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   3  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 528 

action type: buy - action -1
Learning step: 22.39853286743164
desired expected reward: 102.42787170410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[296.99103]
 [308.7585 ]
 [303.92462]
 [272.77258]
 [316.76703]
 [305.7371 ]
 [303.121  ]
 [321.49667]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.268787384033203
desired expected reward: 312.7984619140625



buy possibilites: [-1] 
expected returns: [[286.05994]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -8.602004051208496
desired expected reward: 308.1650695800781






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [16.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [16.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[290.97708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.829705715179443
desired expected reward: 278.230224609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[277.11078]
 [288.53546]
 [282.1003 ]
 [253.04663]
 [281.80276]
 [293.59857]
 [286.0197 ]
 [286.40833]
 [263.91074]
 [280.86624]
 [275.91205]
 [295.70493]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.310815811157227
desired expected reward: 283.83544921875



buy possibilites: [-1] 
expected returns: [[288.77597]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -7.057557582855225
desired expected reward: 275.04278564453125






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[296.94385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -7.870266914367676
desired expected reward: 280.90570068359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[270.82098]
 [279.0116 ]
 [274.6843 ]
 [253.17433]
 [274.21365]
 [285.47772]
 [277.1922 ]
 [278.1336 ]
 [262.24783]
 [274.49414]
 [271.22873]
 [289.1268 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.50413990020752
desired expected reward: 285.65283203125



buy possibilites: [-1] 
expected returns: [[277.1302]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 31 

action type: buy - action 14.0
Learning step: -5.326962471008301
desired expected reward: 256.9208679199219






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  3.  0.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[336.03696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -6.342190742492676
desired expected reward: 270.7879943847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[313.03125]
 [321.24384]
 [283.48856]
 [322.91837]
 [339.78775]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.612495422363281
desired expected reward: 326.5794677734375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [16.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[294.02893]
 [291.06393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 16.] 
adversary cards in discard: [16.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -10.477937698364258
desired expected reward: 329.309814453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[268.16977]
 [274.63644]
 [244.23796]
 [276.65182]
 [289.4379 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 16.] 
adversary cards in discard: [16.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.497721672058105
desired expected reward: 284.3821716308594



buy possibilites: [-1] 
expected returns: [[278.9916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 16.] 
adversary cards in discard: [16.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -312.0 

action type: buy - action 6.0
Learning step: -21.534589767456055
desired expected reward: 222.70338439941406






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 16.] 
cards in discard: [16.  3.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 16.] 
cards in discard: [16.  3.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6] -> size -> 14 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[284.5418 ]
 [245.03194]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  0.] 
cards in discard: [ 6.  3.  0.  3. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -8.493705749511719
desired expected reward: 270.4978942871094



action possibilites: [-1] 
expected returns: [[270.9867]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6.  3.  0.  3. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action 14.0
Learning step: -5.735919952392578
desired expected reward: 238.92648315429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[253.8558 ]
 [265.16037]
 [248.32878]
 [260.19333]
 [239.93631]
 [232.32126]
 [258.40512]
 [272.1084 ]
 [261.75214]
 [281.395  ]
 [262.8028 ]
 [243.05261]
 [249.4111 ]
 [258.93677]
 [237.83054]
 [254.35385]
 [275.4562 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6.  3.  0.  3. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -7.241392612457275
desired expected reward: 263.74530029296875



buy possibilites: [-1] 
expected returns: [[253.8034]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6.  3.  0.  3. 11.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: 20.5 

action type: buy - action 25.0
Learning step: -7.21227502822876
desired expected reward: 271.7447509765625






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.] 
cards in discard: [0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8.  8.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  8.  8.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 0. 6. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[267.8886]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [ 0.  0.  6.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -6.297566890716553
desired expected reward: 247.50584411621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[242.7461 ]
 [249.82318]
 [218.43689]
 [251.41547]
 [264.4577 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [ 0.  0.  6.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -7.287227630615234
desired expected reward: 259.05072021484375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  0.] 
cards in discard: [ 0.  0.  6.  0. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  3.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  0.] 
cards in discard: [ 0.  0.  6.  0. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  3.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  0.] 
cards in discard: [ 0.  0.  6.  0. 16.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  9. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  3.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[312.21793]
 [273.17703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  3.] 
cards in discard: [3. 0. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  9. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -6.105754375457764
desired expected reward: 258.35198974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[289.45822]
 [302.57764]
 [297.9509 ]
 [263.69022]
 [311.90195]
 [298.6536 ]
 [296.88324]
 [317.3806 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.  3.] 
cards in discard: [3. 0. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  9. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.440779685974121
desired expected reward: 304.4519348144531



buy possibilites: [-1] 
expected returns: [[292.44452]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.  3.] 
cards in discard: [ 3.  0.  3.  3.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  8. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 26 

action type: buy - action 11.0
Learning step: -7.715095520019531
desired expected reward: 304.1868591308594






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  8. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  6. 11.  0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 11.  0.  0.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  8. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  6. 11.  0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 11.  0.  0.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0 10  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  8.  8.  8. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  6. 11.  0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 11.  0.  0.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [25.  0.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[172.53442]
 [178.00516]
 [167.92392]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  6. 11.  0.] 
cards in discard: [ 3.  0.  3.  3.  0. 11.  0.  0.  0. 14.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  8.  8. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 16.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0 10  3] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.853662490844727
desired expected reward: 281.5908508300781



action possibilites: [-1] 
expected returns: [[241.0523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  7.  8.  8. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 16.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 20 

action type: take_action - action 25.0
Learning step: -2.3638992309570312
desired expected reward: 173.38763427734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[224.52182]
 [235.18372]
 [228.93161]
 [201.90588]
 [228.82462]
 [239.40231]
 [232.87936]
 [233.0839 ]
 [211.88797]
 [227.7062 ]
 [222.97043]
 [238.98773]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8.  7.  8.  8. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 16.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -5.971256732940674
desired expected reward: 235.0810546875



buy possibilites: [-1] 
expected returns: [[286.33133]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8.  6.  8.  8. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 16.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -293.0 

action type: buy - action 6.0
Learning step: -18.302839279174805
desired expected reward: 183.60304260253906






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  3. 16.] 
cards in discard: [3. 0. 0. 0. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  6.  8.  8. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [ 6. 25.  0.  6. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 3. 6. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [ 6. 25.  0.  6. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 3. 6. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [ 6. 25.  0.  6. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 3. 6. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [ 6. 25.  0.  6. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[213.23178]
 [211.94336]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [ 6. 25.  0.  6. 11.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0. 16.  0.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  6.  6.  0. 16.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -9.230732917785645
desired expected reward: 277.1005859375



action possibilites: [-1] 
expected returns: [[193.77472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6. 25.  0.  6. 11.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 16.  0.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  6.  6.  0. 16.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 36 

action type: gain_card_n - action 9
Learning step: -5.304139137268066
desired expected reward: 223.97726440429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[177.35822]
 [183.85281]
 [155.65402]
 [184.94495]
 [197.44275]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6. 25.  0.  6. 11.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 16.  0.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  6.  6.  0. 16.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -4.191872596740723
desired expected reward: 189.5828399658203






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [10.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 16.  0.  0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  6.  6.  0. 16.  6.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 14.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 14.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 14.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 14.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 6. 14.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[243.06073]
 [212.88635]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 3.] 
adversary cards in discard: [10. 10.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0 10] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -4.304351329803467
desired expected reward: 193.138427734375



action possibilites: [-1] 
expected returns: [[216.95465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 3.] 
adversary cards in discard: [10. 10.  0. 16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0 10] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action 14.0
Learning step: -4.203551769256592
desired expected reward: 208.81381225585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[198.85027]
 [214.72995]
 [208.36322]
 [170.80911]
 [222.85075]
 [209.87944]
 [206.05017]
 [225.85759]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 3.] 
adversary cards in discard: [10. 10.  0. 16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0 10] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -4.72987699508667
desired expected reward: 212.2247772216797






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [10. 10.  0. 16.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 11.  6.  3.] 
adversary cards in discard: [14.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [10. 10.  0. 16.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 11.  6.  3.] 
adversary cards in discard: [14.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [10. 10.  0. 16.  0.  0.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 11.  6.  3.] 
adversary cards in discard: [14.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [11.  0. 11.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[247.50063]
 [245.12727]
 [245.12727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  6.  3.] 
cards in discard: [14.  6.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 16.  6.  0.] 
adversary cards in discard: [10. 10.  0. 16.  0.  0.  0.  3.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -5.510159492492676
desired expected reward: 220.34742736816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[226.10362]
 [202.48598]
 [246.42271]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  6.  3.] 
cards in discard: [14.  6.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  8. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 16.  6.  0.] 
adversary cards in discard: [10. 10.  0. 16.  0.  0.  0.  3.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -6.603036403656006
desired expected reward: 236.15005493164062



buy possibilites: [-1] 
expected returns: [[184.77582]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  6.  3.] 
cards in discard: [14.  6.  3.  3.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  4.  8.  8. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 16.  6.  0.] 
adversary cards in discard: [10. 10.  0. 16.  0.  0.  0.  3.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -21.16684341430664
desired expected reward: 181.3191375732422






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  6.  0.] 
cards in discard: [10. 10.  0. 16.  0.  0.  0.  3.  0.  0.  6.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  6  0 10  3  6  6  0 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  4.  8.  8. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [14.  6.  3.  3.  0.  6. 11.  0. 11.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6] -> size -> 19 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [10. 10.  0. 16.  0.  0.  0.  3.  0.  0.  6.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  0 10  3  6  6  0 10  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  3.  8.  8. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [14.  6.  3.  3.  0.  6. 11.  0. 11.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6] -> size -> 19 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [10. 10.  0. 16.  0.  0.  0.  3.  0.  0.  6.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  0 10  3  6  6  0 10  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  3.  8.  8. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [14.  6.  3.  3.  0.  6. 11.  0. 11.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6] -> size -> 19 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [10. 10.  0. 16.  0.  0.  0.  3.  0.  0.  6.  0.  3.  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  0 10  3  6  6  0 10  0  6  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  3.  8.  8.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [14.  6.  3.  3.  0.  6. 11.  0. 11.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6] -> size -> 19 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[140.3648]
 [146.9747]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.  3.] 
cards in discard: [14.  6.  3.  3.  0.  6. 11.  0. 11.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  3.  8.  8.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  0 10  3  6  6  0 10  0  6  8] -> size -> 21 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -6.29311990737915
desired expected reward: 178.48269653320312



action possibilites: [-1] 
expected returns: [[138.28967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3.  0. 10.] 
cards in discard: [14.  6.  3.  3.  0.  6. 11.  0. 11.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  2.  8.  8.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  3.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  0 10  3  6  6  0 10  0  6  8  6] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 17 

action type: take_action - action 25.0
Learning step: -3.1480019092559814
desired expected reward: 139.04238891601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[116.44037 ]
 [127.35079 ]
 [123.5817  ]
 [ 95.92612 ]
 [121.19197 ]
 [133.69786 ]
 [123.7997  ]
 [124.65325 ]
 [105.873604]
 [121.75076 ]
 [116.98713 ]
 [136.62152 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3.  0. 10.] 
cards in discard: [14.  6.  3.  3.  0.  6. 11.  0. 11.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 27. 30.  8.  2.  8.  8.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  3.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  0 10  3  6  6  0 10  0  6  8  6] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -3.30876088142395
desired expected reward: 134.9809112548828



buy possibilites: [-1] 
expected returns: [[126.83001]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3.  0. 10.] 
cards in discard: [14.  6.  3.  3.  0.  6. 11.  0. 11.  6.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  3.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  0 10  3  6  6  0 10  0  6  8  6] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 48 

action type: buy - action 29.0
Learning step: -0.9789871573448181
desired expected reward: 123.67425537109375






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.  3.  3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3  0 16  0 10  3  6  6  0 10  0  6  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29] -> size -> 20 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29] -> size -> 20 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29] -> size -> 20 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29] -> size -> 20 
adversary victory points: 1
player victory points: -1 





Player: 0 
cards in hand: [ 0. 10.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[170.5622 ]
 [158.99213]
 [180.56313]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 16.  3.  0.  3.] 
adversary cards in discard: [6. 0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: buy - action -1
Learning step: -1.6689773797988892
desired expected reward: 125.1610336303711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[156.93237]
 [167.09283]
 [160.49518]
 [131.30925]
 [171.537  ]
 [165.02924]
 [159.67642]
 [171.81808]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 27. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 16.  3.  0.  3.] 
adversary cards in discard: [6. 0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: -4.051711082458496
desired expected reward: 166.49252319335938



buy possibilites: [-1] 
expected returns: [[144.8517]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 25.  0.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 26. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 16.  3.  0.  3.] 
adversary cards in discard: [6. 0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2. 30.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 29.0 

action type: buy - action 3.0
Learning step: -3.3155949115753174
desired expected reward: 157.1795654296875






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 6. 16.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  3.  0.  3.] 
cards in discard: [6. 0. 8. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  3.  6.  0.] 
adversary cards in discard: [ 3.  0. 10.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3] -> size -> 21 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  3.  0.  3.] 
cards in discard: [6. 0. 8. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 26. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  3.  6.  0.] 
adversary cards in discard: [ 3.  0. 10.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3] -> size -> 21 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  3.  0.  3.] 
cards in discard: [6. 0. 8. 0. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 26. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  3.  6.  0.] 
adversary cards in discard: [ 3.  0. 10.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3] -> size -> 21 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [29. 11.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[137.50763]
 [124.62702]
 [134.45735]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3.  6.  0.] 
cards in discard: [ 3.  0. 10.  0. 25.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  6.  0.  0.  0.] 
adversary cards in discard: [ 6.  0.  8.  0.  3.  0.  6. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1
Learning step: -2.9754631519317627
desired expected reward: 141.87623596191406



action possibilites: [-1] 
expected returns: [[129.40996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  6.  0.] 
cards in discard: [ 3.  0. 10.  0. 25.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  6.  0.  0.  0.] 
adversary cards in discard: [ 6.  0.  8.  0.  3.  0.  6. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 56 

action type: gain_card_n - action 9
Learning step: -0.9746536612510681
desired expected reward: 132.75289916992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[110.23307]
 [ 89.80487]
 [129.821  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  6.  0.] 
cards in discard: [ 3.  0. 10.  0. 25.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 26. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  6.  0.  0.  0.] 
adversary cards in discard: [ 6.  0.  8.  0.  3.  0.  6. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1
Learning step: -1.5333633422851562
desired expected reward: 127.87659454345703






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [10.  6.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  0.  0.] 
cards in discard: [ 6.  0.  8.  0.  3.  0.  6. 16.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  6.  6. 14.  0.] 
adversary cards in discard: [ 3.  0. 10.  0. 25.  0. 10. 11. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10] -> size -> 22 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  0.  0.] 
cards in discard: [ 6.  0.  8.  0.  3.  0.  6. 16.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 26. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  6.  6. 14.  0.] 
adversary cards in discard: [ 3.  0. 10.  0. 25.  0. 10. 11. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10] -> size -> 22 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  0.  0.] 
cards in discard: [ 6.  0.  8.  0.  3.  0.  6. 16.  3.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  6.  6. 14.  0.] 
adversary cards in discard: [ 3.  0. 10.  0. 25.  0. 10. 11. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10] -> size -> 22 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 3.  6.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[111.76949]
 [ 85.34251]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6. 14.  0.] 
cards in discard: [ 3.  0. 10.  0. 25.  0. 10. 11. 29.  3.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [ 6.  0.  8.  0.  3.  0.  6. 16.  3.  0.  3.  3. 10.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -3.3866219520568848
desired expected reward: 126.43437957763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 90.89477]
 [ 72.14346]
 [107.34004]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6. 14.  0.] 
cards in discard: [ 3.  0. 10.  0. 25.  0. 10. 11. 29.  3.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [ 6.  0.  8.  0.  3.  0.  6. 16.  3.  0.  3.  3. 10.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -2.3571255207061768
desired expected reward: 104.30355072021484



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 6.  0.  8.  0.  3.  0.  6. 16.  3.  0.  3.  3. 10.  6.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [ 3.  0. 10.  0. 25.  0. 10. 11. 29.  3.  6.  0.  3.  6.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10] -> size -> 22 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 6.  0.  8.  0.  3.  0.  6. 16.  3.  0.  3.  3. 10.  6.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [ 3.  0. 10.  0. 25.  0. 10. 11. 29.  3.  6.  0.  3.  6.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10] -> size -> 22 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 6.  0.  8.  0.  3.  0.  6. 16.  3.  0.  3.  3. 10.  6.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [ 3.  0. 10.  0. 25.  0. 10. 11. 29.  3.  6.  0.  3.  6.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10] -> size -> 22 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 6.  0.  8.  0.  3.  0.  6. 16.  3.  0.  3.  3. 10.  6.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [ 3.  0. 10.  0. 25.  0. 10. 11. 29.  3.  6.  0.  3.  6.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10] -> size -> 22 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[86.83668]
 [84.64743]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [ 3.  0. 10.  0. 25.  0. 10. 11. 29.  3.  6.  0.  3.  6.  6. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -2.5815701484680176
desired expected reward: 104.75847625732422



action possibilites: [-1] 
expected returns: [[93.108765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 3.  0. 10.  0. 25.  0. 10. 11. 29.  3.  6.  0.  3.  6.  6. 14.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   2  20   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: gain_card_n - action 0
Learning step: -1.2020701169967651
desired expected reward: 71.73827362060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[84.79756]
 [88.01254]
 [70.74242]
 [89.66734]
 [94.97779]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 3.  0. 10.  0. 25.  0. 10. 11. 29.  3.  6.  0.  3.  6.  6. 14.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: -0.8253471255302429
desired expected reward: 92.28341674804688






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [6. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0] -> size -> 23 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0] -> size -> 23 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0] -> size -> 23 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [11.  6.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[123.40693 ]
 [120.280655]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10
  0] -> size -> 25 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -1.1740379333496094
desired expected reward: 93.80372619628906



action possibilites: [-1] 
expected returns: [[122.78098]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10
  0] -> size -> 25 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 46 

action type: gain_card_n - action 9
Learning step: -0.9160907864570618
desired expected reward: 118.65716552734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[112.13677]
 [117.9157 ]
 [ 97.66441]
 [118.71875]
 [132.34442]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10
  0] -> size -> 25 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: -1.5900315046310425
desired expected reward: 121.19094848632812






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [0. 6. 6. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  6.  3. 10.  0.] 
adversary cards in discard: [10. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10] -> size -> 24 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [0. 6. 6. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  6.  3. 10.  0.] 
adversary cards in discard: [10. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10] -> size -> 24 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0. 6. 6. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  6.  3. 10.  0.] 
adversary cards in discard: [10. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10] -> size -> 24 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0. 6. 6. 0. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  6.  3. 10.  0.] 
adversary cards in discard: [10. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10] -> size -> 24 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [10.  6.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[150.62358]
 [137.267  ]
 [137.267  ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3. 10.  0.] 
cards in discard: [10. 11.  6.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  6. 10.  0.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0. 0. 8. 3.] 
adversary owned cards: [ 0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -2.605794668197632
desired expected reward: 129.7386016845703



action possibilites: [-1. 10. 11.] 
expected returns: [[122.49509]
 [103.3113 ]
 [118.1025 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 10.  0. 11.] 
cards in discard: [10. 11.  6.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  6. 10.  0.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0. 0. 8. 3.] 
adversary owned cards: [ 0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action 10.0
Learning step: -2.2125184535980225
desired expected reward: 131.51963806152344



action possibilites: [-1. 11.] 
expected returns: [[145.19585]
 [140.57956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 11.  3.] 
cards in discard: [10. 11.  6.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10] -> size -> 24 
action values: 3 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  6. 10.  0.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0. 0. 8. 3.] 
adversary owned cards: [ 0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: take_action - action 10.0
Learning step: 0.9125568270683289
desired expected reward: 104.22388458251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[125.550446]
 [107.02532 ]
 [147.23615 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 11.  3.] 
cards in discard: [10. 11.  6.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  6. 10.  0.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0. 0. 8. 3.] 
adversary owned cards: [ 0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: take_action - action -1.0
Learning step: -1.443658471107483
desired expected reward: 143.75221252441406



buy possibilites: [-1] 
expected returns: [[156.53374]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 11.  3.] 
cards in discard: [10. 11.  6.  3.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  6. 10.  0.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0. 0. 8. 3.] 
adversary owned cards: [ 0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 27.0 

action type: buy - action 0.0
Learning step: -1.405514121055603
desired expected reward: 124.14494323730469






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [16.  0.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6. 10.  0.] 
cards in discard: [0. 6. 6. 0. 0. 0. 0. 8. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 29.  0.] 
adversary cards in discard: [10. 11.  6.  3.  0.  0.  0. 10. 10.  6.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0] -> size -> 25 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  0.  6.] 
cards in discard: [0. 6. 6. 0. 0. 0. 0. 8. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  6  0 10  0  6  8  6  0  0  3 10  0  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  2.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 29.  0.] 
adversary cards in discard: [10. 11.  6.  3.  0.  0.  0. 10. 10.  6.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0] -> size -> 25 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [0. 6. 6. 0. 0. 0. 0. 8. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  1.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 29.  0.] 
adversary cards in discard: [10. 11.  6.  3.  0.  0.  0. 10. 10.  6.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0] -> size -> 25 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [0. 6. 6. 0. 0. 0. 0. 8. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 25. 30.  8.  1.  8.  8.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 29.  0.] 
adversary cards in discard: [10. 11.  6.  3.  0.  0.  0. 10. 10.  6.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0] -> size -> 25 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [0. 6. 6. 0. 0. 0. 0. 8. 3. 6. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  1.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 29.  0.] 
adversary cards in discard: [10. 11.  6.  3.  0.  0.  0. 10. 10.  6.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0] -> size -> 25 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 14. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
expected returns: [[95.04522]
 [72.42952]
 [87.44727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 29.  0.] 
cards in discard: [10. 11.  6.  3.  0.  0.  0. 10. 10.  6.  3.  0. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  1.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [ 0.  6.  6.  0.  0.  0.  0.  8.  3.  6.  8. 10. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -5.007394313812256
desired expected reward: 151.52633666992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[81.847206]
 [89.77659 ]
 [86.82806 ]
 [61.290222]
 [94.047295]
 [87.59674 ]
 [85.88746 ]
 [95.83011 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14. 29.  0.] 
cards in discard: [10. 11.  6.  3.  0.  0.  0. 10. 10.  6.  3.  0. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 25. 30.  8.  1.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [ 0.  6.  6.  0.  0.  0.  0.  8.  3.  6.  8. 10. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -1.9215401411056519
desired expected reward: 93.12366485595703



buy possibilites: [-1] 
expected returns: [[97.36478]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14. 29.  0.] 
cards in discard: [10. 11.  6.  3.  0.  0.  0. 10. 10.  6.  3.  0. 11.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 30. 30. 25. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [ 0.  6.  6.  0.  0.  0.  0.  8.  3.  6.  8. 10. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8] -> size -> 24 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -294.0 

action type: buy - action 6.0
Learning step: -15.503619194030762
desired expected reward: 44.38291931152344






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  3.] 
cards in discard: [ 0.  6.  6.  0.  0.  0.  0.  8.  3.  6.  8. 10. 16.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  3. 25.  0.  3.] 
adversary cards in discard: [10. 11.  6.  3.  0.  0.  0. 10. 10.  6.  3.  0. 11.  3.  6.  0.  0. 14.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  3.] 
cards in discard: [ 0.  6.  6.  0.  0.  0.  0.  8.  3.  6.  8. 10. 16.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 25. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  3. 25.  0.  3.] 
adversary cards in discard: [10. 11.  6.  3.  0.  0.  0. 10. 10.  6.  3.  0. 11.  3.  6.  0.  0. 14.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  3.] 
cards in discard: [ 0.  6.  6.  0.  0.  0.  0.  8.  3.  6.  8. 10. 16.  0.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 25. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  3. 25.  0.  3.] 
adversary cards in discard: [10. 11.  6.  3.  0.  0.  0. 10. 10.  6.  3.  0. 11.  3.  6.  0.  0. 14.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [ 6.  3. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[25.053223]
 [31.992565]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 25.  0.  3.] 
cards in discard: [10. 11.  6.  3.  0.  0.  0. 10. 10.  6.  3.  0. 11.  3.  6.  0.  0. 14.
 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 25. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8
  0] -> size -> 25 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -3.9067063331604004
desired expected reward: 93.45806884765625



action possibilites: [-1] 
expected returns: [[102.44874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  3. 14.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 25. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8
  0] -> size -> 25 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 27 

action type: take_action - action 25.0
Learning step: 2.0554685592651367
desired expected reward: 34.04802703857422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 88.04031]
 [ 93.68906]
 [ 95.03901]
 [105.54586]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  3. 14.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 25. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8
  0] -> size -> 25 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -1.6151336431503296
desired expected reward: 100.83360290527344






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [10.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 25. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  6.] 
adversary cards in discard: [25.  6.  3.  0.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 25. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  6.] 
adversary cards in discard: [25.  6.  3.  0.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0. 10.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  6.] 
adversary cards in discard: [25.  6.  3.  0.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[56.019794]
 [43.15557 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  6.] 
cards in discard: [25.  6.  3.  0.  3. 14.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 16.  0.  3.  6.] 
adversary cards in discard: [ 3. 10.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8
  0  3] -> size -> 26 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -4.324923992156982
desired expected reward: 101.22091674804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[35.33458 ]
 [47.908794]
 [43.95787 ]
 [55.447346]
 [43.575462]
 [41.650116]
 [58.792725]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  6.] 
cards in discard: [25.  6.  3.  0.  3. 14.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 16.  0.  3.  6.] 
adversary cards in discard: [ 3. 10.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8
  0  3] -> size -> 26 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -1.88190495967865
desired expected reward: 54.13789749145508



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  3.  6.] 
cards in discard: [ 3. 10.  8.  0.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0 10  3  6  0 10  0  6  8  6  0  0  3 10  0  0  6  8
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [25.  6.  3.  0.  3. 14.  0.  0.  0. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 10.  8.  0.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [25.  6.  3.  0.  3. 14.  0.  0.  0. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 10.  8.  0.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [25.  6.  3.  0.  3. 14.  0.  0.  0. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[75.63983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [25.  6.  3.  0.  3. 14.  0.  0.  0. 29.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [ 3. 10.  8.  0.  0. 10.  8.] 
adversary owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -1.4377405643463135
desired expected reward: 57.3549919128418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[66.59043 ]
 [73.39034 ]
 [70.564186]
 [69.438385]
 [77.18667 ]
 [71.413124]
 [71.85869 ]
 [60.234   ]
 [69.605484]
 [66.737206]
 [78.353775]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [25.  6.  3.  0.  3. 14.  0.  0.  0. 29.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [ 3. 10.  8.  0.  0. 10.  8.] 
adversary owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -2.3511922359466553
desired expected reward: 73.28864288330078



buy possibilites: [-1] 
expected returns: [[73.598305]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [25.  6.  3.  0.  3. 14.  0.  0.  0. 29.  0.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 30. 30. 23. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [ 3. 10.  8.  0.  0. 10.  8.] 
adversary owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3] -> size -> 22 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 9.0 

action type: buy - action 3.0
Learning step: -1.4222471714019775
desired expected reward: 69.14192962646484






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [ 3. 10.  8.  0.  0. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 23. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11. 11. 10.  3.] 
adversary cards in discard: [25.  6.  3.  0.  3. 14.  0.  0.  0. 29.  0.  6.  3.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [ 3. 10.  8.  0.  0. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 23. 30.  8.  0.  8.  8.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11. 11. 10.  3.] 
adversary cards in discard: [25.  6.  3.  0.  3. 14.  0.  0.  0. 29.  0.  6.  3.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [ 3. 10.  8.  0.  0. 10.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 23. 30.  8.  0.  8.  8.  7.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11. 11. 10.  3.] 
adversary cards in discard: [25.  6.  3.  0.  3. 14.  0.  0.  0. 29.  0.  6.  3.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [10. 11. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[78.69981]
 [66.63731]
 [77.76789]
 [77.76789]
 [66.63731]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 10.  3.] 
cards in discard: [25.  6.  3.  0.  3. 14.  0.  0.  0. 29.  0.  6.  3.  0.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 23. 30.  8.  0.  8.  8.  7.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 3. 10.  8.  0.  0. 10.  8.  8. 10.  0.  0.  3.  3.] 
adversary owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 23 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -1.646506667137146
desired expected reward: 71.95179748535156



action possibilites: [-1] 
expected returns: [[107.138054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  3.] 
cards in discard: [25.  6.  3.  0.  3. 14.  0.  0.  0. 29.  0.  6.  3.  0.  0.  0.  0.  6.
 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 23. 30.  8.  0.  8.  8.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 3. 10.  8.  0.  0. 10.  8.  8. 10.  0.  0.  3.  3.] 
adversary owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 23 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 43 

action type: gain_card_n - action 6
Learning step: 2.4278018474578857
desired expected reward: 45.083885192871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 90.606094]
 [105.70215 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.  3.] 
cards in discard: [25.  6.  3.  0.  3. 14.  0.  0.  0. 29.  0.  6.  3.  0.  0.  0.  0.  6.
 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 30. 30. 23. 30.  8.  0.  8.  8.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 3. 10.  8.  0.  0. 10.  8.  8. 10.  0.  0.  3.  3.] 
adversary owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 23 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -1.7554324865341187
desired expected reward: 105.38262176513672



buy possibilites: [-1] 
expected returns: [[94.8176]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.  3.] 
cards in discard: [25.  6.  3.  0.  3. 14.  0.  0.  0. 29.  0.  6.  3.  0.  0.  0.  0.  6.
 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  8.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 3. 10.  8.  0.  0. 10.  8.  8. 10.  0.  0.  3.  3.] 
adversary owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 23 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   2  10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: buy - action 0.0
Learning step: -2.5469088554382324
desired expected reward: 88.05918884277344






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 3. 10.  8.  0.  0. 10.  8.  8. 10.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  8.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  3.  6. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0] -> size -> 29 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 3. 10.  8.  0.  0. 10.  8.  8. 10.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  8.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  3.  6. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0] -> size -> 29 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 3. 10.  8.  0.  0. 10.  8.  8. 10.  0.  0.  3.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  3.  6. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0] -> size -> 29 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 6.  3.  6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[77.92637 ]
 [66.911514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  6. 10.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 3. 10.  8.  0.  0. 10.  8.  8. 10.  0.  0.  3.  3. 11.  0.  0.  0.  3.
  6.] 
adversary owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 11] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -2.7368061542510986
desired expected reward: 92.0807876586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[63.32276 ]
 [78.281136]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  6. 10.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 3. 10.  8.  0.  0. 10.  8.  8. 10.  0.  0.  3.  3. 11.  0.  0.  0.  3.
  6.] 
adversary owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 11] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -1.8957465887069702
desired expected reward: 75.73226928710938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 3. 10.  8.  0.  0. 10.  8.  8. 10.  0.  0.  3.  3. 11.  0.  0.  0.  3.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [ 6.  3.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0] -> size -> 29 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 3. 10.  8.  0.  0. 10.  8.  8. 10.  0.  0.  3.  3. 11.  0.  0.  0.  3.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [ 6.  3.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0] -> size -> 29 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[89.84848]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [ 6.  3.  6. 10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  8.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 11] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -1.4655193090438843
desired expected reward: 74.81574249267578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[72.08611 ]
 [77.664055]
 [77.25263 ]
 [89.21873 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [ 6.  3.  6. 10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  8.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 11] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -2.2545604705810547
desired expected reward: 86.56961822509766



buy possibilites: [-1] 
expected returns: [[68.40785]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [ 6.  3.  6. 10.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 30. 30. 23. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  8.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 11] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -23.0 

action type: buy - action 0.0
Learning step: -3.2151291370391846
desired expected reward: 68.87098693847656






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [10.  8.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 11.  0.] 
adversary cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0] -> size -> 30 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 11.  0.] 
adversary cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0] -> size -> 30 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 11.  0.] 
adversary cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0] -> size -> 30 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 3. 25.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[30.977962]
 [35.793007]
 [28.647652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0. 11.  0.] 
cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  3.] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 22 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -1.8320392370224
desired expected reward: 66.57581329345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[18.02885 ]
 [22.669098]
 [23.045559]
 [34.097004]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0. 11.  0.] 
cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 23. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  3.] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 22 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -0.09364166110754013
desired expected reward: 30.884313583374023



buy possibilites: [-1] 
expected returns: [[36.27429]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0. 11.  0.] 
cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  3.] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 36 

action type: buy - action 3.0
Learning step: 1.4827171564102173
desired expected reward: 24.151803970336914






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0. 14.  0. 10.] 
adversary cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.  3.  3. 25.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3] -> size -> 31 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 30. 30. 22. 30.  8.  0.  8.  7.  7.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0. 14.  0. 10.] 
adversary cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.  3.  3. 25.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3] -> size -> 31 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8. 10.  3. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 22. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0. 14.  0. 10.] 
adversary cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.  3.  3. 25.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3] -> size -> 31 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29.  0. 14.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 10.] 
expected returns: [[86.084206]
 [79.15179 ]
 [65.40273 ]
 [75.863594]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 14.  0. 10.] 
cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.  3.  3. 25.  0. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  6.  3.  8.  8.] 
adversary cards in discard: [ 8. 10.  3. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: 1.3642488718032837
desired expected reward: 37.6385383605957



action possibilites: [-1] 
expected returns: [[74.04807]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10.] 
cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.  3.  3. 25.  0. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 30. 30. 22. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [6. 3. 8.] 
adversary cards in discard: [ 8. 10.  3. 29.  0.  0.  0.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action 14.0
Learning step: 0.7959453463554382
desired expected reward: 66.19866943359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[64.57896 ]
 [71.81817 ]
 [68.55813 ]
 [67.585   ]
 [76.30442 ]
 [69.980865]
 [70.56113 ]
 [57.218693]
 [67.974686]
 [64.91715 ]
 [78.24669 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 10.] 
cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.  3.  3. 25.  0. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 30. 30. 22. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [6. 3. 8.] 
adversary cards in discard: [ 8. 10.  3. 29.  0.  0.  0.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1
Learning step: 0.30085793137550354
desired expected reward: 74.34893035888672






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8.] 
cards in discard: [ 8. 10.  3. 29.  0.  0.  0.  0.  0. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.  3.  3. 25.  0. 11.  0. 14.
 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3] -> size -> 31 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8.] 
cards in discard: [ 8. 10.  3. 29.  0.  0.  0.  0.  0. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.  3.  3. 25.  0. 11.  0. 14.
 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3] -> size -> 31 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[60.12952 ]
 [49.575733]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.  3.  3. 25.  0. 11.  0. 14.
 29.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 10.  3. 29.  0.  0.  0.  0.  0. 10.  8.  6.  3.  8.] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -1.2480862140655518
desired expected reward: 76.99858856201172



action possibilites: [-1. 29.] 
expected returns: [[94.14138 ]
 [85.296684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 29.] 
cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.  3.  3. 25.  0. 11.  0. 14.
 29.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 10.  3. 29.  0.  0.  0.  0.  0. 10.  8.  6.  3.  8.] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action 10.0
Learning step: 1.9650853872299194
desired expected reward: 51.54083251953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[73.53657 ]
 [77.45454 ]
 [78.24958 ]
 [87.209984]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 29.] 
cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.  3.  3. 25.  0. 11.  0. 14.
 29.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 22. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 10.  3. 29.  0.  0.  0.  0.  0. 10.  8.  6.  3.  8.] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1.0
Learning step: -0.4809013307094574
desired expected reward: 93.66046905517578



buy possibilites: [-1] 
expected returns: [[73.36031]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 29.] 
cards in discard: [ 6.  3.  6. 10.  3.  0.  0.  6.  6.  0.  3.  3.  3. 25.  0. 11.  0. 14.
 29.  0.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 21. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 10.  3. 29.  0.  0.  0.  0.  0. 10.  8.  6.  3.  8.] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 67 

action type: buy - action 3.0
Learning step: 1.1278800964355469
desired expected reward: 78.58241271972656






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 8. 10.  3. 29.  0.  0.  0.  0.  0. 10.  8.  6.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 21. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3] -> size -> 32 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 8. 10.  3. 29.  0.  0.  0.  0.  0. 10.  8.  6.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 30. 30. 21. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3] -> size -> 32 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 8. 10.  3. 29.  0.  0.  0.  0.  0. 10.  8.  6.  3.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3] -> size -> 32 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 3. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[35.00831 ]
 [29.87804 ]
 [34.136356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29  3] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: -1.4867908954620361
desired expected reward: 71.87351989746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[30.221848]
 [31.09932 ]
 [33.364185]
 [37.89443 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29  3] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: 0.5240541696548462
desired expected reward: 34.49937057495117



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  3.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3] -> size -> 32 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  3  0 10  0  6  8  6  0  0  3 10  0  0  6  8  0  3  8 29  3] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  3.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3] -> size -> 32 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 10  3  0 10  0  8  6  0  0  3 10  0  0  6  8  0  3  8 29  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  3.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3] -> size -> 32 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 10  3  0 10  0  8  6  0  0  3 10  0  0  6  8  0  3  8 29  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  3.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3] -> size -> 32 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 10  3  0 10  0  8  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  3.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3] -> size -> 32 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 3.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[15.858249]
 [13.43798 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0.  3.] 
cards in discard: [ 3. 10.  0.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [ 1. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  8  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -0.6082445383071899
desired expected reward: 37.28618240356445





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.915218]
 [16.468359]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  0.  3.] 
cards in discard: [ 3. 10.  0.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [ 1. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  8  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: 0.5207363963127136
desired expected reward: 15.751714706420898



buy possibilites: [-1] 
expected returns: [[19.810728]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  0.  3.] 
cards in discard: [ 3. 10.  0.  0. 11.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [ 1. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10  3  0 10  0  8  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -11.0 

action type: buy - action 0.0
Learning step: -0.7000195384025574
desired expected reward: 11.215198516845703






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 3.] 
cards in discard: [ 1. 10.  8.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0 10  0  8  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 1. 10.  8.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 1. 10.  8.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 6.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-10.0735  ]
 [-10.063702]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.  0.] 
cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 1. 10.  8.  0.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: -0.2670519948005676
desired expected reward: 19.543676376342773



action possibilites: [-1] 
expected returns: [[73.29923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 1. 10.  8.  0.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5   0   4  20   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: gain_card_n - action 0
Learning step: 2.6092565059661865
desired expected reward: -7.591219902038574





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[61.127132]
 [68.377426]
 [66.396255]
 [72.820786]
 [65.9076  ]
 [65.09616 ]
 [74.915344]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 1. 10.  8.  0.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: -0.1488262265920639
desired expected reward: 73.15040588378906






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 1. 10.  8.  0.  0.  0.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 14.  6.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 1. 10.  8.  0.  0.  0.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 14.  6.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[43.681377]
 [35.09054 ]
 [22.42084 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 14.  6.] 
cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3.  6.  6.  3.] 
adversary cards in discard: [ 1. 10.  8.  0.  0.  0.  8.  0.  3.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -1.9801321029663086
desired expected reward: 72.93521881103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[25.514135]
 [30.486837]
 [30.993563]
 [40.35802 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 14.  6.] 
cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3.  6.  6.  3.] 
adversary cards in discard: [ 1. 10.  8.  0.  0.  0.  8.  0.  3.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -0.46917134523391724
desired expected reward: 43.21221160888672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [10.  3.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  6.  3.] 
cards in discard: [ 1. 10.  8.  0.  0.  0.  8.  0.  3.  0.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0.  6.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.  0.
 29.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6.  3. 29.] 
cards in discard: [ 1. 10.  8.  0.  0.  0.  8.  0.  3.  0.  3.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0.  6.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.  0.
 29.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 3.] 
cards in discard: [ 1. 10.  8.  0.  0.  0.  8.  0.  3.  0.  3.  0.  0. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
action values: 2 
buys: 0 
player value: 1 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0.  6.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.  0.
 29.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 3.] 
cards in discard: [ 1. 10.  8.  0.  0.  0.  8.  0.  3.  0.  3.  0.  0. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
action values: 2 
buys: 1 
player value: 1 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0.  6.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.  0.
 29.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [10.  3.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[65.705   ]
 [52.721043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.  6.] 
cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.  0.
 29.  0. 14.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 1. 10.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: 0.3013772964477539
desired expected reward: 40.6594123840332





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[46.899315]
 [64.67408 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.  6.] 
cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.  0.
 29.  0. 14.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 1. 10.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -1.029415488243103
desired expected reward: 64.67556762695312



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 1. 10.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [25.  0.  3. 10.  6.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.  0.
 29.  0. 14.  6. 10.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  7.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [25.  0.  3. 10.  6.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.  0.
 29.  0. 14.  6. 10.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  6.  0.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  6.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [25.  0.  3. 10.  6.] 
adversary cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.  0.
 29.  0. 14.  6. 10.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [25.  0.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[62.890507]
 [65.20647 ]
 [54.926693]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3. 10.  6.] 
cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.  0.
 29.  0. 14.  6. 10.  3.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  6.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [ 8.  1. 10.  3.  6.  0.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -0.8871059417724609
desired expected reward: 63.786964416503906



action possibilites: [-1] 
expected returns: [[122.21072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  6.  0.  3.] 
cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.  0.
 29.  0. 14.  6. 10.  3.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  6.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [ 8.  1. 10.  3.  6.  0.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 40 

action type: take_action - action 25.0
Learning step: 1.489417314529419
desired expected reward: 66.69588470458984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[111.30863 ]
 [114.72823 ]
 [115.33359 ]
 [122.205345]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  6.  0.  3.] 
cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.  0.
 29.  0. 14.  6. 10.  3.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  6.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [ 8.  1. 10.  3.  6.  0.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: -1.5169647932052612
desired expected reward: 120.6937484741211



buy possibilites: [-1] 
expected returns: [[19.783464]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  6.  0.  3.] 
cards in discard: [ 3. 10.  0.  0. 11.  0.  3.  3. 29.  0.  3.  0. 11.  6.  0.  0.  0.  0.
 29.  0. 14.  6. 10.  3.  3.  0.  6.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [ 8.  1. 10.  3.  6.  0.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 47 

action type: buy - action 8.0
Learning step: -2.9715511798858643
desired expected reward: 112.36203002929688






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [29.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10.  0.  0.] 
cards in discard: [ 8.  1. 10.  3.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  6. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 8.  1. 10.  3.  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  6. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 8.  1. 10.  3.  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  6. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 8.  1. 10.  3.  6.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  6. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 6.  6. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[33.771645]
 [24.29725 ]
 [32.008114]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10. 11.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [ 8.  1. 10.  3.  6.  0.  0.  0. 29.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: 0.6577460169792175
desired expected reward: 20.44120979309082



action possibilites: [-1. 11.] 
expected returns: [[60.901024]
 [60.031403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [ 8.  1. 10.  3.  6.  0.  0.  0. 29.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action 10.0
Learning step: 2.0770623683929443
desired expected reward: 26.374286651611328





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[51.65794 ]
 [60.030777]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
action values: 2 
buys: 1 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [ 8.  1. 10.  3.  6.  0.  0.  0. 29.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: 0.1852973997592926
desired expected reward: 61.08633041381836






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  8.] 
cards in discard: [ 8.  1. 10.  3.  6.  0.  0.  0. 29.  3. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 29. 10.  0.  6.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  8.] 
cards in discard: [ 8.  1. 10.  3.  6.  0.  0.  0. 29.  3. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 29. 10.  0.  6.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 29. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[-0.06645632]
 [-1.7798923 ]
 [-2.6009326 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10.  0.  6.] 
cards in discard: [10.  6.  6. 11.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 8.  1. 10.  3.  6.  0.  0.  0. 29.  3. 10.  0.  0. 10.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -2.076826810836792
desired expected reward: 57.95396041870117



action possibilites: [-1. 29.] 
expected returns: [[27.56641 ]
 [23.933939]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  6.  3.] 
cards in discard: [10.  6.  6. 11.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 8.  1. 10.  3.  6.  0.  0.  0. 29.  3. 10.  0.  0. 10.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action 10.0
Learning step: 2.669773578643799
desired expected reward: 0.06883454322814941





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.588146]
 [25.487898]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  6.  3.] 
cards in discard: [10.  6.  6. 11.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 8.  1. 10.  3.  6.  0.  0.  0. 29.  3. 10.  0.  0. 10.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: 1.0787882804870605
desired expected reward: 28.64519691467285






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [ 8.  1. 10.  3.  6.  0.  0.  0. 29.  3. 10.  0.  0. 10.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [ 8.  1. 10.  3.  6.  0.  0.  0. 29.  3. 10.  0.  0. 10.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  5.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [ 8.  1. 10.  3.  6.  0.  0.  0. 29.  3. 10.  0.  0. 10.  0.  3.  0.  8.
  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  4.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[99.52255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  4.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8] -> size -> 25 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: 1.914862871170044
desired expected reward: 27.402755737304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[85.15319 ]
 [92.67086 ]
 [89.14032 ]
 [95.90244 ]
 [90.602356]
 [87.89005 ]
 [96.1158  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  7.  4.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8] -> size -> 25 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -1.948341727256775
desired expected reward: 97.57421112060547



buy possibilites: [-1] 
expected returns: [[13.220551]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8] -> size -> 25 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0 -1  0  0 18  0] 
sum of rewards: 36 

action type: buy - action 11.0
Learning step: -2.697659730911255
desired expected reward: 93.20478057861328






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  0. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 29.  6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  8. 29.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8 11] -> size -> 36 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  8. 29.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8 11] -> size -> 36 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  8. 29.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8 11] -> size -> 36 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [ 1. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  8. 29.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8 11] -> size -> 36 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 3. 10. 11.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8. 29.] 
expected returns: [[68.61684 ]
 [64.412605]
 [69.27409 ]
 [66.98776 ]
 [66.97182 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  8. 29.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14  6 25 11  6 10  6 29  3 10  0 10
  0  6  3 29  0  0  3  3  0  0  8 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 10.  0.] 
adversary cards in discard: [ 1. 10. 29.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8 10] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: 1.8136732578277588
desired expected reward: 15.034223556518555



action possibilites: [-1] 
expected returns: [[77.64726]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 10.  0.] 
adversary cards in discard: [ 1. 10. 29.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8 10] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.570407509803772
desired expected reward: 73.77901458740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[61.134495]
 [83.22124 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 10.  0.] 
adversary cards in discard: [ 1. 10. 29.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8 10] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -0.795444667339325
desired expected reward: 76.85181427001953



buy possibilites: [-1] 
expected returns: [[50.13025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 10.  0.] 
adversary cards in discard: [ 1. 10. 29.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8 10] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: buy - action 0.0
Learning step: -2.0287938117980957
desired expected reward: 59.10569381713867






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 10.  0.] 
cards in discard: [ 1. 10. 29.  3.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0] -> size -> 35 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 10.] 
cards in discard: [ 1. 10. 29.  3.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 10  3  0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0
  8 10] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0] -> size -> 35 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1. 10. 29.  3.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0] -> size -> 35 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1. 10. 29.  3.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0] -> size -> 35 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0] -> size -> 35 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [14.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[ 6.275669 ]
 [-2.5826807]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  8. 10.  3.  0.] 
adversary cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.] 
adversary owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -1.5397323369979858
desired expected reward: 48.59051513671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[2.691424 ]
 [5.3499928]
 [4.0326085]
 [3.5304232]
 [7.4535522]
 [4.751551 ]
 [4.9728894]
 [1.0592198]
 [4.136198 ]
 [3.227675 ]
 [8.026965 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 29. 30. 20. 30.  8.  0.  8.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  8. 10.  3.  0.] 
adversary cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.] 
adversary owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: 0.707150936126709
desired expected reward: 6.982837200164795



buy possibilites: [-1] 
expected returns: [[33.81761]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  8. 10.  3.  0.] 
adversary cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.] 
adversary owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0 -1  0  0 32  0] 
sum of rewards: 49 

action type: buy - action 16.0
Learning step: 3.034374952316284
desired expected reward: 6.564805030822754






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  3.  0.] 
cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 25.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29. 16. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16] -> size -> 36 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 25.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29. 16. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16] -> size -> 36 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 25.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29. 16. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16] -> size -> 36 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 25.] 
adversary cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29. 16. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16] -> size -> 36 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  6.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[28.248768]
 [29.845924]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  0. 25.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29. 16. 14.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 6. 8. 0.] 
adversary cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.  0. 10.  3.  8.  3.  0.  0.] 
adversary owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -0.13276557624340057
desired expected reward: 33.684844970703125



action possibilites: [-1] 
expected returns: [[53.15775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0. 0.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29. 16. 14.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 6. 8. 0.] 
adversary cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.  0. 10.  3.  8.  3.  0.  0.] 
adversary owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 40 

action type: take_action - action 25.0
Learning step: 1.6919845342636108
desired expected reward: 31.773279190063477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[28.796518]
 [40.193493]
 [35.791435]
 [34.010426]
 [47.260933]
 [37.05702 ]
 [37.48625 ]
 [13.806524]
 [33.593582]
 [27.47544 ]
 [48.735115]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0. 0.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29. 16. 14.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 6. 8. 0.] 
adversary cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.  0. 10.  3.  8.  3.  0.  0.] 
adversary owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1
Learning step: 0.1066526398062706
desired expected reward: 53.264400482177734



buy possibilites: [-1] 
expected returns: [[43.951893]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0. 0.] 
cards in discard: [10.  6.  6. 11.  3.  3. 10.  3. 29.  0.  6.  3. 11.  0.  3.  3.  0.  0.
  0.  8. 10. 29. 16. 14.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [8. 0. 6. 8. 0.] 
adversary cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.  0. 10.  3.  8.  3.  0.  0.] 
adversary owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  20.   0.   0.  20.   0.   0.   0.   0.  -2.   0.   0.
  4.5  0. ] 
sum of rewards: 40.5 

action type: buy - action 10.0
Learning step: 1.3342386484146118
desired expected reward: 34.927818298339844






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [8. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 8. 0.] 
cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.  0. 10.  3.  8.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  0  6  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  6. 25.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16 10] -> size -> 37 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.  0. 10.  3.  8.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  6. 25.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16 10] -> size -> 37 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.  0. 10.  3.  8.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  6. 25.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16 10] -> size -> 37 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 1. 10. 29.  3.  0.  6.  0.  0. 10.  8.  0. 10.  3.  8.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  6. 25.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16 10] -> size -> 37 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3.  6. 25.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[60.69465 ]
 [59.086105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 25.  6.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -0.44547900557518005
desired expected reward: 43.506412506103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[51.850163]
 [60.178062]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 25.  6.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -1.3506921529769897
desired expected reward: 59.34395980834961



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  8.  3.  3.  0.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16 10] -> size -> 37 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 29. 30. 20. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  8.  3.  3.  0.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16 10] -> size -> 37 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 29. 30. 19. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  8.  3.  3.  0.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16 10] -> size -> 37 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  8.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[38.135044]
 [28.557516]
 [28.275484]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  3.  0.] 
cards in discard: [ 3.  6. 25.  6.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  6 25 11  6 10  6 29  3 10  0 10  0  6
  3 29  0  0  3  3  0  0  8 11  0 16 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 19. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  8.  8.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0.] 
adversary owned cards: [10  0  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -2.3597307205200195
desired expected reward: 57.818336486816406



action possibilites: [-1] 
expected returns: [[13.781691]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 3.  6. 25.  6.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 19. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  8.  8.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0.] 
adversary owned cards: [10  0  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: trash_cards_n_from_hand - action 3
Learning step: -0.1878267377614975
desired expected reward: 27.770469665527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.848993]
 [14.482943]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 3.  6. 25.  6.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 29. 30. 19. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  8.  8.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0.] 
adversary owned cards: [10  0  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: 0.5062514543533325
desired expected reward: 14.287941932678223






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 3. 29.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  8.  8.] 
cards in discard: [3. 0. 0. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0  3 10  0  0  6  8  0  3  8 29  3  1  8  0  8 10  0  0  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 19. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  3. 29. 14.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10] -> size -> 35 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.] 
cards in discard: [3. 0. 0. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  0 10  0  0  6  0  3  8 29  3  1  8  0  8 10  0  0  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 19. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  3. 29. 14.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10] -> size -> 35 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.] 
cards in discard: [3. 0. 0. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  0 10  0  0  6  0  3  8 29  3  1  8  0  8 10  0  0  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 29. 30. 19. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  3. 29. 14.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10] -> size -> 35 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  0.  3. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 14.] 
expected returns: [[19.549038 ]
 [14.773148 ]
 [15.252754 ]
 [10.6206875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 29. 14.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 19. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 10.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3  8 29  3  1  8  0  8 10  0  0  0  3] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: 0.040091611444950104
desired expected reward: 14.523030281066895





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.831327]
 [20.06427 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 29. 14.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 29. 30. 19. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 10.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3  8 29  3  1  8  0  8 10  0  0  0  3] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -0.17837142944335938
desired expected reward: 19.370670318603516



buy possibilites: [-1] 
expected returns: [[69.24503]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 29. 14.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 29. 30. 19. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 10.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3  8 29  3  1  8  0  8 10  0  0  0  3] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  10.   0.   0.   0. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: -23.0 

action type: buy - action 0.0
Learning step: -0.2835536003112793
desired expected reward: 13.547782897949219






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 10.  0.] 
cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3  8 29  3  1  8  0  8 10  0  0  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 19. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  6.  0. 11.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0] -> size -> 36 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 19. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  6.  0. 11.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0] -> size -> 36 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 29. 30. 19. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  6.  0. 11.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0] -> size -> 36 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  6.  0. 11.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  0.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[28.565937]
 [23.871113]
 [27.93998 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  0. 11.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.  3.  8.  0. 10.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -2.94931960105896
desired expected reward: 66.29571533203125



action possibilites: [-1. 11.] 
expected returns: [[42.242493]
 [40.215347]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.  0.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  6.  4.  9.  7.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.  3.  8.  0. 10.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 19 

action type: take_action - action 10.0
Learning step: 0.6898698806762695
desired expected reward: 24.56097412109375



action possibilites: [-1.] 
expected returns: [[15.801181]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  6.  4.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.  3.  8.  0. 10.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 40  0  0  0  0 -2  0  0 16  0] 
sum of rewards: 52 

action type: gain_card_n - action 6
Learning step: 1.6671589612960815
desired expected reward: 26.462570190429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[11.158964]
 [13.354053]
 [12.013022]
 [14.195882]
 [12.812834]
 [11.696238]
 [14.034476]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  6.  4.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.  3.  8.  0. 10.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 1.405090570449829
desired expected reward: 17.20627212524414






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  0. 10.] 
cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.  3.  8.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  6.  4.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  3.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  0. 10.] 
cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.  3.  8.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  6.  4.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  3.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0. 10.] 
cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.  3.  8.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  6.  4.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  3.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0. 10.] 
cards in discard: [ 3.  0.  0.  0.  0.  0.  8. 29.  3.  3.  8.  0. 10.  0. 23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  6.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  3.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 16.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[48.937572]
 [46.324146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  3.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  6.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: 0.2774146497249603
desired expected reward: 14.31190013885498





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[46.401623]
 [47.383453]
 [49.961075]
 [50.017776]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  3.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  6.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -1.4479742050170898
desired expected reward: 47.48961639404297



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [0. 3. 1. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  6.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  6.  0.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.  0.  0. 16.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  6.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  6.  0.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.  0.  0. 16.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 6.] 
cards in discard: [11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  5.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  6.  0.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.  0.  0. 16.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[46.679184]
 [38.545113]
 [44.674877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  6.  0.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.  0.  0. 16.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  5.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 23.] 
adversary cards in discard: [11.  0.  3.  1.  3.  6.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -1.60739266872406
desired expected reward: 48.41040802001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[30.921185]
 [35.791595]
 [35.110863]
 [44.6081  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11.  6.  0.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.  0.  0. 16.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  5.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 23.] 
adversary cards in discard: [11.  0.  3.  1.  3.  6.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -1.564702033996582
desired expected reward: 45.11448287963867



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 23.] 
cards in discard: [11.  0.  3.  1.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  5.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.  0.  0. 16.  3.  3.  0. 29. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [11.  0.  3.  1.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11] -> size -> 24 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  5.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.  0.  0. 16.  3.  3.  0. 29. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [11.  0.  3.  1.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11] -> size -> 24 
action values: 0 
buys: 2 
player value: 5 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  5.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.  0.  0. 16.  3.  3.  0. 29. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 3 


buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [11.  0.  3.  1.  3.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 29. 30. 18. 30.  8.  0.  7.  4.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.  0.  0. 16.  3.  3.  0. 29. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [11.  0.  3.  1.  3.  6. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 17. 30.  8.  0.  7.  4.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.  0.  0. 16.  3.  3.  0. 29. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-7.8455887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.  0.  0. 16.  3.  3.  0. 29. 11.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 17. 30.  8.  0.  7.  4.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  1.  3.  6. 11.  3. 23. 10.  0.  0.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -3.0069310665130615
desired expected reward: 41.601173400878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.418421 ]
 [-10.497761 ]
 [ -7.9122157]
 [-10.381778 ]
 [ -8.765738 ]
 [-11.379925 ]
 [-10.596205 ]
 [ -7.2333765]
 [ -7.3021903]
 [ -7.138237 ]
 [ -7.8455906]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.  0.  0. 16.  3.  3.  0. 29. 11.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 29. 30. 17. 30.  8.  0.  7.  4.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  1.  3.  6. 11.  3. 23. 10.  0.  0.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -0.40033388137817383
desired expected reward: -8.245922088623047



buy possibilites: [-1] 
expected returns: [[0.58842516]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  6. 25.  6.  0.  8.  3.  3.  0. 10.  0.  3. 29. 14. 29. 10. 11.  0.
  6.  0.  0.  0.  0. 16.  3.  3.  0. 29. 11.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 8. 29. 30. 17. 30.  8.  0.  7.  4.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  1.  3.  6. 11.  3. 23. 10.  0.  0.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0. -30.   0.   0.   0.  -3.   0.   0.
   0.   0.] 
sum of rewards: -45.0 

action type: buy - action 0.0
Learning step: -1.7158390283584595
desired expected reward: -12.134268760681152






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [11.  0.  3.  1.  3.  6. 11.  3. 23. 10.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 17. 30.  8.  0.  7.  4.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 6.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0] -> size -> 38 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [11.  0.  3.  1.  3.  6. 11.  3. 23. 10.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 29. 30. 17. 30.  8.  0.  7.  4.  4.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 6.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0] -> size -> 38 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [11.  0.  3.  1.  3.  6. 11.  3. 23. 10.  0.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 6.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0] -> size -> 38 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 6.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[21.37006 ]
 [19.899998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 3.  8. 29.  3. 10.] 
adversary cards in discard: [11.  0.  3.  1.  3.  6. 11.  3. 23. 10.  0.  0.  0.  0.  8.  8.  0.  0.
  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -0.16094553470611572
desired expected reward: 0.42747962474823





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.81538 ]
 [23.488682]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 3.  8. 29.  3. 10.] 
adversary cards in discard: [11.  0.  3.  1.  3.  6. 11.  3. 23. 10.  0.  0.  0.  0.  8.  8.  0.  0.
  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -1.162467360496521
desired expected reward: 20.207595825195312



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 29.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29.  3. 10.] 
cards in discard: [11.  0.  3.  1.  3.  6. 11.  3. 23. 10.  0.  0.  0.  0.  8.  8.  0.  0.
  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0] -> size -> 38 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 29.  3. 10.] 
cards in discard: [11.  0.  3.  1.  3.  6. 11.  3. 23. 10.  0.  0.  0.  0.  8.  8.  0.  0.
  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0] -> size -> 38 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 29.  3. 10.] 
cards in discard: [11.  0.  3.  1.  3.  6. 11.  3. 23. 10.  0.  0.  0.  0.  8.  8.  0.  0.
  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0] -> size -> 38 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[58.864025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 6.  3.  0.  3. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8  0] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -0.44999369978904724
desired expected reward: 23.038692474365234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[58.677456]
 [62.3731  ]
 [60.54784 ]
 [60.16302 ]
 [64.425934]
 [61.582344]
 [61.83912 ]
 [54.786076]
 [60.42    ]
 [58.85386 ]
 [64.91412 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 6.  3.  0.  3. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8  0] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -2.1520941257476807
desired expected reward: 56.71192932128906



buy possibilites: [-1] 
expected returns: [[81.07174]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8  0] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0  -4   0   0  32   0] 
sum of rewards: 16 

action type: buy - action 29.0
Learning step: -0.4678415358066559
desired expected reward: 61.37126922607422






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [10.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  6. 25.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29] -> size -> 39 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  6. 25.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29] -> size -> 39 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  6. 25.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29] -> size -> 39 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11. 29.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[32.249695]
 [31.170189]
 [26.678764]
 [34.717976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  6. 25.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [10.  3.  3.  0. 10.  8.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8  0] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -3.931474447250366
desired expected reward: 77.14026641845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.906685]
 [28.338951]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29.  6. 25.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [10.  3.  3.  0. 10.  8.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8  0] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -1.6541019678115845
desired expected reward: 30.5955810546875



buy possibilites: [-1] 
expected returns: [[41.533504]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29.  6. 25.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [10.  3.  3.  0. 10.  8.] 
adversary owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8  0] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0. -30.   0.   0.   0.  -5.   0.   0.
   0.   0.] 
sum of rewards: -47.0 

action type: buy - action 0.0
Learning step: -2.339015245437622
desired expected reward: 16.567676544189453






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 0.] 
cards in discard: [10.  3.  3.  0. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  6  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11
 11  3  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29. 14.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0] -> size -> 40 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  3.  3.  0. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29. 14.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0] -> size -> 40 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  3.  3.  0. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29. 14.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0] -> size -> 40 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  3.  3.  0. 10.  8. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29. 14.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0] -> size -> 40 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0. 11.  0. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 14.] 
expected returns: [[69.72171 ]
 [67.51481 ]
 [60.43139 ]
 [51.331596]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29. 14.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 1.  3. 29. 23. 11.] 
adversary cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -1.7334845066070557
desired expected reward: 39.800018310546875



action possibilites: [-1] 
expected returns: [[17.043346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 14.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 1.  3. 29. 23. 11.] 
adversary cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0  -6   0   0   9   0] 
sum of rewards: 1 

action type: gain_card_n - action 1
Learning step: -2.687068462371826
desired expected reward: 59.72380447387695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[11.865334]
 [12.823681]
 [13.197176]
 [14.973331]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 14.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 1.  3. 29. 23. 11.] 
adversary cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1
Learning step: -0.6448142528533936
desired expected reward: 16.39853286743164



buy possibilites: [-1] 
expected returns: [[69.99669]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 14.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 28. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 1.  3. 29. 23. 11.] 
adversary cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -20.   0.   0.  20. -30.   0.   0.   0.  -7.   0.   0.
   0.   0.] 
sum of rewards: -39.0 

action type: buy - action 0.0
Learning step: -0.9683412909507751
desired expected reward: 10.896992683410645






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 1.  3. 29. 23. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 23. 11.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29. 23. 11.] 
cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 29. 11. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29. 11. 11.] 
cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10] -> size -> 28 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 5. 28. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 11.  3.] 
cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10] -> size -> 28 
action values: 1 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 17. 30.  8.  0.  7.  4.  3.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3.] 
cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23. 29. 11.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 17. 30.  8.  0.  7.  4.  2.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.] 
cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23. 29. 11.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8] -> size -> 29 
action values: 0 
buys: 2 
player value: 4 
card supply: [ 5. 28. 30. 17. 30.  8.  0.  7.  4.  2.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
adversary victory points: 3
player victory points: 5 


buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.] 
cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23. 29. 11.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  4.  2.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.] 
cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.  8.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23. 29. 11.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[115.570015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 10.  0.] 
adversary cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.  8.  0.  8. 23. 29. 11.
  1. 11.  3.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8] -> size -> 31 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -1.9995092153549194
desired expected reward: 67.99717712402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 99.49923 ]
 [104.604004]
 [106.14197 ]
 [113.92291 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 10.  0.] 
adversary cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.  8.  0.  8. 23. 29. 11.
  1. 11.  3.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8] -> size -> 31 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -4.447656154632568
desired expected reward: 111.12236022949219



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.  0.] 
cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.  8.  0.  8. 23. 29. 11.
  1. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8. 10.  0. 29. 10.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10.  0.] 
cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.  8.  0.  8. 23. 29. 11.
  1. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8. 10.  0. 29. 10.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10.  0.] 
cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.  8.  0.  8. 23. 29. 11.
  1. 11.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8. 10.  0. 29. 10.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 8. 10.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29. 10.] 
expected returns: [[17.979454]
 [14.435333]
 [13.108149]
 [14.423677]
 [13.108149]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 29. 10.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.  3.  0.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.  8.  0.  8. 23. 29. 11.
  1. 11.  3.  3.  0.  8.  0. 10.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -6.948207855224609
desired expected reward: 106.97470092773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.266483]
 [17.979454]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0. 29. 10.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.  3.  0.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.  8.  0.  8. 23. 29. 11.
  1. 11.  3.  3.  0.  8.  0. 10.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -2.15083384513855
desired expected reward: 15.828627586364746



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.  8.  0.  8. 23. 29. 11.
  1. 11.  3.  3.  0.  8.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [16.  0.  3.  6.  6.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.  3.  0.  3.  3.  0.  8. 10.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  3.  0. 10.  8. 10.  8.  0.  0.  0.  3.  8.  0.  8. 23. 29. 11.
  1. 11.  3.  3.  0.  8.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [16.  0.  3.  6.  6.] 
adversary cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.  3.  0.  3.  3.  0.  8. 10.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16.  0.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[19.853315]
 [16.948547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  6.  6.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.  3.  0.  3.  3.  0.  8. 10.  0. 29. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -2.0766777992248535
desired expected reward: 15.90278434753418





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.071014]
 [19.853315]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  6.  6.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.  3.  0.  3.  3.  0.  8. 10.  0. 29. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -2.1861443519592285
desired expected reward: 17.667171478271484



buy possibilites: [-1] 
expected returns: [[85.90074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  6.  6.] 
cards in discard: [ 6.  3.  0.  3. 10. 29.  3.  0.  0.  0.  0.  0.  0. 11. 29.  6. 25.  1.
  0. 11.  0.  0. 29. 14.  3.  0.  3.  3.  0.  8. 10.  0. 29. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -30.   0.   0.   0. -30.   0.   0.   0.  -8.   0.   0.
   0.   0.] 
sum of rewards: -70.0 

action type: buy - action 0.0
Learning step: -2.3207833766937256
desired expected reward: 12.75021743774414






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[14.795397]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 1.  3. 10.  0.  0.] 
adversary cards in discard: [10.  0.  0. 10. 10.  3.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -5.562140941619873
desired expected reward: 80.3386001586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[10.940775 ]
 [13.21624  ]
 [12.233505 ]
 [11.976526 ]
 [14.23871  ]
 [12.780029 ]
 [12.9657135]
 [ 8.383984 ]
 [12.028358 ]
 [10.986254 ]
 [14.718536 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 1.  3. 10.  0.  0.] 
adversary cards in discard: [10.  0.  0. 10. 10.  3.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -2.050510883331299
desired expected reward: 12.74488639831543



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 1.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  0.  0.] 
cards in discard: [10.  0.  0. 10. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3. 11.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 11.] 
cards in discard: [10.  0.  0. 10. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 16. 30.  8.  0.  7.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3. 11.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [10.  0.  0. 10. 10.  3. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 16. 30.  8.  0.  6.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3. 11.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [10.  0.  0. 10. 10.  3. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 28. 30. 16. 30.  8.  0.  6.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3. 11.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [10.  0.  0. 10. 10.  3. 16.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 28. 30. 15. 30.  8.  0.  6.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3. 11.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [10.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[5.5712075]
 [2.9145179]
 [3.3211303]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3. 11.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 15. 30.  8.  0.  6.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 8.] 
adversary cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1.0
Learning step: -2.7380568981170654
desired expected reward: 11.980475425720215



action possibilites: [-1. 11. 10.] 
expected returns: [[16.916409]
 [14.926987]
 [13.420742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11. 10.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 15. 30.  8.  0.  6.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 8.] 
adversary cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action 10.0
Learning step: -0.8822875022888184
desired expected reward: 2.032236099243164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[14.030155 ]
 [15.3361435]
 [14.685595 ]
 [18.386335 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11. 10.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 15. 30.  8.  0.  6.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 8.] 
adversary cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -1.5787856578826904
desired expected reward: 15.337624549865723



buy possibilites: [-1] 
expected returns: [[75.50231]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11. 10.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 28. 30. 15. 30.  8.  0.  6.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 8.] 
adversary cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -40.   0.   0.  20. -30.   0.   0.   0.  -9.   0.   0.
   0.   0.] 
sum of rewards: -61.0 

action type: buy - action 0.0
Learning step: -2.0527055263519287
desired expected reward: 11.977445602416992






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 8.] 
cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 15. 30.  8.  0.  6.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10.  3. 29. 11.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0. 10.  0.  0.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0] -> size -> 44 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0. 8.] 
cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 28. 30. 15. 30.  8.  0.  6.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10.  3. 29. 11.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0. 10.  0.  0.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0] -> size -> 44 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  3. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[124.10352 ]
 [117.44823 ]
 [118.829216]
 [123.106316]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29. 11.  0.] 
cards in discard: [ 0.  3.  0.  0.  0.  0. 10.  0.  0.  3. 11. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 15. 30.  8.  0.  6.  4.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0. 11.] 
adversary cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.  8.  0.  8.  0.
  8.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -3.1370880603790283
desired expected reward: 72.36522674560547



action possibilites: [-1] 
expected returns: [[80.6937]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.  0.] 
cards in discard: [ 0.  3.  0.  0.  0.  0. 10.  0.  0.  3. 11. 10. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 15. 30.  8.  0.  6.  3.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0. 11.] 
adversary cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.  8.  0.  8.  0.
  8.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0 -10   0   0   9   0] 
sum of rewards: -23 

action type: gain_card_n - action 4
Learning step: -4.735555171966553
desired expected reward: 103.28770446777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[65.90715]
 [78.04278]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 29.  0.] 
cards in discard: [ 0.  3.  0.  0.  0.  0. 10.  0.  0.  3. 11. 10. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 28. 30. 15. 30.  8.  0.  6.  3.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0. 11.] 
adversary cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.  8.  0.  8.  0.
  8.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1
Learning step: -3.4806790351867676
desired expected reward: 77.21302032470703



buy possibilites: [-1] 
expected returns: [[57.149338]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 29.  0.] 
cards in discard: [ 0.  3.  0.  0.  0.  0. 10.  0.  0.  3. 11. 10. 11.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0 11  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 28. 30. 15. 30.  8.  0.  6.  3.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0. 11.] 
adversary cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.  8.  0.  8.  0.
  8.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -40.   0.   0.  20. -30.   0.   0.   0. -11.   0.   0.
   0.   0.] 
sum of rewards: -63.0 

action type: buy - action 0.0
Learning step: -5.15949821472168
desired expected reward: 60.74766540527344






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 3. 29.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0. 11.] 
cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.  8.  0.  8.  0.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 15. 30.  8.  0.  6.  3.  1.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 29.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0. 10.  0.  0.  3. 11. 10. 11.  0. 11. 10.  3. 29.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0 11  0] -> size -> 46 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.] 
cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.  8.  0.  8.  0.
  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 15. 30.  8.  0.  6.  3.  0.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 29.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0. 10.  0.  0.  3. 11. 10. 11.  0. 11. 10.  3. 29.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0 11  0] -> size -> 46 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.] 
cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.  8.  0.  8.  0.
  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 28. 30. 15. 30.  8.  0.  6.  3.  0.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 29.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0. 10.  0.  0.  3. 11. 10. 11.  0. 11. 10.  3. 29.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0 11  0] -> size -> 46 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.] 
cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.  8.  0.  8.  0.
  8.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3  8  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 14. 30.  8.  0.  6.  3.  0.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 29.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0. 10.  0.  0.  3. 11. 10. 11.  0. 11. 10.  3. 29.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0 11  0] -> size -> 46 
adversary victory points: 3
player victory points: 8 





Player: 0 
cards in hand: [ 0.  6.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[82.1509  ]
 [79.008156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 29.  0.] 
cards in discard: [ 0.  3.  0.  0.  0.  0. 10.  0.  0.  3. 11. 10. 11.  0. 11. 10.  3. 29.
  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0 11  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 14. 30.  8.  0.  6.  3.  0.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.  8.  0.  8.  0.
  8.  8.  3. 11.  3. 29.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3  8  3] -> size -> 36 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: -3.6354751586914062
desired expected reward: 53.51386260986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[74.85451 ]
 [79.36959 ]
 [77.39098 ]
 [80.764946]
 [76.386765]
 [80.062126]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 29.  0.] 
cards in discard: [ 0.  3.  0.  0.  0.  0. 10.  0.  0.  3. 11. 10. 11.  0. 11. 10.  3. 29.
  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0 11  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 28. 30. 14. 30.  8.  0.  6.  3.  0.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.  8.  0.  8.  0.
  8.  8.  3. 11.  3. 29.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3  8  3] -> size -> 36 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: -4.93447208404541
desired expected reward: 77.21643829345703



Player 1 won the game! 



Player 0 bought cards:
Copper: 12 
Silver: 0 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 1 
Workshop: 3 
Chapel: 1 
Witch: 1 
Poacher: 2 
Militia: 1 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  6.  0. 29.  0.] 
cards in discard: [ 0.  3.  0.  0.  0.  0. 10.  0.  0.  3. 11. 10. 11.  0. 11. 10.  3. 29.
  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  6 25 11  6  6 29  3 10  0 10  0  6  3 29
  0  0  3  3  0  0  8 11  0 16 10  0 29  0 29  0  1  0  0  0 11  0 10] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 14. 30.  8.  0.  6.  3.  0.  9.  5.  9.  9.  0. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0. 10. 10.  3. 16.  3. 10. 11.  1.  3.  0.  0.  8.  0.  8.  0.
  8.  8.  3. 11.  3. 29.  0.  0.] 
adversary owned cards: [10  0  0  0 10  0  0  0  3 29  3  1  8  0  8 10  0  0  0  3  3 23 11 11
  3  8  0 10  8  0  8  3 16  3  8  3] -> size -> 36 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3  -50    0    0    0    0    0    0    0  -12    0    0
    9    0] 
sum of rewards: -555 

action type: buy - action 10.0
Learning step: -31.569339752197266
desired expected reward: 44.81743240356445



