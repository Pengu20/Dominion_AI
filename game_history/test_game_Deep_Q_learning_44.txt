 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.174305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -390        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000395 

action type: buy - action -1.0
Learning step: -120015.078125
desired expected reward: -120033.109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[13.785227]
 [19.7127  ]
 [ 6.259825]
 [19.487247]
 [18.814213]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.707761764526367



buy possibilites: [-1] 
expected returns: [[18.146852]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 19.712692260742188






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.929918]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.146852493286133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[16.765358 ]
 [24.281889 ]
 [22.257359 ]
 [11.738712 ]
 [ 9.840431 ]
 [21.251501 ]
 [27.776052 ]
 [22.12208  ]
 [35.434547 ]
 [29.194836 ]
 [14.9234295]
 [21.470308 ]
 [20.097542 ]
 [14.098227 ]
 [22.340881 ]
 [19.998539 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.394817352294922



buy possibilites: [-1] 
expected returns: [[19.215088]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  0.  3.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 35.43455123901367






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.731737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.215087890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.555334]
 [26.240479]
 [24.453596]
 [13.502001]
 [23.569248]
 [29.26146 ]
 [24.272278]
 [30.47873 ]
 [18.00095 ]
 [22.485394]
 [24.587017]
 [23.10936 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.402332305908203



buy possibilites: [-1] 
expected returns: [[32.836544]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 30.478729248046875






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29] -> size -> 13 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[26.428022]
 [38.974583]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 25.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 11.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.836544036865234



action possibilites: [-1] 
expected returns: [[44.07321]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 11.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.20853805541992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[38.008083]
 [45.10244 ]
 [43.249542]
 [31.354343]
 [48.27551 ]
 [43.03405 ]
 [41.181152]
 [42.412712]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 11.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.073211669921875



buy possibilites: [-1] 
expected returns: [[28.206812]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 11.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 48.27550506591797






Player: 1 
cards in hand: [ 3.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 11.] 
cards in discard: [1. 0. 0. 0. 3. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 11.] 
cards in discard: [1. 0. 0. 0. 3. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 11.] 
cards in discard: [1. 0. 0. 0. 3. 3. 6. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[14.3741  ]
 [19.862106]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.206811904907227



action possibilites: [-1] 
expected returns: [[12.566555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 22.344539642333984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[10.806154]
 [17.959482]
 [16.08894 ]
 [ 4.087591]
 [15.136406]
 [21.234686]
 [15.881809]
 [22.67781 ]
 [ 9.144632]
 [14.011265]
 [16.29796 ]
 [15.551746]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.56655502319336



buy possibilites: [-1] 
expected returns: [[26.363838]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 22.677810668945312






Player: 1 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  8.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[52.830326]
 [62.361004]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  8.  8. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [14. 14. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.36383819580078



action possibilites: [-1. 25.] 
expected returns: [[34.305317]
 [44.60895 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 25.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  8.  8. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [14. 14. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 61.1894645690918



action possibilites: [-1] 
expected returns: [[58.952053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0. 3.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  8.  8. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [14. 14. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 44.60894012451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[53.888927]
 [65.747375]
 [62.664516]
 [43.60656 ]
 [60.93095 ]
 [71.271614]
 [62.326496]
 [73.7087  ]
 [51.38428 ]
 [59.24364 ]
 [63.24274 ]
 [62.4743  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0. 3.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  8.  8. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [14. 14. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.95205307006836



buy possibilites: [-1] 
expected returns: [[105.66056]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0. 3.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  7.  8. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [14. 14. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 73.70870971679688






Player: 1 
cards in hand: [6. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [14. 14. 11.  0.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  7.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [14. 14. 11.  0.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  7.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [14. 14. 11.  0.  0.  0.  0.  6. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14  6 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 6.9952683]
 [13.027264 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [14. 14. 11.  0.  0.  0.  0.  6. 29.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14  6 29] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.66056060791016



action possibilites: [-1.] 
expected returns: [[15.030067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [14. 14. 11.  0.  0.  0.  0.  6. 29.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14  6 29] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 12.533531188964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[10.564283 ]
 [16.634293 ]
 [15.0532   ]
 [ 4.9076486]
 [14.241417 ]
 [19.355871 ]
 [14.866955 ]
 [20.52032  ]
 [ 9.191811 ]
 [13.285862 ]
 [15.2620945]
 [14.471773 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [14. 14. 11.  0.  0.  0.  0.  6. 29.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14  6 29] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.030067443847656



buy possibilites: [-1] 
expected returns: [[39.65266]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  5.  8. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [14. 14. 11.  0.  0.  0.  0.  6. 29.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14  6 29] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 20.52032470703125






Player: 1 
cards in hand: [3. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 8.] 
cards in discard: [14. 14. 11.  0.  0.  0.  0.  6. 29.  6.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1  6  8 14 14  6 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  5.  8. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11. 10. 29.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [14. 14. 11.  0.  0.  0.  0.  6. 29.  6.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  5.  8. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11. 10. 29.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [14. 14. 11.  0.  0.  0.  0.  6. 29.  6.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  5.  8. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11. 10. 29.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [14. 14. 11.  0.  0.  0.  0.  6. 29.  6.  0.  3.  0.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  5.  8. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11. 10. 29.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29. 11. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 29.] 
expected returns: [[108.70957 ]
 [116.972885]
 [115.25703 ]
 [106.75995 ]
 [116.972885]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10. 29.  3.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  5.  8. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.65266036987305



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[56.906456]
 [62.865673]
 [55.206364]
 [64.32568 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  3.  3.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  5.  8. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 115.84406280517578



action possibilites: [-1. 11. 10.] 
expected returns: [[84.37947 ]
 [91.68957 ]
 [82.718575]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  3.  0.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  5.  8. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 64.32567596435547



action possibilites: [-1] 
expected returns: [[67.5539]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 172 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 94.0264663696289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[61.136127]
 [70.013054]
 [67.66083 ]
 [52.7553  ]
 [74.00645 ]
 [67.48174 ]
 [65.12951 ]
 [66.20475 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  8.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.55390167236328



buy possibilites: [-1] 
expected returns: [[75.25247]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  7.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 199 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 74.00645446777344






Player: 1 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  7.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11] -> size -> 20 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  7.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11] -> size -> 20 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  6.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11] -> size -> 20 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[16.263924]
 [14.470413]
 [26.367584]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  6.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 11. 14. 14.] 
adversary cards in discard: [11.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11] -> size -> 19 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.25247192382812



action possibilites: [-1] 
expected returns: [[53.58369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 29. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  6.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 11. 14. 14.] 
adversary cards in discard: [11.  3.  0.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11  6] -> size -> 20 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 25.513832092285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[48.614677]
 [56.669483]
 [54.60204 ]
 [41.265156]
 [60.201073]
 [54.313145]
 [52.245705]
 [54.872864]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 29. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  6.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 11. 14. 14.] 
adversary cards in discard: [11.  3.  0.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11  6] -> size -> 20 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.58369064331055



buy possibilites: [-1] 
expected returns: [[80.18593]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 29. 10.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 11. 14. 14.] 
adversary cards in discard: [11.  3.  0.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11  6] -> size -> 20 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 60.20106887817383






Player: 1 
cards in hand: [ 0.  6. 11. 14. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11. 14. 14.] 
cards in discard: [11.  3.  0.  0.  1.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3. 11.  0.  3.] 
adversary cards in discard: [11. 25. 10.  0.  0.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11] -> size -> 21 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11. 14. 14.] 
cards in discard: [11.  3.  0.  0.  1.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3. 11.  0.  3.] 
adversary cards in discard: [11. 25. 10.  0.  0.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11] -> size -> 21 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [29.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[77.6141 ]
 [85.79931]
 [84.16135]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  0.  3.] 
cards in discard: [11. 25. 10.  0.  0.  0. 29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [11.  3.  0.  0.  1.  0.  6.  0.  6. 11. 14. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.18592834472656



action possibilites: [-1. 11. 29.] 
expected returns: [[132.28023]
 [139.05473]
 [141.00737]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3. 29.] 
cards in discard: [11. 25. 10.  0.  0.  0. 29. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [11.  3.  0.  0.  1.  0.  6.  0.  6. 11. 14. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 85.79656219482422



action possibilites: [-1. 11. 29.] 
expected returns: [[87.79395 ]
 [95.010155]
 [97.05878 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3. 29.] 
cards in discard: [11. 25. 10.  0.  0.  0. 29. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [11.  3.  0.  0.  1.  0.  6.  0.  6. 11. 14. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 141.00738525390625



action possibilites: [-1. 11.] 
expected returns: [[61.526043]
 [67.93392 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.  3.] 
cards in discard: [11. 25. 10.  0.  0.  0. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [11.  3.  0.  0.  1.  0.  6.  0.  6. 11. 14. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 97.05878448486328



action possibilites: [-1] 
expected returns: [[86.003975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [11. 25. 10.  0.  0.  0. 29. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  5.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [11.  3.  0.  0.  1.  0.  6.  0.  6. 11. 14. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 70.57391357421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[78.611885]
 [86.83205 ]
 [84.71764 ]
 [71.15136 ]
 [83.51139 ]
 [90.54094 ]
 [84.435196]
 [92.190056]
 [76.95596 ]
 [82.32078 ]
 [85.176125]
 [85.15729 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [11. 25. 10.  0.  0.  0. 29. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  5.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [11.  3.  0.  0.  1.  0.  6.  0.  6. 11. 14. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.00397491455078



buy possibilites: [-1] 
expected returns: [[57.54462]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [11. 25. 10.  0.  0.  0. 29. 10. 10. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  4.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [11.  3.  0.  0.  1.  0.  6.  0.  6. 11. 14. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 323 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 92.1900634765625






Player: 1 
cards in hand: [ 3.  0. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  8.  0.] 
cards in discard: [11.  3.  0.  0.  1.  0.  6.  0.  6. 11. 14. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  6  8 14 14  6 29  0 11  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  4.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [11. 25. 10.  0.  0.  0. 29. 10. 10. 29. 29. 29. 29. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29] -> size -> 23 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [11.  3.  0.  0.  1.  0.  6.  0.  6. 11. 14. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  4.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [11. 25. 10.  0.  0.  0. 29. 10. 10. 29. 29. 29. 29. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29] -> size -> 23 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11.  3.  0.  0.  1.  0.  6.  0.  6. 11. 14. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  4.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [11. 25. 10.  0.  0.  0. 29. 10. 10. 29. 29. 29. 29. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29] -> size -> 23 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[86.915665]
 [91.384026]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [11. 25. 10.  0.  0.  0. 29. 10. 10. 29. 29. 29. 29. 11.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  4.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.544620513916016



action possibilites: [-1] 
expected returns: [[45.371593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11. 25. 10.  0.  0.  0. 29. 10. 10. 29. 29. 29. 29. 11.  3.  0.  3.  3.
 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  4.  8. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 93.1364517211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[38.296574]
 [44.773014]
 [43.04498 ]
 [33.01644 ]
 [47.846664]
 [42.82006 ]
 [41.0945  ]
 [43.53268 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11. 25. 10.  0.  0.  0. 29. 10. 10. 29. 29. 29. 29. 11.  3.  0.  3.  3.
 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  5.  9.  9.  4.  8. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.3715934753418



buy possibilites: [-1] 
expected returns: [[7.363378]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11. 25. 10.  0.  0.  0. 29. 10. 10. 29. 29. 29. 29. 11.  3.  0.  3.  3.
 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  4.  9.  9.  4.  8. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 47.84668731689453






Player: 1 
cards in hand: [3. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  4.  9.  9.  4.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11] -> size -> 25 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  4.  9.  9.  4.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11] -> size -> 25 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[45.09084 ]
 [48.947666]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  4.  9.  9.  4.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 1. 11.  8.  0. 14.] 
adversary cards in discard: [3. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.363378047943115



action possibilites: [-1] 
expected returns: [[27.550934]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  4.  9.  9.  4.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 11.  8.  0. 14.] 
adversary cards in discard: [3. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 49.42464065551758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.670866]
 [31.294888]
 [29.613132]
 [18.926579]
 [34.278072]
 [29.335808]
 [27.654047]
 [30.326725]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  4.  9.  9.  4.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 11.  8.  0. 14.] 
adversary cards in discard: [3. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.550933837890625



buy possibilites: [-1] 
expected returns: [[21.253006]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  3.  9.  9.  4.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 11.  8.  0. 14.] 
adversary cards in discard: [3. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 34.27806854248047






Player: 1 
cards in hand: [ 1. 11.  8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  8.  0. 14.] 
cards in discard: [3. 0. 6. 0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  3.  9.  9.  4.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 10.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11] -> size -> 27 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0. 14.] 
cards in discard: [ 3.  0.  6.  0.  3. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  3.  9.  9.  3.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 10.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11] -> size -> 27 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0. 14.] 
cards in discard: [ 3.  0.  6.  0.  3. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  3.  9.  9.  3.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 10.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11] -> size -> 27 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0. 14.] 
cards in discard: [ 3.  0.  6.  0.  3. 29. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  2.  9.  9.  3.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 10.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11] -> size -> 27 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10. 29. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[26.635723]
 [23.950733]
 [31.07737 ]
 [23.950733]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  0.  3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  2.  9.  9.  3.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 14.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3. 29. 11. 11.  1.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.253005981445312



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[ 5.404323 ]
 [ 3.5903192]
 [ 3.5903192]
 [11.069679 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3. 29.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  2.  9.  9.  3.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 14.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3. 29. 11. 11.  1.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.512615203857422



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[23.701818]
 [22.067131]
 [22.067131]
 [29.843182]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3. 29.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  2.  9.  9.  3.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 14.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3. 29. 11. 11.  1.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 11.069683074951172



action possibilites: [-1. 10. 10.] 
expected returns: [[12.696785]
 [11.244688]
 [11.244688]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3.  3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  2.  9.  9.  3.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 14.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3. 29. 11. 11.  1.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.84317398071289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 6.551864  ]
 [14.392326  ]
 [12.144711  ]
 [ 0.20250249]
 [10.943426  ]
 [18.230595  ]
 [11.949312  ]
 [19.768452  ]
 [ 4.9226804 ]
 [ 9.854961  ]
 [12.4408245 ]
 [11.3070545 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  3.  3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  2.  9.  9.  3.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 14.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3. 29. 11. 11.  1.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.696788787841797



buy possibilites: [-1] 
expected returns: [[53.08529]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  3.  3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  2.  9.  9.  2.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 14.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3. 29. 11. 11.  1.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 303 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 19.768451690673828






Player: 1 
cards in hand: [ 3.  0.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 14.  0.] 
cards in discard: [ 3.  0.  6.  0.  3. 29. 11. 11.  1.  8.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  2.  9.  9.  2.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 25. 10. 11. 29.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 29. 29. 29. 29. 10. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29] -> size -> 28 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 14.  0.] 
cards in discard: [ 3.  0.  6.  0.  3. 29. 11. 11.  1.  8.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  2.  9.  9.  2.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 25. 10. 11. 29.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 29. 29. 29. 29. 10. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29] -> size -> 28 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 14.  0.] 
cards in discard: [ 3.  0.  6.  0.  3. 29. 11. 11.  1.  8.  0. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  2.  9.  9.  2.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 25. 10. 11. 29.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 29. 29. 29. 29. 10. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29] -> size -> 28 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11. 29.] 
expected returns: [[12.800297]
 [22.288048]
 [10.238316]
 [16.728819]
 [18.084959]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 10. 11. 29.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 29. 29. 29. 29. 10. 10.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  2.  9.  9.  2.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0] -> size -> 21 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.085289001464844



action possibilites: [-1] 
expected returns: [[19.530159]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 29. 10.  3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 29. 29. 29. 29. 10. 10.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  2.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.28805923461914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.779522]
 [ 9.404022]
 [21.160347]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 29. 10.  3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 29. 29. 29. 29. 10. 10.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  2.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.53015899658203






Player: 1 
cards in hand: [ 3.  0.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  6.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  2.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11. 11.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 29. 29. 29. 29. 10. 10.  0.  3.  3. 25.  0.
 10. 11. 29. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29] -> size -> 28 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  6.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  2.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11. 11.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 29. 29. 29. 29. 10. 10.  0.  3.  3. 25.  0.
 10. 11. 29. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29] -> size -> 28 
adversary victory points: 4
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[43.64596 ]
 [48.406414]
 [46.762627]
 [46.762627]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11. 11.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 29. 29. 29. 29. 10. 10.  0.  3.  3. 25.  0.
 10. 11. 29. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  2.  8. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0. 14.  6.  3.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 21.160350799560547



action possibilites: [-1. 11. 11.] 
expected returns: [[18.540956]
 [23.615639]
 [23.615639]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  2.  8. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0. 14.  6.  3.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 48.406429290771484



action possibilites: [-1] 
expected returns: [[43.25085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  2.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0. 14.  6.  3.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 212 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 24.959951400756836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[38.88533 ]
 [45.222927]
 [43.618786]
 [33.23074 ]
 [42.73149 ]
 [48.077656]
 [43.344196]
 [49.46336 ]
 [37.675453]
 [41.74005 ]
 [44.013054]
 [44.4826  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  2.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0. 14.  6.  3.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.250850677490234



buy possibilites: [-1] 
expected returns: [[28.678785]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [10. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0. 14.  6.  3.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 313 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 49.463356018066406






Player: 1 
cards in hand: [11.  0. 14.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 14.  6.  3.] 
cards in discard: [ 6.  3.  0.  0. 11.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 29.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  3.] 
cards in discard: [ 6.  3.  0.  0. 11.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [29.  3. 29.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  3.] 
cards in discard: [ 6.  3.  0.  0. 11.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [29.  3. 29.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  3.] 
cards in discard: [ 6.  3.  0.  0. 11.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [29.  3. 29.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[23.497238]
 [28.398567]
 [28.398567]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.] 
cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [14.  6.  0.  0.  1.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0] -> size -> 23 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0 733   0] 
sum of rewards: 878 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 124.28544616699219



action possibilites: [-1. 29. 10.] 
expected returns: [[45.353146]
 [54.428375]
 [44.504063]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10.] 
cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [14.  6.  0.  0.  1.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0] -> size -> 23 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.398574829101562



action possibilites: [-1. 10.] 
expected returns: [[20.819101]
 [18.597767]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.] 
cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [14.  6.  0.  0.  1.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0] -> size -> 23 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 54.42838668823242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.959412]
 [20.581932]
 [10.646381]
 [20.336536]
 [20.824188]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.] 
cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
action values: 1 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [14.  6.  0.  0.  1.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0] -> size -> 23 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 20.819101333618164






Player: 1 
cards in hand: [14.  6.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.  0.  1.] 
cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [10. 10.  3. 11. 29.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.  0.  1.] 
cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [10. 10.  3. 11. 29.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.  0.  1.] 
cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [10. 10.  3. 11. 29.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10. 10.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 29.] 
expected returns: [[ 6.7191787]
 [ 3.6184192]
 [ 3.6184192]
 [ 9.281441 ]
 [10.55245  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 11. 29.] 
cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11. 29.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.  0. 14.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0] -> size -> 24 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.82418441772461



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[19.042667]
 [15.862232]
 [15.862232]
 [23.839458]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 11.  0.] 
cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11. 29.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.  0. 14.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0] -> size -> 24 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 10.552446365356445



action possibilites: [-1] 
expected returns: [[-9.609259]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.] 
cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  3. 10. 10.] 
adversary cards in hand: [11. 29.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.  0. 14.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0] -> size -> 24 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 212 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 25.878570556640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-11.005909]
 [ -8.815334]
 [-13.829456]
 [ -8.905796]
 [ -9.180458]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.] 
cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  3. 10. 10.] 
adversary cards in hand: [11. 29.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.  0. 14.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0] -> size -> 24 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.609258651733398



buy possibilites: [-1] 
expected returns: [[3.9756842]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.] 
cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  3. 10. 10.] 
adversary cards in hand: [11. 29.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.  0. 14.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0] -> size -> 24 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 231 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -8.81533432006836






Player: 1 
cards in hand: [11. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3.  0.  0.] 
cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.  0. 14.  6.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 25. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3. 10.  3. 29.
 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3] -> size -> 32 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  3.  0.  0.] 
cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.  0. 14.  6.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 25. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3. 10.  3. 29.
 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3] -> size -> 32 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  3.  0.  0.] 
cards in discard: [ 6.  3.  0.  0. 11.  6.  0. 14. 11.  0.  6.  3.  0. 14.  6.  0.  0.  1.
  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 25. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3. 10.  3. 29.
 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3] -> size -> 32 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 25. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10. 11.] 
expected returns: [[82.29909]
 [84.36604]
 [90.01516]
 [77.71073]
 [84.36604]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25. 10. 11.] 
cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3. 10.  3. 29.
 11. 10. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  2.  9.  9.  1.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14. 14.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3] -> size -> 25 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.97568416595459



action possibilites: [-1] 
expected returns: [[39.42499]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 11. 29.  0.] 
cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3. 10.  3. 29.
 11. 10. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  2.  9.  9.  1.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14. 14.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6] -> size -> 26 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 90.01515197753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[33.678017]
 [38.22549 ]
 [28.769512]
 [37.911083]
 [39.76139 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10. 11. 29.  0.] 
cards in discard: [10. 29. 29. 11.  0.  0. 11.  0.  0.  3. 29. 29.  3. 10.  3. 10.  3. 29.
 11. 10. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  2.  9.  9.  1.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14. 14.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6] -> size -> 26 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.424991607666016






Player: 1 
cards in hand: [ 0. 14. 14.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 14.  3.  8.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  2.  9.  9.  1.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3] -> size -> 32 
adversary victory points: 5
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  8.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  2.  9.  9.  1.  8. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3] -> size -> 32 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  8.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  2.  9.  9.  1.  8. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3] -> size -> 32 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  8.] 
cards in discard: [ 6. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  2.  9.  9.  1.  8. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3] -> size -> 32 
adversary victory points: 5
player victory points: -1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[6.411965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  2.  9.  9.  1.  8. 10.  2. 10. 10.] 
adversary cards in hand: [1. 3. 6. 3. 0.] 
adversary cards in discard: [ 6. 10. 14.  0. 14.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10] -> size -> 27 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0 760   0] 
sum of rewards: 935 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 135.4084930419922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.6532583]
 [ 6.063811 ]
 [ 4.289065 ]
 [-6.3799143]
 [ 9.233517 ]
 [ 4.049392 ]
 [ 2.3135881]
 [ 4.17617  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  2.  9.  9.  1.  8. 10.  2. 10. 10.] 
adversary cards in hand: [1. 3. 6. 3. 0.] 
adversary cards in discard: [ 6. 10. 14.  0. 14.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10] -> size -> 27 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 6.4119648933410645



buy possibilites: [-1] 
expected returns: [[30.463211]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 29. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  1.  9.  9.  1.  8. 10.  2. 10. 10.] 
adversary cards in hand: [1. 3. 6. 3. 0.] 
adversary cards in discard: [ 6. 10. 14.  0. 14.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10] -> size -> 27 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 229 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 9.233509063720703






Player: 1 
cards in hand: [1. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6. 3. 0.] 
cards in discard: [ 6. 10. 14.  0. 14.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  1.  9.  9.  1.  8. 10.  2. 10. 10.] 
adversary cards in hand: [10. 29. 10.  0.  0.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11] -> size -> 33 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 3. 0.] 
cards in discard: [ 6. 10. 14.  0. 14.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  1.  9.  9.  1.  8. 10.  2. 10. 10.] 
adversary cards in hand: [10. 29. 10.  0.  0.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11] -> size -> 33 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 3. 0.] 
cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  1.  9.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [10. 29. 10.  0.  0.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11] -> size -> 33 
adversary victory points: 5
player victory points: -1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10. 29. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[43.300343]
 [42.546623]
 [49.509655]
 [42.546623]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  0.  0.] 
cards in discard: [10. 29. 11.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  1.  9.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 29.  0.] 
adversary cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10] -> size -> 28 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.463211059570312



action possibilites: [-1. 10. 10. 25.] 
expected returns: [[ 8.962212]
 [ 7.693847]
 [ 7.693847]
 [19.466024]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0. 25.] 
cards in discard: [10. 29. 11.  0.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  1.  9.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 29.  0.] 
adversary cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10] -> size -> 28 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 49.5096435546875



action possibilites: [-1] 
expected returns: [[36.738174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.  3.  3.] 
cards in discard: [10. 29. 11.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  1.  9.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 29.  0.] 
adversary cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6] -> size -> 29 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 19.466028213500977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.50002 ]
 [36.65441 ]
 [35.064354]
 [25.4185  ]
 [39.409916]
 [34.84557 ]
 [33.255524]
 [35.118614]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.  3.  3.] 
cards in discard: [10. 29. 11.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  1.  9.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 29.  0.] 
adversary cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6] -> size -> 29 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.73817443847656



buy possibilites: [-1] 
expected returns: [[81.45959]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.  3.  3.] 
cards in discard: [10. 29. 11.  0.  0.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  9.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 29.  0.] 
adversary cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6] -> size -> 29 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 269 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 39.40991973876953






Player: 1 
cards in hand: [ 6.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 29.  0.] 
cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  9.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 29. 10.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11] -> size -> 34 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.] 
cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  9.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 29. 10.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11] -> size -> 34 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  8.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 29. 10.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11] -> size -> 34 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  8.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 29. 10.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11] -> size -> 34 
adversary victory points: 5
player victory points: -2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 10.] 
expected returns: [[10.493052]
 [15.431904]
 [ 8.185905]
 [15.431904]
 [ 8.185905]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 29. 10.] 
cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  8.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0.  6.] 
adversary cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.  6.  0.  8. 29. 11.
  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8] -> size -> 30 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.45958709716797



action possibilites: [-1. 10. 10.] 
expected returns: [[15.738434]
 [12.61405 ]
 [12.61405 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  3.] 
cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  8.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0.  6.] 
adversary cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.  6.  0.  8. 29. 11.
  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8] -> size -> 30 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.47519302368164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[11.190487 ]
 [16.088503 ]
 [ 5.5168395]
 [15.82074  ]
 [17.244053 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  3.] 
cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  8.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0.  6.] 
adversary cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.  6.  0.  8. 29. 11.
  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8] -> size -> 30 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.738414764404297






Player: 1 
cards in hand: [ 0. 11.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0.  6.] 
cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.  6.  0.  8. 29. 11.
  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  8.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [11. 29. 29. 11. 11.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11] -> size -> 34 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6.] 
cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.  6.  0.  8. 29. 11.
  6.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [11. 29. 29. 11. 11.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11] -> size -> 34 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6.] 
cards in discard: [ 6. 10. 14.  0. 14.  3.  8. 10.  1.  3.  6.  3.  0.  6.  0.  8. 29. 11.
  6.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [11. 29. 29. 11. 11.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11] -> size -> 34 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11. 29. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 11. 11.] 
expected returns: [[20.584534]
 [20.449865]
 [21.664698]
 [21.664698]
 [20.449865]
 [20.449865]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29. 11. 11.] 
cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6] -> size -> 31 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 17.244035720825195



action possibilites: [-1. 11. 11. 11. 10.] 
expected returns: [[54.47207 ]
 [55.208244]
 [55.208244]
 [55.208244]
 [50.58188 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 10.] 
cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6] -> size -> 31 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.649673461914062



action possibilites: [-1] 
expected returns: [[64.651855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.] 
cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3. 29. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6] -> size -> 31 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 339 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 56.31122970581055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[59.060905]
 [55.828762]
 [64.42073 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 10.] 
cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3. 29. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6] -> size -> 31 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.65185546875






Player: 1 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0. 29. 11. 11.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3. 29. 15. 29. 11. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15] -> size -> 35 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0. 29. 11. 11.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3. 29. 15. 29. 11. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15] -> size -> 35 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0. 29. 11. 11.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3. 29. 15. 29. 11. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15] -> size -> 35 
adversary victory points: 5
player victory points: -2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10.  0. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 11.] 
expected returns: [[35.87353 ]
 [32.939156]
 [39.398987]
 [38.173588]
 [38.173588]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 11. 11.] 
cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3. 29. 15. 29. 11. 11. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 11. 14.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3] -> size -> 32 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.42073822021484



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[34.15514 ]
 [30.93507 ]
 [35.945255]
 [35.945255]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 11.] 
cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3. 29. 15. 29. 11. 11. 11. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 11. 14.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3] -> size -> 32 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 35.80585861206055



action possibilites: [-1] 
expected returns: [[7.797399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3. 29. 15. 29. 11. 11. 11. 10.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 6.  0.  6. 11. 14.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3] -> size -> 32 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 299 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 37.17715835571289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[4.425201  ]
 [7.9311347 ]
 [0.33778787]
 [7.796903  ]
 [7.7204843 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.] 
cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3. 29. 15. 29. 11. 11. 11. 10.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 6.  0.  6. 11. 14.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3] -> size -> 32 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.797399044036865



buy possibilites: [-1] 
expected returns: [[27.89069]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.] 
cards in discard: [10. 29. 11.  0.  0.  0. 11. 29. 25. 10. 10.  0.  0.  3.  3. 29. 29.  0.
 10. 10.  3. 29. 15. 29. 11. 11. 11. 10.  3. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15 15  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 6.  0.  6. 11. 14.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3] -> size -> 32 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 7.931137561798096






Player: 1 
cards in hand: [ 6.  0.  6. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 11. 14.] 
cards in discard: [ 3.  0.  3.  0.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  3. 10.  0.  8.  9.  1.  8. 10.  1. 10.  8.] 
adversary cards in hand: [15.  3.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15 15  3] -> size -> 37 
adversary victory points: 6
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 14.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  3. 10.  0.  8.  9.  1.  7. 10.  1. 10.  8.] 
adversary cards in hand: [15.  3.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15 15  3] -> size -> 37 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 14.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 24. 30.  8.  3. 10.  0.  8.  9.  1.  7. 10.  1. 10.  8.] 
adversary cards in hand: [15.  3.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15 15  3] -> size -> 37 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 14.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  3. 10.  0.  8.  9.  1.  7. 10.  1. 10.  8.] 
adversary cards in hand: [15.  3.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15 15  3] -> size -> 37 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [15.  3.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[1.384664 ]
 [2.181229 ]
 [7.1314883]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15 15  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  3. 10.  0.  8.  9.  1.  7. 10.  1. 10.  8.] 
adversary cards in hand: [29. 14. 10. 10.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0] -> size -> 34 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.890689849853516



action possibilites: [-1. 15.] 
expected returns: [[-8.028347 ]
 [-7.7047963]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  3.] 
cards in discard: [29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10
 11 10 11 29 10 29 10  3 11 11 15 15  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  3. 10.  0.  8.  9.  1.  7. 10.  1. 10.  8.] 
adversary cards in hand: [29. 14. 10. 10.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0] -> size -> 34 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.4785237312316895



action possibilites: [-1] 
expected returns: [[-0.571686]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 29. 30. 24. 30.  8.  3. 10.  0.  8.  9.  1.  7. 10.  1. 10.  8.] 
adversary cards in hand: [29. 14. 10. 10.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0] -> size -> 34 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -7.704792022705078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-3.5785165e+00]
 [ 1.0448418e+00]
 [-1.5783024e-01]
 [-7.5935130e+00]
 [-7.8190494e-01]
 [-3.1170273e-01]
 [ 4.0039577e+00]
 [-4.6186843e+00]
 [-1.5143744e+00]
 [ 4.6734810e-03]
 [-5.9196877e-01]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 24. 30.  8.  3. 10.  0.  8.  9.  1.  7. 10.  1. 10.  8.] 
adversary cards in hand: [29. 14. 10. 10.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0] -> size -> 34 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.5716860294342041



buy possibilites: [-1] 
expected returns: [[-16.600868]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [29. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  3. 10.  0.  8.  9.  0.  7. 10.  1. 10.  8.] 
adversary cards in hand: [29. 14. 10. 10.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0] -> size -> 34 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0 -20   0   0 128   0] 
sum of rewards: 383 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 4.00395393371582






Player: 1 
cards in hand: [29. 14. 10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 10. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14. 10. 10.  3.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  3. 10.  0.  8.  9.  0.  7. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 25. 29. 10. 10.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
adversary victory points: 6
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10.  3.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 24. 30.  8.  3. 10.  0.  8.  9.  0.  7. 10.  1. 10.  8.] 
adversary cards in hand: [25. 29. 10.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 10.  3.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 24. 30.  8.  3. 10.  0.  8.  9.  0.  7. 10.  1. 10.  8.] 
adversary cards in hand: [25. 29. 10.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 10.  3.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  3. 10.  0.  7.  9.  0.  7. 10.  1. 10.  8.] 
adversary cards in hand: [25. 29. 10.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [25. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.] 
expected returns: [[-5.9645147]
 [-1.7843182]
 [-3.725123 ]
 [-7.3940606]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 10.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  3. 10.  0.  7.  9.  0.  7. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  1.  6. 11.  6.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8] -> size -> 35 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0 -20   0   0 952   0] 
sum of rewards: 1167 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -10.294694900512695



action possibilites: [-1] 
expected returns: [[2.0776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11. 11.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  0.  7.  9.  0.  7. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  1.  6. 11.  6.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6] -> size -> 36 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -1.784315824508667





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.77094936]
 [-3.9048855 ]
 [ 1.9574218 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 11. 11.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  0.  7.  9.  0.  7. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  1.  6. 11.  6.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6] -> size -> 36 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.0776000022888184






Player: 1 
cards in hand: [ 0.  1.  6. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6. 11.  6.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  0.  7.  9.  0.  7. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  3. 10.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 6.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  0.  7.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  3.  3. 10.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  0.  7.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  3.  3. 10.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  3.  3. 10.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[19.275352]
 [15.027632]
 [15.027632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3. 10.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 0. 6. 8.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.  8. 11.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8] -> size -> 38 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 1.9574251174926758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.809252]
 [ 9.115721]
 [20.610197]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3. 10.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 0. 6. 8.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.  8. 11.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8] -> size -> 38 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.27536392211914



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 8.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.  8. 11.  0.  1.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0.  3.  0. 29.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 8.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.  8. 11.  0.  1.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0.  3.  0. 29.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 8.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.  8. 11.  0.  1.  6.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0.  3.  0. 29.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[ 7.7591453]
 [ 6.0907645]
 [10.593809 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 29.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [3. 6. 8. 6. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.  8. 11.  0.  1.  6.  6.  0.  0.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0] -> size -> 39 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.610206604003906



action possibilites: [-1. 10.] 
expected returns: [[33.86212 ]
 [31.603039]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [3. 6. 8. 6. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.  8. 11.  0.  1.  6.  6.  0.  0.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0] -> size -> 39 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.14288330078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[31.15054 ]
 [36.32241 ]
 [34.84321 ]
 [26.855886]
 [34.635838]
 [33.34313 ]
 [35.646523]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [3. 6. 8. 6. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.  8. 11.  0.  1.  6.  6.  0.  0.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0] -> size -> 39 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.86212921142578



buy possibilites: [-1] 
expected returns: [[66.09493]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [3. 6. 8. 6. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.  8. 11.  0.  1.  6.  6.  0.  0.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0] -> size -> 39 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 36.32242202758789






Player: 1 
cards in hand: [3. 6. 8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 6. 3.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.  8. 11.  0.  1.  6.  6.  0.  0.  0.  0.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [29. 11. 11. 11. 15.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1. 29. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1] -> size -> 38 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 6. 3.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.  8. 11.  0.  1.  6.  6.  0.  0.  0.  0.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0] -> size -> 39 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [29. 11. 11. 11. 15.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1. 29. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1] -> size -> 38 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 6. 3.] 
cards in discard: [ 3.  0.  3.  0.  0. 11. 14.  0. 11.  6.  0.  6. 14.  8. 14. 29. 10. 10.
  3.  6. 15.  8. 11.  0.  1.  6.  6.  0.  0.  0.  0.  6.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [29. 11. 11. 11. 15.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1. 29. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1] -> size -> 38 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [29. 11. 11. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11. 11. 15.] 
expected returns: [[24.566078]
 [26.956944]
 [25.420555]
 [25.420555]
 [25.420555]
 [22.046703]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11. 11. 15.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1. 29. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 6. 29. 14.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.09493255615234



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[89.12354 ]
 [89.794624]
 [89.794624]
 [83.90901 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1. 29. 10.  0.  0. 11. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 6. 29. 14.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.798587799072266



action possibilites: [-1] 
expected returns: [[19.807796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1. 29. 10.  0.  0. 11. 15.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 6. 29. 14.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 292 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 87.03047943115234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.255335]
 [11.632132]
 [19.630482]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1. 29. 10.  0.  0. 11. 15.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 6. 29. 14.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.807796478271484






Player: 1 
cards in hand: [ 6. 29. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 14.  1.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  0. 11. 10. 29.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1. 29. 10.  0.  0. 11. 15.  1. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1] -> size -> 39 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29. 14.  1.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  0. 11. 10. 29.] 
adversary cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1. 29. 10.  0.  0. 11. 15.  1. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1] -> size -> 39 
adversary victory points: 6
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[70.467964]
 [75.755714]
 [66.42031 ]
 [77.71493 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10. 29.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1. 29. 10.  0.  0. 11. 15.  1. 29. 11. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.63047981262207



action possibilites: [-1. 11. 11.] 
expected returns: [[76.71716 ]
 [81.314766]
 [81.314766]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1. 29. 10.  0.  0. 11. 15.  1. 29. 11. 11. 10.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 71.51873016357422



action possibilites: [-1] 
expected returns: [[31.304558]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1. 29. 10.  0.  0. 11. 15.  1. 29. 11. 11. 10.  0. 10.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 77.16553497314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.311718]
 [19.389706]
 [31.304546]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [29. 29. 29. 15.  3.  3.  0. 10. 25. 29. 10. 11. 11.  0. 10.  3.  3. 10.
  0.  3.  1. 29. 10.  0.  0. 11. 15.  1. 29. 11. 11. 10.  0. 10.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.30455780029297






Player: 1 
cards in hand: [0. 0. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [ 6. 29. 14.  1.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [25. 10. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [ 6. 29. 14.  1.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [25. 10. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [25. 10. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [25. 10. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29. 29. 29.] 
expected returns: [[39.94929 ]
 [50.07034 ]
 [38.951996]
 [45.156837]
 [45.156837]
 [45.156837]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  2. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0. 15. 14. 11.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0] -> size -> 41 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.30455780029297



action possibilites: [-1] 
expected returns: [[11.660856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 29. 29. 29.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0. 15. 14. 11.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6] -> size -> 42 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 50.070316314697266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[6.4188876]
 [3.093554 ]
 [9.752426 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 29. 29. 29.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0. 15. 14. 11.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6] -> size -> 42 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.660856246948242






Player: 1 
cards in hand: [10.  0. 15. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 14. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15. 14. 11.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [11. 10.  3.  1. 29.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1. 15. 14. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 14. 11.  8.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [11. 10.  3.  1. 29.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 14. 11.  8.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [11. 10.  3.  1. 29.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 14. 11.  8.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  1. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [11. 10.  3.  1. 29.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [11. 10.  3.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[20.579071]
 [25.092316]
 [19.693222]
 [26.109327]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  1. 29.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  1. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [11.  0.  0.  8.  3.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0] -> size -> 43 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 9.752426147460938



action possibilites: [-1.] 
expected returns: [[21.238949]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  1. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [11.  0.  0.  8.  3.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0] -> size -> 43 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.67559051513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[16.81284 ]
 [22.61967 ]
 [21.11288 ]
 [12.362986]
 [20.926947]
 [19.42015 ]
 [21.062855]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 24. 30.  8.  1. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [11.  0.  0.  8.  3.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0] -> size -> 43 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.238948822021484



buy possibilites: [-1] 
expected returns: [[49.73104]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  1. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [11.  0.  0.  8.  3.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0] -> size -> 43 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 22.61968421936035






Player: 1 
cards in hand: [11.  0.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8.  3.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  1. 10.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [10. 10.  3. 10.  1.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1] -> size -> 41 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [10. 10.  3. 10.  1.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1] -> size -> 41 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [10. 10.  3. 10.  1.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1] -> size -> 41 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [10. 10.  3. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[64.21048]
 [59.41298]
 [59.41298]
 [59.41298]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 10.  1.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  0.  6. 10.  6.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16] -> size -> 44 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.731040954589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[56.445057]
 [61.602497]
 [50.902477]
 [61.230442]
 [64.47181 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3. 10.  1.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  0.  6. 10.  6.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16] -> size -> 44 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 64.21048736572266



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  6. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 10.  6.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3  1  6  8 14 14  6  0 11  6 29 11  0  6  0  0
  3  6 10 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11. 15.  0. 11.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1] -> size -> 41 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11. 15.  0. 11.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1] -> size -> 41 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11. 15.  0. 11.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1] -> size -> 41 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 15.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11.] 
expected returns: [[25.463945]
 [26.457188]
 [24.246822]
 [26.457188]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15.  0. 11.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6.  8.  3. 14.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16] -> size -> 41 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.47180938720703



action possibilites: [-1] 
expected returns: [[47.537636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 11.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6.  8.  3. 14.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16] -> size -> 41 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: 242 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 24.79665756225586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[40.186867]
 [44.614944]
 [35.52154 ]
 [44.264004]
 [47.498405]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 11.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 24. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6.  8.  3. 14.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16] -> size -> 41 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.537635803222656






Player: 1 
cards in hand: [ 0.  6.  8.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  3. 14.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  0. 29.  3.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1] -> size -> 42 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  8.  3. 14.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 24. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  0. 29.  3.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1] -> size -> 42 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  8.  3. 14.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.  8.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  0. 29.  3.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1] -> size -> 42 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[32.237423]
 [32.015366]
 [33.160866]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29.  3.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 3. 6. 6.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.  8.  6.  0.  0.  6.  8.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0] -> size -> 42 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 47.4984245300293



action possibilites: [-1. 11. 11.] 
expected returns: [[61.77991 ]
 [66.535866]
 [66.535866]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 3. 6. 6.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.  8.  6.  0.  0.  6.  8.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0] -> size -> 42 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 30.299354553222656



action possibilites: [-1] 
expected returns: [[46.13685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 3. 6. 6.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.  8.  6.  0.  0.  6.  8.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0] -> size -> 42 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -80   0   0  27   0] 
sum of rewards: 252 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 63.28377151489258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.338573]
 [38.016422]
 [46.13683 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 3. 6. 6.] 
adversary cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.  8.  6.  0.  0.  6.  8.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0] -> size -> 42 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.13684844970703






Player: 1 
cards in hand: [0. 3. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 6.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.  8.  6.  0.  0.  6.  8.  3. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [10. 10.  3. 11.  0.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.  1. 29. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1] -> size -> 43 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 6.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.  8.  6.  0.  0.  6.  8.  3. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [10. 10.  3. 11.  0.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.  1. 29. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1] -> size -> 43 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 6.] 
cards in discard: [ 6. 29. 14.  1.  0.  0.  0.  0.  6.  6.  3.  6.  0. 10.  0. 15. 14. 11.
  8. 16. 11.  0.  0.  8.  3.  8.  6.  0.  0.  6.  8.  3. 14.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [10. 10.  3. 11.  0.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.  1. 29. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1] -> size -> 43 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [10. 10.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[31.850716]
 [29.70316 ]
 [29.70316 ]
 [37.795197]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 11.  0.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.  1. 29. 11.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [14.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 46.13684844970703



action possibilites: [-1] 
expected returns: [[59.078793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.  1. 29. 11.  3. 11.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [14.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -90   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 34.14726638793945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[53.51016 ]
 [47.175625]
 [59.078785]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.  1. 29. 11.  3. 11.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 22. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [14.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.078792572021484






Player: 1 
cards in hand: [14.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  7. 10.  1. 10.  7.] 
adversary cards in hand: [11. 15. 29. 29.  0.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.  1. 29. 11.  3. 11.  1. 11. 10. 10.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1] -> size -> 44 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.] 
cards in discard: [14.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [11. 15. 29. 29.  0.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.  1. 29. 11.  3. 11.  1. 11. 10. 10.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1] -> size -> 44 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.] 
cards in discard: [14.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 22. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [11. 15. 29. 29.  0.] 
adversary cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.  1. 29. 11.  3. 11.  1. 11. 10. 10.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1] -> size -> 44 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11. 15. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 29. 29.] 
expected returns: [[100.23687 ]
 [105.41875 ]
 [100.526886]
 [107.09146 ]
 [107.09146 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 29. 29.  0.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.  1. 29. 11.  3. 11.  1. 11. 10. 10.
  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 59.078792572021484



action possibilites: [-1. 29.] 
expected returns: [[ 94.99131]
 [100.64175]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.] 
cards in discard: [25. 10. 29. 29. 29. 29.  3. 11. 10.  1. 29.  3.  1.  3. 10. 10.  3. 10.
  1.  1. 11.  0. 15.  0. 11.  0.  0.  1. 29. 11.  3. 11.  1. 11. 10. 10.
  3.  0. 11. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 22. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 107.58863067626953



action possibilites: [-1.] 
expected returns: [[17.243372]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1. 29.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 22. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 96.79547882080078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[16.181673]
 [21.004639]
 [19.724491]
 [11.578541]
 [19.604086]
 [18.323938]
 [18.537151]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 29.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 22. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.243371963500977



buy possibilites: [-1] 
expected returns: [[6.89825]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 29.  1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -100    0    0
   54    0] 
sum of rewards: 259 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 21.004648208618164






Player: 1 
cards in hand: [0. 0. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 0.] 
cards in discard: [14. 11. 14.  0.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [11. 29.  3.  0. 10.] 
adversary cards in discard: [ 1. 29.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1] -> size -> 45 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6. 0.] 
cards in discard: [14. 11. 14.  0.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 21. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [11. 29.  3.  0. 10.] 
adversary cards in discard: [ 1. 29.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1] -> size -> 45 
adversary victory points: 6
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [11. 29.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[ 7.257898]
 [10.248806]
 [11.196882]
 [ 5.789478]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3.  0. 10.] 
cards in discard: [ 1. 29.  1. 29. 29.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [ 6.  0.  1.  0. 14.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.898250102996826



action possibilites: [-1. 11. 10.] 
expected returns: [[10.496113]
 [15.814602]
 [ 9.848034]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  1.] 
cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 21. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [ 6.  0.  1.  0. 14.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 11.390003204345703



action possibilites: [-1] 
expected returns: [[28.697231]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.] 
cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 20. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [ 6.  0.  1.  0. 14.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 13.155170440673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[25.693855]
 [28.325382]
 [27.508814]
 [24.187202]
 [27.282833]
 [26.552668]
 [28.813278]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.] 
cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 20. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [ 6.  0.  1.  0. 14.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.69723129272461






Player: 1 
cards in hand: [ 6.  0.  1.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1.  0. 14.] 
cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [10. 29.  1.  0. 11.] 
adversary cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1] -> size -> 46 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1.  0. 14.] 
cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 20. 30. 24. 30.  8.  1.  9.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [10. 29.  1.  0. 11.] 
adversary cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1] -> size -> 46 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1.  0. 14.] 
cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0. 16.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14 16] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 24. 30.  8.  1.  8.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [10. 29.  1.  0. 11.] 
adversary cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1] -> size -> 46 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10. 29.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[ 9.821974 ]
 [ 7.5014377]
 [14.496222 ]
 [13.240522 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  1.  0. 11.] 
cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 24. 30.  8.  1.  8.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0. 16.  6.  0.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14 16] -> size -> 45 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.81328582763672



action possibilites: [-1. 10. 11.] 
expected returns: [[31.486843]
 [30.647503]
 [36.104435]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.  1. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 20. 30. 24. 30.  8.  1.  8.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0. 16.  6.  0.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14 16] -> size -> 45 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 10.665380477905273



action possibilites: [-1] 
expected returns: [[85.1242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.  1. 11.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 19. 30. 24. 30.  8.  1.  8.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0. 16.  6.  0.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14 16] -> size -> 45 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: 212 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 33.6656379699707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[79.36188 ]
 [84.114914]
 [73.727325]
 [83.85457 ]
 [85.271355]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.  1. 11.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 19. 30. 24. 30.  8.  1.  8.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0. 16.  6.  0.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14 16] -> size -> 45 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.12419891357422






Player: 1 
cards in hand: [6. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0. 16.  6.  0.  1.  0. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14 16] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 19. 30. 24. 30.  8.  1.  8.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [10. 10.  1.  1.  1.] 
adversary cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.  1. 11.  1. 29. 11.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1  1] -> size -> 47 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0. 16.  6.  0.  1.  0. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14 16] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 19. 30. 24. 30.  8.  1.  8.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [10. 10.  1.  1.  1.] 
adversary cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.  1. 11.  1. 29. 11.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1  1] -> size -> 47 
adversary victory points: 6
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [10. 10.  1.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[12.317362]
 [ 9.521568]
 [ 9.521568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  1.  1.  1.] 
cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.  1. 11.  1. 29. 11.
 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 19. 30. 24. 30.  8.  1.  8.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11. 11.  0.  8.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0. 16.  6.  0.  1.  0. 14.  6.
  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14 16] -> size -> 45 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 85.2713623046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 8.130102 ]
 [11.888584 ]
 [ 7.224404 ]
 [10.982893 ]
 [ 5.884273 ]
 [ 4.986378 ]
 [10.480429 ]
 [10.708212 ]
 [17.729843 ]
 [ 7.5566936]
 [11.087397 ]
 [ 9.802519 ]
 [ 7.3289084]
 [11.315174 ]
 [12.598314 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  1.  1.  1.] 
cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.  1. 11.  1. 29. 11.
 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 6 
card supply: [19. 19. 30. 24. 30.  8.  1.  8.  0.  6.  9.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11. 11.  0.  8.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0. 16.  6.  0.  1.  0. 14.  6.
  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14 16] -> size -> 45 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.31735610961914



buy possibilites: [-1] 
expected returns: [[16.10186]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  1.  1.  1.] 
cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.  1. 11.  1. 29. 11.
 10.  0. 25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1  1 25] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 19. 30. 24. 30.  8.  1.  8.  0.  6.  8.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11. 11.  0.  8.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0. 16.  6.  0.  1.  0. 14.  6.
  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14 16] -> size -> 45 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[  -5.     0.     0.   270.     0.     0.     0.     0.     0.     0.
    0.  -130.     0.     0.    62.5    0. ] 
sum of rewards: 197.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 17.729833602905273






Player: 1 
cards in hand: [ 0. 11. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  8.] 
cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0. 16.  6.  0.  1.  0. 14.  6.
  0.  0.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14 16] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 19. 30. 24. 30.  8.  1.  8.  0.  6.  8.  0.  6. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 11.  1.  3. 11.] 
adversary cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.  1. 11.  1. 29. 11.
 10.  0. 25. 10. 10.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1  1 25] -> size -> 48 
adversary victory points: 6
player victory points: -3 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 3 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 0 
Witch: 2 
Poacher: 8 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3. 11.  1.  3. 11.] 
cards in discard: [ 1. 29.  1. 29. 29.  0.  3.  0.  1. 29. 11. 10.  1.  1. 11.  1. 29. 11.
 10.  0. 25. 10. 10.  1.  1.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 25 29 11 10 29 29 29 10 11 11 10 29 10 11
 10 11 29 10 29 10  3 11 11 15 15  3 29  1  1  1  1  1  1  1  1  1  1 25] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 19. 30. 24. 30.  8.  1.  8.  0.  6.  8.  0.  6. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  8.] 
adversary cards in discard: [14. 11. 14.  0.  0.  0.  0.  0.  8.  6.  0. 16.  6.  0.  1.  0. 14.  6.
  0.  0.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11  3  1  8 14 14  6  0 11  6 29 11  0  6  0  0  3  6
 10  6  8  6  3 14  0  8  6 15  8  0  0  0  6  0 16  0  0 14 16 10] -> size -> 46 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[     -5 3000000       0     270       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000265 

action type: buy - action -1
Learning step: 120009.9609375
desired expected reward: 120026.0625



