 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[34.239346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000095 

action type: buy - action -1.0
Learning step: -300021.46875
desired expected reward: -299901.6875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.471382]
 [61.77728 ]
 [49.81618 ]
 [13.859271]
 [69.18194 ]
 [50.658466]
 [39.278023]
 [33.986443]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.99414825439453



buy possibilites: [-1] 
expected returns: [[24.083271]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 69.18193817138672






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[32.453136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.083271026611328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[31.058708]
 [61.052876]
 [48.598248]
 [13.956237]
 [50.766026]
 [68.66408 ]
 [49.486183]
 [91.76894 ]
 [26.938396]
 [37.794224]
 [55.499725]
 [32.12927 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.826702117919922



buy possibilites: [-1] 
expected returns: [[11.462454]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 91.76895141601562






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3. 29.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 5.773967]
 [29.32153 ]
 [19.990822]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.462453842163086



action possibilites: [-1. 11.] 
expected returns: [[18.251965]
 [41.571953]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.936500549316406



action possibilites: [-1] 
expected returns: [[25.390553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 52.8921012878418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.878963]
 [51.690735]
 [41.53111 ]
 [12.727366]
 [56.158764]
 [42.43597 ]
 [33.60301 ]
 [27.800491]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.390552520751953



buy possibilites: [-1] 
expected returns: [[14.448882]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 56.158756256103516






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[34.483944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.448882102966309





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[33.680935]
 [52.69632 ]
 [45.135223]
 [21.07483 ]
 [46.31049 ]
 [58.42122 ]
 [45.627815]
 [75.62866 ]
 [30.887321]
 [38.18879 ]
 [49.42916 ]
 [33.999615]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.23183822631836



buy possibilites: [-1] 
expected returns: [[28.201077]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11.  3.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 75.628662109375






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 5.504012]
 [25.927124]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 14.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.20107650756836



action possibilites: [-1.] 
expected returns: [[28.102665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 14.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 23.58300018310547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[35.313442]
 [60.306515]
 [49.49387 ]
 [15.987636]
 [52.555626]
 [65.66509 ]
 [50.61324 ]
 [86.153946]
 [30.47108 ]
 [40.17609 ]
 [55.041294]
 [32.922264]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 14.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.102664947509766



buy possibilites: [-1] 
expected returns: [[8.924544]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 14.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 86.15394592285156






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 14.  0.  0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0. 11.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.  0.  0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0. 11.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.  0.  0.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0. 11.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 2.4455166]
 [25.922405 ]
 [17.579887 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0. 11.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.924544334411621



action possibilites: [-1. 11. 10.] 
expected returns: [[22.116234]
 [39.456615]
 [25.581188]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 10.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.847591400146484



action possibilites: [-1] 
expected returns: [[12.84302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 48.06232452392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.679543]
 [36.806473]
 [30.572357]
 [12.601087]
 [40.37531 ]
 [31.084621]
 [24.848942]
 [19.700092]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.84302043914795



buy possibilites: [-1] 
expected returns: [[11.406146]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 40.375308990478516






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [14.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 3.5244184]
 [34.63167  ]
 [21.101833 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.] 
cards in discard: [0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14. 10. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 300   0] 
sum of rewards: 295 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 157.45150756835938



action possibilites: [-1. 11. 29.] 
expected returns: [[-5.403589]
 [ 9.660234]
 [29.769703]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.] 
cards in discard: [0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14. 10. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.018779754638672



action possibilites: [-1. 11.] 
expected returns: [[27.828289]
 [60.269985]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.] 
cards in discard: [0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14. 10. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.769718170166016



action possibilites: [-1] 
expected returns: [[53.889706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14. 10. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 73.00826263427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[63.912075]
 [89.930595]
 [78.620285]
 [45.271626]
 [94.8106  ]
 [79.84222 ]
 [68.71127 ]
 [60.02853 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14. 10. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.889705657958984



buy possibilites: [-1] 
expected returns: [[32.76545]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0.  0. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14. 10. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 109 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 94.81060028076172






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14. 10. 14.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [29. 11.  0. 11.  0.] 
adversary cards in discard: [ 0.  0. 10. 11. 29. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14. 10. 14.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [29. 11.  0. 11.  0.] 
adversary cards in discard: [ 0.  0. 10. 11. 29. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14. 10. 14.  0.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [29. 11.  0. 11.  0.] 
adversary cards in discard: [ 0.  0. 10. 11. 29. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29. 11.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[-6.863909]
 [15.043506]
 [ 9.347669]
 [ 9.347669]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 11.  0.] 
cards in discard: [ 0.  0. 10. 11. 29. 29. 11.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.76544952392578



action possibilites: [-1. 11. 11.] 
expected returns: [[12.220231]
 [26.611927]
 [26.611927]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.  0.] 
cards in discard: [ 0.  0. 10. 11. 29. 29. 11.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 14.282465934753418



action possibilites: [-1] 
expected returns: [[29.08556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [ 0.  0. 10. 11. 29. 29. 11.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 33.15925216674805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.029545]
 [40.42988 ]
 [35.820187]
 [18.042648]
 [35.47001 ]
 [46.516895]
 [35.563385]
 [56.267014]
 [25.98449 ]
 [31.76297 ]
 [38.71838 ]
 [32.151176]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [ 0.  0. 10. 11. 29. 29. 11.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.085559844970703



buy possibilites: [-1] 
expected returns: [[32.719776]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [ 0.  0. 10. 11. 29. 29. 11.  0.  3. 10. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 56.26701354980469






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10. 10.] 
adversary cards in discard: [ 0.  0. 10. 11. 29. 29. 11.  0.  3. 10. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10. 10.] 
adversary cards in discard: [ 0.  0. 10. 11. 29. 29. 11.  0.  3. 10. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10. 10.] 
adversary cards in discard: [ 0.  0. 10. 11. 29. 29. 11.  0.  3. 10. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  3.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[48.463154]
 [50.10392 ]
 [50.10392 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10. 10.] 
cards in discard: [ 0.  0. 10. 11. 29. 29. 11.  0.  3. 10. 29. 29. 11.  0. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.71977615356445



action possibilites: [-1. 10.] 
expected returns: [[44.66277]
 [50.6375 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 49.13753128051758



action possibilites: [-1.] 
expected returns: [[62.366077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29] -> size -> 22 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 50.637508392333984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[76.79077 ]
 [96.14527 ]
 [87.6762  ]
 [61.252018]
 [98.42471 ]
 [88.934364]
 [80.38531 ]
 [72.94484 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 62.3660774230957



buy possibilites: [-1] 
expected returns: [[16.955383]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5. 10. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 98.4247055053711






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  3.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5. 10. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29. 29.] 
adversary cards in discard: [11. 10. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5. 10. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29. 29.] 
adversary cards in discard: [11. 10. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5. 10. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29. 29.] 
adversary cards in discard: [11. 10. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29. 29.] 
adversary cards in discard: [11. 10. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 11. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[17.599792]
 [34.610966]
 [42.789646]
 [42.789646]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29. 29.] 
cards in discard: [11. 10. 10.  3.  3.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0.  0. 14.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0.  8. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.95538330078125



action possibilites: [-1. 11. 29. 10.] 
expected returns: [[21.504837]
 [33.615192]
 [43.221565]
 [21.068832]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29. 10.] 
cards in discard: [11. 10. 10.  3.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0.  0. 14.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0.  8. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.92947769165039



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[24.246422]
 [36.40967 ]
 [25.405315]
 [36.40967 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10. 11.] 
cards in discard: [11. 10. 10.  3.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0.  0. 14.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0.  8. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.22157669067383



action possibilites: [-1] 
expected returns: [[26.767002]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [11. 10. 10.  3.  3.  0.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  0. 14.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0.  8. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.25446701049805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.052681]
 [35.365284]
 [31.754528]
 [14.89203 ]
 [31.449284]
 [39.73737 ]
 [31.791683]
 [45.001774]
 [22.868896]
 [28.180923]
 [34.184345]
 [28.51815 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [11. 10. 10.  3.  3.  0.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  0. 14.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0.  8. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.76700210571289



buy possibilites: [-1] 
expected returns: [[33.140095]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [11. 10. 10.  3.  3.  0.  0.  0. 10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  5.  8. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  0. 14.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0.  8. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 45.00177001953125






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [14.  0.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 14.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0.  8. 10.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  5.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11. 11. 10.  0. 29.] 
adversary cards in discard: [11. 10. 10.  3.  3.  0.  0.  0. 10. 29. 29. 29. 11.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0.  8. 10.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  5.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10. 29.] 
adversary cards in discard: [11. 10. 10.  3.  3.  0.  0.  0. 10. 29. 29. 29. 11.  0.  0. 10. 11. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0.  8. 10.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  5.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10. 29.] 
adversary cards in discard: [11. 10. 10.  3.  3.  0.  0.  0. 10. 29. 29. 29. 11.  0.  0. 10. 11. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0.  8. 10.  3.  0.  0.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10. 29.] 
adversary cards in discard: [11. 10. 10.  3.  3.  0.  0.  0. 10. 29. 29. 29. 11.  0.  0. 10. 11. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[102.2528 ]
 [114.46942]
 [102.40939]
 [117.44679]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.] 
cards in discard: [11. 10. 10.  3.  3.  0.  0.  0. 10. 29. 29. 29. 11.  0.  0. 10. 11. 11.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 563   0] 
sum of rewards: 528 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 44.21367263793945



action possibilites: [-1. 11. 10.] 
expected returns: [[140.29755]
 [157.41867]
 [134.15192]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.] 
cards in discard: [11. 10. 10.  3.  3.  0.  0.  0. 10. 29. 29. 29. 11.  0.  0. 10. 11. 11.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 117.44676971435547



action possibilites: [-1] 
expected returns: [[117.48971]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [11. 10. 10.  3.  3.  0.  0.  0. 10. 29. 29. 29. 11.  0.  0. 10. 11. 11.
  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 161.5168914794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[105.96503]
 [ 93.41751]
 [119.71002]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [11. 10. 10.  3.  3.  0.  0.  0. 10. 29. 29. 29. 11.  0.  0. 10. 11. 11.
  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 117.48970794677734






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10] -> size -> 26 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  3. 10. 10.] 
adversary cards in hand: [10. 29.  0.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10] -> size -> 26 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  3. 10. 10.] 
adversary cards in hand: [10. 29.  0.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10] -> size -> 26 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  3. 10. 10.] 
adversary cards in hand: [10. 29.  0.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10] -> size -> 26 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[30.544155]
 [34.130527]
 [58.996426]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.] 
cards in discard: [11. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  3. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 3. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0 590   0] 
sum of rewards: 525 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 184.4300537109375



action possibilites: [-1. 10. 10.] 
expected returns: [[92.854454]
 [96.11221 ]
 [96.11221 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [11. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  3. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 3. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.030025482177734



action possibilites: [-1. 10. 11.] 
expected returns: [[71.024414]
 [73.77073 ]
 [91.18147 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.] 
cards in discard: [11. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10] -> size -> 26 
action values: 2 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  3. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 3. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 96.11219787597656



action possibilites: [-1. 10.] 
expected returns: [[87.36206]
 [90.81685]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [11. 10. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  2. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 3. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 22 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 99.71050262451172



action possibilites: [-1. 29.] 
expected returns: [[41.090397]
 [69.21866 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.] 
cards in discard: [11. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10] -> size -> 27 
action values: 2 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  2. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 3. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 90.81687927246094



action possibilites: [-1. 10.] 
expected returns: [[69.496826]
 [72.10783 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [11. 10. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10. 11. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10] -> size -> 27 
action values: 2 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  2. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 3. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 69.21866607666016



action possibilites: [-1.] 
expected returns: [[70.89845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [11. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 10. 11. 10. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10] -> size -> 27 
action values: 3 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  2. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 3. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 72.10781860351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 72.75526 ]
 [ 88.54686 ]
 [ 82.57308 ]
 [ 60.31014 ]
 [ 83.19154 ]
 [ 93.06393 ]
 [ 82.90383 ]
 [103.661026]
 [ 70.272545]
 [ 76.9384  ]
 [ 86.02884 ]
 [ 73.71199 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 10. 11. 10. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5.  7. 10.  2. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 3. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 70.89845275878906



buy possibilites: [-1] 
expected returns: [[3.8168736]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11. 10. 10. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 10. 11. 10. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 3. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0 120   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 103.66102600097656






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 3.] 
cards in discard: [ 3. 14.  3.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 3.] 
cards in discard: [ 3. 14.  3.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 3.] 
cards in discard: [ 3. 14.  3.  8.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  4.  7. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.77568]
 [37.09808]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  4.  7. 10.  1. 10. 10.] 
adversary cards in hand: [10. 14.  0.  0.  0.] 
adversary cards in discard: [ 3. 14.  3.  8.  0.  0. 10.  0.  3.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.816873550415039



action possibilites: [-1] 
expected returns: [[65.618614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  4.  7. 10.  0. 10. 10.] 
adversary cards in hand: [10. 14.  0.  0.  0.] 
adversary cards in discard: [ 3. 14.  3.  8.  0.  0. 10.  0.  3.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.95917892456055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[58.26804]
 [78.93152]
 [72.32818]
 [42.93972]
 [87.20571]
 [71.94482]
 [64.53399]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  4.  7. 10.  0. 10. 10.] 
adversary cards in hand: [10. 14.  0.  0.  0.] 
adversary cards in discard: [ 3. 14.  3.  8.  0.  0. 10.  0.  3.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.61861419677734



buy possibilites: [-1] 
expected returns: [[97.744545]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10. 10.] 
adversary cards in hand: [10. 14.  0.  0.  0.] 
adversary cards in discard: [ 3. 14.  3.  8.  0.  0. 10.  0.  3.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 87.20570373535156






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [10. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0.  0.  0.] 
cards in discard: [ 3. 14.  3.  8.  0.  0. 10.  0.  3.  3.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3. 10.] 
adversary cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10. 11. 11.  3.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  0.  0.] 
cards in discard: [ 3. 14.  3.  8.  0.  0. 10.  0.  3.  3.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3. 10.] 
adversary cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10. 11. 11.  3.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  0.  0.] 
cards in discard: [ 3. 14.  3.  8.  0.  0. 10.  0.  3.  3.  1.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3. 10.] 
adversary cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10. 11. 11.  3.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [11. 11.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[37.022335]
 [59.140865]
 [59.140865]
 [40.80582 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  3. 10.] 
cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10. 11. 11.  3.  0.  0.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.74454498291016



action possibilites: [-1] 
expected returns: [[73.8049]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 10.] 
cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10. 11. 11.  3.  0.  0.
  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 65.17088317871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[67.38432]
 [52.66115]
 [72.63895]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 10.] 
cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10. 11. 11.  3.  0.  0.
  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.80490112304688






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 1. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0.  3. 29. 29.] 
adversary cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10. 11. 11.  3.  0.  0.
  0. 15. 11. 11.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15] -> size -> 31 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 29.] 
adversary cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10. 11. 11.  3.  0.  0.
  0. 15. 11. 11.  0.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15] -> size -> 31 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 29.] 
adversary cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10. 11. 11.  3.  0.  0.
  0. 15. 11. 11.  0.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15] -> size -> 31 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [2.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 29. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 29.] 
adversary cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10. 11. 11.  3.  0.  0.
  0. 15. 11. 11.  0.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15] -> size -> 31 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [10. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[39.896862]
 [35.12964 ]
 [60.15819 ]
 [60.15819 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 29.] 
cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10. 11. 11.  3.  0.  0.
  0. 15. 11. 11.  0.  3. 10.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 2. 14.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0 772   0] 
sum of rewards: 707 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 161.12930297851562



action possibilites: [-1. 29. 29.] 
expected returns: [[38.14291]
 [46.98142]
 [46.98142]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.] 
cards in discard: [11. 10. 10. 29. 29. 10. 11. 10. 29. 10.  0.  0. 10. 11. 11.  3.  0.  0.
  0. 15. 11. 11.  0.  3. 10.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 29. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 2. 14.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.502872467041016



action possibilites: [-1.] 
expected returns: [[41.119232]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 29. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 2. 14.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.257999420166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[41.66568 ]
 [56.64071 ]
 [51.320946]
 [29.418182]
 [60.98463 ]
 [51.455093]
 [43.99246 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 29. 28. 30.  8. 10. 10.  4.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 2. 14.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 41.119232177734375



buy possibilites: [-1] 
expected returns: [[41.419273]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 28. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 2. 14.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 29 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 60.98463821411133






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 2. 14.  1.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 28. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [11. 11.  0. 10. 29.] 
adversary cards in discard: [29. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11] -> size -> 32 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 2. 14.  1.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 29. 28. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [11. 11.  0. 10. 29.] 
adversary cards in discard: [29. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11] -> size -> 32 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 2. 14.  1.  0.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 29. 27. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [11. 11.  0. 10. 29.] 
adversary cards in discard: [29. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11] -> size -> 32 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [11. 11.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10. 29.] 
expected returns: [[16.040234]
 [28.562504]
 [28.562504]
 [12.356994]
 [33.48197 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 10. 29.] 
cards in discard: [29. 11. 29. 29.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 27. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8.  3.  1.  0.] 
adversary cards in discard: [ 2. 14.  1.  0.  0.  0.  3.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.419273376464844



action possibilites: [-1. 11. 11. 10. 10.] 
expected returns: [[67.95876 ]
 [80.253555]
 [80.253555]
 [64.437546]
 [64.437546]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 10.] 
cards in discard: [29. 11. 29. 29.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 29. 27. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8.  3.  1.  0.] 
adversary cards in discard: [ 2. 14.  1.  0.  0.  0.  3.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.637775421142578



action possibilites: [-1] 
expected returns: [[62.42735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 29. 27. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  8.  3.  1.  0.] 
adversary cards in discard: [ 2. 14.  1.  0.  0.  0.  3.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 9 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 84.12642669677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.678566]
 [43.533466]
 [62.83218 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 29. 27. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  8.  3.  1.  0.] 
adversary cards in discard: [ 2. 14.  1.  0.  0.  0.  3.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.42734909057617






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [10.  8.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  1.  0.] 
cards in discard: [ 2. 14.  1.  0.  0.  0.  3.  0.  3.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 27. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0. 11.  0. 10.] 
adversary cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15] -> size -> 33 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  1.  0.] 
cards in discard: [ 2. 14.  1.  0.  0.  0.  3.  0.  3.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 29. 27. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0. 11.  0. 10.] 
adversary cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15] -> size -> 33 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[57.72226]
 [58.65846]
 [77.3333 ]
 [58.65846]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0. 10.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 27. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10. 14. 14.  3.  3.] 
adversary cards in discard: [ 2. 14.  1.  0.  0.  0.  3.  0.  3.  0.  3.  0. 10.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 62.832157135009766



action possibilites: [-1] 
expected returns: [[49.61732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 27. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  7.] 
adversary cards in hand: [10. 14. 14.  3.  3.] 
adversary cards in discard: [ 2. 14.  1.  0.  0.  0.  3.  0.  3.  0.  3.  0. 10.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: -11 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 83.34107971191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[42.6113  ]
 [53.385044]
 [31.058636]
 [53.183258]
 [48.193256]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 29. 27. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  7.] 
adversary cards in hand: [10. 14. 14.  3.  3.] 
adversary cards in discard: [ 2. 14.  1.  0.  0.  0.  3.  0.  3.  0.  3.  0. 10.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.6173210144043



buy possibilites: [-1] 
expected returns: [[19.37798]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 26. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  7.] 
adversary cards in hand: [10. 14. 14.  3.  3.] 
adversary cards in discard: [ 2. 14.  1.  0.  0.  0.  3.  0.  3.  0.  3.  0. 10.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 53.38503646850586






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [10. 14. 14.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14. 14.  3.  3.] 
cards in discard: [ 2. 14.  1.  0.  0.  0.  3.  0.  3.  0.  3.  0. 10.  8.  3.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 26. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  3.  3. 10. 11.] 
adversary cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15  3] -> size -> 35 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  3.  3.] 
cards in discard: [ 2. 14.  1.  0.  0.  0.  3.  0.  3.  0.  3.  0. 10.  8.  3.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 29. 26. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 11.] 
adversary cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15  3] -> size -> 35 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  3.  3.] 
cards in discard: [ 2. 14.  1.  0.  0.  0.  3.  0.  3.  0.  3.  0. 10.  8.  3.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 29. 26. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 11.] 
adversary cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15  3] -> size -> 35 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [ 3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[42.311497]
 [49.50388 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 26. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  7.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0 927   0] 
sum of rewards: 862 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 115.1114730834961



action possibilites: [-1] 
expected returns: [[49.334698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15  3 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 26. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 9 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 52.28998565673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[39.390736]
 [28.731785]
 [49.390873]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15  3 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 29. 26. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.33469772338867






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 26. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [10. 29. 15.  0. 29.] 
adversary cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15  3 15] -> size -> 36 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 29. 26. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [10. 29. 15.  0. 29.] 
adversary cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15  3 15] -> size -> 36 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 29. 25. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [10. 29. 15.  0. 29.] 
adversary cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15  3 15] -> size -> 36 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [10. 29. 15.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 15. 29.] 
expected returns: [[47.858025]
 [44.713005]
 [51.907856]
 [48.409695]
 [51.907856]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 15.  0. 29.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15  3 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 25. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [10.  3.  3.  0.  1.] 
adversary cards in discard: [3. 8. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 49.3908576965332



action possibilites: [-1. 10. 15.] 
expected returns: [[39.561337]
 [34.592136]
 [40.771854]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  0.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10
 29 10 10 29 10 11 15 11 15 15  3 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 29. 25. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [10.  3.  3.  0.  1.] 
adversary cards in discard: [3. 8. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 47.904815673828125



action possibilites: [-1] 
expected returns: [[37.29787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 28. 29. 25. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [10.  3.  3.  0.  1.] 
adversary cards in discard: [3. 8. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 40.771846771240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[18.858212]
 [31.845879]
 [29.871143]
 [14.237254]
 [11.974623]
 [24.874943]
 [42.496197]
 [28.505169]
 [53.829624]
 [40.903748]
 [20.33625 ]
 [29.15561 ]
 [16.445019]
 [33.17403 ]
 [36.598293]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 29. 25. 30.  8. 10. 10.  3.  9. 10.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [10.  3.  3.  0.  1.] 
adversary cards in discard: [3. 8. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.29787063598633



buy possibilites: [-1] 
expected returns: [[79.473335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3. 29. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 25. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [10.  3.  3.  0.  1.] 
adversary cards in discard: [3. 8. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0 -10   0   0 250   0] 
sum of rewards: 185 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 53.82965850830078






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [10.  3.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.  1.] 
cards in discard: [3. 8. 0. 3. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 25. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [11.  0. 11. 10. 10.] 
adversary cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3. 29. 25. 29. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25] -> size -> 36 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.  1.] 
cards in discard: [3. 8. 0. 3. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 29. 25. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [11.  0. 11. 10. 10.] 
adversary cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3. 29. 25. 29. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25] -> size -> 36 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.  1.] 
cards in discard: [3. 8. 0. 3. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 29. 25. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [11.  0. 11. 10. 10.] 
adversary cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3. 29. 25. 29. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25] -> size -> 36 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [11.  0. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10. 10.] 
expected returns: [[ 6.009633 ]
 [12.89461  ]
 [12.89461  ]
 [-1.4109073]
 [-1.4109073]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 10. 10.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3. 29. 25. 29. 15. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 25. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  0.  0. 10.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.47333526611328



action possibilites: [-1] 
expected returns: [[-11.228865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 10.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3. 29. 25. 29. 15. 10.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 25. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  0.  0. 10.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0 -20   0   0  64   0] 
sum of rewards: -31 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 14.350607872009277





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-28.04638 ]
 [-33.92646 ]
 [-11.228835]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10. 10.] 
cards in discard: [29. 11. 29. 29.  0.  0. 15. 29. 11. 11. 10. 10. 15.  3. 11. 10.  0.  0.
 10.  3. 10. 15. 11.  3.  3. 29. 25. 29. 15. 10.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 29. 25. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  0.  0. 10.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.228864669799805






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [ 3.  8.  0.  3.  0.  0.  0. 10.  3.  3.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 25. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  5.] 
adversary cards in hand: [ 0. 10. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15] -> size -> 37 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [ 3.  8.  0.  3.  0.  0.  0. 10.  3.  3.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 29. 25. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  5.] 
adversary cards in hand: [ 0. 10. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15] -> size -> 37 
adversary victory points: 4
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 10.] 
expected returns: [[ 9.303578]
 [ 8.118634]
 [20.935226]
 [17.295528]
 [ 8.118634]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 11. 10.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 25. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  5.] 
adversary cards in hand: [ 1. 14. 14.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  0.  0. 10.  3.  3.  0.  1.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -11.228864669799805



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[42.5189  ]
 [44.697178]
 [51.21828 ]
 [44.697178]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10.] 
cards in discard: [15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 29. 25. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  5.] 
adversary cards in hand: [ 1. 14. 14.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  0.  0. 10.  3.  3.  0.  1.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.17496395111084



action possibilites: [-1] 
expected returns: [[63.283085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [15. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 29. 25. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 14. 14.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  0.  0. 10.  3.  3.  0.  1.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0 -30   0   0  64   0] 
sum of rewards: -21 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 54.579036712646484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[51.969303]
 [64.93416 ]
 [41.77553 ]
 [63.93984 ]
 [63.43218 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [15. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 29. 25. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 14. 14.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  0.  0. 10.  3.  3.  0.  1.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.283084869384766



buy possibilites: [-1] 
expected returns: [[44.88931]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [15. 15.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15 15  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 14. 14.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  0.  0. 10.  3.  3.  0.  1.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0 -40   0   0  16   0] 
sum of rewards: -49 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 64.93415069580078






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 1. 14. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14. 14.  0.  0.] 
cards in discard: [ 3.  8.  0.  3.  0.  0.  0. 10.  3.  3.  0.  1.  3.  0.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  4.] 
adversary cards in hand: [15. 10. 29.  0. 15.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15 15  3] -> size -> 39 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14. 14.  0.  0.] 
cards in discard: [ 3.  8.  0.  3.  0.  0.  0. 10.  3.  3.  0.  1.  3.  0.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 29. 24. 30.  8. 10. 10.  3.  9.  9.  4.  7. 10.  0. 10.  4.] 
adversary cards in hand: [15. 10. 29.  0. 15.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15 15  3] -> size -> 39 
adversary victory points: 5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14. 14.  0.  0.] 
cards in discard: [ 3.  8.  0.  3.  0.  0.  0. 10.  3.  3.  0.  1.  3.  0.  0. 10.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8. 10. 10.  3.  9.  9.  4.  6. 10.  0. 10.  4.] 
adversary cards in hand: [15. 10. 29.  0. 15.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15 15  3] -> size -> 39 
adversary victory points: 5
player victory points: 7 





Player: 0 
cards in hand: [15. 10. 29.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 29. 15.] 
expected returns: [[39.412643]
 [44.48368 ]
 [38.469646]
 [55.26431 ]
 [44.48368 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 29.  0. 15.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15 15  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8. 10. 10.  3.  9.  9.  4.  6. 10.  0. 10.  4.] 
adversary cards in hand: [10. 14.  3.  3.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.88930892944336



action possibilites: [-1. 15. 10. 15.] 
expected returns: [[57.823116]
 [65.25334 ]
 [57.448128]
 [65.25334 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0. 15.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29
 10 10 29 10 11 15 11 15 15  3 15 25 15 15  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 29. 24. 30.  8. 10. 10.  3.  9.  9.  4.  6. 10.  0. 10.  4.] 
adversary cards in hand: [10. 14.  3.  3.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.1281623840332



action possibilites: [-1] 
expected returns: [[26.086987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 28. 29. 24. 30.  8. 10. 10.  3.  9.  9.  4.  6. 10.  0. 10.  4.] 
adversary cards in hand: [10. 14.  3.  3.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 65.25334930419922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[19.639202]
 [29.900593]
 [27.609245]
 [10.743886]
 [25.007523]
 [35.472637]
 [26.916473]
 [39.076675]
 [19.318378]
 [30.0472  ]
 [26.271   ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 29. 24. 30.  8. 10. 10.  3.  9.  9.  4.  6. 10.  0. 10.  4.] 
adversary cards in hand: [10. 14.  3.  3.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.086986541748047



buy possibilites: [-1] 
expected returns: [[22.22017]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8. 10. 10.  3.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [10. 14.  3.  3.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0 -40   0   0 128   0] 
sum of rewards: 63 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 39.07667541503906






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [10. 14.  3.  3.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  3.  3.  2.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8. 10. 10.  3.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [25. 10. 11. 11. 29.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29] -> size -> 39 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  3.  3.  2.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 29. 24. 30.  8. 10. 10.  3.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [25. 10. 11. 11. 29.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29] -> size -> 39 
adversary victory points: 5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  3.  3.  2.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 29. 24. 30.  8. 10. 10.  3.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [25. 10. 11. 11. 29.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29] -> size -> 39 
adversary victory points: 5
player victory points: 7 





Player: 0 
cards in hand: [25. 10. 11. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11. 11. 29.] 
expected returns: [[18.53201 ]
 [31.915524]
 [16.296413]
 [25.459595]
 [25.459595]
 [26.924923]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 11. 11. 29.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8. 10. 10.  3.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [ 0. 10. 14.  3.  3.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.220169067382812



action possibilites: [-1] 
expected returns: [[29.930851]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 29. 11. 15.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  3.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [ 0. 10. 14.  3.  3.  2.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6] -> size -> 29 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.915515899658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.35762 ]
 [ 8.459506]
 [28.788689]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11. 29. 11. 15.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  3.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [ 0. 10. 14.  3.  3.  2.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6] -> size -> 29 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.930850982666016






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  3.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29] -> size -> 39 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  3.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29] -> size -> 39 
adversary victory points: 5
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[81.712494]
 [78.120056]
 [78.120056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  3.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 14.  1.  0.  0.] 
adversary cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6] -> size -> 29 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.788700103759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[69.496155]
 [85.38545 ]
 [81.99094 ]
 [58.680878]
 [93.35586 ]
 [80.88679 ]
 [81.47342 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  3.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 14.  1.  0.  0.] 
adversary cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6] -> size -> 29 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 81.7125015258789



buy possibilites: [-1] 
expected returns: [[76.97275]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 14.  1.  0.  0.] 
adversary cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6] -> size -> 29 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0 -50   0   0  54   0] 
sum of rewards: -31 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 93.35586547851562






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  0.  0.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [11.  3.  3. 11. 29.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11] -> size -> 40 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  0.  0.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [11.  3.  3. 11. 29.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11] -> size -> 40 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  0.  0.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6 22] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  4.] 
adversary cards in hand: [11.  3.  3. 11. 29.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11] -> size -> 40 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [11.  3.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[28.347115]
 [36.465656]
 [36.465656]
 [36.34222 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3. 11. 29.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  4.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6 22] -> size -> 30 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 76.97274780273438



action possibilites: [-1] 
expected returns: [[27.88707]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 29.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  3.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6 22] -> size -> 30 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -60   0   0  64   0] 
sum of rewards: -11 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 39.01108169555664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.368984]
 [11.49998 ]
 [27.88707 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11. 29.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  3.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6 22] -> size -> 30 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.887069702148438






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  3.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6 22] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  3.] 
adversary cards in hand: [11.  3. 10. 10.  0.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0. 15. 11.  3.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15] -> size -> 41 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 8.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3
  3  0 14  0  6 22] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  3.] 
adversary cards in hand: [11.  3. 10. 10.  0.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0. 15. 11.  3.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15] -> size -> 41 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  3.] 
adversary cards in hand: [11.  3. 10. 10.  0.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0. 15. 11.  3.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15] -> size -> 41 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  3.] 
adversary cards in hand: [11.  3. 10. 10.  0.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0. 15. 11.  3.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15] -> size -> 41 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  3.] 
adversary cards in hand: [11.  3. 10. 10.  0.] 
adversary cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0. 15. 11.  3.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15] -> size -> 41 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [11.  3. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[20.8182  ]
 [34.837666]
 [14.97586 ]
 [14.97586 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 10.  0.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0. 15. 11.  3.  3. 11. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 14.  0.  0. 14.] 
adversary cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.
  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0] -> size -> 28 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.887069702148438



action possibilites: [-1] 
expected returns: [[6.4532375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0. 15. 11.  3.  3. 11. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 14.  0.  0. 14.] 
adversary cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.
  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0] -> size -> 28 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 39 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 38.891639709472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-10.455225]
 [-23.15429 ]
 [  6.453252]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [15. 15.  3. 29. 11.  0. 10. 10.  3. 29. 29. 15. 10. 15. 25. 10. 11. 11.
 29. 11. 15. 11. 10.  0. 10.  0.  0. 15. 11.  3.  3. 11. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 14.  0.  0. 14.] 
adversary cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.
  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0] -> size -> 28 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.453237533569336






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0. 14.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.
  0. 10.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  2.] 
adversary cards in hand: [11. 10. 15. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.
  0. 10.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  2.] 
adversary cards in hand: [15. 29. 29.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.
  0. 10.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  6. 10.  0.  9.  2.] 
adversary cards in hand: [15. 29. 29.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [ 0. 10. 14.  3.  3.  2.  6.  0.  3.  3.  1.  0. 22.  0. 14.  1.  0.  0.
  0. 10.  8.  3. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  5. 10.  0.  9.  2.] 
adversary cards in hand: [15. 29. 29.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [15. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 29.] 
expected returns: [[53.17416 ]
 [57.58956 ]
 [71.472595]
 [71.472595]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 29.] 
cards in discard: [11. 10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  5. 10.  0.  9.  2.] 
adversary cards in hand: [10. 14.  2. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14] -> size -> 29 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[  -5    0    0   30    0    0    0    0    0    0    0  -70    0    0
 1463    0] 
sum of rewards: 1418 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 44.102752685546875



action possibilites: [-1. 15. 11.] 
expected returns: [[20.554138]
 [17.422142]
 [27.535751]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.] 
cards in discard: [11. 10. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  5. 10.  0.  9.  2.] 
adversary cards in hand: [10. 14.  2. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14] -> size -> 29 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 57.06583023071289



action possibilites: [-1] 
expected returns: [[34.41792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [11. 10. 29. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  5. 10.  0.  9.  1.] 
adversary cards in hand: [10. 14.  2. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14] -> size -> 29 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -80   0   0  64   0] 
sum of rewards: 49 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.87749481201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.542885]
 [14.760577]
 [34.752476]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [11. 10. 29. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  5. 10.  0.  9.  1.] 
adversary cards in hand: [10. 14.  2. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14] -> size -> 29 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.41791915893555






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [10. 14.  2. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  2. 14.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  5. 10.  0.  9.  1.] 
adversary cards in hand: [ 3.  0. 29. 29. 11.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15] -> size -> 43 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  2. 14.  0.  1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  5. 10.  0.  9.  1.] 
adversary cards in hand: [ 3.  0. 29. 29. 11.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15] -> size -> 43 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2. 14.  0.  1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  5. 10.  0.  9.  1.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15] -> size -> 43 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2. 14.  0.  1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 8 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  9.  3.  5. 10.  0.  9.  1.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15] -> size -> 43 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2. 14.  0.  1.] 
cards in discard: [25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  8.  3.  5. 10.  0.  9.  1.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15] -> size -> 43 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.703098]
 [39.661236]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  8.  3.  5. 10.  0.  9.  1.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [25. 10. 14.  2. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25] -> size -> 30 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[  -5    0    0   30    0    0    0    0    0    0    0  -80    0    0
 1527    0] 
sum of rewards: 1472 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 51.52474594116211



action possibilites: [-1] 
expected returns: [[36.54353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [25. 10. 14.  2. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25] -> size -> 30 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -90   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 44.58612060546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.818092]
 [19.840492]
 [38.122066]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [25. 10. 14.  2. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25] -> size -> 30 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.54352951049805






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [25. 10. 14.  2. 14.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  0. 10. 29. 15.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15] -> size -> 44 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [25. 10. 14.  2. 14.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 29. 24. 30.  8.  9. 10.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  0. 10. 29. 15.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15] -> size -> 44 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  0. 10. 29. 15.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15] -> size -> 44 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0. 10. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 15.] 
expected returns: [[39.20694 ]
 [35.10464 ]
 [59.861835]
 [44.065884]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 29. 15.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  6. 22.  3.  3.] 
adversary cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 38.122074127197266



action possibilites: [-1. 15. 10.] 
expected returns: [[35.144753]
 [32.28839 ]
 [26.4474  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  6. 22.  3.  3.] 
adversary cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 44.50886535644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.101448]
 [13.398028]
 [34.683453]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 10.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15] -> size -> 44 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 28. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  6. 22.  3.  3.] 
adversary cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 35.14474868774414






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 3.  6. 22.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 22.  3.  3.] 
cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [15. 10. 11.  3. 11.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15] -> size -> 44 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 22.  3.  3.] 
cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [15. 10. 11.  3. 11.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15] -> size -> 44 
adversary victory points: 5
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [15. 10. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11. 11.] 
expected returns: [[57.495518]
 [61.77335 ]
 [52.413944]
 [71.069626]
 [71.069626]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11.  3. 11.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [14.  0. 10.  0.  1.] 
adversary cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.  3.  6. 22.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 34.683448791503906



action possibilites: [-1] 
expected returns: [[31.461746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  3. 11.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [14.  0. 10.  0.  1.] 
adversary cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.  3.  6. 22.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[  -5    0    0   30    0    0   20    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: -28 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 61.40877914428711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.710987]
 [11.562398]
 [31.30394 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  3. 11.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [14.  0. 10.  0.  1.] 
adversary cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.  3.  6. 22.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.461746215820312






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [14.  0. 10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10.  0.  1.] 
cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.  3.  6. 22.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [15. 10. 15. 15.  3.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1] -> size -> 45 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 10.  0.  1.] 
cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.  3.  6. 22.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  5. 10.  0.  9.  0.] 
adversary cards in hand: [15. 10. 15. 15.  3.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1] -> size -> 45 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 10.  0.  1.] 
cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.  3.  6. 22.  3.  3.
 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [15. 10. 15. 15.  3.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1] -> size -> 45 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [15. 10. 15. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 15. 15.] 
expected returns: [[45.323353]
 [41.074253]
 [34.71962 ]
 [41.074253]
 [41.074253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 15. 15.  3.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 3. 14. 14.  0.  0.] 
adversary cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.  3.  6. 22.  3.  3.
 14. 14.  0. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14] -> size -> 32 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.30394744873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.441425]
 [19.50179 ]
 [45.323353]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 15. 15.  3.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1] -> size -> 45 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 3. 14. 14.  0.  0.] 
adversary cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.  3.  6. 22.  3.  3.
 14. 14.  0. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14] -> size -> 32 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 45.323368072509766



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 3. 14. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14. 14.  0.  0.] 
cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.  3.  6. 22.  3.  3.
 14. 14.  0. 10.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10.  0. 10. 11. 10.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11. 15. 10. 15. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1] -> size -> 45 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.] 
cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.  3.  6. 22.  3.  3.
 14. 14.  0. 10.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11. 10.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11. 15. 10. 15. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1] -> size -> 45 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.] 
cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.  3.  6. 22.  3.  3.
 14. 14.  0. 10.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 29. 24. 30.  8.  9.  9.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11. 10.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11. 15. 10. 15. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1] -> size -> 45 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.] 
cards in discard: [25. 10. 14.  2. 14.  0.  1. 16.  0.  0.  0.  0.  8.  3.  6. 22.  3.  3.
 14. 14.  0. 10.  0.  1. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  9.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11. 10.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11. 15. 10. 15. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1] -> size -> 45 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[13.295499 ]
 [ 1.3214917]
 [13.440124 ]
 [ 1.3214917]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11. 15. 10. 15. 15.  3.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  9.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16] -> size -> 33 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[  -5    0    0   30    0    0    0    0    0    0    0 -100    0    0
 1466    0] 
sum of rewards: 1391 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 34.37688064575195



action possibilites: [-1] 
expected returns: [[-7.850897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11. 15. 10. 15. 15.  3.  0. 10.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  8.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16] -> size -> 33 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -110    0 -300
    0    0] 
sum of rewards: -395 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 3.119831085205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-38.75987  ]
 [-47.19364  ]
 [ -7.8509073]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11. 15. 10. 15. 15.  3.  0. 10.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  8.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16] -> size -> 33 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.850896835327148






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  8.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [25. 15.  0. 15.  3.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11. 15. 10. 15. 15.  3.  0. 10.  6. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6] -> size -> 46 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 29. 24. 30.  8.  8.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [25. 15.  0. 15.  3.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11. 15. 10. 15. 15.  3.  0. 10.  6. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6] -> size -> 46 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 29. 23. 30.  8.  8.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [25. 15.  0. 15.  3.] 
adversary cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11. 15. 10. 15. 15.  3.  0. 10.  6. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6] -> size -> 46 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [25. 15.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 15.] 
expected returns: [[27.657516]
 [48.134735]
 [27.542538]
 [27.542538]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15.  0. 15.  3.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11. 15. 10. 15. 15.  3.  0. 10.  6. 11. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 23. 30.  8.  8.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 14. 10. 14.  6.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16  3] -> size -> 34 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -7.850896835327148



action possibilites: [-1] 
expected returns: [[19.931866]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.  3. 29. 29.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11. 15. 10. 15. 15.  3.  0. 10.  6. 11. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 23. 30.  8.  7.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 14. 10. 14.  6.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16  3  6] -> size -> 35 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.134761810302734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 0.90724945]
 [-7.8331223 ]
 [19.93188   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  3. 29. 29.] 
cards in discard: [11. 10. 29. 15. 29. 11. 15. 29. 29. 15. 11.  3.  0.  0. 10. 29.  3. 15.
 10.  1. 11. 15. 10.  3. 11. 15. 10. 15. 15.  3.  0. 10.  6. 11. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 29. 23. 30.  8.  7.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 14. 10. 14.  6.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16  3  6] -> size -> 35 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.931865692138672






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0. 14. 10. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10. 14.  6.] 
cards in discard: [3. 0. 3. 0. 0. 3. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16  3  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 23. 30.  8.  7.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 15. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6] -> size -> 46 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 14.  6.] 
cards in discard: [3. 0. 3. 0. 0. 3. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16  3  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 29. 23. 30.  8.  7.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11.  0.] 
adversary cards in discard: [15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6] -> size -> 46 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 14.  6.] 
cards in discard: [3. 0. 3. 0. 0. 3. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16  3  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 29. 23. 30.  8.  7.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11.  0.] 
adversary cards in discard: [15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6] -> size -> 46 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 14.  6.] 
cards in discard: [3. 0. 3. 0. 0. 3. 6. 1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16  3  6  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 23. 30.  8.  7.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11.  0.] 
adversary cards in discard: [15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6] -> size -> 46 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[47.52425 ]
 [39.966003]
 [54.863705]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.] 
cards in discard: [15. 11.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 23. 30.  8.  7.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [14. 16.  2. 10.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16  3  6  1] -> size -> 36 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0 -110    0    0
 1466    0] 
sum of rewards: 1351 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 62.825923919677734



action possibilites: [-1] 
expected returns: [[10.442524]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [15. 11.  1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 29. 23. 30.  8.  7.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [14. 16.  2. 10.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16  3  6  1] -> size -> 36 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 43.75695037841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.9130745]
 [ 3.9023385]
 [10.553351 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [15. 11.  1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 29. 23. 30.  8.  7.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [14. 16.  2. 10.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16  3  6  1] -> size -> 36 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.442523956298828






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [14. 16.  2. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  2. 10.  0.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14
  0  6 22  0 14 25 16 14 16  3  6  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 29. 23. 30.  8.  7.  8.  2.  9.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [11.  3. 29. 15.  0.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1] -> size -> 47 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  2. 10.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0
  6 22  0 14 25 16 14 16  3  6  1  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 29. 23. 30.  8.  7.  8.  2.  8.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [11.  3. 29. 15.  0.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1] -> size -> 47 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  2. 10.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0
  6 22  0 14 25 16 14 16  3  6  1  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 29. 23. 30.  8.  7.  8.  2.  8.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [11.  3. 29. 15.  0.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1] -> size -> 47 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  2. 10.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0
  6 22  0 14 25 16 14 16  3  6  1  8  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [11.  3. 29. 15.  0.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1] -> size -> 47 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [11.  3. 29. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15.] 
expected returns: [[65.54447]
 [74.01352]
 [75.76997]
 [67.10542]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29. 15.  0.] 
cards in discard: [15. 11.  1. 11. 10.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [16.  8.  0.  0. 14.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0
  6 22  0 14 25 16 14 16  3  6  1  8  3] -> size -> 37 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.553357124328613



action possibilites: [-1. 15.] 
expected returns: [[61.844975]
 [62.778225]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10
 10 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [16.  8.  0.  0. 14.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0
  6 22  0 14 25 16 14 16  3  6  1  8  3] -> size -> 37 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 66.55704498291016



action possibilites: [-1] 
expected returns: [[76.41021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [16.  8.  0.  0. 14.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0
  6 22  0 14 25 16 14 16  3  6  1  8  3] -> size -> 37 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 62.77824783325195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
expected returns: [[65.85947 ]
 [82.36452 ]
 [78.88491 ]
 [55.06333 ]
 [74.436714]
 [90.662735]
 [77.704216]
 [94.95537 ]
 [66.06508 ]
 [77.555275]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  3.  4. 10.  0.  9.  0.] 
adversary cards in hand: [16.  8.  0.  0. 14.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0
  6 22  0 14 25 16 14 16  3  6  1  8  3] -> size -> 37 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.41020965576172



buy possibilites: [-1] 
expected returns: [[82.00043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  2.  4. 10.  0.  9.  0.] 
adversary cards in hand: [16.  8.  0.  0. 14.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0
  6 22  0 14 25 16 14 16  3  6  1  8  3] -> size -> 37 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -120    0    0
  128    0] 
sum of rewards: 13 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 94.95536804199219






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [16.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0.  0. 14.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0
  6 22  0 14 25 16 14 16  3  6  1  8  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  2.  4. 10.  0.  9.  0.] 
adversary cards in hand: [15. 15. 29. 10. 11.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29] -> size -> 47 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  2.  4. 10.  0.  9.  0.] 
adversary cards in hand: [15. 15. 29. 10. 11.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29] -> size -> 47 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  2.  4. 10.  0.  9.  0.] 
adversary cards in hand: [15. 15. 29. 10. 11.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29] -> size -> 47 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  2.  4. 10.  0.  9.  0.] 
adversary cards in hand: [15. 15. 29. 10. 11.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29] -> size -> 47 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [15. 15. 29. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 29. 10. 11.] 
expected returns: [[72.566826]
 [75.48656 ]
 [75.48656 ]
 [88.166435]
 [66.17344 ]
 [86.0515  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 29. 10. 11.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  2.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  0. 14.  3. 25.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0] -> size -> 36 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.00042724609375



action possibilites: [-1. 15. 15. 10.] 
expected returns: [[31.366657]
 [29.23724 ]
 [29.23724 ]
 [23.657421]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  2.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  0. 14.  3. 25.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0] -> size -> 36 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 74.27664947509766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.360657 ]
 [12.7175665]
 [31.162758 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 10.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29] -> size -> 47 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  2.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  0. 14.  3. 25.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0] -> size -> 36 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.366687774658203






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 14.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  3. 25.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  7.  8.  2.  8.  8.  2.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 3. 10.  1. 11. 10.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29] -> size -> 47 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  3.  0.  1.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  6.  8.  2.  8.  8.  2.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 3. 10.  1. 11. 10.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6] -> size -> 48 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  3.  0.  1.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 29. 22. 30.  8.  6.  8.  2.  8.  8.  2.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 3. 10.  1. 11. 10.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6] -> size -> 48 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  3.  0.  1.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  6.  8.  2.  8.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 3. 10.  1. 11. 10.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6] -> size -> 48 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 3. 10.  1. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[14.933148 ]
 [ 4.9357586]
 [21.182331 ]
 [ 4.9357586]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1. 11. 10.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  6.  8.  2.  8.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  1.  3. 14. 22.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14. 29. 25.  3.  0. 14.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29] -> size -> 37 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0 -130    0 -300
    0    0] 
sum of rewards: -495 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.162765502929688



action possibilites: [-1] 
expected returns: [[37.956158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1. 10.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 22. 30.  8.  6.  8.  2.  8.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  1.  3. 14. 22.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14. 29. 25.  3.  0. 14.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29] -> size -> 37 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: -158 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 10.10779094696045





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.97379 ]
 [34.20479 ]
 [14.092626]
 [32.41239 ]
 [37.95615 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1. 10.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 24. 29. 22. 30.  8.  6.  8.  2.  8.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  1.  3. 14. 22.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14. 29. 25.  3.  0. 14.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29] -> size -> 37 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.95615768432617






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  3. 14. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 14. 22.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14. 29. 25.  3.  0. 14.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 22. 30.  8.  6.  8.  2.  8.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 10. 15. 15. 11.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 22.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14. 29. 25.  3.  0. 14.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 24. 29. 22. 30.  8.  6.  8.  2.  8.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 10. 15.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 22.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14. 29. 25.  3.  0. 14.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 24. 29. 22. 30.  8.  6.  8.  2.  8.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 10. 15.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 22.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  6.  1. 14.  0. 10. 14.  6.  8.  3. 16. 14.  2.
 10.  0.  8.  0. 14. 29. 25.  3.  0. 14.  3.  0.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 24. 29. 22. 30.  8.  6.  8.  2.  7.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 10. 15.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [10. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15.] 
expected returns: [[-2.6671803]
 [-8.892033 ]
 [-8.892033 ]
 [-6.296677 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 22. 30.  8.  6.  8.  2.  7.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [14.  3.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8] -> size -> 38 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0 -140    0    0
 1466    0] 
sum of rewards: 1261 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 58.113765716552734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-14.463111 ]
 [-16.373634 ]
 [ -2.6671803]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 24. 29. 22. 30.  8.  6.  8.  2.  7.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [14.  3.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8] -> size -> 38 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -2.6671841144561768



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 22. 30.  8.  6.  8.  2.  7.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [29.  3. 15.  0. 29.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 24. 29. 22. 30.  8.  6.  8.  2.  7.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [29.  3. 15.  0. 29.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  8.  0.] 
cards in discard: [3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  2.  7.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [29.  3. 15.  0. 29.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [29.  3. 15.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 29.] 
expected returns: [[17.323612]
 [21.096985]
 [13.957158]
 [21.096985]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 15.  0. 29.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  2.  7.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 2.  3. 14.  3. 22.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3] -> size -> 39 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -2.6671841144561768



action possibilites: [-1. 15. 29.] 
expected returns: [[16.080826]
 [12.513564]
 [14.485972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 29.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  2.  7.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 2.  3. 14.  3. 22.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3] -> size -> 39 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 22.996448516845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-0.40289688]
 [10.50154   ]
 [-7.7346597 ]
 [ 8.782639  ]
 [16.080826  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 29.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  2.  7.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 2.  3. 14.  3. 22.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3] -> size -> 39 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.080841064453125






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 2.  3. 14.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  3. 14.  3. 22.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  2.  7.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [15. 29. 15.  3. 29.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  3. 14.  3.  3. 14.  6.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  2.  7.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [15. 29. 15.  3. 29.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  3. 14.  3.  3. 14.  6.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  2.  7.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [15. 29. 15.  3. 29.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  3. 14.  3.  3. 14.  6.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  2.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [15. 29. 15.  3. 29.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [15. 29. 15.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 15. 29.] 
expected returns: [[44.21783]
 [45.00012]
 [56.3009 ]
 [45.00012]
 [56.3009 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 15.  3. 29.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  2.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [25. 10. 16.  0. 14.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 16.080841064453125



action possibilites: [-1. 15. 15. 29.] 
expected returns: [[ 7.2626505]
 [ 6.665061 ]
 [ 6.665061 ]
 [10.332175 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 29.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.
  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  2.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [25. 10. 16.  0. 14.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 43.224239349365234



action possibilites: [-1.] 
expected returns: [[-17.617035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.
  3. 10. 15. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  2.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [25. 10. 16.  0. 14.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.176817893981934





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-28.582233]
 [-17.850906]
 [-19.23422 ]
 [-33.843567]
 [-10.607699]
 [-20.51633 ]
 [-17.617033]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.
  3. 10. 15. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  2.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [25. 10. 16.  0. 14.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -17.617034912109375



buy possibilites: [-1] 
expected returns: [[-15.30948]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.
  3. 10. 15. 15. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [25. 10. 16.  0. 14.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -90    0    0   40    0    0    0    0 -150    0    0
   54    0] 
sum of rewards: -151 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -10.607702255249023






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [25. 10. 16.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 16. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 16.  0. 14.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [25. 15.  0.  6. 29.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.
  3. 10. 15. 15. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1. 25. 16. 14. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 16.  0. 14. 14.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6
 22  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 21. 30.  8.  6.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [25. 15.  0.  6. 29.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.
  3. 10. 15. 15. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1. 25. 14. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 14. 14.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 21. 30.  8.  5.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [25. 15.  0.  6. 29.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.
  3. 10. 15. 15. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 14. 14.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6] -> size -> 40 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 24. 29. 21. 30.  8.  5.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [25. 15.  0.  6. 29.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.
  3. 10. 15. 15. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 14. 14.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 21. 30.  8.  5.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [25. 15.  0.  6. 29.] 
adversary cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.
  3. 10. 15. 15. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [25. 15.  0.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 29.] 
expected returns: [[66.705894]
 [87.622475]
 [70.976395]
 [81.11194 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15.  0.  6. 29.] 
cards in discard: [15. 11.  1. 11. 10.  0. 11.  3. 29. 29. 15.  3. 10. 11. 29. 15. 15. 10.
  6.  1. 11.  3. 10.  1. 10. 15. 11. 10. 10. 15.  3. 11. 29. 15.  0. 29.
  3. 10. 15. 15. 11. 29. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 21. 30.  8.  5.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10.  0.  6.  0.  3.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.] 
adversary owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0] -> size -> 41 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -15.309479713439941



action possibilites: [-1] 
expected returns: [[157.0964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6. 29. 10. 11.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 21. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10.  0.  6.  0.  3.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6] -> size -> 42 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 87.62248229980469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[134.799  ]
 [119.60428]
 [155.715  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6. 29. 10. 11.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 29. 21. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10.  0.  6.  0.  3.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6] -> size -> 42 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 157.09640502929688






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [10.  0.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  0.  3.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 21. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [11.  1. 10.  6. 15.] 
adversary cards in discard: [25. 15.  0.  6. 29. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 21. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [11.  1. 10.  6. 15.] 
adversary cards in discard: [25. 15.  0.  6. 29. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 29. 21. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [11.  1. 10.  6. 15.] 
adversary cards in discard: [25. 15.  0.  6. 29. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [11.  1. 10.  6. 15.] 
adversary cards in discard: [25. 15.  0.  6. 29. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [11.  1. 10.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15.] 
expected returns: [[111.35357]
 [129.17108]
 [ 98.23705]
 [112.67673]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 10.  6. 15.] 
cards in discard: [25. 15.  0.  6. 29. 10. 11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [14.  0.  1.  8.  1.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3. 10.  0.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3] -> size -> 43 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 155.71502685546875



action possibilites: [-1] 
expected returns: [[74.971115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  6. 15.] 
cards in discard: [25. 15.  0.  6. 29. 10. 11.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [14.  0.  1.  8.  1.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3. 10.  0.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3] -> size -> 43 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0 -160    0    0
   27    0] 
sum of rewards: -178 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 111.04669189453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[61.00574 ]
 [68.84553 ]
 [57.5249  ]
 [66.833015]
 [77.71818 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  6. 15.] 
cards in discard: [25. 15.  0.  6. 29. 10. 11.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [14.  0.  1.  8.  1.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3. 10.  0.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3] -> size -> 43 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.97111511230469






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [14.  0.  1.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  1.  8.  1.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3. 10.  0.  6.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 15. 29. 10. 29.] 
adversary cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  1.  8.  1.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3. 10.  0.  6.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 15. 29. 10. 29.] 
adversary cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  1.  8.  1.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3. 10.  0.  6.  0.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 5 
card supply: [22. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 15. 29. 10. 29.] 
adversary cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0. 15. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 10. 29.] 
expected returns: [[185.33342]
 [183.84148]
 [203.79007]
 [167.646  ]
 [203.79007]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29. 10. 29.] 
cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3. 10.  0.  6.  0.  3.  3.  0. 14.  0.  1.  8.
  1.] 
adversary owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 44 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 77.71819305419922



action possibilites: [-1. 15. 10. 29.] 
expected returns: [[125.86795 ]
 [125.77057 ]
 [115.016624]
 [139.16066 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 29.] 
cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.  0. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3. 10.  0.  6.  0.  3.  3.  0. 14.  0.  1.  8.
  1.] 
adversary owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 44 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 207.32275390625



action possibilites: [-1. 15.] 
expected returns: [[142.66687]
 [139.88005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.  0. 11. 10. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3. 10.  0.  6.  0.  3.  3.  0. 14.  0.  1.  8.
  1.] 
adversary owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 44 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 123.60957336425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[109.086044]
 [133.22449 ]
 [ 93.309715]
 [129.2351  ]
 [140.89973 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.  0. 11. 10. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
action values: 1 
buys: 1 
player value: 2 
card supply: [22. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3. 10.  0.  6.  0.  3.  3.  0. 14.  0.  1.  8.
  1.] 
adversary owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 44 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 142.6668701171875






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 1. 0.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3. 10.  0.  6.  0.  3.  3.  0. 14.  0.  1.  8.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  0 14  3  1  8 14  3 10  1  2  3  3  0 14  0  6 22
  0 14 25 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11. 15. 29. 11.] 
adversary cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.  0. 11. 10. 10. 29.
 29. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3. 10.  0.  6.  0.  3.  3.  0. 14.  0.  1.  8.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 14 10  0 14  3  8 14  3 10  1  2  3  3  0 14  0  6 22  0 14 25
 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11. 15. 29. 11.] 
adversary cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.  0. 11. 10. 10. 29.
 29. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 14.  3.  0.  8.  0.  8. 22. 29.  2.  3. 14.  3.  3. 14.  6.  6.  0.
 10. 16. 25. 14. 14.  6.  3. 10.  0.  6.  0.  3.  3.  0. 14.  0.  1.  8.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 14 10  0 14  3  8 14  3 10  1  2  3  3  0 14  0  6 22  0 14 25
 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11. 15. 29. 11.] 
adversary cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.  0. 11. 10. 10. 29.
 29. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [10. 11. 15. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 29. 11.] 
expected returns: [[ 5.2306986]
 [ 2.2222776]
 [14.145413 ]
 [ 8.237516 ]
 [16.820911 ]
 [14.145413 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15. 29. 11.] 
cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.  0. 11. 10. 10. 29.
 29. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14 10  0 14  3  8 14  3 10  1  2  3  3  0 14  0  6 22  0 14 25
 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 140.89971923828125



action possibilites: [-1. 10. 11. 15.] 
expected returns: [[59.008286]
 [53.443047]
 [70.54769 ]
 [61.94501 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15.] 
cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.  0. 11. 10. 10. 29.
 29. 15. 15. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 23. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14 10  0 14  3  8 14  3 10  1  2  3  3  0 14  0  6 22  0 14 25
 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.010689735412598



action possibilites: [-1] 
expected returns: [[56.9063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.] 
cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.  0. 11. 10. 10. 29.
 29. 15. 15. 11.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 22. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14 10  0 14  3  8 14  3 10  1  2  3  3  0 14  0  6 22  0 14 25
 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -170    0    0
   27    0] 
sum of rewards: -138 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 61.13432693481445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.15341 ]
 [34.70799 ]
 [56.906292]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.] 
cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.  0. 11. 10. 10. 29.
 29. 15. 15. 11.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 22. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14 10  0 14  3  8 14  3 10  1  2  3  3  0 14  0  6 22  0 14 25
 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.90629959106445






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 6. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  0 14  3  8 14  3 10  1  2  3  3  0 14  0  6 22  0 14 25
 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [29.  0. 11.  0. 29.] 
adversary cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.  0. 11. 10. 10. 29.
 29. 15. 15. 11.  1. 29. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1  1] -> size -> 52 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  0 14  3  8 14  3 10  1  2  3  3  0 14  0  6 22  0 14 25
 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 22. 29. 20. 30.  8.  4.  8.  1.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [29.  0. 11.  0. 29.] 
adversary cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.  0. 11. 10. 10. 29.
 29. 15. 15. 11.  1. 29. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1  1] -> size -> 52 
adversary victory points: 3
player victory points: 4 


Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 9 
Chapel: 0 
Witch: 1 
Poacher: 8 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29.  0. 11.  0. 29.] 
cards in discard: [25. 15.  0.  6. 29. 10. 11.  1. 11.  1. 10.  6. 15.  0. 11. 10. 10. 29.
 29. 15. 15. 11.  1. 29. 11. 10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 29 10 11 10 11 10 29 11 10 29 10 10
 29 10 11 15 11 15 15  3 15 25 15 15  3 29 11 15 15 15 15  1  6  1 29  6
  1 11  1  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 29. 20. 30.  8.  4.  8.  0.  6.  8.  1.  4. 10.  0.  9.  0.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [11.] 
adversary owned cards: [ 0  0  0 14 10  0 14  3  8 14  3 10  1  2  3  3  0 14  0  6 22  0 14 25
 14 16  3  6  1  8  3  0 29  8  3  8  6  0  6  3  0 11] -> size -> 42 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000035 

action type: buy - action -1.0
Learning step: -300009.21875
desired expected reward: -299952.3125



