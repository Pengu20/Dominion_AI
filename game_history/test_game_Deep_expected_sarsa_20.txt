 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[86.862305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000065 

action type: buy - action -1
Learning step: -120002.4609375
desired expected reward: -120005.9609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[77.09472 ]
 [86.35044 ]
 [82.9652  ]
 [69.6562  ]
 [83.29231 ]
 [88.38031 ]
 [82.49222 ]
 [93.60304 ]
 [74.819374]
 [79.10697 ]
 [83.97018 ]
 [87.23727 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 89.47819519042969



buy possibilites: [-1] 
expected returns: [[92.7811]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 93.60304260253906






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[103.60205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 92.78109741210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 94.00875 ]
 [102.869194]
 [ 99.57569 ]
 [ 86.63849 ]
 [104.88353 ]
 [ 99.12836 ]
 [ 95.92771 ]
 [103.743416]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 105.24372100830078



buy possibilites: [-1] 
expected returns: [[107.31584]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 104.8835220336914






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[83.65776]
 [84.64842]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 107.31584167480469



action possibilites: [-1] 
expected returns: [[87.47043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 87.441650390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[77.775444]
 [82.39211 ]
 [71.72307 ]
 [82.020004]
 [85.76383 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.47042846679688






Player: 1 
cards in hand: [ 0.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [10. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [10. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [10. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[91.609024]
 [97.83222 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [10. 11.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  0.] 
adversary cards in discard: [ 0.  0.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 85.76382446289062



action possibilites: [-1.] 
expected returns: [[93.03955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 11.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  0.] 
adversary cards in discard: [ 0.  0.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 98.6231689453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 83.96803 ]
 [ 92.73416 ]
 [ 89.53699 ]
 [ 79.80623 ]
 [ 76.63241 ]
 [ 89.83595 ]
 [ 94.6574  ]
 [ 89.08846 ]
 [103.72252 ]
 [ 99.55695 ]
 [ 81.72571 ]
 [ 91.23934 ]
 [ 85.891266]
 [ 82.473206]
 [ 90.491844]
 [ 93.59587 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 11.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  0.] 
adversary cards in discard: [ 0.  0.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 93.03955078125



buy possibilites: [-1] 
expected returns: [[105.63937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 11.  0.  0.  3.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  0.] 
adversary cards in discard: [ 0.  0.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 103.7225112915039






Player: 1 
cards in hand: [ 3.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.  0.] 
cards in discard: [ 0.  0.  3. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  3.  0.] 
cards in discard: [ 0.  0.  3. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  3.  0.] 
cards in discard: [ 0.  0.  3. 11.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[ 90.64278]
 [100.74992]
 [ 91.69536]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25. 11.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.63937377929688



action possibilites: [-1] 
expected returns: [[99.88768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 102.3399658203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 94.97354 ]
 [103.00629 ]
 [ 99.99304 ]
 [ 88.733406]
 [104.88791 ]
 [ 99.588005]
 [ 96.70443 ]
 [103.85184 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.88768005371094



buy possibilites: [-1] 
expected returns: [[103.254486]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  0.  0.  0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 104.88789367675781






Player: 1 
cards in hand: [ 3.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 10.] 
adversary cards in discard: [11. 25.  3.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 10.] 
adversary cards in discard: [11. 25.  3.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 10.] 
adversary cards in discard: [11. 25.  3.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [6. 1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 10.] 
adversary cards in discard: [11. 25.  3.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[82.68266 ]
 [87.282074]
 [76.89619 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 10.] 
cards in discard: [11. 25.  3.  3. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 6.  1. 29.  3.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 103.25448608398438



action possibilites: [-1. 10.] 
expected returns: [[104.40411]
 [ 97.49921]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [11. 25.  3.  3. 11.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 6.  1. 29.  3.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 86.95748901367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 98.78791 ]
 [106.78482 ]
 [103.7587  ]
 [ 95.24714 ]
 [ 92.577896]
 [104.04727 ]
 [108.60136 ]
 [103.3348  ]
 [117.2605  ]
 [113.24037 ]
 [ 96.85277 ]
 [105.37159 ]
 [100.45731 ]
 [ 97.49002 ]
 [104.65912 ]
 [107.58713 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [11. 25.  3.  3. 11.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 6.  1. 29.  3.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 104.40412139892578



buy possibilites: [-1] 
expected returns: [[124.35352]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [11. 25.  3.  3. 11.  0.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 6.  1. 29.  3.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 295 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 117.260498046875






Player: 1 
cards in hand: [0. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [ 6.  1. 29.  3.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [ 6.  1. 29.  3.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [ 6.  1. 29.  3.  0.  0.  0. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[89.86717 ]
 [99.219345]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 124.35352325439453



action possibilites: [-1] 
expected returns: [[102.56978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.79806518554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 98.68921 ]
 [106.76027 ]
 [103.816765]
 [ 91.9378  ]
 [104.09126 ]
 [108.53231 ]
 [103.40373 ]
 [113.08014 ]
 [ 96.62826 ]
 [100.460236]
 [104.69696 ]
 [107.55681 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.56977844238281



buy possibilites: [-1] 
expected returns: [[114.84357]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3.  0. 11.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 113.08012390136719






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 25. 10. 11.] 
adversary cards in discard: [29. 25.  0.  0.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 25. 10. 11.] 
adversary cards in discard: [29. 25.  0.  0.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 25. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10. 11.] 
expected returns: [[115.38537 ]
 [120.50266 ]
 [124.07535 ]
 [108.83009 ]
 [116.297844]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 25. 10. 11.] 
cards in discard: [29. 25.  0.  0.  0.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 114.84356689453125



action possibilites: [-1] 
expected returns: [[92.43831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10. 11.  0.  3.] 
cards in discard: [29. 25.  0.  0.  0.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 122.5478744506836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[89.68033 ]
 [84.458145]
 [96.76529 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 10. 11.  0.  3.] 
cards in discard: [29. 25.  0.  0.  0.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.43830871582031






Player: 1 
cards in hand: [3. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [6. 3. 0. 0. 0. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [6. 3. 0. 0. 0. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [6. 3. 0. 0. 0. 0. 6. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  7.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[76.320206]
 [77.15712 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  7.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 1. 3. 3. 0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 6. 1. 3. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 96.7652816772461



action possibilites: [-1] 
expected returns: [[83.205246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 1. 3. 3. 0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 6. 1. 3. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 79.56636047363281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[78.94354 ]
 [84.99964 ]
 [82.75877 ]
 [74.303444]
 [86.368256]
 [82.44643 ]
 [80.24886 ]
 [85.61604 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 1. 3. 3. 0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 6. 1. 3. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.20524597167969



buy possibilites: [-1] 
expected returns: [[91.2357]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  6.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 1. 3. 3. 0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 6. 1. 3. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 86.36825561523438






Player: 1 
cards in hand: [8. 1. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 3. 3. 0.] 
cards in discard: [6. 3. 0. 0. 0. 0. 6. 1. 3. 6. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  6.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 29. 25.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 3. 3. 0.] 
cards in discard: [6. 3. 0. 0. 0. 0. 6. 1. 3. 6. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  6.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 29. 25.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 3. 3. 0.] 
cards in discard: [ 6.  3.  0.  0.  0.  0.  6.  1.  3.  6.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 29. 25.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[102.323456]
 [107.60263 ]
 [111.28746 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29. 25.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.23570251464844



action possibilites: [-1] 
expected returns: [[113.602036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29.  0. 29.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 29. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 108.37802124023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[108.21935]
 [113.2157 ]
 [101.66194]
 [112.81378]
 [116.85416]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 29.  0. 29.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 29. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 113.60203552246094






Player: 1 
cards in hand: [ 1.  0.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 29. 11.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11. 25.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0.  3. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 29. 11.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11. 25.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0.  3. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25.] 
expected returns: [[88.35959]
 [81.38445]
 [89.30412]
 [97.48561]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11. 25.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0.  3. 29.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 6. 0. 3.] 
adversary cards in discard: [ 6.  1.  0.  3. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 116.8541488647461



action possibilites: [-1] 
expected returns: [[82.519485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11. 10. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  5. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 6. 0. 3.] 
adversary cards in discard: [ 6.  1.  0.  3. 29. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 96.052001953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[81.606346]
 [85.159   ]
 [76.91053 ]
 [84.87384 ]
 [87.748215]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11. 10. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  5. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 6. 0. 3.] 
adversary cards in discard: [ 6.  1.  0.  3. 29. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.51948547363281






Player: 1 
cards in hand: [8. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 0. 3.] 
cards in discard: [ 6.  1.  0.  3. 29. 11.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  5. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 25.  3.] 
adversary cards in discard: [25. 10.  0.  0. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 0. 3.] 
cards in discard: [ 6.  1.  0.  3. 29. 11.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  5. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 25.  3.] 
adversary cards in discard: [25. 10.  0.  0. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 0. 3.] 
cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  5. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 25.  3.] 
adversary cards in discard: [25. 10.  0.  0. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[77.73155]
 [82.18312]
 [85.32745]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 25.  3.] 
cards in discard: [25. 10.  0.  0. 11. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  5. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 1. 0. 3.] 
adversary cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.  8.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0] -> size -> 24 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.74821472167969



action possibilites: [-1] 
expected returns: [[84.30513]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3. 29.  0.] 
cards in discard: [25. 10.  0.  0. 11. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  4. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 1. 0. 3.] 
adversary cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.  8.  3.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 82.9300537109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[77.26993 ]
 [83.66016 ]
 [81.30334 ]
 [72.06626 ]
 [85.168755]
 [80.97976 ]
 [78.66242 ]
 [84.32776 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3. 29.  0.] 
cards in discard: [25. 10.  0.  0. 11. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  4. 10.  6.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 1. 0. 3.] 
adversary cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.  8.  3.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.30513000488281



buy possibilites: [-1] 
expected returns: [[82.59028]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3. 29.  0.] 
cards in discard: [25. 10.  0.  0. 11. 10. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  4. 10.  5.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 1. 0. 3.] 
adversary cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.  8.  3.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 85.16875457763672






Player: 1 
cards in hand: [6. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 0. 3.] 
cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.  8.  3.  6.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  4. 10.  5.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [25. 10.  0.  0. 11. 10. 11. 11. 25.  0. 29.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11] -> size -> 20 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 3.] 
cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.  8.  3.  6.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  4. 10.  5.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [25. 10.  0.  0. 11. 10. 11. 11. 25.  0. 29.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11] -> size -> 20 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 3.] 
cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.  8.  3.  6.  0.  3.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  4. 10.  5.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [25. 10.  0.  0. 11. 10. 11. 11. 25.  0. 29.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11] -> size -> 20 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[52.240532]
 [52.871708]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  0.] 
cards in discard: [25. 10.  0.  0. 11. 10. 11. 11. 25.  0. 29.  0.  3. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  4. 10.  5.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  0.  0.] 
adversary cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.  8.  3.  6.  0.  3.  6.  1.  6.  0.  1.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.59027862548828



action possibilites: [-1] 
expected returns: [[62.877716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [25. 10.  0.  0. 11. 10. 11. 11. 25.  0. 29.  0.  3. 29.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  4. 10.  5.  9.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  0.  0.] 
adversary cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.  8.  3.  6.  0.  3.  6.  1.  6.  0.  1.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 54.76921081542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[55.251873]
 [59.91632 ]
 [49.309433]
 [59.538616]
 [63.343636]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [25. 10.  0.  0. 11. 10. 11. 11. 25.  0. 29.  0.  3. 29.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  4. 10.  5.  9.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  0.  0.] 
adversary cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.  8.  3.  6.  0.  3.  6.  1.  6.  0.  1.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.877716064453125






Player: 1 
cards in hand: [ 0.  6. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  0.  0.] 
cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.  8.  3.  6.  0.  3.  6.  1.  6.  0.  1.
  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  4. 10.  5.  9.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10] -> size -> 21 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0.  0.] 
cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.  8.  3.  6.  0.  3.  6.  1.  6.  0.  1.
  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  4. 10.  5.  9.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10] -> size -> 21 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0.  0.] 
cards in discard: [ 6.  1.  0.  3. 29. 11.  6.  0.  8.  3.  6.  0.  3.  6.  1.  6.  0.  1.
  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  4. 10.  5.  9.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10] -> size -> 21 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11.] 
expected returns: [[49.97498 ]
 [50.533016]
 [55.39527 ]
 [50.533016]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 25. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  4. 10.  5.  9.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10] -> size -> 27 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 63.34363555908203



action possibilites: [-1] 
expected returns: [[65.30833]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 11.  3. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  9.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6] -> size -> 28 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 53.159812927246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[61.985603]
 [58.320488]
 [66.78267 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 11.  3. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  9.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6] -> size -> 28 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.3083267211914






Player: 1 
cards in hand: [3. 0. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 6. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  9.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [25.  3.  0. 11. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10] -> size -> 21 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 6. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  9.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [25.  3.  0. 11. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10] -> size -> 21 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 6. 0.] 
cards in discard: [6. 8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [25.  3.  0. 11. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10] -> size -> 21 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[60.494568]
 [65.43062 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [25.  3.  0. 11. 11.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 10.  3.] 
adversary cards in discard: [6. 8. 3. 0. 1. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 66.78266906738281



action possibilites: [-1. 11.] 
expected returns: [[84.57013]
 [85.37879]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [25.  3.  0. 11. 11.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 10.  3.] 
adversary cards in discard: [6. 8. 3. 0. 1. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 64.7450942993164



action possibilites: [-1] 
expected returns: [[55.577324]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25.  3.  0. 11. 11.  3. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  8.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 10.  3.] 
adversary cards in discard: [6. 8. 3. 0. 1. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 242 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 87.8258056640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[50.707485]
 [57.62012 ]
 [55.091045]
 [47.648155]
 [45.374702]
 [55.33433 ]
 [59.144512]
 [54.737785]
 [66.35196 ]
 [63.041542]
 [49.041206]
 [56.440613]
 [52.20871 ]
 [49.593456]
 [55.844063]
 [58.291035]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25.  3.  0. 11. 11.  3. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  8.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 10.  3.] 
adversary cards in discard: [6. 8. 3. 0. 1. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.57732391357422



buy possibilites: [-1] 
expected returns: [[63.17003]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25.  3.  0. 11. 11.  3. 11. 10. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 10.  3.] 
adversary cards in discard: [6. 8. 3. 0. 1. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 465 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 66.35196685791016






Player: 1 
cards in hand: [ 0.  3. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 10.  3.] 
cards in discard: [6. 8. 3. 0. 1. 6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 10. 10. 25.] 
adversary cards in discard: [25.  3.  0. 11. 11.  3. 11. 10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3. 10.] 
cards in discard: [6. 8. 3. 0. 1. 6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 10. 10. 25.] 
adversary cards in discard: [25.  3.  0. 11. 11.  3. 11. 10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  3.] 
cards in discard: [6. 8. 3. 0. 1. 6. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8] -> size -> 29 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 10. 10. 25.] 
adversary cards in discard: [25.  3.  0. 11. 11.  3. 11. 10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [6. 8. 3. 0. 1. 6. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8] -> size -> 29 
action values: 3 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 10. 10. 25.] 
adversary cards in discard: [25.  3.  0. 11. 11.  3. 11. 10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [6. 8. 3. 0. 1. 6. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 10. 10. 25.] 
adversary cards in discard: [25.  3.  0. 11. 11.  3. 11. 10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10.  0. 10. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 25.] 
expected returns: [[43.991123]
 [38.510998]
 [38.510998]
 [38.510998]
 [51.50677 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10. 25.] 
cards in discard: [25.  3.  0. 11. 11.  3. 11. 10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  3. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 6. 8. 6.] 
adversary cards in discard: [ 6.  8.  3.  0.  1.  6.  0. 10. 10. 29.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.17002868652344



action possibilites: [-1] 
expected returns: [[33.564514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.  3. 29.] 
cards in discard: [25.  3.  0. 11. 11.  3. 11. 10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  2. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 6. 8. 6.] 
adversary cards in discard: [ 6.  8.  3.  0.  1.  6.  0. 10. 10. 29.  0.  3.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6] -> size -> 30 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 51.506771087646484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.095655]
 [24.24865 ]
 [33.9245  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.  3. 29.] 
cards in discard: [25.  3.  0. 11. 11.  3. 11. 10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  2. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 6. 8. 6.] 
adversary cards in discard: [ 6.  8.  3.  0.  1.  6.  0. 10. 10. 29.  0.  3.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6] -> size -> 30 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.56451416015625






Player: 1 
cards in hand: [0. 1. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 8. 6.] 
cards in discard: [ 6.  8.  3.  0.  1.  6.  0. 10. 10. 29.  0.  3.  3.  3.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  2. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  3.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 8. 6.] 
cards in discard: [ 6.  8.  3.  0.  1.  6.  0. 10. 10. 29.  0.  3.  3.  3.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  2. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  3.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
adversary victory points: 3
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11.  3.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[45.866444]
 [46.364006]
 [50.604675]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  2. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 1.  0. 11.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  0.  1.  6.  0. 10. 10. 29.  0.  3.  3.  3.  0.  6.  0.  1.
  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6] -> size -> 30 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.92450714111328



action possibilites: [-1] 
expected returns: [[69.754616]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  1. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 1.  0. 11.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  0.  1.  6.  0. 10. 10. 29.  0.  3.  3.  3.  0.  6.  0.  1.
  6.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 49.10969924926758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[61.00839 ]
 [64.192856]
 [56.89298 ]
 [63.93519 ]
 [66.57637 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  1. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 1.  0. 11.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  0.  1.  6.  0. 10. 10. 29.  0.  3.  3.  3.  0.  6.  0.  1.
  6.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 69.7546157836914






Player: 1 
cards in hand: [ 1.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  0.  0.] 
cards in discard: [ 6.  8.  3.  0.  1.  6.  0. 10. 10. 29.  0.  3.  3.  3.  0.  6.  0.  1.
  6.  8.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  1. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25. 10. 11. 29.  0.] 
adversary cards in discard: [25. 11.  3.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.  0.] 
cards in discard: [ 6.  8.  3.  0.  1.  6.  0. 10. 10. 29.  0.  3.  3.  3.  0.  6.  0.  1.
  6.  8.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 29. 30.  8.  1. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25. 10. 11. 29.  0.] 
adversary cards in discard: [25. 11.  3.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.  0.] 
cards in discard: [ 6.  8.  3.  0.  1.  6.  0. 10. 10. 29.  0.  3.  3.  3.  0.  6.  0.  1.
  6.  8.  6.  6.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8.  1. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25. 10. 11. 29.  0.] 
adversary cards in discard: [25. 11.  3.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
adversary victory points: 3
player victory points: -5 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [25. 10. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11. 29.] 
expected returns: [[39.22411 ]
 [46.068645]
 [34.335224]
 [39.940384]
 [43.23296 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 11. 29.  0.] 
cards in discard: [25. 11.  3.  0.  0. 29. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  1. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1] -> size -> 32 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 66.57636260986328



action possibilites: [-1] 
expected returns: [[50.76329]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29.  0. 10.  3.] 
cards in discard: [25. 11.  3.  0.  0. 29. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6] -> size -> 33 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.06864929199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[45.442932]
 [51.450775]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 29.  0. 10.  3.] 
cards in discard: [25. 11.  3.  0.  0. 29. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6] -> size -> 33 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.76329040527344






Player: 1 
cards in hand: [0. 6. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 0.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10. 11.] 
adversary cards in discard: [25. 11.  3.  0.  0. 29. 11. 25. 10. 11. 29.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 0.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10. 11.] 
adversary cards in discard: [25. 11.  3.  0.  0. 29. 11. 25. 10. 11. 29.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 0.] 
cards in discard: [6. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10. 11.] 
adversary cards in discard: [25. 11.  3.  0.  0. 29. 11. 25. 10. 11. 29.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[32.26884 ]
 [28.09636 ]
 [28.09636 ]
 [32.876945]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10. 11.] 
cards in discard: [25. 11.  3.  0.  0. 29. 11. 25. 10. 11. 29.  0. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 6.] 
adversary cards in discard: [6. 8. 0. 6. 6. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 51.450782775878906



action possibilites: [-1] 
expected returns: [[35.544327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [25. 11.  3.  0.  0. 29. 11. 25. 10. 11. 29.  0. 10.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 6.] 
adversary cards in discard: [6. 8. 0. 6. 6. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 349 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.75017547607422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[30.033066]
 [33.485165]
 [33.203827]
 [36.089363]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [25. 11.  3.  0.  0. 29. 11. 25. 10. 11. 29.  0. 10.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 6.] 
adversary cards in discard: [6. 8. 0. 6. 6. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.54432678222656






Player: 1 
cards in hand: [6. 3. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 6.] 
cards in discard: [6. 8. 0. 6. 6. 6. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 6.] 
cards in discard: [6. 8. 0. 6. 6. 6. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
adversary victory points: 3
player victory points: -6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[37.2633  ]
 [37.76883 ]
 [42.086174]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [6. 8. 0. 6. 6. 6. 0. 6. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 36.089359283447266



action possibilites: [-1] 
expected returns: [[55.589348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [6. 8. 0. 6. 6. 6. 0. 6. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.72154998779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[51.986877]
 [55.252228]
 [54.9897  ]
 [57.692593]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [6. 8. 0. 6. 6. 6. 0. 6. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.58934783935547






Player: 1 
cards in hand: [ 0. 10.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  3.  6.] 
cards in discard: [6. 8. 0. 6. 6. 6. 0. 6. 3. 0. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10.  0. 10. 10.] 
adversary cards in discard: [25. 11.  3.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  3.  6.] 
cards in discard: [6. 8. 0. 6. 6. 6. 0. 6. 3. 0. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10.  0. 10. 10.] 
adversary cards in discard: [25. 11.  3.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  3.  6.] 
cards in discard: [6. 8. 0. 6. 6. 6. 0. 6. 3. 0. 3. 6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10.  0. 10. 10.] 
adversary cards in discard: [25. 11.  3.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [25. 10.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10. 10.] 
expected returns: [[45.83395 ]
 [53.81634 ]
 [39.938038]
 [39.938038]
 [39.938038]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0. 10. 10.] 
cards in discard: [25. 11.  3.  0.  0.  3. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [1. 0. 8. 0. 1.] 
adversary cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.692596435546875



action possibilites: [-1] 
expected returns: [[38.22988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.  0. 29.] 
cards in discard: [25. 11.  3.  0.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [1. 0. 8. 0. 1.] 
adversary cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 53.81635284423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[33.577255]
 [37.220695]
 [36.924664]
 [39.92786 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.  0. 29.] 
cards in discard: [25. 11.  3.  0.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [1. 0. 8. 0. 1.] 
adversary cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.229881286621094






Player: 1 
cards in hand: [1. 0. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 0. 1.] 
cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [15.  0. 10. 11. 25.] 
adversary cards in discard: [25. 11.  3.  0.  0.  3. 29. 25. 10.  0. 10. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 0. 1.] 
cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 26. 30. 29. 30.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [15.  0. 10. 11. 25.] 
adversary cards in discard: [25. 11.  3.  0.  0.  3. 29. 25. 10.  0. 10. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 0. 1.] 
cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8  0  4] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 29. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [15.  0. 10. 11. 25.] 
adversary cards in discard: [25. 11.  3.  0.  0.  3. 29. 25. 10.  0. 10. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [15.  0. 10. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11. 25.] 
expected returns: [[28.358967]
 [26.606277]
 [24.44056 ]
 [28.965418]
 [34.143883]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10. 11. 25.] 
cards in discard: [25. 11.  3.  0.  0.  3. 29. 25. 10.  0. 10. 10.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 1. 0. 8.] 
adversary cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8  0  4] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 39.9278678894043



action possibilites: [-1] 
expected returns: [[43.371872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10. 11.  0. 11.] 
cards in discard: [25. 11.  3.  0.  0.  3. 29. 25. 10.  0. 10. 10.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 1. 0. 8.] 
adversary cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8  0  4] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.143882751464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[37.017914]
 [40.771294]
 [40.463818]
 [43.582146]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10. 11.  0. 11.] 
cards in discard: [25. 11.  3.  0.  0.  3. 29. 25. 10.  0. 10. 10.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 29. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 1. 0. 8.] 
adversary cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8  0  4] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.37187194824219






Player: 1 
cards in hand: [6. 0. 1. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 0. 8.] 
cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  0  8  6  1  3  6  6  1 10  6  6  0
  6  1 10  6  8  6  6  1  6  8  0  4] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 29. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11. 11. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[38.880737]
 [39.291466]
 [39.291466]
 [39.291466]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11.  6. 10. 29.  1.] 
adversary cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4] -> size -> 34 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 43.5821533203125



action possibilites: [-1] 
expected returns: [[52.651318]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0.] 
cards in discard: [15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11.  6. 10. 29.  1.] 
adversary cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4] -> size -> 34 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 259 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.152034759521484





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[49.428608]
 [53.950592]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  3.  0.] 
cards in discard: [15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 29. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11.  6. 10. 29.  1.] 
adversary cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4] -> size -> 34 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.65131759643555






Player: 1 
cards in hand: [11.  6. 10. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 10. 29.  1.] 
cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.  8.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [25. 29. 10. 10.  0.] 
adversary cards in discard: [15. 11. 11. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 29.  1.  3.] 
cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.  8.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [25. 29. 10. 10.  0.] 
adversary cards in discard: [15. 11. 11. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  1.  3.] 
cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.  8.  6.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [25. 29. 10. 10.  0.] 
adversary cards in discard: [15. 11. 11. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  1.  3.] 
cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.  8.  6.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  7.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [25. 29. 10. 10.  0.] 
adversary cards in discard: [15. 11. 11. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  1.  3.] 
cards in discard: [ 6.  8.  0.  6.  6.  6.  0.  6.  3.  0.  3.  6.  0.  0. 10.  6.  3.  6.
  4.  1.  0.  8.  0.  1.  8.  6.  0.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [25. 29. 10. 10.  0.] 
adversary cards in discard: [15. 11. 11. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [25. 29. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10. 10.] 
expected returns: [[62.5075  ]
 [69.79625 ]
 [66.70587 ]
 [57.238636]
 [57.238636]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 10. 10.  0.] 
cards in discard: [15. 11. 11. 11.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [29.  3.  6. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 53.95059585571289



action possibilites: [-1] 
expected returns: [[74.33851]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10.  0. 25.  0.] 
cards in discard: [15. 11. 11. 11.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [29.  3.  6. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 69.7962417602539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[68.88755]
 [73.15709]
 [72.81421]
 [76.29729]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 10.  0. 25.  0.] 
cards in discard: [15. 11. 11. 11.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [29.  3.  6. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.33850860595703






Player: 1 
cards in hand: [29.  3.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  6. 10.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 15.  3. 29.  0.] 
adversary cards in discard: [15. 11. 11. 11.  3.  0. 25. 29. 10. 10.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  6. 10.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 15.  3. 29.  0.] 
adversary cards in discard: [15. 11. 11. 11.  3.  0. 25. 29. 10. 10.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
adversary victory points: 3
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[55.7171  ]
 [53.24246 ]
 [60.583527]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3. 29.  0.] 
cards in discard: [15. 11. 11. 11.  3.  0. 25. 29. 10. 10.  0. 25.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 6. 8. 6. 0.] 
adversary cards in discard: [29.  3.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 76.29728698730469



action possibilites: [-1. 15.] 
expected returns: [[62.222107]
 [59.802113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.] 
cards in discard: [15. 11. 11. 11.  3.  0. 25. 29. 10. 10.  0. 25.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 6. 8. 6. 0.] 
adversary cards in discard: [29.  3.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 55.03006362915039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[56.599483]
 [62.54284 ]
 [60.235188]
 [60.451996]
 [64.1013  ]
 [59.941128]
 [68.115166]
 [55.182022]
 [57.819187]
 [60.864216]
 [63.20887 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0.] 
cards in discard: [15. 11. 11. 11.  3.  0. 25. 29. 10. 10.  0. 25.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  7. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 6. 8. 6. 0.] 
adversary cards in discard: [29.  3.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 62.22209930419922



buy possibilites: [-1] 
expected returns: [[49.007423]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0.] 
cards in discard: [15. 11. 11. 11.  3.  0. 25. 29. 10. 10.  0. 25.  0.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  6. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 6. 8. 6. 0.] 
adversary cards in discard: [29.  3.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 68.11515808105469






Player: 1 
cards in hand: [8. 6. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 8. 6. 0.] 
cards in discard: [29.  3.  6. 10.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  6. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 10.  0. 10. 11.] 
adversary cards in discard: [15. 11. 11. 11.  3.  0. 25. 29. 10. 10.  0. 25.  0.  3. 29. 29.  0. 15.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29] -> size -> 26 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 8. 6. 0.] 
cards in discard: [29.  3.  6. 10.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  6. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 10.  0. 10. 11.] 
adversary cards in discard: [15. 11. 11. 11.  3.  0. 25. 29. 10. 10.  0. 25.  0.  3. 29. 29.  0. 15.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29] -> size -> 26 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 8. 6. 0.] 
cards in discard: [29.  3.  6. 10.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  6. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 10.  0. 10. 11.] 
adversary cards in discard: [15. 11. 11. 11.  3.  0. 25. 29. 10. 10.  0. 25.  0.  3. 29. 29.  0. 15.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29] -> size -> 26 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[34.39162 ]
 [30.39811 ]
 [30.39811 ]
 [34.957123]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 10. 11.] 
cards in discard: [15. 11. 11. 11.  3.  0. 25. 29. 10. 10.  0. 25.  0.  3. 29. 29.  0. 15.
  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  6. 10. 10.  4. 10.  8.] 
adversary cards in hand: [6. 0. 3. 6. 1.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8  0] -> size -> 37 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.007423400878906



action possibilites: [-1] 
expected returns: [[43.37625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 10.] 
cards in discard: [15. 11. 11. 11.  3.  0. 25. 29. 10. 10.  0. 25.  0.  3. 29. 29.  0. 15.
  0.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [6. 0. 3. 6. 1.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8  0] -> size -> 37 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[38.23112]
 [43.5543 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 10.] 
cards in discard: [15. 11. 11. 11.  3.  0. 25. 29. 10. 10.  0. 25.  0.  3. 29. 29.  0. 15.
  0.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [6. 0. 3. 6. 1.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8  0] -> size -> 37 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.376251220703125






Player: 1 
cards in hand: [6. 0. 3. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6. 1.] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11. 10. 15. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 1.] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  6.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11. 10. 15. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 1.] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8  0  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11. 10. 15. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [11. 10. 15. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15. 11. 25.] 
expected returns: [[64.84411 ]
 [65.393814]
 [60.99994 ]
 [63.282936]
 [65.393814]
 [70.18134 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 15. 11. 25.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8  0  8] -> size -> 38 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 43.554298400878906



action possibilites: [-1] 
expected returns: [[98.47458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 15. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8  0  8] -> size -> 38 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 70.18135070800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[93.167435]
 [99.743095]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 15. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8  0  8] -> size -> 38 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 98.47457885742188






Player: 1 
cards in hand: [6. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29  0  8  6  3  6  6  1 10  6  6  0  6  1
 10  6  8  6  6  1  6  8  0  4  3  8  0  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11. 29. 25. 10. 15.] 
adversary cards in discard: [25. 11. 10. 15. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11. 29. 25. 10. 15.] 
adversary cards in discard: [25. 11. 10. 15. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11. 29. 25. 10. 15.] 
adversary cards in discard: [25. 11. 10. 15. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11. 29. 25. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25. 10. 15.] 
expected returns: [[ 96.35731 ]
 [ 97.19589 ]
 [101.054016]
 [104.334366]
 [ 90.29841 ]
 [ 93.91811 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 25. 10. 15.] 
cards in discard: [25. 11. 10. 15. 11. 11.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 11. 10.  3.  1.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 99.74310302734375



action possibilites: [-1] 
expected returns: [[94.18155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10. 15. 29.  0.] 
cards in discard: [25. 11. 10. 15. 11. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 11. 10.  3.  1.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 104.33436584472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[87.56604]
 [95.14241]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 10. 15. 29.  0.] 
cards in discard: [25. 11. 10. 15. 11. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 11. 10.  3.  1.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.18154907226562






Player: 1 
cards in hand: [ 0. 11. 10.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3.  1.] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 10. 29.  0.  3.] 
adversary cards in discard: [25. 11. 10. 15. 11. 11.  0. 25. 11. 29. 10. 15. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  3.  1.] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 10. 29.  0.  3.] 
adversary cards in discard: [25. 11. 10. 15. 11. 11.  0. 25. 11. 29. 10. 15. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  3.  1.] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.
  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 10. 29.  0.  3.] 
adversary cards in discard: [25. 11. 10. 15. 11. 11.  0. 25. 11. 29. 10. 15. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[82.80289 ]
 [77.528244]
 [86.94054 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.  0.  3.] 
cards in discard: [25. 11. 10. 15. 11. 11.  0. 25. 11. 29. 10. 15. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [8. 3. 4. 0. 6.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.
  1.  0. 11. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 95.14242553710938



action possibilites: [-1. 10. 10.] 
expected returns: [[57.60698]
 [52.46428]
 [52.46428]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 10.] 
cards in discard: [25. 11. 10. 15. 11. 11.  0. 25. 11. 29. 10. 15. 29.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [8. 3. 4. 0. 6.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.
  1.  0. 11. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 82.19296264648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[51.6481  ]
 [55.124565]
 [54.843018]
 [58.096436]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 10.] 
cards in discard: [25. 11. 10. 15. 11. 11.  0. 25. 11. 29. 10. 15. 29.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [8. 3. 4. 0. 6.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.
  1.  0. 11. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 57.60697937011719






Player: 1 
cards in hand: [8. 3. 4. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 4. 0. 6.] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.
  1.  0. 11. 10.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 15.  0. 25.  0.] 
adversary cards in discard: [25. 11. 10. 15. 11. 11.  0. 25. 11. 29. 10. 15. 29.  0.  3. 29. 10.  0.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 4. 0. 6.] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.
  1.  0. 11. 10.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 15.  0. 25.  0.] 
adversary cards in discard: [25. 11. 10. 15. 11. 11.  0. 25. 11. 29. 10. 15. 29.  0.  3. 29. 10.  0.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
adversary victory points: 3
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[46.971336]
 [45.061897]
 [53.424065]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 25.  0.] 
cards in discard: [25. 11. 10. 15. 11. 11.  0. 25. 11. 29. 10. 15. 29.  0.  3. 29. 10.  0.
  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [6. 0. 6. 0. 6.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.
  1.  0. 11. 10.  3.  1.  8.  3.  4.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.096435546875



action possibilites: [-1] 
expected returns: [[50.49498]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.  3.  0.] 
cards in discard: [25. 11. 10. 15. 11. 11.  0. 25. 11. 29. 10. 15. 29.  0.  3. 29. 10.  0.
  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [6. 0. 6. 0. 6.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.
  1.  0. 11. 10.  3.  1.  8.  3.  4.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 53.42406463623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[45.9378  ]
 [50.287655]
 [48.687016]
 [48.84885 ]
 [51.337048]
 [48.46873 ]
 [54.12374 ]
 [44.83005 ]
 [46.88531 ]
 [49.15676 ]
 [50.730812]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0.  3.  0.] 
cards in discard: [25. 11. 10. 15. 11. 11.  0. 25. 11. 29. 10. 15. 29.  0.  3. 29. 10.  0.
  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  5.  7.  6. 10. 10.  4. 10.  7.] 
adversary cards in hand: [6. 0. 6. 0. 6.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.
  1.  0. 11. 10.  3.  1.  8.  3.  4.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.49497985839844



buy possibilites: [-1] 
expected returns: [[57.160324]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0.  3.  0.] 
cards in discard: [25. 11. 10. 15. 11. 11.  0. 25. 11. 29. 10. 15. 29.  0.  3. 29. 10.  0.
  3. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  5.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [6. 0. 6. 0. 6.] 
adversary cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.
  1.  0. 11. 10.  3.  1.  8.  3.  4.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 54.123741149902344






Player: 1 
cards in hand: [6. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 6.] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.
  1.  0. 11. 10.  3.  1.  8.  3.  4.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  5.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 10.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29] -> size -> 28 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 6.] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.
  1.  0. 11. 10.  3.  1.  8.  3.  4.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  5.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 10.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29] -> size -> 28 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 6.] 
cards in discard: [29.  3.  6. 10.  0.  0.  8.  6.  8.  6.  0.  8.  6.  0.  3.  6.  1.  8.
  1.  0. 11. 10.  3.  1.  8.  3.  4.  0.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  4.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 10.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29] -> size -> 28 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[73.206825]
 [68.870285]
 [71.45436 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  4.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [29.  0.  6.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.16032409667969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[69.42751 ]
 [74.35801 ]
 [72.54399 ]
 [75.45147 ]
 [72.293526]
 [70.497444]
 [74.84628 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  5.  4.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [29.  0.  6.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 73.20682525634766



buy possibilites: [-1] 
expected returns: [[115.45441]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 15.  0.] 
cards in discard: [11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  4.  4.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [29.  0.  6.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 199 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 75.45146942138672






Player: 1 
cards in hand: [29.  0.  6.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  8.  1.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  4.  4.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11. 11. 25. 29. 25.] 
adversary cards in discard: [11.  0. 10.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 4.] 
cards in discard: [6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  4.  4.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11. 11. 25. 29. 25.] 
adversary cards in discard: [11.  0. 10.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 4.] 
cards in discard: [6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  4.  4.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11. 11. 25. 29. 25.] 
adversary cards in discard: [11.  0. 10.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 4.] 
cards in discard: [ 6. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  4.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11. 11. 25. 29. 25.] 
adversary cards in discard: [11.  0. 10.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [11. 11. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25. 29. 25.] 
expected returns: [[77.66563 ]
 [78.35748 ]
 [78.35748 ]
 [84.72651 ]
 [81.786026]
 [84.72651 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 25. 29. 25.] 
cards in discard: [11.  0. 10.  0. 15.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  4.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 1. 10. 11.  6.  6.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8 11] -> size -> 37 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 115.45440673828125



action possibilites: [-1] 
expected returns: [[96.576675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29. 25.  0. 15.] 
cards in discard: [11.  0. 10.  0. 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  4.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 1. 10. 11.  6.  6.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8 11] -> size -> 37 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 84.72650909423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[89.152954]
 [97.11934 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 29. 25.  0. 15.] 
cards in discard: [11.  0. 10.  0. 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  4.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 1. 10. 11.  6.  6.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8 11] -> size -> 37 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.57667541503906






Player: 1 
cards in hand: [ 1. 10. 11.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 11.  6.  6.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  4.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [29.  0.  0.  3. 15.] 
adversary cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 11.  6.  6.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  4.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [29.  0.  0.  3. 15.] 
adversary cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 11.  6.  6.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8 11  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [29.  0.  0.  3. 15.] 
adversary cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[84.93043 ]
 [90.547745]
 [82.155464]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3. 15.] 
cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10.  8.  1.  8.  0.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8 11  8] -> size -> 38 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 97.11934661865234



action possibilites: [-1. 15. 25.] 
expected returns: [[82.27905 ]
 [79.16701 ]
 [92.617096]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 25.] 
cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10.  8.  1.  8.  0.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8 11  8] -> size -> 38 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 84.16594696044922



action possibilites: [-1] 
expected returns: [[79.395874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0. 29.] 
cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10.  8.  1.  8.  0.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8 11  8] -> size -> 38 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 92.61709594726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[72.41692 ]
 [80.29287 ]
 [77.381775]
 [77.65654 ]
 [82.04883 ]
 [76.97665 ]
 [86.59272 ]
 [70.52855 ]
 [74.086174]
 [78.24217 ]
 [81.07045 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0. 29.] 
cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10.  8.  1.  8.  0.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8 11  8] -> size -> 38 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.3958740234375



buy possibilites: [-1] 
expected returns: [[91.27006]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0. 29.] 
cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.  3. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10.  8.  1.  8.  0.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8 11  8] -> size -> 38 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 313 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 86.59272766113281






Player: 1 
cards in hand: [10.  8.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  1.  8.  0.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29  0  8  3  6  6  1 10  6  6  0  6  1 10  6  8  6
  6  1  6  8  0  4  3  8  0  8  1  8 11  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10. 29.  3. 10. 10.] 
adversary cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.  3. 29. 29. 25.  0.
  0. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29] -> size -> 30 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11 29  0  8  3  6  6  6  6  0  6  1 10  6  8  6  6  1  6
  8  0  4  3  8  0  8  1  8 11  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10. 29.  3. 10. 10.] 
adversary cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.  3. 29. 29. 25.  0.
  0. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29] -> size -> 30 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11 29  0  8  3  6  6  6  6  0  6  1 10  6  8  6  6  1  6
  8  0  4  3  8  0  8  1  8 11  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10. 29.  3. 10. 10.] 
adversary cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.  3. 29. 29. 25.  0.
  0. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29] -> size -> 30 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10. 29.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 10.] 
expected returns: [[76.85311 ]
 [71.510155]
 [81.09747 ]
 [71.510155]
 [71.510155]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3. 10. 10.] 
cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.  3. 29. 29. 25.  0.
  0. 15.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  7.] 
adversary cards in hand: [8. 3. 8. 6. 3.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3 11 29  0  8  3  6  6  6  6  0  6  1 10  6  8  6  6  1  6
  8  0  4  3  8  0  8  1  8 11  8] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.27005767822266



action possibilites: [-1. 10. 10. 10. 11.] 
expected returns: [[73.53164 ]
 [68.9856  ]
 [68.9856  ]
 [68.9856  ]
 [74.243355]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 11.] 
cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.  3. 29. 29. 25.  0.
  0. 15.  0. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  7.] 
adversary cards in hand: [8. 3. 8. 6. 3.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3 11 29  0  8  3  6  6  6  6  0  6  1 10  6  8  6  6  1  6
  8  0  4  3  8  0  8  1  8 11  8] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 76.27360534667969



action possibilites: [-1] 
expected returns: [[80.37846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.  3. 29. 29. 25.  0.
  0. 15.  0. 29.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [8. 3. 8. 6. 3.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3 11 29  0  8  3  6  6  6  6  0  6  1 10  6  8  6  6  1  6
  8  0  4  3  8  0  8  1  8 11  8] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 249 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 76.35577392578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[74.42453]
 [80.39659]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [11.  0. 10.  0. 15.  0. 25. 11. 11. 29. 25.  0. 15.  3. 29. 29. 25.  0.
  0. 15.  0. 29.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [8. 3. 8. 6. 3.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3 11 29  0  8  3  6  6  6  6  0  6  1 10  6  8  6  6  1  6
  8  0  4  3  8  0  8  1  8 11  8] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.37846374511719






Player: 1 
cards in hand: [8. 3. 8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 6. 3.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 29  0  8  3  6  6  6  6  0  6  1 10  6  8  6  6  1  6
  8  0  4  3  8  0  8  1  8 11  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  3. 25. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 8. 6. 3.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 29  0  8  3  6  6  6  6  0  6  1 10  6  8  6  6  1  6
  8  0  4  3  8  0  8  1  8 11  8] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  3. 25. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
adversary victory points: 3
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 25. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[112.149475]
 [119.83508 ]
 [112.95538 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 11.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [6. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 29  0  8  3  6  6  6  6  0  6  1 10  6  8  6  6  1  6
  8  0  4  3  8  0  8  1  8 11  8] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.3965835571289



action possibilites: [-1] 
expected returns: [[146.89275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [6. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 29  0  8  3  6  6  6  6  0  6  1 10  6  8  6  6  1  6
  8  0  4  3  8  0  8  1  8 11  8] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 119.8350830078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[141.03114]
 [145.3582 ]
 [145.01003]
 [148.52321]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [6. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 29  0  8  3  6  6  6  6  0  6  1 10  6  8  6  6  1  6
  8  0  4  3  8  0  8  1  8 11  8] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 146.8927459716797






Player: 1 
cards in hand: [6. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 0. 3.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 29  0  8  3  6  6  6  6  0  6  1 10  6  8  6  6  1  6
  8  0  4  3  8  0  8  1  8 11  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [11. 29. 25. 15. 15.] 
adversary cards in discard: [25.  0.  3. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [11. 29. 25. 15. 15.] 
adversary cards in discard: [25.  0.  3. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [11. 29. 25. 15. 15.] 
adversary cards in discard: [25.  0.  3. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [11. 29. 25. 15. 15.] 
adversary cards in discard: [25.  0.  3. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11. 29. 25. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25. 15. 15.] 
expected returns: [[127.374725]
 [128.3323  ]
 [132.70667 ]
 [136.44246 ]
 [124.616264]
 [124.616264]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 25. 15. 15.] 
cards in discard: [25.  0.  3. 11.  3.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.  0.  8.] 
adversary owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 148.52320861816406



action possibilites: [-1] 
expected returns: [[126.25328]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 15. 15. 29.  0.] 
cards in discard: [25.  0.  3. 11.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.  0.  8.] 
adversary owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 136.44248962402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[118.04141]
 [126.38367]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 15. 15. 29.  0.] 
cards in discard: [25.  0.  3. 11.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.  0.  8.] 
adversary owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 126.25328063964844






Player: 1 
cards in hand: [0. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [10. 15. 29. 25. 11.] 
adversary cards in discard: [25.  0.  3. 11.  3.  3.  0. 25. 11. 29. 15. 15. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [10. 15. 29. 25. 11.] 
adversary cards in discard: [25.  0.  3. 11.  3.  3.  0. 25. 11. 29. 15. 15. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [10. 15. 29. 25. 11.] 
adversary cards in discard: [25.  0.  3. 11.  3.  3.  0. 25. 11. 29. 15. 15. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10. 15. 29. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 29. 25. 11.] 
expected returns: [[90.51302]
 [83.68591]
 [87.75934]
 [95.80029]
 [99.54682]
 [91.44492]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 29. 25. 11.] 
cards in discard: [25.  0.  3. 11.  3.  3.  0. 25. 11. 29. 15. 15. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [6. 0. 6. 6. 1.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.  0.  8.  0.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0  0] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 126.38365173339844



action possibilites: [-1] 
expected returns: [[92.785095]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 29. 11. 11.  0.] 
cards in discard: [25.  0.  3. 11.  3.  3.  0. 25. 11. 29. 15. 15. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [6. 0. 6. 6. 1.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.  0.  8.  0.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0  0] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.54684448242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[84.52231]
 [93.09613]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 29. 11. 11.  0.] 
cards in discard: [25.  0.  3. 11.  3.  3.  0. 25. 11. 29. 15. 15. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [6. 0. 6. 6. 1.] 
adversary cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.  0.  8.  0.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0  0] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.78509521484375






Player: 1 
cards in hand: [6. 0. 6. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6. 1.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.  0.  8.  0.  0.  6.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [10. 29. 11.  0.  0.] 
adversary cards in discard: [25.  0.  3. 11.  3.  3.  0. 25. 11. 29. 15. 15. 29.  0. 25. 10. 15. 29.
 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 1.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.  0.  8.  0.  0.  6.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  3.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [10. 29. 11.  0.  0.] 
adversary cards in discard: [25.  0.  3. 11.  3.  3.  0. 25. 11. 29. 15. 15. 29.  0. 25. 10. 15. 29.
 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 1.] 
cards in discard: [ 6. 11. 29.  0.  8.  1.  4.  8.  1. 10. 11.  6.  6.  8.  8.  8.  3.  8.
  6.  3.  0.  8.  0.  0.  6.  0.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [10. 29. 11.  0.  0.] 
adversary cards in discard: [25.  0.  3. 11.  3.  3.  0. 25. 11. 29. 15. 15. 29.  0. 25. 10. 15. 29.
 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10. 29. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[57.578808]
 [52.464096]
 [61.645027]
 [58.303772]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11.  0.  0.] 
cards in discard: [25.  0.  3. 11.  3.  3.  0. 25. 11. 29. 15. 15. 29.  0. 25. 10. 15. 29.
 11. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [10.  8. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0  0  8] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 93.09614562988281



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[40.374107]
 [37.3897  ]
 [40.81966 ]
 [37.3897  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10.] 
cards in discard: [25.  0.  3. 11.  3.  3.  0. 25. 11. 29. 15. 15. 29.  0. 25. 10. 15. 29.
 11. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  6.] 
adversary cards in hand: [10.  8. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0  0  8] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 56.992454528808594



action possibilites: [-1] 
expected returns: [[55.241165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [25.  0.  3. 11.  3.  3.  0. 25. 11. 29. 15. 15. 29.  0. 25. 10. 15. 29.
 11. 11.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [10.  8. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0  0  8] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 249 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.11046600341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[48.919476]
 [52.619728]
 [52.323242]
 [55.30705 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [25.  0.  3. 11.  3.  3.  0. 25. 11. 29. 15. 15. 29.  0. 25. 10. 15. 29.
 11. 11.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [10.  8. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0  0  8] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.24116516113281






Player: 1 
cards in hand: [10.  8. 11.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.  6.  8.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [10. 15. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1.  8. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  6.  8.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3
  8  0  8  1  8 11  8  0  0  8] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [10. 15. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3 29  0  8  3  6  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8
  0  8  1  8 11  8  0  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [10. 15. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [10. 15. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [10. 15. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [10. 15. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [10. 15. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 29. 10.] 
expected returns: [[118.94102 ]
 [114.013725]
 [116.93233 ]
 [123.09741 ]
 [114.013725]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [29.  0.  3.  6.  3.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 55.30705642700195



action possibilites: [-1. 10. 15. 10.] 
expected returns: [[126.02402]
 [120.65929]
 [123.83151]
 [120.65929]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10.  0.] 
cards in discard: [25.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [29.  0.  3.  6.  3.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 118.37462615966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[119.77875]
 [123.62068]
 [123.30705]
 [126.49817]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 10.  0.] 
cards in discard: [25.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [29.  0.  3.  6.  3.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 126.02401733398438






Player: 1 
cards in hand: [29.  0.  3.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  6.  3.] 
cards in discard: [ 0. 10.  8.  8.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [15. 11. 25. 29. 29.] 
adversary cards in discard: [25. 29. 10. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  6.  3.] 
cards in discard: [ 0. 10.  8.  8.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [15. 11. 25. 29. 29.] 
adversary cards in discard: [25. 29. 10. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  6.  3.] 
cards in discard: [ 0. 10.  8.  8.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [15. 11. 25. 29. 29.] 
adversary cards in discard: [25. 29. 10. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [15. 11. 25. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 25. 29. 29.] 
expected returns: [[143.0301 ]
 [140.60915]
 [143.85751]
 [150.97731]
 [147.69844]
 [147.69844]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 25. 29. 29.] 
cards in discard: [25. 29. 10. 15. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [6. 8. 6. 4. 0.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 126.4981689453125



action possibilites: [-1] 
expected returns: [[117.86988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 29. 29. 15.  3.] 
cards in discard: [25. 29. 10. 15. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [6. 8. 6. 4. 0.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 150.97731018066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[110.15089]
 [118.22525]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 29. 29. 15.  3.] 
cards in discard: [25. 29. 10. 15. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [6. 8. 6. 4. 0.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 117.86988067626953






Player: 1 
cards in hand: [6. 8. 6. 4. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 4. 0.] 
cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [11.  3. 29. 29. 15.] 
adversary cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 4. 0.] 
cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [11.  3. 29. 29. 15.] 
adversary cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [11.  3. 29. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 15.] 
expected returns: [[85.219345]
 [86.076126]
 [90.02454 ]
 [90.02454 ]
 [82.74263 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29. 29. 15.] 
cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 118.22525024414062



action possibilites: [-1. 11. 15.] 
expected returns: [[102.84954]
 [103.77115]
 [100.19689]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 15.  3.] 
cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  5.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 84.53077697753906



action possibilites: [-1] 
expected returns: [[80.35596]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.] 
cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  4.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 106.51519012451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[72.99016]
 [80.41583]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.] 
cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  4.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.35595703125






Player: 1 
cards in hand: [ 0.  6.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.  0.] 
cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  4.] 
adversary cards in hand: [11.  0. 11.  0.  0.] 
adversary cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15. 29. 11.  3.
 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.  0.] 
cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  4. 10.  4.] 
adversary cards in hand: [11.  0. 11.  0.  0.] 
adversary cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15. 29. 11.  3.
 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.  0.] 
cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  3. 10.  4.] 
adversary cards in hand: [11.  0. 11.  0.  0.] 
adversary cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15. 29. 11.  3.
 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[75.03885]
 [75.64008]
 [75.64008]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.  0.] 
cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15. 29. 11.  3.
 15.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  3. 10.  4.] 
adversary cards in hand: [1. 1. 6. 6. 3.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.  0.
  6.  0. 11.  0.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.41584014892578



action possibilites: [-1] 
expected returns: [[78.628044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15. 29. 11.  3.
 15.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  3. 10.  3.] 
adversary cards in hand: [1. 1. 6. 6. 3.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.  0.
  6.  0. 11.  0.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 77.4405517578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[70.90608 ]
 [77.67297 ]
 [75.126465]
 [79.21828 ]
 [74.77421 ]
 [72.31068 ]
 [78.34718 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15. 29. 11.  3.
 15.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  3.  2.  7.  4. 10. 10.  3. 10.  3.] 
adversary cards in hand: [1. 1. 6. 6. 3.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.  0.
  6.  0. 11.  0.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.62804412841797



buy possibilites: [-1] 
expected returns: [[61.791565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15. 29. 11.  3.
 15.  3. 15. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  2.  2.  7.  4. 10. 10.  3. 10.  3.] 
adversary cards in hand: [1. 1. 6. 6. 3.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.  0.
  6.  0. 11.  0.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 79.2182846069336






Player: 1 
cards in hand: [1. 1. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 6. 6. 3.] 
cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.  0.
  6.  0. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  2.  2.  7.  4. 10. 10.  3. 10.  3.] 
adversary cards in hand: [10. 11.  0. 15. 10.] 
adversary cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15. 29. 11.  3.
 15.  3. 15. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11] -> size -> 35 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 6. 6. 3.] 
cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.  0.
  6.  0. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  2.  2.  7.  4. 10. 10.  3. 10.  3.] 
adversary cards in hand: [10. 11.  0. 15. 10.] 
adversary cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15. 29. 11.  3.
 15.  3. 15. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11] -> size -> 35 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 6. 6. 3.] 
cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.  0.
  6.  0. 11.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  2.  2.  7.  4. 10. 10.  3. 10.  2.] 
adversary cards in hand: [10. 11.  0. 15. 10.] 
adversary cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15. 29. 11.  3.
 15.  3. 15. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11] -> size -> 35 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [10. 11.  0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 10.] 
expected returns: [[58.42857 ]
 [55.16468 ]
 [58.894875]
 [57.11481 ]
 [55.16468 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 15. 10.] 
cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15. 29. 11.  3.
 15.  3. 15. 11. 11.  0. 11.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  2.  2.  7.  4. 10. 10.  3. 10.  2.] 
adversary cards in hand: [1. 0. 0. 6. 8.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.  0.
  6.  0. 11.  0. 15.  1.  1.  6.  6.  3.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10 15] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.79156494140625



action possibilites: [-1] 
expected returns: [[48.642796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15. 10.] 
cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15. 29. 11.  3.
 15.  3. 15. 11. 11.  0. 11.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  2.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [1. 0. 0. 6. 8.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.  0.
  6.  0. 11.  0. 15.  1.  1.  6.  6.  3.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10 15] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 60.27766418457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[43.643085]
 [47.93696 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 15. 10.] 
cards in discard: [25. 29. 10. 15. 10.  0. 25. 15. 11. 29. 29. 15.  3. 29. 15. 29. 11.  3.
 15.  3. 15. 11. 11.  0. 11.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  2.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [1. 0. 0. 6. 8.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.  0.
  6.  0. 11.  0. 15.  1.  1.  6.  6.  3.] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10 15] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.64279556274414






Player: 1 
cards in hand: [1. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 6. 8.] 
cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.  0.
  6.  0. 11.  0. 15.  1.  1.  6.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  2.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15] -> size -> 36 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 8.] 
cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.  0.
  6.  0. 11.  0. 15.  1.  1.  6.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  2.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15] -> size -> 36 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 8.] 
cards in discard: [ 0. 10.  8.  8.  8.  0. 29.  0.  3.  6.  3.  6.  8.  6.  4.  0. 10.  0.
  6.  0. 11.  0. 15.  1.  1.  6.  6.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10 15 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  1.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15] -> size -> 36 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [29.  0. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[149.17012]
 [153.43855]
 [156.5023 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  1.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [6. 6. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10 15 11] -> size -> 37 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 47.93695831298828



action possibilites: [-1] 
expected returns: [[195.34178]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 15. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  1.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [6. 6. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10 15 11] -> size -> 37 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 156.50230407714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[188.6455 ]
 [195.51942]
 [193.01286]
 [197.02904]
 [192.66168]
 [190.15512]
 [196.20134]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0. 15. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  1.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [6. 6. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10 15 11] -> size -> 37 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 195.34178161621094



buy possibilites: [-1] 
expected returns: [[179.30598]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0. 15. 11.] 
cards in discard: [11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [6. 6. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10 15 11] -> size -> 37 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 197.02903747558594






Player: 1 
cards in hand: [6. 6. 8. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 8. 8.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  8  3  6  6  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0
  8  1  8 11  8  0  0  8  0  0 10 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [25. 10. 29.  3.  3.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [25. 10. 29.  3.  3.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [25. 10. 29.  3.  3.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [25. 10. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29.] 
expected returns: [[129.2242 ]
 [137.30447]
 [123.12138]
 [133.96901]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 29.  3.  3.] 
cards in discard: [11. 25. 29.  0.  0.  0. 15. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [8. 1. 0. 0. 8.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 179.3059844970703



action possibilites: [-1] 
expected returns: [[122.0939]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3.  3. 11. 15.] 
cards in discard: [11. 25. 29.  0.  0.  0. 15. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [8. 1. 0. 0. 8.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 137.3044891357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[114.41455 ]
 [122.253204]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  3.  3. 11. 15.] 
cards in discard: [11. 25. 29.  0.  0.  0. 15. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [8. 1. 0. 0. 8.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.09390258789062






Player: 1 
cards in hand: [8. 1. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 0. 8.] 
cards in discard: [8. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11. 11. 15. 10. 25.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0. 8.] 
cards in discard: [8. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  4. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11. 11. 15. 10. 25.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0. 8.] 
cards in discard: [ 8.  8. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  3. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11. 11. 15. 10. 25.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [11. 11. 15. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15. 10. 25.] 
expected returns: [[ 99.640205]
 [100.65922 ]
 [100.65922 ]
 [ 96.71724 ]
 [ 92.39362 ]
 [109.28031 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15. 10. 25.] 
cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  3. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 3.  0. 10. 29.  0.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8.] 
adversary owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 122.25320434570312



action possibilites: [-1] 
expected returns: [[89.422646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15. 10. 29. 15.] 
cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  3. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 3.  0. 10. 29.  0.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8.] 
adversary owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 109.28031921386719





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[80.78363]
 [88.9884 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 15. 10. 29. 15.] 
cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  3. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 3.  0. 10. 29.  0.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8.] 
adversary owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.42264556884766






Player: 1 
cards in hand: [ 3.  0. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 29.  0.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  3. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11.  0.  3.  0. 29.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0. 11.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  3. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11.  0.  3.  0. 29.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11.  0.  3.  0. 29.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 11. 29.] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11.  0.  3.  0. 29.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 11. 29.] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11.  0.  3.  0. 29.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 11. 29.] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11.  0.  3.  0. 29.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[89.60826]
 [90.39661]
 [93.98341]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 29.] 
cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  6.  0.  6. 11.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.] 
adversary owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29  0] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.98839569091797



action possibilites: [-1. 11.] 
expected returns: [[60.196278]
 [60.959465]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.] 
cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 28. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  6.  0.  6. 11.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.] 
adversary owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29  0] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 89.00862121582031



action possibilites: [-1] 
expected returns: [[51.781334]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.  0. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 30. 28. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  6.  0.  6. 11.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.] 
adversary owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29  0] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 92 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 59.612464904785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[45.627876]
 [48.67909 ]
 [48.432907]
 [50.90374 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.  0. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 24. 30. 28. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  6.  0.  6. 11.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.] 
adversary owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29  0] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.781333923339844






Player: 1 
cards in hand: [ 1.  6.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0.  6. 11.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 28. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29. 15. 11.  0. 15.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.  0. 10.  1. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 6.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29  0  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 28. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29. 15. 11.  0. 15.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.  0. 10.  1. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 6.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29  0  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 23. 30. 28. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29. 15. 11.  0. 15.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.  0. 10.  1. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 6.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29  0  1  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 27. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29. 15. 11.  0. 15.] 
adversary cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.  0. 10.  1. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [29. 15. 11.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 11. 15.] 
expected returns: [[40.53437 ]
 [42.876907]
 [39.35965 ]
 [40.957256]
 [39.35965 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 11.  0. 15.] 
cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.  0. 10.  1. 29. 11.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [8. 3. 8. 1. 0.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.] 
adversary owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29  0  1  3] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.90373992919922



action possibilites: [-1. 15. 15. 15.] 
expected returns: [[17.957981]
 [17.10966 ]
 [17.10966 ]
 [17.10966 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15.] 
cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.  0. 10.  1. 29. 11.  3.  0. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 27. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [8. 3. 8. 1. 0.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.] 
adversary owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29  0  1  3] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 40.22258758544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.358839]
 [17.957981]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 15.] 
cards in discard: [11. 25. 29.  0.  0.  0. 15. 11. 25. 10. 29.  3.  3. 11. 15. 25. 11. 11.
 15. 10. 29. 15.  0. 10.  1. 29. 11.  3.  0. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [21. 23. 30. 27. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [8. 3. 8. 1. 0.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.] 
adversary owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29  0  1  3] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.95797348022461






Player: 1 
cards in hand: [8. 3. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 1. 0.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  0  3  0  6  1 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8
 11  8  0  0  8  0  0 10 15 11 29 29  0  1  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0. 25. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8
  0  0  8  0  0 10 15 11 29 29  0  1  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0. 25. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8
  0  0  8  0  0 10 15 11 29 29  0  1  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 30. 27. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0. 25. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8
  0  0  8  0  0 10 15 11 29 29  0  1  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 27. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0. 25. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 10.] 
expected returns: [[149.17531]
 [157.4944 ]
 [146.63411]
 [142.86449]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 15. 10.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 4.  6.  6.  0. 15.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.  8.  8.  0.] 
adversary owned cards: [ 0 29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8
  0  0  8  0  0 10 15 11 29 29  0  1  3  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 17.95797348022461



action possibilites: [-1] 
expected returns: [[167.45323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 4.  6.  6.  0. 15.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.  8.  8.  0.] 
adversary owned cards: [ 0 29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8
  0  0  8  0  0 10 15 11 29 29  0  1  3  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 157.49440002441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[158.52315]
 [166.32631]
 [163.45421]
 [154.9472 ]
 [163.72403]
 [163.05226]
 [176.67747]
 [172.52016]
 [156.59949]
 [164.98476]
 [160.18015]
 [157.24107]
 [164.31296]
 [167.10046]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 23. 30. 27. 29.  8.  0. 10.  0.  2.  7.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 4.  6.  6.  0. 15.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.  8.  8.  0.] 
adversary owned cards: [ 0 29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8
  0  0  8  0  0 10 15 11 29 29  0  1  3  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 167.45323181152344



buy possibilites: [-1] 
expected returns: [[191.3589]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.  0.  0.  1.] 
cards in discard: [25.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 4.  6.  6.  0. 15.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.  8.  8.  0.] 
adversary owned cards: [ 0 29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8
  0  0  8  0  0 10 15 11 29 29  0  1  3  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -40   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 176.67747497558594






Player: 1 
cards in hand: [ 4.  6.  6.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  6.  6.  0. 15.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.  8.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8
  0  0  8  0  0 10 15 11 29 29  0  1  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29. 10. 15. 15. 15.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 6. 6.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.  8.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 23. 30. 27. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29. 10. 15. 15. 15.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 6. 6.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.  8.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 23. 30. 27. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29. 10. 15. 15. 15.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 6. 6.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.  8.  8.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29. 10. 15. 15. 15.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [29. 10. 15. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 15. 15. 15.] 
expected returns: [[117.73978 ]
 [123.21821 ]
 [110.620125]
 [114.86559 ]
 [114.86559 ]
 [114.86559 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 15. 15. 15.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.  8.  8.  0.  3. 15.  4.  6.  6.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 191.35890197753906



action possibilites: [-1. 10. 15. 15.] 
expected returns: [[103.58914 ]
 [ 95.903824]
 [100.47788 ]
 [100.47788 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 15.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.  8.  8.  0.  3. 15.  4.  6.  6.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 116.92779541015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 94.12433]
 [103.71617]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 15.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.  8.  8.  0.  3. 15.  4.  6.  6.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 103.58914184570312






Player: 1 
cards in hand: [0. 3. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8. 0.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.  8.  8.  0.  3. 15.  4.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15. 29. 11.  3. 10.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 8. 0.] 
cards in discard: [ 8.  8. 29.  8.  1.  0.  0.  8. 29.  3. 10.  0. 10. 11. 29.  0.  0.  1.
  3. 11.  1.  6.  0.  6.  0.  8.  8.  0.  3. 15.  4.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15. 29. 11.  3. 10.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [15. 29. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11. 10.] 
expected returns: [[105.04732 ]
 [102.343475]
 [110.28902 ]
 [105.96218 ]
 [ 98.37336 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 11.  3. 10.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29.  8.  8.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 103.7161865234375



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[81.66756 ]
 [82.61972 ]
 [75.08898 ]
 [87.012344]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29.  8.  8.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 108.78499603271484



action possibilites: [-1.] 
expected returns: [[82.12868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29.  8.  8.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 80.90216827392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[74.11965 ]
 [81.634674]
 [78.862785]
 [78.4758  ]
 [75.73428 ]
 [82.35915 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29.  8.  8.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 82.12867736816406






Player: 1 
cards in hand: [29.  8.  8.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  8.  1.  8.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11.  0. 11.  0.  3.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3.] 
cards in discard: [8. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11.  0. 11.  0.  3.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3.] 
cards in discard: [8. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11.  0. 11.  0.  3.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3.] 
cards in discard: [8. 1. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11.  0. 11.  0.  3.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [11.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[76.53545]
 [77.3339 ]
 [77.3339 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.  3.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0.  3. 11.  0. 29.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.35914611816406



action possibilites: [-1] 
expected returns: [[65.80777]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0.  3. 11.  0. 29.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 22 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 75.91226196289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[58.531906]
 [61.697735]
 [61.442955]
 [64.09571 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 22. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0.  3. 11.  0. 29.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.80776977539062






Player: 1 
cards in hand: [ 0.  3. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0. 29.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15.  0. 11. 15. 25.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.  1. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1] -> size -> 40 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0. 29.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 22. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15.  0. 11. 15. 25.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.  1. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1] -> size -> 40 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0. 29.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 22. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15.  0. 11. 15. 25.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.  1. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1] -> size -> 40 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [15.  0. 11. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 15. 25.] 
expected returns: [[37.29845]
 [36.11432]
 [37.72785]
 [36.11432]
 [41.47344]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11. 15. 25.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.  1. 11.  0. 11.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 8. 10.  1.  6.  0.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.09571838378906



action possibilites: [-1] 
expected returns: [[30.184204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11. 15. 29. 29.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.  1. 11.  0. 11.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 8. 10.  1.  6.  0.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.47343444824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.30297 ]
 [30.184204]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 11. 15. 29. 29.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.  1. 11.  0. 11.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 22. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 8. 10.  1.  6.  0.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.1842041015625






Player: 1 
cards in hand: [ 8. 10.  1.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  1.  6.  0.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11.  3. 10. 11. 15.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.  1. 11.  0. 11.  0.  3. 25. 15.  0. 11. 15. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1] -> size -> 40 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  1.  6.  0.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 22. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [11.  3. 10. 11. 15.] 
adversary cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.  1. 11.  0. 11.  0.  3. 25. 15.  0. 11. 15. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1] -> size -> 40 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [11.  3. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 15.] 
expected returns: [[48.230816]
 [48.762474]
 [44.43249 ]
 [48.762474]
 [46.701633]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 11. 15.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.  1. 11.  0. 11.  0.  3. 25. 15.  0. 11. 15. 29. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0.  6. 11.  0.  6.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 30.1842041015625



action possibilites: [-1] 
expected returns: [[21.78299]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 15.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.  1. 11.  0. 11.  0.  3. 25. 15.  0. 11. 15. 29. 29.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0.  6. 11.  0.  6.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 47.812007904052734





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.223206]
 [21.78299 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 15.] 
cards in discard: [25. 25.  0. 15. 10.  0.  0.  1. 15. 25. 29. 10. 15. 15. 15.  3. 11. 10.
 29. 29.  0.  1. 11.  0. 11.  0.  3. 25. 15.  0. 11. 15. 29. 29.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 21. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0.  6. 11.  0.  6.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.782989501953125






Player: 1 
cards in hand: [ 0.  6. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  0.  6.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 3. 10. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  0.  6.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 21. 30. 26. 29.  8.  0. 10.  0.  2.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 3. 10. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  0.  6.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 3. 10. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 11.] 
expected returns: [[155.1665 ]
 [149.65645]
 [159.51398]
 [155.9147 ]
 [155.9147 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29. 11. 11.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [10.  4.  8.  3.  0.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 21.782989501953125



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[162.04367]
 [162.86742]
 [162.86742]
 [162.86742]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.] 
cards in discard: [ 3. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 21. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [10.  4.  8.  3.  0.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 154.5383758544922



action possibilites: [-1] 
expected returns: [[153.83583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.] 
cards in discard: [ 3. 10.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [10.  4.  8.  3.  0.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -70   0   0  27   0] 
sum of rewards: 22 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 161.37249755859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[147.07892]
 [153.87733]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.] 
cards in discard: [ 3. 10.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [10.  4.  8.  3.  0.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 153.83583068847656






Player: 1 
cards in hand: [10.  4.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  4.  8.  3.  0.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [25.  0. 15.  0. 29.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 8. 3. 0. 3.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [25.  0. 15.  0. 29.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 8. 3. 0. 3.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [25.  0. 15.  0. 29.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [25.  0. 15.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 29.] 
expected returns: [[114.72063 ]
 [124.94856 ]
 [111.713745]
 [120.7159  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 15.  0. 29.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15.  0.  6.  0.  6.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 153.87734985351562



action possibilites: [-1] 
expected returns: [[87.50385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 29. 29. 10.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15.  0.  6.  0.  6.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 124.94856262207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[80.48884]
 [84.96884]
 [84.60399]
 [88.27684]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 29. 29. 10.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15.  0.  6.  0.  6.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.] 
adversary owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.50385284423828






Player: 1 
cards in hand: [15.  0.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.  0.  6.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0
  0  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [10. 11.  1. 15. 25.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0
  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [10. 11.  1. 15. 25.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0
  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [10. 11.  1. 15. 25.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0
  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [10. 11.  1. 15. 25.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [10. 11.  1. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 25.] 
expected returns: [[52.906105]
 [48.35146 ]
 [53.548096]
 [51.049232]
 [59.27764 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  1. 15. 25.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0.  8.  8.  0. 29.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.  0. 15.  6.  0.  6.] 
adversary owned cards: [29  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0
  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.27685546875



action possibilites: [-1] 
expected returns: [[63.904526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  1. 15.  0.  1.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0.  8.  8.  0. 29.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.  0. 15.  6.  0.  6.] 
adversary owned cards: [29  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0
  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 59.277645111083984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[55.087543]
 [61.05049 ]
 [58.87049 ]
 [52.311867]
 [59.09195 ]
 [58.569077]
 [68.71897 ]
 [65.76688 ]
 [53.570103]
 [60.037533]
 [56.389313]
 [54.086914]
 [59.51467 ]
 [61.60611 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  1. 15.  0.  1.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 20. 30. 26. 29.  8.  0. 10.  0.  1.  6.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0.  8.  8.  0. 29.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.  0. 15.  6.  0.  6.] 
adversary owned cards: [29  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0
  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.90452575683594



buy possibilites: [-1] 
expected returns: [[62.870743]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  1. 15.  0.  1.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0.  8.  8.  0. 29.] 
adversary cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.  0. 15.  6.  0.  6.] 
adversary owned cards: [29  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0
  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -80   0   0 250   0] 
sum of rewards: 215 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 68.71896362304688






Player: 1 
cards in hand: [ 0.  8.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8.  0. 29.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.  0. 15.  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  0  6 10  6  8  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0
  8  0  0 10 15 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15. 15. 11. 15. 15.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25] -> size -> 43 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.  0. 15.  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  6 10  6  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0
 10 15 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15. 15. 11. 15. 15.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25] -> size -> 43 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  1.  0. 29.  8.  8.  3.  0.  0.  3. 11.  0. 29.  8. 10.  1.  6.  0.
  8.  0.  6. 11.  0.  6. 10.  4.  8.  3.  0.  3.  0. 15.  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  6 10  6  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0
 10 15 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 20. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15. 15. 11. 15. 15.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25] -> size -> 43 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [15. 15. 11. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 11. 15. 15.] 
expected returns: [[55.465305]
 [53.730797]
 [53.730797]
 [56.071518]
 [53.730797]
 [53.730797]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 11. 15. 15.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [8. 8. 6. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  6 10  6  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0
 10 15 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.87074279785156



action possibilites: [-1] 
expected returns: [[50.413277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 19. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [8. 8. 6. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  6 10  6  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0
 10 15 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -90   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 54.993690490722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[46.24813 ]
 [50.413273]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 15. 15.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 19. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [8. 8. 6. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  6 10  6  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0
 10 15 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.41327667236328






Player: 1 
cards in hand: [8. 8. 6. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6. 6. 1.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  6 10  6  6  6  1  6  8  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0
 10 15 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 19. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15.  0. 11.  3. 29.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1. 11. 15. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1] -> size -> 44 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  6 10  6  6  6  6  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0 10 15
 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 19. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15.  0. 11.  3. 29.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1. 11. 15. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1] -> size -> 44 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  6 10  6  6  6  6  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0 10 15
 11 29 29  0  1  3  0  3  0  0  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 19. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15.  0. 11.  3. 29.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1. 11. 15. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1] -> size -> 44 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  6 10  6  6  6  6  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0 10 15
 11 29 29  0  1  3  0  3  0  0  8  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 19. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [15.  0. 11.  3. 29.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1. 11. 15. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1] -> size -> 44 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [15.  0. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29.] 
expected returns: [[38.0409  ]
 [36.78482 ]
 [38.499153]
 [40.619843]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11.  3. 29.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1. 11. 15. 15. 15. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 19. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [10.  3.  0.  3. 29.] 
adversary cards in discard: [0. 8. 6. 6.] 
adversary owned cards: [ 3  6 10  6  6  6  6  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0 10 15
 11 29 29  0  1  3  0  3  0  0  8  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.41327667236328



action possibilites: [-1. 15. 11.] 
expected returns: [[27.98278 ]
 [26.792257]
 [28.415522]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1. 11. 15. 15. 15. 15.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 19. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [10.  3.  0.  3. 29.] 
adversary cards in discard: [0. 8. 6. 6.] 
adversary owned cards: [ 3  6 10  6  6  6  6  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0 10 15
 11 29 29  0  1  3  0  3  0  0  8  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.6978759765625



action possibilites: [-1] 
expected returns: [[35.927036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1. 11. 15. 15. 15. 15.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [10.  3.  0.  3. 29.] 
adversary cards in discard: [0. 8. 6. 6.] 
adversary owned cards: [ 3  6 10  6  6  6  6  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0 10 15
 11 29 29  0  1  3  0  3  0  0  8  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   40    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: -8 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 27.670307159423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[32.237503]
 [35.927044]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1. 11. 15. 15. 15. 15.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [10.  3.  0.  3. 29.] 
adversary cards in discard: [0. 8. 6. 6.] 
adversary owned cards: [ 3  6 10  6  6  6  6  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0 10 15
 11 29 29  0  1  3  0  3  0  0  8  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.92703628540039






Player: 1 
cards in hand: [10.  3.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3. 29.] 
cards in discard: [0. 8. 6. 6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  6 10  6  6  6  6  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0 10 15
 11 29 29  0  1  3  0  3  0  0  8  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [25.  0. 25. 11.  1.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1. 11. 15. 15. 15. 15.  0.  0.  1. 29. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3. 29.] 
cards in discard: [0. 8. 6. 6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  6 10  6  6  6  6  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0 10 15
 11 29 29  0  1  3  0  3  0  0  8  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [25.  0. 25. 11.  1.] 
adversary cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1. 11. 15. 15. 15. 15.  0.  0.  1. 29. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [25.  0. 25. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 11.] 
expected returns: [[17.778067]
 [20.423435]
 [20.423435]
 [18.067772]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25. 11.  1.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1. 11. 15. 15. 15. 15.  0.  0.  1. 29. 11. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0. 15.  0.  4.  8.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.] 
adversary owned cards: [ 3  6 10  6  6  6  6  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0 10 15
 11 29 29  0  1  3  0  3  0  0  8  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 35.92703628540039



action possibilites: [-1] 
expected returns: [[13.957588]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  1. 29. 15.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1. 11. 15. 15. 15. 15.  0.  0.  1. 29. 11. 15.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0. 15.  0.  4.  8.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.] 
adversary owned cards: [ 3  6 10  6  6  6  6  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0 10 15
 11 29 29  0  1  3  0  3  0  0  8  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 20.423431396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[12.894562]
 [13.894468]
 [13.47036 ]
 [13.41844 ]
 [13.083563]
 [13.957584]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 11.  1. 29. 15.] 
cards in discard: [ 3. 10.  1. 29. 11. 11. 11. 25.  0. 15.  0. 29. 29. 10. 25. 25. 10. 11.
  1. 15.  0.  1.  1. 11. 15. 15. 15. 15.  0.  0.  1. 29. 11. 15.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0. 15.  0.  4.  8.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.] 
adversary owned cards: [ 3  6 10  6  6  6  6  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0 10 15
 11 29 29  0  1  3  0  3  0  0  8  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.957588195800781






Player: 1 
cards in hand: [ 0. 15.  0.  4.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  4.  8.] 
cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  6 10  6  6  6  6  0  4  3  8  0  8  1  8 11  8  0  0  8  0  0 10 15
 11 29 29  0  1  3  0  3  0  0  8  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  6 10  6  6  6  6  0  3  8  0  8  1  8 11  8  0  0  8  0  0 10 11 29
 29  0  1  3  0  3  0  0  8  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1] -> size -> 45 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  6 10  6  6  6  6  0  3  8  0  8  1  8 11  8  0  0  8  0  0 10 11 29
 29  0  1  3  0  3  0  0  8  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1] -> size -> 45 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[137.24135]
 [131.87845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29.  8.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.] 
adversary owned cards: [ 3  6 10  6  6  6  6  0  3  8  0  8  1  8 11  8  0  0  8  0  0 10 11 29
 29  0  1  3  0  3  0  0  8  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 13.957588195800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[131.27257]
 [137.4278 ]
 [135.1652 ]
 [135.37257]
 [134.851  ]
 [142.34608]
 [129.74648]
 [132.61021]
 [135.83775]
 [138.05872]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  2. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29.  8.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.] 
adversary owned cards: [ 3  6 10  6  6  6  6  0  3  8  0  8  1  8 11  8  0  0  8  0  0 10 11 29
 29  0  1  3  0  3  0  0  8  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 137.24136352539062



buy possibilites: [-1] 
expected returns: [[133.36836]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  3.  0.] 
cards in discard: [29.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29.  8.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.] 
adversary owned cards: [ 3  6 10  6  6  6  6  0  3  8  0  8  1  8 11  8  0  0  8  0  0 10 11 29
 29  0  1  3  0  3  0  0  8  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  120    0    0    0    0    0    0    0 -110    0    0
  128    0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 142.34608459472656






Player: 1 
cards in hand: [29.  8.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  6.  0.  0.] 
cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  6 10  6  6  6  6  0  3  8  0  8  1  8 11  8  0  0  8  0  0 10 11 29
 29  0  1  3  0  3  0  0  8  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0. 29.  1. 25. 11.] 
adversary cards in discard: [29.  1.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29] -> size -> 46 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  6 10  6  6  6  6  0  3  8  0  8  1  8 11  8  0  0  8  0  0 10 11 29
 29  0  1  3  0  3  0  0  8  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0. 29.  1. 25. 11.] 
adversary cards in discard: [29.  1.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29] -> size -> 46 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  6 10  6  6  6  6  0  3  8  0  8  1  8 11  8  0  0  8  0  0 10 11 29
 29  0  1  3  0  3  0  0  8  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 0. 29.  1. 25. 11.] 
adversary cards in discard: [29.  1.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29] -> size -> 46 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  1. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11.] 
expected returns: [[150.00941]
 [154.39413]
 [157.49565]
 [150.78964]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1. 25. 11.] 
cards in discard: [29.  1.  0. 10.  3.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [8. 6. 1. 3. 0.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6. 29.  0.  0.  0.] 
adversary owned cards: [ 3  6 10  6  6  6  6  0  3  8  0  8  1  8 11  8  0  0  8  0  0 10 11 29
 29  0  1  3  0  3  0  0  8  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 133.3683624267578



action possibilites: [-1] 
expected returns: [[137.63655]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1. 11.  3. 11.] 
cards in discard: [29.  1.  0. 10.  3.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [8. 6. 1. 3. 0.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6. 29.  0.  0.  0.] 
adversary owned cards: [ 3  6 10  6  6  6  6  0  3  8  0  8  1  8 11  8  0  0  8  0  0 10 11 29
 29  0  1  3  0  3  0  0  8  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 157.4956512451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[127.567154]
 [136.40147 ]
 [133.17625 ]
 [132.72552 ]
 [129.5003  ]
 [137.24434 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1. 11.  3. 11.] 
cards in discard: [29.  1.  0. 10.  3.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [8. 6. 1. 3. 0.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6. 29.  0.  0.  0.] 
adversary owned cards: [ 3  6 10  6  6  6  6  0  3  8  0  8  1  8 11  8  0  0  8  0  0 10 11 29
 29  0  1  3  0  3  0  0  8  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 137.6365509033203






Player: 1 
cards in hand: [8. 6. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 1. 3. 0.] 
cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6. 29.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  6 10  6  6  6  6  0  3  8  0  8  1  8 11  8  0  0  8  0  0 10 11 29
 29  0  1  3  0  3  0  0  8  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  0. 25. 29. 15.] 
adversary cards in discard: [29.  1.  0. 10.  3.  0. 25.  0. 29.  1. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29] -> size -> 46 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6. 29.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6 10  6  6  6  6  3  8  0  8  8 11  8  0  0  8  0  0 10 11 29 29  0  1
  3  0  3  0  0  8  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  0. 25. 29. 15.] 
adversary cards in discard: [29.  1.  0. 10.  3.  0. 25.  0. 29.  1. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29] -> size -> 46 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6. 29.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6 10  6  6  6  6  3  8  0  8  8 11  8  0  0  8  0  0 10 11 29 29  0  1
  3  0  3  0  0  8  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  0. 25. 29. 15.] 
adversary cards in discard: [29.  1.  0. 10.  3.  0. 25.  0. 29.  1. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29] -> size -> 46 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 25. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 15.] 
expected returns: [[ 99.61157]
 [109.82801]
 [105.59277]
 [ 96.51856]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25. 29. 15.] 
cards in discard: [29.  1.  0. 10.  3.  0. 25.  0. 29.  1. 11.  3. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  0.  8.  0. 11.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6. 29.  0.  0.  0.
  8.  6.] 
adversary owned cards: [ 6 10  6  6  6  6  3  8  0  8  8 11  8  0  0  8  0  0 10 11 29 29  0  1
  3  0  3  0  0  8  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 137.24432373046875



action possibilites: [-1] 
expected returns: [[94.28773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 15. 25.  1.] 
cards in discard: [29.  1.  0. 10.  3.  0. 25.  0. 29.  1. 11.  3. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  0.  8.  0. 11.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6. 29.  0.  0.  0.
  8.  6.] 
adversary owned cards: [ 6 10  6  6  6  6  3  8  0  8  8 11  8  0  0  8  0  0 10 11 29 29  0  1
  3  0  3  0  0  8  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 109.82801055908203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[81.27672 ]
 [89.009735]
 [86.18363 ]
 [77.6811  ]
 [86.44899 ]
 [85.788055]
 [98.8969  ]
 [95.094986]
 [79.30586 ]
 [87.684654]
 [82.96984 ]
 [79.963326]
 [87.02372 ]
 [89.76888 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29. 15. 25.  1.] 
cards in discard: [29.  1.  0. 10.  3.  0. 25.  0. 29.  1. 11.  3. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  5.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  0.  8.  0. 11.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6. 29.  0.  0.  0.
  8.  6.] 
adversary owned cards: [ 6 10  6  6  6  6  3  8  0  8  8 11  8  0  0  8  0  0 10 11 29 29  0  1
  3  0  3  0  0  8  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.28772735595703



buy possibilites: [-1] 
expected returns: [[105.46518]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29. 15. 25.  1.] 
cards in discard: [29.  1.  0. 10.  3.  0. 25.  0. 29.  1. 11.  3. 11. 25.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29 25] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  4.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [ 1.  0.  8.  0. 11.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6. 29.  0.  0.  0.
  8.  6.] 
adversary owned cards: [ 6 10  6  6  6  6  3  8  0  8  8 11  8  0  0  8  0  0 10 11 29 29  0  1
  3  0  3  0  0  8  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  150    0    0   20    0    0    0    0 -120    0    0
  250    0] 
sum of rewards: 295 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 98.89689636230469






Player: 1 
cards in hand: [ 1.  0.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8.  0. 11.] 
cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6. 29.  0.  0.  0.
  8.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 10  6  6  6  6  3  8  0  8  8 11  8  0  0  8  0  0 10 11 29 29  0  1
  3  0  3  0  0  8  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  1.  4.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [29. 11. 15. 29. 15.] 
adversary cards in discard: [29.  1.  0. 10.  3.  0. 25.  0. 29.  1. 11.  3. 11. 25. 25.  1.  0. 29.
 15. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29 25] -> size -> 47 
adversary victory points: 3
player victory points: -2 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 0 
Witch: 6 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29. 11. 15. 29. 15.] 
cards in discard: [29.  1.  0. 10.  3.  0. 25.  0. 29.  1. 11.  3. 11. 25. 25.  1.  0. 29.
 15. 25.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11 25 29 10 11 11 10 10 25 15
 15 29 15 29 11 29 15 15 15 15 11 15 11  1 25  1  1  1 25  1  1 29 25] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 26. 29.  8.  0. 10.  0.  0.  4.  1. 10. 10.  3. 10.  1.] 
adversary cards in hand: [1. 0. 8. 0.] 
adversary cards in discard: [ 0.  8.  6.  6. 10.  3.  0.  3. 29.  8.  0.  0.  8.  6. 29.  0.  0.  0.
  8.  6.  8.] 
adversary owned cards: [ 6 10  6  6  6  6  3  8  0  8  8 11  8  0  0  8  0  0 10 11 29 29  0  1
  3  0  3  0  0  8  0  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     150       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000145 

action type: buy - action -1
Learning step: 120001.578125
desired expected reward: 120107.046875



