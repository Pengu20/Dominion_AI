 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[311.7894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3  -10    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -512 

action type: buy - action -1.0
Learning step: -34.43484115600586
desired expected reward: 142.26197814941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[288.08923]
 [296.12445]
 [295.37326]
 [278.21973]
 [305.66925]
 [297.42044]
 [296.7804 ]
 [315.09097]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.98462200164795
desired expected reward: 305.1187744140625



buy possibilites: [-1] 
expected returns: [[286.36755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 10.0
Learning step: -7.595752716064453
desired expected reward: 289.1846923828125






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[305.7691]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.495792388916016
desired expected reward: 278.87176513671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[285.58084]
 [293.83173]
 [293.11053]
 [275.25076]
 [291.32355]
 [303.45377]
 [295.1272 ]
 [301.7981 ]
 [285.7282 ]
 [294.51608]
 [294.66583]
 [313.06906]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.717476844787598
desired expected reward: 298.9530029296875



buy possibilites: [-1] 
expected returns: [[304.1236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  3.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -9.036259651184082
desired expected reward: 276.5445556640625






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[325.61847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.938417911529541
desired expected reward: 296.1851806640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[309.41412]
 [316.34058]
 [315.48026]
 [300.7389 ]
 [314.17975]
 [324.16647]
 [317.4676 ]
 [322.87772]
 [309.34497]
 [316.6837 ]
 [316.74765]
 [331.63486]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.234691619873047
desired expected reward: 318.2214050292969



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8. 3. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 1] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[342.46808]
 [323.388  ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  3.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 1] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.08150577545166
desired expected reward: 322.5533752441406



action possibilites: [-1.] 
expected returns: [[360.2942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 1] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 19 

action type: take_action - action 10.0
Learning step: -7.169491767883301
desired expected reward: 317.35272216796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[335.30078]
 [343.51974]
 [342.7307 ]
 [325.01038]
 [352.57172]
 [344.7791 ]
 [344.08606]
 [361.372  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 1] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -9.241284370422363
desired expected reward: 351.05291748046875



buy possibilites: [-1] 
expected returns: [[338.73846]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 3. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 1] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 20.0 

action type: buy - action 8.0
Learning step: -8.617340087890625
desired expected reward: 336.1617736816406






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [1. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 1] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 1] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 1 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[325.06702]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 1 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -10.20802116394043
desired expected reward: 328.53045654296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[296.96988]
 [305.0482 ]
 [304.3928 ]
 [286.9948 ]
 [302.5982 ]
 [314.54636]
 [306.3157 ]
 [312.93073]
 [297.16565]
 [305.77423]
 [305.95502]
 [323.20697]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 1 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.876800537109375
desired expected reward: 315.8522033691406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [3. 1. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 1 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [3. 1. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 1 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[320.34808]
 [302.935  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 1 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.636672973632812
desired expected reward: 313.57025146484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[298.60977]
 [306.49216]
 [305.70468]
 [288.83517]
 [315.543  ]
 [307.7511 ]
 [307.05914]
 [324.45203]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 1 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.66618824005127
desired expected reward: 312.5279235839844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 1 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 1 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 1 3 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [10.  3.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[310.14288]
 [291.92343]
 [292.4649 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 1.] 
adversary cards in discard: [0. 3. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 1 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.982609748840332
desired expected reward: 314.469482421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[276.0359 ]
 [266.41202]
 [302.76132]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 1.] 
adversary cards in discard: [0. 3. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 1 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.514655113220215
desired expected reward: 298.9051513671875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 1.] 
cards in discard: [0. 3. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 1 3 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 1.] 
cards in discard: [0. 3. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 1 3 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 1.] 
cards in discard: [ 0.  3.  3.  0.  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[303.45306]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -8.894147872924805
desired expected reward: 293.8672180175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[280.32352]
 [287.79697]
 [287.06244]
 [271.03616]
 [285.5148 ]
 [296.41336]
 [288.99017]
 [294.94852]
 [280.38702]
 [288.35052]
 [288.4498 ]
 [304.8296 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.197121620178223
desired expected reward: 294.97711181640625



buy possibilites: [-1] 
expected returns: [[307.9404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  8.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -10.0 

action type: buy - action 8.0
Learning step: -8.020848274230957
desired expected reward: 280.96929931640625






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [1. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[265.38748]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [29.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.968716621398926
desired expected reward: 297.9716796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[248.19357]
 [253.79276]
 [252.79507]
 [242.8458 ]
 [240.8713 ]
 [251.99413]
 [259.64502]
 [254.75124]
 [264.6906 ]
 [258.7922 ]
 [247.89827]
 [250.99045]
 [253.79405]
 [245.13956]
 [253.74918]
 [265.4491 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [29.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.207058906555176
desired expected reward: 259.717529296875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0.  0.] 
cards in discard: [29.  1.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [29.  1.  0.  3.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [29.  1.  0.  3.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [29.  1.  0.  3.  3.  0.  6. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[329.94528]
 [317.2715 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -6.062832832336426
desired expected reward: 259.38623046875



action possibilites: [-1] 
expected returns: [[273.85544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 10  0  8  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 7
Learning step: -9.328271865844727
desired expected reward: 296.47210693359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[260.16916]
 [253.52025]
 [278.9038 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 10  0  8  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -7.831326484680176
desired expected reward: 266.02410888671875



buy possibilites: [-1] 
expected returns: [[264.12454]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 0. 0. 0. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -315.0 

action type: buy - action 6.0
Learning step: -22.48320960998535
desired expected reward: 231.03700256347656






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [29. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  8.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  8.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10] -> size -> 16 
action values: 2 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  8.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  8.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  8.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [ 6.  8.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[295.12564]
 [278.57233]
 [277.73346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  1.  0.] 
adversary cards in discard: [10. 10. 29.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -8.458812713623047
desired expected reward: 255.6657257080078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[271.6383 ]
 [262.8493 ]
 [295.82504]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  1.  0.] 
adversary cards in discard: [10. 10. 29.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -10.202621459960938
desired expected reward: 286.428466796875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  1.  0.] 
cards in discard: [10. 10. 29.  0.  3.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  8.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [10. 10. 29.  0.  3.  3.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  8.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [10. 10. 29.  0.  3.  3.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  8.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [10. 10. 29.  0.  3.  3.  0.  6.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  8.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[281.11685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6.  8.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -10.699723243713379
desired expected reward: 285.1252746582031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[260.57806]
 [267.70752]
 [266.9387 ]
 [253.8678 ]
 [251.78935]
 [265.51367]
 [275.85455]
 [268.8533 ]
 [282.16586]
 [274.51746]
 [260.59537]
 [264.93338]
 [268.17334]
 [257.2521 ]
 [268.27664]
 [284.61975]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6.  8.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 28. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -10.194937705993652
desired expected reward: 271.6507263183594



buy possibilites: [-1] 
expected returns: [[294.77936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6.  8.  0. 10.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -40.5 

action type: buy - action 1.0
Learning step: -8.557123184204102
desired expected reward: 259.1503601074219






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 0.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[242.15518]
 [229.70943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3.  0.] 
adversary cards in discard: [11.  1.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -11.626538276672363
desired expected reward: 283.15283203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[220.1804 ]
 [226.26117]
 [225.51979]
 [212.5373 ]
 [224.37352]
 [233.07951]
 [227.24516]
 [231.94925]
 [220.09517]
 [226.57265]
 [226.60207]
 [239.69582]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3.  0.] 
adversary cards in discard: [11.  1.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -9.171446800231934
desired expected reward: 233.18785095214844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [29.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [11.  1.  3.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  1.  3.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  1.  3.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  1.  3.  0.  8.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[297.4983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [0. 0. 0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  6.  0. 10. 10.] 
adversary cards in discard: [11.  1.  3.  0.  8.  0. 11. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -7.58052921295166
desired expected reward: 232.1152801513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[274.3472 ]
 [281.9149 ]
 [281.03036]
 [264.84537]
 [279.57263]
 [290.7623 ]
 [283.1759 ]
 [289.31274]
 [274.28226]
 [282.34338]
 [282.4157 ]
 [299.3339 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [0. 0. 0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  6.  0. 10. 10.] 
adversary cards in discard: [11.  1.  3.  0.  8.  0. 11. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -10.555150985717773
desired expected reward: 285.1898193359375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 1.  6.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0. 10. 10.] 
cards in discard: [11.  1.  3.  0.  8.  0. 11. 29.  0.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0. 10.  3.] 
cards in discard: [11.  1.  3.  0.  8.  0. 11. 29.  0.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0.  3. 11.] 
cards in discard: [11.  1.  3.  0.  8.  0. 11. 29.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11] -> size -> 21 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 3.] 
cards in discard: [11.  1.  3.  0.  8.  0. 11. 29.  0.  0.  3.  0.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8.  9.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 3.] 
cards in discard: [11.  1.  3.  0.  8.  0. 11. 29.  0.  0.  3.  0.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 28. 30.  8.  8.  9.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[225.18866]
 [211.27715]
 [210.67104]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  0  8  8  6  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8.  9.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 10. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -12.300605773925781
desired expected reward: 287.0333251953125



action possibilites: [-1] 
expected returns: [[234.88913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6  1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8.  9.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 10. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 3
Learning step: -6.3088603019714355
desired expected reward: 200.56845092773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[204.46983]
 [195.8723 ]
 [228.66335]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6  1] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  8.  9.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 10. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -8.125800132751465
desired expected reward: 226.76333618164062



buy possibilites: [-1] 
expected returns: [[246.39722]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  7.  9.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 10. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -336.0 

action type: buy - action 6.0
Learning step: -21.0496768951416
desired expected reward: 174.82261657714844






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10. 29.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  7.  9.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 6.] 
adversary cards in discard: [ 6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  3. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  7.  9.  7.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 6.] 
adversary cards in discard: [ 6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  3.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  7.  9.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 6.] 
adversary cards in discard: [ 6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 1.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 11. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  7.  9.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 6.] 
adversary cards in discard: [ 6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 1.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 11. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 28. 30.  8.  7.  9.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 6.] 
adversary cards in discard: [ 6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 1.] 
cards in discard: [29.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 11. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 26. 30. 28. 30.  8.  7.  9.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 6.] 
adversary cards in discard: [ 6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [3. 1. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[208.6675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 6.] 
cards in discard: [ 6.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  7.  9.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  3.  0.] 
adversary cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -10.427464485168457
desired expected reward: 235.96975708007812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[192.04457]
 [198.57802]
 [198.08727]
 [184.3494 ]
 [196.5211 ]
 [206.76031]
 [199.65257]
 [205.2969 ]
 [192.17392]
 [199.2635 ]
 [199.38603]
 [214.87282]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 6.] 
cards in discard: [ 6.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 28. 30.  8.  7.  9.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  3.  0.] 
adversary cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -8.624999046325684
desired expected reward: 199.9259796142578



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  3.  0.] 
cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  7.  9.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  3.  0.] 
cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 28. 30.  8.  7.  9.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  3.  0.] 
cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  7.  9.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [6. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[285.78986]
 [268.82764]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  7.  9.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 11.  3.] 
adversary cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.  3.  0.  8. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1.0
Learning step: -7.747412204742432
desired expected reward: 207.12542724609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[252.66507]
 [260.73312]
 [259.93774]
 [242.5772 ]
 [270.0853 ]
 [262.02695]
 [261.34082]
 [279.4717 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 27. 30.  8.  7.  9.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 11.  3.] 
adversary cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.  3.  0.  8. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -11.544715881347656
desired expected reward: 273.7691650390625



buy possibilites: [-1] 
expected returns: [[238.85385]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 11.  3.] 
adversary cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.  3.  0.  8. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -48 

action type: buy - action 11.0
Learning step: -10.530051231384277
desired expected reward: 259.55517578125






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 16. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16. 11.  3.] 
cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.  3.  0.  8. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  1.  3.  8.] 
adversary cards in discard: [11.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6 11] -> size -> 13 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16. 11.  3.] 
cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.  3.  0.  8. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 27. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  1.  3.  8.] 
adversary cards in discard: [11.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6 11] -> size -> 13 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16. 11.  3.] 
cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.  3.  0.  8. 10.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 27. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  1.  3.  8.] 
adversary cards in discard: [11.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6 11] -> size -> 13 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [10.  0.  1.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[227.67403]
 [212.85056]
 [213.24626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  3.  8.] 
cards in discard: [11.  6.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  3.] 
adversary cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.  3.  0.  8. 10.  3.  0.  0.  3.  0.
 16. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -10.272307395935059
desired expected reward: 228.58154296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[214.74452]
 [221.3164 ]
 [220.82646]
 [206.61186]
 [229.18488]
 [222.35211]
 [221.9564 ]
 [237.0005 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  3.  8.] 
cards in discard: [11.  6.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 27. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  3.] 
adversary cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.  3.  0.  8. 10.  3.  0.  0.  3.  0.
 16. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -9.545113563537598
desired expected reward: 217.57093811035156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0.  3.] 
cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.  3.  0.  8. 10.  3.  0.  0.  3.  0.
 16. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 1. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6 11] -> size -> 13 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.  3.  0.  8. 10.  3.  0.  0.  3.  0.
 16. 11.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 1. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6 11] -> size -> 13 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.  3.  0.  8. 10.  3.  0.  0.  3.  0.
 16. 11.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3  0  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 26. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 1. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6 11] -> size -> 13 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [29.  0. 10. 11. 29.  0.  6.  3.  1.  3.  0.  8. 10.  3.  0.  0.  3.  0.
 16. 11.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3  0  3  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 25. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 1. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6 11] -> size -> 13 
adversary victory points: -1
player victory points: 7 





Player: 0 
cards in hand: [0. 8. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[156.50241]
 [146.90448]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 6. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6  1  6 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3  0  3  3] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -11.917059898376465
desired expected reward: 210.57763671875



action possibilites: [-1] 
expected returns: [[219.39406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3  0  3  3] -> size -> 28 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: trash_cards_n_from_hand - action 8
Learning step: -5.259947299957275
desired expected reward: 143.66632080078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[190.46825]
 [196.07495]
 [183.0523 ]
 [197.3877 ]
 [212.21175]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 25. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3  0  3  3] -> size -> 28 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -9.183070182800293
desired expected reward: 210.2109832763672



buy possibilites: [-1] 
expected returns: [[172.51]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3  0  3  3] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -36 

action type: buy - action 3.0
Learning step: -7.722271919250488
desired expected reward: 188.3526611328125






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  1. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  3  0 11 29  6 10 10  3  1 11 11 16 29  0
  3  0  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3] -> size -> 12 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3] -> size -> 12 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 24. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3] -> size -> 12 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3] -> size -> 12 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [ 0.  0.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[184.09842]
 [166.56403]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  6. 10.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -7.827102184295654
desired expected reward: 164.68289184570312



action possibilites: [-1.  8.] 
expected returns: [[184.02495]
 [168.9689 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 8.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action 10.0
Learning step: -6.457278728485107
desired expected reward: 159.30970764160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[165.8364 ]
 [171.85297]
 [157.87114]
 [173.41402]
 [188.495  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 8.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  6.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -7.407380104064941
desired expected reward: 176.61756896972656



buy possibilites: [-1] 
expected returns: [[203.85175]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 8.] 
cards in discard: [3. 8. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  6.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -36 

action type: buy - action 8.0
Learning step: -5.884037494659424
desired expected reward: 167.52999877929688






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 0.  8.  3.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  6.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3  8] -> size -> 13 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 0.  8.  3.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  6.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3  8] -> size -> 13 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 0.  8.  3.  0. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 24. 30.  8.  7.  9.  6.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3  8] -> size -> 13 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [ 0.  0. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[230.53122]
 [220.56581]
 [225.75851]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  7.  9.  6.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  1.  3.  0.  3.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0] -> size -> 29 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -8.276415824890137
desired expected reward: 195.57533264160156



action possibilites: [-1. 11.] 
expected returns: [[228.83861]
 [225.15822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3  8] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  7.  9.  6.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  1.  3.  0.  3.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0] -> size -> 29 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -43 

action type: take_action - action 10.0
Learning step: -8.051775932312012
desired expected reward: 212.42581176757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[217.12885]
 [221.09325]
 [220.17389]
 [211.9567 ]
 [219.77911]
 [224.95941]
 [221.80663]
 [224.43578]
 [216.71982]
 [220.9023 ]
 [220.77692]
 [228.30649]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 24. 30.  8.  7.  9.  6.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  1.  3.  0.  3.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0] -> size -> 29 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -8.616104125976562
desired expected reward: 220.22251892089844



buy possibilites: [-1] 
expected returns: [[187.25969]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3  8  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 26. 30. 24. 30.  8.  6.  9.  6.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  1.  3.  0.  3.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0] -> size -> 29 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -70.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -355.0 

action type: buy - action 6.0
Learning step: -24.13449478149414
desired expected reward: 187.8222198486328






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [10.  1.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  0.  3.] 
cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  6.  9.  6.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [ 6. 10.  0.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3  8  6] -> size -> 14 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  0.  3.] 
cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 24. 30.  8.  6.  9.  6.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [ 6. 10.  0.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3  8  6] -> size -> 14 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  0.  3.] 
cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  6.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [ 6. 10.  0.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3  8  6] -> size -> 14 
adversary victory points: 0
player victory points: 7 





Player: 0 
cards in hand: [3. 0. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[204.14386]
 [191.78389]
 [191.78389]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 6. 8.] 
cards in discard: [ 6. 10.  0.  0. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0  8  8  6 11  3  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  6.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0. 16. 29.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6. 11. 10.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11] -> size -> 30 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -8.713278770446777
desired expected reward: 178.54641723632812



action possibilites: [-1] 
expected returns: [[172.0313]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [ 6. 10.  0.  0. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  6.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0. 16. 29.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6. 11. 10.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11] -> size -> 30 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: trash_cards_n_from_hand - action 9
Learning step: -8.162307739257812
desired expected reward: 184.18446350097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[156.07678]
 [148.31146]
 [176.8653 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [ 6. 10.  0.  0. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  6.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0. 16. 29.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6. 11. 10.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11] -> size -> 30 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -7.6113128662109375
desired expected reward: 164.41998291015625






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [11.  3.  0. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 16. 29.] 
cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6. 11. 10.  1.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  6.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16. 29.] 
cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6. 11. 10.  1.  3.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  5.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16. 29.] 
cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6. 11. 10.  1.  3.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 24. 30.  8.  5.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [0. 8. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[197.892  ]
 [187.07187]
 [187.07187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  5.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6. 11. 10.  1.  3.  0.  3.  6.
 11.  3.  0. 16. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6] -> size -> 31 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -7.771691799163818
desired expected reward: 169.09359741210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[181.08131]
 [175.06573]
 [197.99272]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 24. 30.  8.  5.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6. 11. 10.  1.  3.  0.  3.  6.
 11.  3.  0. 16. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6] -> size -> 31 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -8.827285766601562
desired expected reward: 187.95233154296875



buy possibilites: [-1] 
expected returns: [[218.32455]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 8. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  5.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6. 11. 10.  1.  3.  0.  3.  6.
 11.  3.  0. 16. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6] -> size -> 31 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: -8.891763687133789
desired expected reward: 172.18954467773438






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  0.] 
cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6. 11. 10.  1.  3.  0.  3.  6.
 11.  3.  0. 16. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  5.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11.  3.  0.  6.] 
adversary cards in discard: [0. 0. 8. 6. 8. 3.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0] -> size -> 13 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.  0.] 
cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6. 11. 10.  1.  3.  0.  3.  6.
 11.  3.  0. 16. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 24. 30.  8.  5.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11.  3.  0.  6.] 
adversary cards in discard: [0. 0. 8. 6. 8. 3.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0] -> size -> 13 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.  0.] 
cards in discard: [ 0.  8.  3.  0. 11.  0.  3.  0.  0.  0.  6. 11. 10.  1.  3.  0.  3.  6.
 11.  3.  0. 16. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 24. 30.  8.  5.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11.  3.  0.  6.] 
adversary cards in discard: [0. 0. 8. 6. 8. 3.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0] -> size -> 13 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [10. 11.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[161.02074]
 [151.23708]
 [155.84811]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0.  6.] 
cards in discard: [0. 0. 8. 6. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  5.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0] -> size -> 32 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -10.619321823120117
desired expected reward: 207.70523071289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[150.16333]
 [145.66313]
 [161.94795]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  0.  6.] 
cards in discard: [0. 0. 8. 6. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  5.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0] -> size -> 32 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -7.7651262283325195
desired expected reward: 152.6923065185547



buy possibilites: [-1] 
expected returns: [[108.82311]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  0.  6.] 
cards in discard: [0. 0. 8. 6. 8. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  4.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0] -> size -> 32 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -70.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -376.0 

action type: buy - action 6.0
Learning step: -23.6346378326416
desired expected reward: 122.02849578857422






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  4.  9.  5.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6] -> size -> 14 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.] 
cards in discard: [8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  4.  9.  5.  5. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6] -> size -> 14 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.] 
cards in discard: [8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  4.  9.  5.  5. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6] -> size -> 14 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [ 6. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[178.8798 ]
 [175.04768]
 [171.11536]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  4.  9.  5.  5. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  6. 29.  0.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8] -> size -> 33 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -5.28499174118042
desired expected reward: 103.53812408447266



action possibilites: [-1. 11.] 
expected returns: [[149.88882]
 [145.27684]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  4.  9.  5.  5. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  6. 29.  0.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8] -> size -> 33 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -55 

action type: take_action - action 10.0
Learning step: -7.925897121429443
desired expected reward: 162.3712158203125



action possibilites: [-1.] 
expected returns: [[97.58991]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  3.  9.  5.  5. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  6. 29.  0.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8] -> size -> 33 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -80    0    0   40    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -347 

action type: gain_card_n - action 3
Learning step: -22.148120880126953
desired expected reward: 117.72976684570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 87.99453 ]
 [ 93.39862 ]
 [ 92.983475]
 [ 81.29244 ]
 [ 99.82368 ]
 [ 94.24975 ]
 [ 93.91627 ]
 [106.12805 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 24. 30.  8.  3.  9.  5.  5. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  6. 29.  0.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8] -> size -> 33 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -5.022033214569092
desired expected reward: 92.56787872314453






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 29.  0.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  3.  9.  5.  5. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6] -> size -> 15 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 6.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  3.  9.  5.  5. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6] -> size -> 15 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 6.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 24. 30.  8.  3.  9.  5.  5. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6] -> size -> 15 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 6.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  3.  9.  5.  4. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6] -> size -> 15 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [3. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[159.09879]
 [151.51057]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 8.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  3.  9.  5.  4. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -6.2109880447387695
desired expected reward: 99.91705322265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[139.28217]
 [142.38496]
 [134.54794]
 [143.62984]
 [150.58076]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 8.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 24. 30.  8.  3.  9.  5.  4. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -8.864602088928223
desired expected reward: 146.71749877929688



buy possibilites: [-1] 
expected returns: [[135.44066]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 8.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 24. 30.  8.  2.  9.  5.  4. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8] -> size -> 34 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -90.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -398.0 

action type: buy - action 6.0
Learning step: -23.579984664916992
desired expected reward: 110.96797180175781






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 11.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  2.  9.  5.  4. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6] -> size -> 16 
adversary victory points: -3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1.  9.  5.  4. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6] -> size -> 16 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 24. 30.  8.  1.  9.  5.  4. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6] -> size -> 16 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 23. 30.  8.  1.  9.  5.  4. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6] -> size -> 16 
adversary victory points: -3
player victory points: 6 





Player: 0 
cards in hand: [6. 0. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[88.435   ]
 [76.912926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  1.  9.  5.  4. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3] -> size -> 36 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action -1
Learning step: -9.809508323669434
desired expected reward: 125.63114929199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[65.97714 ]
 [59.743984]
 [82.88759 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 23. 30.  8.  1.  9.  5.  4. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3] -> size -> 36 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: take_action - action -1.0
Learning step: -7.0805559158325195
desired expected reward: 69.94624328613281



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  1.  9.  5.  4. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  6.  6.] 
adversary cards in discard: [6. 0. 6. 8. 3.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6] -> size -> 16 
adversary victory points: -3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 23. 30.  8.  1.  9.  5.  4. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  6.  6.] 
adversary cards in discard: [6. 0. 6. 8. 3.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6] -> size -> 16 
adversary victory points: -3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  1.  9.  5.  3. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  6.  6.] 
adversary cards in discard: [6. 0. 6. 8. 3.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6] -> size -> 16 
adversary victory points: -3
player victory points: 6 





Player: 0 
cards in hand: [10.  0.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[59.745304]
 [51.654392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  6.  6.] 
cards in discard: [6. 0. 6. 8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  1.  9.  5.  3. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  1.  0. 29.  0.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8] -> size -> 37 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action -1.0
Learning step: -7.760756015777588
desired expected reward: 75.1268310546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[49.68556 ]
 [53.07402 ]
 [44.709442]
 [54.30638 ]
 [61.978325]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  6.  6.] 
cards in discard: [6. 0. 6. 8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 23. 30.  8.  1.  9.  5.  3. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  1.  0. 29.  0.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8] -> size -> 37 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: take_action - action -1.0
Learning step: -6.623039245605469
desired expected reward: 53.04380798339844



buy possibilites: [-1] 
expected returns: [[78.79994]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  6.  6.] 
cards in discard: [6. 0. 6. 8. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  1.  9.  5.  3. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  1.  0. 29.  0.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8] -> size -> 37 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -79 

action type: buy - action 3.0
Learning step: -4.8307013511657715
desired expected reward: 48.24329376220703






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [11.  1.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0. 29.  0.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  1.  9.  5.  3. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [ 6.  0.  6.  8.  3.  3. 10.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3] -> size -> 17 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  0.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [ 6.  0.  6.  8.  3.  3. 10.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3] -> size -> 17 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29.  0.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [ 6.  0.  6.  8.  3.  3. 10.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3] -> size -> 17 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29.  0.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3. 16. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16 14] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [ 6.  0.  6.  8.  3.  3. 10.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3] -> size -> 17 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [11.  3.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[78.88128]
 [75.94487]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  6.] 
cards in discard: [ 6.  0.  6.  8.  3.  3. 10.  0.  0.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  3. 11.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3. 16. 14. 11.  1.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16 14] -> size -> 39 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -6.53652286529541
desired expected reward: 72.26342010498047



action possibilites: [-1] 
expected returns: [[81.16823]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6.] 
cards in discard: [ 6.  0.  6.  8.  3.  3. 10.  0.  0.  6.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  3. 11.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3. 16. 14. 11.  1.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16 14] -> size -> 39 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -58 

action type: gain_card_n - action 9
Learning step: -4.888038158416748
desired expected reward: 71.39842987060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[65.48458 ]
 [70.14153 ]
 [59.840763]
 [71.03418 ]
 [83.64817 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6.] 
cards in discard: [ 6.  0.  6.  8.  3.  3. 10.  0.  0.  6.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  3. 11.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3. 16. 14. 11.  1.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16 14] -> size -> 39 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -5.7243971824646
desired expected reward: 75.44383239746094



buy possibilites: [-1] 
expected returns: [[22.18722]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6.] 
cards in discard: [ 6.  0.  6.  8.  3.  3. 10.  0.  0.  6.  6. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  3. 11.] 
adversary cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3. 16. 14. 11.  1.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16 14] -> size -> 39 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -80.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -97.0 

action type: buy - action 0.0
Learning step: -7.625016689300537
desired expected reward: 57.85957336425781






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  3. 11.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3. 16. 14. 11.  1.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16 14] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  3. 11.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3. 16. 14. 11.  1.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  3. 11.] 
cards in discard: [ 8. 11.  3.  0.  3. 10.  8. 29.  3.  3.  6.  0.  6.  6.  3. 11.  0. 10.
  0.  0.  8.  3.  0.  0. 16.  3. 16. 14. 11.  1.  0. 29.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [10.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[51.935112]
 [47.27469 ]
 [47.27469 ]
 [47.70501 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0] -> size -> 40 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -4.340093612670898
desired expected reward: 17.847126007080078



action possibilites: [-1. 10.  8. 11.] 
expected returns: [[ 0.86592937]
 [-1.5222846 ]
 [-1.4111024 ]
 [-0.40253925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0] -> size -> 40 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 10.0
Learning step: -5.71582555770874
desired expected reward: 41.55885314941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-2.677308  ]
 [-2.2595794 ]
 [-2.6779747 ]
 [-1.9929937 ]
 [ 0.11800194]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0] -> size -> 40 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.4199624061584473
desired expected reward: -2.554033041000366






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [8. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29  6 10 10  3  1 11 11 16 29  0  3
  0  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 6. 3. 0.] 
adversary cards in discard: [10.  0. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 6. 3. 0.] 
adversary cards in discard: [10.  0. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 6. 3. 0.] 
adversary cards in discard: [10.  0. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 6. 3. 0.] 
adversary cards in discard: [10.  0. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [6. 6. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[58.729618]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 3. 0.] 
cards in discard: [10.  0. 10.  0.  8. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3. 11. 11.  3.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0] -> size -> 40 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1.0
Learning step: -3.5344836711883545
desired expected reward: -3.416482925415039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.48611 ]
 [40.38658 ]
 [59.354023]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 3. 0.] 
cards in discard: [10.  0. 10.  0.  8. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3. 11. 11.  3.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0] -> size -> 40 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -6.610205173492432
desired expected reward: 52.11941146850586



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [29.  3. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11. 11.  3.] 
cards in discard: [0. 8. 0. 3. 0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 3. 6. 0.] 
adversary cards in discard: [10.  0. 10.  0.  8. 11.  6.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  3.] 
cards in discard: [0. 8. 0. 3. 0. 3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 21. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 3. 6. 0.] 
adversary cards in discard: [10.  0. 10.  0.  8. 11.  6.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 11.  3.] 
cards in discard: [0. 8. 0. 3. 0. 3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 21. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 3. 6. 0.] 
adversary cards in discard: [10.  0. 10.  0.  8. 11.  6.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 11.  3.] 
cards in discard: [0. 8. 0. 3. 0. 3. 0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 3. 6. 0.] 
adversary cards in discard: [10.  0. 10.  0.  8. 11.  6.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [0. 8. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[72.21841 ]
 [62.082623]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 6. 0.] 
cards in discard: [10.  0. 10.  0.  8. 11.  6.  6.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  3.  8. 14.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0] -> size -> 42 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1.0
Learning step: -6.7664971351623535
desired expected reward: 52.58753204345703



action possibilites: [-1] 
expected returns: [[74.37328]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [10.  0. 10.  0.  8. 11.  6.  6.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  3.  8. 14.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0] -> size -> 42 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -98 

action type: trash_cards_n_from_hand - action 2
Learning step: -5.518287658691406
desired expected reward: 40.3154411315918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[66.21481 ]
 [69.693306]
 [61.6386  ]
 [70.52237 ]
 [78.35789 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [10.  0. 10.  0.  8. 11.  6.  6.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  3.  8. 14.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0] -> size -> 42 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -98 

action type: take_action - action -1
Learning step: -6.987565517425537
desired expected reward: 67.3857192993164






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 6.  3.  8. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  8. 14.  0.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
adversary victory points: -3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 0.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  3. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
adversary victory points: -3
player victory points: 8 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[61.40761]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8] -> size -> 43 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: discard_down_to_3_cards - action 1
Learning step: -5.5633225440979
desired expected reward: 15.336551666259766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[51.232094]
 [55.052208]
 [54.441017]
 [46.39296 ]
 [59.134804]
 [55.685413]
 [55.107643]
 [63.073154]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8] -> size -> 43 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action -1.0
Learning step: -7.668436527252197
desired expected reward: 53.739173889160156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 3.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  6.  0.  8. 10.] 
adversary cards in discard: [3. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 3.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  6.  0.  8. 10.] 
adversary cards in discard: [3. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
adversary victory points: -3
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  6.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[100.94934 ]
 [ 92.63938 ]
 [ 92.398575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  8. 10.] 
cards in discard: [3. 6. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  1.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8] -> size -> 43 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1.0
Learning step: -6.864040374755859
desired expected reward: 56.20911407470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[86.77036]
 [83.58722]
 [99.36258]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  8. 10.] 
cards in discard: [3. 6. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  1.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8] -> size -> 43 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action -1.0
Learning step: -8.849339485168457
desired expected reward: 92.10002136230469



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0. 29. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  1.  0.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  6. 11.  0.] 
adversary cards in discard: [ 3.  6.  0.  0.  0.  6.  6.  0.  8. 10.] 
adversary owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
adversary victory points: -3
player victory points: 8 


action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  0. 16.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  6. 11.  0.] 
adversary cards in discard: [ 3.  6.  0.  0.  0.  6.  6.  0.  8. 10.] 
adversary owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
adversary victory points: -3
player victory points: 8 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 16.  3.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8] -> size -> 43 
action values: 2 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  6. 11.  0.] 
adversary cards in discard: [ 3.  6.  0.  0.  0.  6.  6.  0.  8. 10.] 
adversary owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 16.  3.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 26. 30. 21. 30.  8.  1.  8.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  6. 11.  0.] 
adversary cards in discard: [ 3.  6.  0.  0.  0.  6.  6.  0.  8. 10.] 
adversary owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 16.  3.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 21. 30.  8.  1.  7.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  6. 11.  0.] 
adversary cards in discard: [ 3.  6.  0.  0.  0.  6.  6.  0.  8. 10.] 
adversary owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
adversary victory points: -3
player victory points: 8 





Player: 0 
cards in hand: [10.  8.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
expected returns: [[14.835832]
 [ 9.909659]
 [10.199233]
 [12.261682]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  6. 11.  0.] 
cards in discard: [ 3.  6.  0.  0.  0.  6.  6.  0.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  8  6 11  3  8  6  0  6  6  6  3 10  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 30.  8.  1.  7.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16] -> size -> 44 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1.0
Learning step: -10.578454971313477
desired expected reward: 88.78413391113281



action possibilites: [-1] 
expected returns: [[77.20388]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 3.  6.  0.  0.  0.  6.  6.  0.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 30.  8.  1.  7.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16] -> size -> 44 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -98 

action type: trash_cards_n_from_hand - action 11
Learning step: -3.7699501514434814
desired expected reward: 8.370798110961914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[66.9992 ]
 [64.33459]
 [75.22068]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 3.  6.  0.  0.  0.  6.  6.  0.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 26. 30. 21. 30.  8.  1.  7.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16] -> size -> 44 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -98 

action type: take_action - action -1
Learning step: -7.160364627838135
desired expected reward: 70.04351806640625



buy possibilites: [-1] 
expected returns: [[94.41795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 3.  6.  0.  0.  0.  6.  6.  0.  8. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 21. 30.  8.  1.  7.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16] -> size -> 44 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -128 

action type: buy - action 0.0
Learning step: -7.625555515289307
desired expected reward: 59.373634338378906






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  6.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 21. 30.  8.  1.  7.  5.  2. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 8 





Player: 0 
cards in hand: [6. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[45.639835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.  8.  0. 11.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0] -> size -> 46 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1
Learning step: -9.594001770019531
desired expected reward: 84.8239517211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[36.414932]
 [38.1484  ]
 [34.019005]
 [39.070713]
 [42.741234]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.  8.  0. 11.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0] -> size -> 46 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action -1.0
Learning step: -7.288125514984131
desired expected reward: 38.35171127319336



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11.  0.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.  8.  0. 11.  0.  0.
  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  3  0 11 29 10 10  3  1 11 11 16 29  0  3  0
  3  3  0  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [6. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.  8.  0. 11.  0.  0.
  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0
  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [6. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.  8.  0. 11.  0.  0.
  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0
  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [6. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  0.  3.  0.  3.  0. 11. 29.  3. 11.  3.  8. 14.  6.  3.  8.  0.
  3.  0.  8.  0.  3. 16. 29. 10.  0.  1.  0. 16.  3.  8.  0. 11.  0.  0.
  3.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0
  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [6. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 8 





Player: 0 
cards in hand: [ 0.  0.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[71.53566 ]
 [58.77048 ]
 [59.317387]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  8.] 
cards in discard: [6. 0. 0. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0
  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 44 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1.0
Learning step: -6.5486321449279785
desired expected reward: 36.19259262084961



action possibilites: [-1.  8.] 
expected returns: [[78.99599 ]
 [65.774925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [6. 0. 0. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0
  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 44 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0   20    0    0    0    0    0    0    0
    0    1] 
sum of rewards: -97 

action type: take_action - action 10.0
Learning step: -5.836466312408447
desired expected reward: 52.93403625488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[51.641346]
 [57.343235]
 [56.81197 ]
 [44.659145]
 [64.087456]
 [58.25513 ]
 [57.803535]
 [70.897545]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [6. 0. 0. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0
  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 44 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -98 

action type: take_action - action -1.0
Learning step: -7.446737766265869
desired expected reward: 71.54926300048828






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 16.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  3. 10.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0
  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 6.  0.  0.  3.  6. 10.  0.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  3. 10.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0
  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 6.  0.  0.  3.  6. 10.  0.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 6. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[50.33499 ]
 [41.503506]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 6. 0.] 
cards in discard: [ 6.  0.  0.  3.  6. 10.  0.  0.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  6  3  8  6  0  6  6  6  3 10  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  8.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0
  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 44 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1.0
Learning step: -8.376564979553223
desired expected reward: 62.52099609375



action possibilites: [-1] 
expected returns: [[73.41223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 6.  0.  0.  3.  6. 10.  0.  0.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  8.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0
  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: trash_cards_n_from_hand - action 5
Learning step: -3.8921144008636475
desired expected reward: 30.98567771911621





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[58.550076]
 [52.83498 ]
 [72.761566]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6.  0.  0.  3.  6. 10.  0.  0.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  8.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0
  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -5.998981952667236
desired expected reward: 67.41324615478516






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [29.  3. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10.  0.  8.] 
cards in discard: [ 3.  0. 16.  3. 10.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0
  0 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 6. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10.] 
cards in discard: [ 3.  0. 16.  3. 10.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0
 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 6. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 10.] 
cards in discard: [ 3.  0. 16.  3. 10.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0
 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 6. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [8. 6. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[56.195286]
 [48.133827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3.  3.  8.  0.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.] 
adversary owned cards: [ 0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0
 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 43 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -7.231896877288818
desired expected reward: 65.5296630859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[46.26354 ]
 [42.18479 ]
 [58.582924]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3.  3.  8.  0.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.] 
adversary owned cards: [ 0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0
 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 43 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -6.430670261383057
desired expected reward: 49.760536193847656



buy possibilites: [-1] 
expected returns: [[111.53838]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3.  3.  8.  0.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.] 
adversary owned cards: [ 0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0
 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 43 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -126.0 

action type: buy - action 0.0
Learning step: -6.103564262390137
desired expected reward: 40.15998458862305






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [14.  3.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  8.  0.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0
 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [0. 8. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0
 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0
 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 26. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0
 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[39.5988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [ 0.  8.  6.  3.  3.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0
 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: discard_down_to_3_cards - action 0
Learning step: -3.9981486797332764
desired expected reward: -2.2157139778137207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.201647]
 [30.427097]
 [27.394249]
 [30.948044]
 [35.040062]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 0.  8.  6.  3.  3.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0
 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -6.056084156036377
desired expected reward: 33.54271697998047



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8  3  0 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0
 11  6  0  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [3. 6. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[109.062096]
 [100.200195]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  3  8  0  6  6  6  3 10  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  3. 11. 11.  8.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1] -> size -> 41 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -4.165199279785156
desired expected reward: 30.87487030029297



action possibilites: [-1] 
expected returns: [[82.45857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  8  0  6  6  3 10  0  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  3. 11. 11.  8.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1] -> size -> 41 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: trash_cards_n_from_hand - action 9
Learning step: -7.207066535949707
desired expected reward: 98.04061126708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[59.82332]
 [54.29432]
 [76.19242]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  8  0  6  6  3 10  0  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  3. 11. 11.  8.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1] -> size -> 41 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -6.394123077392578
desired expected reward: 76.064453125



buy possibilites: [-1] 
expected returns: [[50.913578]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  3. 11. 11.  8.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1] -> size -> 41 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -106 

action type: buy - action 0.0
Learning step: -6.948539733886719
desired expected reward: 52.874778747558594






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 6.  3. 11. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11. 11.  8.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [0. 8. 6.] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.  8.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [0. 8. 6.] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11.  8.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [0. 8. 6.] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[102.460976]
 [ 92.7884  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [0. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 6. 0. 1.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0] -> size -> 42 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -5.1282057762146
desired expected reward: 45.78537368774414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[80.5205  ]
 [84.96365 ]
 [84.5235  ]
 [74.99168 ]
 [90.14476 ]
 [85.687675]
 [85.311676]
 [95.062675]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [0. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 6. 0. 1.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0] -> size -> 42 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -7.885570049285889
desired expected reward: 93.72078704833984



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [3. 8. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 0. 1.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 0. 1.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 0. 1.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [ 0.  0.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[125.41617]
 [114.18492]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 11.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.  3.  8.  6.  0.  1.] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0] -> size -> 43 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -6.811831951141357
desired expected reward: 88.2508316040039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 99.52604 ]
 [104.33509 ]
 [103.712265]
 [ 93.51039 ]
 [109.85676 ]
 [105.137375]
 [104.56596 ]
 [115.128   ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 25. 30. 21. 30.  8.  1.  7.  5.  1. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 11.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.  3.  8.  6.  0.  1.] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0] -> size -> 43 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -8.634086608886719
desired expected reward: 116.75540161132812



buy possibilites: [-1] 
expected returns: [[126.258965]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  6.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 25. 30. 21. 30.  8.  1.  7.  5.  0. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 11.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.  3.  8.  6.  0.  1.] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0] -> size -> 43 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -94.0 

action type: buy - action 8.0
Learning step: -7.1160407066345215
desired expected reward: 98.02130889892578






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 11.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.  3.  8.  6.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 21. 30.  8.  1.  7.  5.  0. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  0.  0. 10.  6.] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0  8] -> size -> 13 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.  3.  8.  6.  0.  1. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 21. 30.  8.  1.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  0.  0. 10.  6.] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0  8] -> size -> 13 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.  3.  8.  6.  0.  1. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 25. 30. 21. 30.  8.  1.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  0.  0. 10.  6.] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0  8] -> size -> 13 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.  3.  8.  6.  0.  1. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 25. 30. 21. 30.  8.  1.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  0.  0. 10.  6.] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0  8] -> size -> 13 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [3. 8. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[104.78302 ]
 [ 96.999626]
 [ 96.999626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 0. 8.] 
cards in discard: [ 8.  0.  0.  0. 10.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 21. 30.  8.  1.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.  3.  8.  6.  0.  1. 10.  0. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0] -> size -> 45 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -8.83080005645752
desired expected reward: 117.42816162109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 89.80392 ]
 [ 86.071365]
 [101.87455 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 0. 8.] 
cards in discard: [ 8.  0.  0.  0. 10.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 25. 30. 21. 30.  8.  1.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.  3.  8.  6.  0.  1. 10.  0. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0] -> size -> 45 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -7.882108211517334
desired expected reward: 96.90088653564453



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  3.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.  3.  8.  6.  0.  1. 10.  0. 11.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  0  3  0  3  3  0  0 11  6  0
  8  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 21. 30.  8.  1.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0  8] -> size -> 13 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.  3.  8.  6.  0.  1. 10.  0. 11.  0.  0.  3.  3.
  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  3  0  3  3  0  0 11  6  0  8
  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 21. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0  8] -> size -> 13 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.  3.  8.  6.  0.  1. 10.  0. 11.  0.  0.  3.  3.
  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  3  0  3  3  0  0 11  6  0  8
  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 25. 30. 21. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0  8] -> size -> 13 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  0. 16.  3. 10.  8. 29.  3. 10.  1. 14.  3.  3.  8.  0.  8.  0.  0.
 11.  6.  3. 11.  8.  0.  3.  8.  6.  0.  1. 10.  0. 11.  0.  0.  3.  3.
  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  3  0  3  3  0  0 11  6  0  8
  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0  8] -> size -> 13 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [6. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[126.03857]
 [116.62972]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  0  6  6  3 10  0  0  0  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 16. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  3  0  3  3  0  0 11  6  0  8
  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 46 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -7.12628173828125
desired expected reward: 94.74826049804688



action possibilites: [-1] 
expected returns: [[37.45921]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  6  6 10  0  0  0  0  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 16. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  3  0  3  3  0  0 11  6  0  8
  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 46 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: trash_cards_n_from_hand - action 8
Learning step: -9.909936904907227
desired expected reward: 118.14543914794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.494173]
 [35.306805]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  6  6 10  0  0  0  0  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 16. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  3  0  3  3  0  0 11  6  0  8
  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 46 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: take_action - action -1
Learning step: -5.492644786834717
desired expected reward: 31.966564178466797



buy possibilites: [-1] 
expected returns: [[63.469013]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  6  6 10  0  0  0  0  8  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 16. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  3  0  3  3  0  0 11  6  0  8
  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 46 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: buy - action 0.0
Learning step: -5.7466559410095215
desired expected reward: 20.747516632080078






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  8. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 16. 29.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 29 10 10  3  1 11 11 16 29  3  0  3  3  0  0 11  6  0  8
  8  6  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 10.  8.  0.  0.] 
adversary cards in discard: [0. 8. 6.] 
adversary owned cards: [ 8  8  6  6 10  0  0  0  0  8  0] -> size -> 11 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 10.  8.  0.  0.] 
adversary cards in discard: [0. 8. 6.] 
adversary owned cards: [ 8  8  6  6 10  0  0  0  0  8  0] -> size -> 11 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 10.  8.  0.  0.] 
adversary cards in discard: [0. 8. 6.] 
adversary owned cards: [ 8  8  6  6 10  0  0  0  0  8  0] -> size -> 11 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [ 6. 10.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[74.0439 ]
 [66.76846]
 [67.30853]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  8.  0.  0.] 
cards in discard: [0. 8. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6  6 10  0  0  0  0  8  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 44 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1
Learning step: -6.939378261566162
desired expected reward: 56.52963638305664



action possibilites: [-1] 
expected returns: [[41.64084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [0. 8. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  6 10  0  0  8  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: trash_cards_n_from_hand - action 9
Learning step: -6.402590274810791
desired expected reward: 64.38758850097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[34.445686]
 [43.990864]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [0. 8. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  6 10  0  0  8  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -4.9616618156433105
desired expected reward: 36.679176330566406



buy possibilites: [-1] 
expected returns: [[43.40047]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [0. 8. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  6 10  0  0  8  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -106 

action type: buy - action 0.0
Learning step: -5.737649917602539
desired expected reward: 22.545560836791992






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [8. 3. 0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  0  0  8  0  0] -> size -> 9 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [8. 3. 0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 25. 30. 20. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  0  0  8  0  0] -> size -> 9 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [8. 3. 0. 3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  0  0  8  0  0] -> size -> 9 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [8. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[78.797295]
 [72.50465 ]
 [72.50465 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6 10  0  0  8  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  6. 29. 10.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3] -> size -> 45 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -5.794620037078857
desired expected reward: 37.60585021972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[66.36538 ]
 [68.46312 ]
 [75.007904]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6 10  0  0  8  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  6. 29. 10.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3] -> size -> 45 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: take_action - action -1.0
Learning step: -7.551609992980957
desired expected reward: 69.76155090332031



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  6. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6. 29. 10.] 
cards in discard: [8. 3. 0. 3. 0. 0. 3. 3. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  0  0  8  0  0] -> size -> 9 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  0  0  8  0  0] -> size -> 9 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  0  0  8  0  0] -> size -> 9 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  0  0  8  0  0] -> size -> 9 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [ 6.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[73.5515 ]
 [64.89269]
 [64.38793]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6 10  0  0  8  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10] -> size -> 46 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1.0
Learning step: -7.5050554275512695
desired expected reward: 67.50286102294922



action possibilites: [-1.  8.] 
expected returns: [[33.01547 ]
 [27.823626]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  6 10  0  0  8  0  0] -> size -> 9 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10] -> size -> 46 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    0    1] 
sum of rewards: -85 

action type: take_action - action 10.0
Learning step: -6.712544918060303
desired expected reward: 56.640193939208984



action possibilites: [-1.] 
expected returns: [[14.160515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  8  6 10  8  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10] -> size -> 46 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   40    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -126 

action type: trash_cards_n_from_hand - action 4
Learning step: -7.09908390045166
desired expected reward: 15.254826545715332





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[4.6223783]
 [8.664234 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  8  6 10  8  0] -> size -> 6 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10] -> size -> 46 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   40    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -126 

action type: take_action - action -1.0
Learning step: -6.84247350692749
desired expected reward: 7.3180413246154785






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [0. 3. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  6.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  6.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10.  6.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [10.  6.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
expected returns: [[-2.6755714]
 [-2.6755714]
 [-2.6755714]
 [-2.6755714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  8.  8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6 10  8  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 3. 3. 3. 8.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 47 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -166 

action type: buy - action -1.0
Learning step: -8.793412208557129
desired expected reward: -0.12917613983154297





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.6755714]
 [-2.6755714]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  8.  8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6 10  8  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 3. 3. 3. 8.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 47 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -166 

action type: take_action - action -1.0
Learning step: -8.226422309875488
desired expected reward: -10.901993751525879



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3. 8.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 3. 8.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 47 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  0. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.  8.] 
expected returns: [[-2.6755714]
 [-2.6755714]
 [-2.6755714]
 [-2.6755714]
 [-2.6755714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  8.  8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6 10  8  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 47 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -166 

action type: buy - action -1.0
Learning step: -8.226422309875488
desired expected reward: -10.901993751525879





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.6755714]
 [-2.6755714]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  8.  8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6 10  8  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 47 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -166 

action type: take_action - action -1.0
Learning step: -8.226422309875488
desired expected reward: -10.901993751525879



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.  6.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 8. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0.  6.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 8. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [8. 8. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[-2.6755714]
 [-2.6755714]
 [-2.6755714]
 [-2.6755714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6 10  8  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 8. 6. 0.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 47 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -166 

action type: buy - action -1.0
Learning step: -8.226422309875488
desired expected reward: -10.901993751525879





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.6755714]
 [-2.6755714]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6 10  8  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 8. 6. 0.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.] 
adversary owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 47 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -166 

action type: take_action - action -1.0
Learning step: -8.226422309875488
desired expected reward: -10.901993751525879



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 6. 0.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  3 10 10  3  1 11 11 29  3  0  3  3  0  0 11  6  0  8  8  6
  3  8 16 14  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  8.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  8.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  8.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [ 6.  8.  8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 10.] 
expected returns: [[24.754845]
 [21.538504]
 [21.538504]
 [21.538504]
 [21.083956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  8.  8. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6 10  8  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11. 16. 14.  8.  0.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.  8.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 43 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -166 

action type: buy - action -1.0
Learning step: -7.6699090003967285
desired expected reward: -10.345479965209961





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.512995]
 [22.856344]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  8.  8. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6 10  8  0] -> size -> 6 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11. 16. 14.  8.  0.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.  8.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 43 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -166 

action type: take_action - action -1.0
Learning step: -9.00635051727295
desired expected reward: 14.62885570526123



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [11. 16. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16. 14.  8.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  8. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  8.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [6. 8. 8.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  8.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  5.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [6. 8. 8.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  8.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [6. 8. 8.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 8  8  6 10  8  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[14.049746]
 [11.470255]
 [11.470255]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8.] 
cards in discard: [10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6 10  8  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 11.  3.  0. 16.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.  8. 11. 14. 11.
 16.  8.  0.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11] -> size -> 44 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -166 

action type: discard_down_to_3_cards - action 5
Learning step: -9.89899730682373
desired expected reward: 27.8336181640625



action possibilites: [-1] 
expected returns: [[16.490206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 10  8  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 11.  3.  0. 16.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.  8. 11. 14. 11.
 16.  8.  0.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11] -> size -> 44 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -146 

action type: trash_cards_n_from_hand - action 1
Learning step: -7.528468608856201
desired expected reward: 4.461497783660889





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 7.081451]
 [13.387317]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 10  8  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 11.  3.  0. 16.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.  8. 11. 14. 11.
 16.  8.  0.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11] -> size -> 44 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -146 

action type: take_action - action -1
Learning step: -7.869153022766113
desired expected reward: 8.621052742004395



buy possibilites: [-1] 
expected returns: [[25.769629]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 10  8  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 19. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 11.  3.  0. 16.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.  8. 11. 14. 11.
 16.  8.  0.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11] -> size -> 44 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20  -30    0    0  -30    0    0    0
    0    0] 
sum of rewards: -146 

action type: buy - action 0.0
Learning step: -7.074256420135498
desired expected reward: 0.00719451904296875






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [10. 11.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0. 16.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.  8. 11. 14. 11.
 16.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 19. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  0. 16.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.  8. 11. 14. 11.
 16.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 25. 30. 19. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  0. 16.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  3.  3.  3. 10. 11. 10. 29.  1.  0.  6. 15.  0.
  3.  1.  0.  3.  8.  3.  3.  3.  8.  0.  8. 10.  0.  6.  8. 11. 14. 11.
 16.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 25. 30. 19. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0] -> size -> 6 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [ 6.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[58.896847]
 [54.155544]
 [54.67503 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  0.  8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 19. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 6. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0] -> size -> 45 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -30    0    0    0
    0    0] 
sum of rewards: -136 

action type: buy - action -1
Learning step: -6.8075270652771
desired expected reward: 18.962100982666016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[47.453377]
 [48.939404]
 [53.410732]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  0.  8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 25. 30. 19. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 6. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0] -> size -> 45 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -30    0    0    0
    0    0] 
sum of rewards: -136 

action type: take_action - action -1.0
Learning step: -8.591948509216309
desired expected reward: 50.27064895629883



buy possibilites: [-1] 
expected returns: [[-2.6794598]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  0.  8.] 
cards in discard: [3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 6. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0] -> size -> 45 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0 -30   0   0   0   8   0] 
sum of rewards: -117 

action type: buy - action 3.0
Learning step: -8.357258796691895
desired expected reward: 40.582149505615234






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [3. 6. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 6. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3] -> size -> 7 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 6. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3] -> size -> 7 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0. 3.] 
cards in discard: [0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 6. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3] -> size -> 7 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [8. 6. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-1.6937548]
 [-2.6794598]
 [-2.6794598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29. 11.  1. 14.  0.] 
adversary cards in discard: [0. 3. 6. 8. 0. 3.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: -6.170132637023926
desired expected reward: -8.849592208862305





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.6794598]
 [-2.498808 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29. 11.  1. 14.  0.] 
adversary cards in discard: [0. 3. 6. 8. 0. 3.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: -6.197707176208496
desired expected reward: -8.394309043884277



buy possibilites: [-1] 
expected returns: [[62.716175]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 3. 8.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29. 11.  1. 14.  0.] 
adversary cards in discard: [0. 3. 6. 8. 0. 3.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: -4.704913139343262
desired expected reward: -7.384372711181641






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [29. 11.  1. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  1. 14.  0.] 
cards in discard: [0. 3. 6. 8. 0. 3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3  0] -> size -> 8 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  1.  0.] 
cards in discard: [0. 3. 6. 8. 0. 3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  6 10  8  0  0  3  0] -> size -> 8 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  1.  0.] 
cards in discard: [0. 3. 6. 8. 0. 3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  6 10  8  0  0  3  0] -> size -> 8 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [ 8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[71.04918]
 [65.23056]
 [64.89624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.] 
cards in discard: [0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 1. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: discard_down_to_3_cards - action 1
Learning step: -3.6880016326904297
desired expected reward: 5.49636173248291





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[58.374615]
 [67.89039 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.] 
cards in discard: [0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 1. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -6.795401096343994
desired expected reward: 63.279273986816406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [8. 1. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 3. 3. 0.] 
cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3  0] -> size -> 8 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 3. 3. 0.] 
cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3  0] -> size -> 8 
adversary victory points: 0
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10.  3.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[69.90146 ]
 [61.478306]
 [61.91946 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  8.  6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0. 10.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -6.697251796722412
desired expected reward: 61.19312286376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[39.207306]
 [49.314583]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.  6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0. 10.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -6.354894161224365
desired expected reward: 46.46451950073242



buy possibilites: [-1] 
expected returns: [[31.85535]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.  6.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0. 10.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: -7.493619441986084
desired expected reward: 31.71367835998535






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0. 10.] 
cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0. 10.] 
cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[32.75304 ]
 [26.355705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 11.  3.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -5.671760559082031
desired expected reward: 26.183589935302734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[21.178528]
 [23.534039]
 [30.3858  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 11.  3.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -5.735789775848389
desired expected reward: 26.096481323242188



buy possibilites: [-1] 
expected returns: [[33.95801]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 8.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3  0  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 11.  3.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: -6.544871807098389
desired expected reward: 14.633655548095703






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11.  3.] 
cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3  0  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.] 
cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3  0  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.] 
cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0 29] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3  0  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.] 
cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10. 29.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0 29  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3  0  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [ 0.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[56.842907]
 [49.902378]
 [49.75577 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3  0  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [16.  3. 16.  0.  8.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10. 29.  0. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0 29  0] -> size -> 48 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -5.251471996307373
desired expected reward: 28.706539154052734



action possibilites: [-1.  8.  8.] 
expected returns: [[14.1730585]
 [10.422472 ]
 [10.422472 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6 10  8  0  0  3  0  0  0] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [16.  3. 16.  0.  8.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10. 29.  0. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0 29  0] -> size -> 48 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 10.0
Learning step: -5.926260471343994
desired expected reward: 43.24948501586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 5.1975846]
 [ 6.982052 ]
 [ 6.7580194]
 [ 9.0133505]
 [ 7.0779467]
 [10.918274 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6 10  8  0  0  3  0  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [16.  3. 16.  0.  8.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10. 29.  0. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0 29  0] -> size -> 48 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -4.260412693023682
desired expected reward: 9.912649154663086






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [16.  3. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 16.  0.  8.] 
cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10. 29.  0. 11.  0. 10.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3  0 11  0  8  8  6  3  8 16 14
  0  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0 29  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3  0  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 16.] 
cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10. 29.  0. 11.  0. 10.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3 11  0  8  8  6  3  8 16 14  0
  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0 29  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3  0  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3. 16.] 
cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10. 29.  0. 11.  0. 10.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3 11  0  8  8  6  3  8 16 14  0
  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0 29  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  0  3  0  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [8. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[46.209145]
 [40.281807]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  0  3  0  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10. 29.  0. 11.  0. 10.  3.  3.  8. 16.  3. 16.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3 11  0  8  8  6  3  8 16 14  0
  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0 29  0] -> size -> 47 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -4.2956156730651855
desired expected reward: 6.622665882110596



action possibilites: [-1] 
expected returns: [[-1.0982046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  0  0  0  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10. 29.  0. 11.  0. 10.  3.  3.  8. 16.  3. 16.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3 11  0  8  8  6  3  8 16 14  0
  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0 29  0] -> size -> 47 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: trash_cards_n_from_hand - action 8
Learning step: -5.706343173980713
desired expected reward: 32.92631912231445





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.6914785]
 [-2.6914785]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  0  0  0  0] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10. 29.  0. 11.  0. 10.  3.  3.  8. 16.  3. 16.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3 11  0  8  8  6  3  8 16 14  0
  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0 29  0] -> size -> 47 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: -3.755648136138916
desired expected reward: -4.85385274887085



Player 1 won the game! 



Player 0 bought cards:
Copper: 13 
Silver: 1 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 5 

Remodel: 0 
Workshop: 1 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  0  0  0  0  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 25. 30. 18. 30.  8.  0.  7.  4.  0. 10.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [ 0.  3.  6.  8.  0.  3. 14. 29. 11.  1.  0.  8.  1.  3.  3.  0.  3. 10.
  3.  0. 10. 29.  0. 11.  0. 10.  3.  3.  8. 16.  3. 16.] 
adversary owned cards: [ 3  3  8  3 10 10  3  1 11 11 29  3  3  3 11  0  8  8  6  3  8 16 14  0
  0  3  0  8 16  8  0  0  1  0  0 10  0  6  3  3 10 15 11  0  0 29  0] -> size -> 47 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0  -90    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -605 

action type: buy - action 0.0
Learning step: -30.115427017211914
desired expected reward: -32.80690383911133



