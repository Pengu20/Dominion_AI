 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[346.9666]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    1  -90    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -594 

action type: buy - action -1.0
Learning step: -35.400733947753906
desired expected reward: 78.61393737792969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[342.1355 ]
 [342.6572 ]
 [342.9489 ]
 [342.26132]
 [342.55307]
 [342.72137]
 [343.6879 ]
 [342.7488 ]
 [344.10767]
 [344.3592 ]
 [343.29202]
 [343.91196]
 [343.04053]
 [343.2646 ]
 [343.93942]
 [346.83768]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.7854642868042
desired expected reward: 338.78875732421875



buy possibilites: [-1] 
expected returns: [[322.01443]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 6.0 

action type: buy - action 16.0
Learning step: -9.590744018554688
desired expected reward: 333.130615234375






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[334.82315]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.110658645629883
desired expected reward: 312.9037780761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[333.13354]
 [333.94693]
 [333.5511 ]
 [333.74683]
 [337.8357 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.92538833618164
desired expected reward: 327.4107666015625



buy possibilites: [-1] 
expected returns: [[330.61615]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -25.388690948486328
desired expected reward: 308.1623840332031






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  3.  3.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[323.6613 ]
 [319.54498]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -10.372527122497559
desired expected reward: 320.2436218261719



action possibilites: [-1] 
expected returns: [[319.78815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 1 

action type: gain_card_n - action 2
Learning step: -8.061808586120605
desired expected reward: 298.07904052734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[310.74466]
 [311.26633]
 [311.55804]
 [311.1622 ]
 [312.29703]
 [311.35794]
 [311.64966]
 [315.44678]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -9.10383129119873
desired expected reward: 310.684326171875






Player: 1 
cards in hand: [ 0.  3.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [ 3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [ 3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.  3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [ 3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3] -> size -> 12 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[342.34152]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [ 3. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -9.179039001464844
desired expected reward: 306.2677307128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[340.5006 ]
 [341.31403]
 [340.91818]
 [341.11392]
 [345.2028 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [ 3. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -10.650155067443848
desired expected reward: 333.49652099609375



buy possibilites: [-1] 
expected returns: [[328.22794]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [ 3. 16.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -4 

action type: buy - action 3.0
Learning step: -9.880575180053711
desired expected reward: 331.4334716796875






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  3. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  3. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 27. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  3. 10.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[345.46915]
 [341.35284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.214899063110352
desired expected reward: 319.0130310058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[338.5118 ]
 [339.03348]
 [339.32523]
 [338.92938]
 [340.06418]
 [339.1251 ]
 [339.4168 ]
 [343.21396]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 27. 30.  8.  9.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.345939636230469
desired expected reward: 337.7795715332031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 0.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 27. 30.  8.  9.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 0.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 0.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3] -> size -> 13 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[354.00836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 0.  3. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 10.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -10.260425567626953
desired expected reward: 332.9535217285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[339.49722]
 [339.9962 ]
 [340.27472]
 [339.88718]
 [340.98764]
 [340.08527]
 [340.36383]
 [344.00854]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 0.  3. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 10.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -10.543728828430176
desired expected reward: 331.9447326660156



buy possibilites: [-1] 
expected returns: [[327.14584]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 0.  3. 16.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 10.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -20.0 

action type: buy - action 8.0
Learning step: -10.643484115600586
desired expected reward: 329.4418029785156






Player: 1 
cards in hand: [ 3.  0. 16. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16. 10.  0.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8] -> size -> 14 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  0.  0.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8] -> size -> 14 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0.  0.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8] -> size -> 14 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0.  0.] 
cards in discard: [ 3.  3.  0.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8] -> size -> 14 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[329.04926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -10.013749122619629
desired expected reward: 317.132080078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[322.28204]
 [323.0596 ]
 [322.67203]
 [322.87015]
 [326.79337]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -10.345858573913574
desired expected reward: 320.4783020019531



buy possibilites: [-1] 
expected returns: [[333.1471]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -14 

action type: buy - action 8.0
Learning step: -9.347698211669922
desired expected reward: 313.5224609375






Player: 1 
cards in hand: [ 0. 10.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8] -> size -> 15 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 16.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8] -> size -> 15 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[364.2693]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [8. 0. 3. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 10.  0.  3.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -9.560412406921387
desired expected reward: 323.586669921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[356.4062 ]
 [356.90518]
 [357.18375]
 [356.7962 ]
 [357.8966 ]
 [356.9943 ]
 [357.27286]
 [360.91748]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [8. 0. 3. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 10.  0.  3.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -11.254280090332031
desired expected reward: 353.05426025390625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 8. 10.  0.  3.  0.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 8. 10.  0.  3.  0.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8.  9.  8. 10.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 8. 10.  0.  3.  0.  3. 16.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 25. 30.  8.  9.  8. 10.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8] -> size -> 15 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[321.50604]
 [317.5828 ]
 [317.5533 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  9.  8. 10.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 8. 10.  0.  3.  0.  3. 16.  3.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -12.423796653747559
desired expected reward: 348.49371337890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[316.78137]
 [317.55893]
 [317.17133]
 [317.36945]
 [321.2927 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 25. 30.  8.  9.  8. 10.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 8. 10.  0.  3.  0.  3. 16.  3.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.580451011657715
desired expected reward: 312.4602355957031



buy possibilites: [-1] 
expected returns: [[313.21805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 16.  0.  0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  9.  8. 10.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 8. 10.  0.  3.  0.  3. 16.  3.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -24 

action type: buy - action 8.0
Learning step: -10.021066665649414
desired expected reward: 307.348388671875






Player: 1 
cards in hand: [ 0.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 8. 10.  0.  3.  0.  3. 16.  3.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  9.  8. 10.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  8. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 8. 10.  0.  3.  0.  3. 16.  3.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 25. 30.  8.  9.  8. 10.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  8. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 8. 10.  0.  3.  0.  3. 16.  3.  3.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  8. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[328.65646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 8.  3.  8. 16.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -9.868189811706543
desired expected reward: 303.349853515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[323.95966]
 [324.45856]
 [324.73715]
 [324.34958]
 [325.45007]
 [324.5477 ]
 [324.8263 ]
 [328.47095]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 8.  3.  8. 16.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 25. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.697153091430664
desired expected reward: 317.8678894042969



buy possibilites: [-1] 
expected returns: [[314.13486]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 8.  3.  8. 16.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -14 

action type: buy - action 1.0
Learning step: -9.85489559173584
desired expected reward: 314.60369873046875






Player: 1 
cards in hand: [ 0. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 8.] 
adversary cards in discard: [ 8.  3.  8. 16.  0.  0.  1.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8  1] -> size -> 17 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 25. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 8.] 
adversary cards in discard: [ 8.  3.  8. 16.  0.  0.  1.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8  1] -> size -> 17 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 24. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 8.] 
adversary cards in discard: [ 8.  3.  8. 16.  0.  0.  1.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8  1] -> size -> 17 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[310.23734]
 [306.3141 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 8.] 
cards in discard: [ 8.  3.  8. 16.  0.  0.  1.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 24. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  3. 10.  0.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -10.883706092834473
desired expected reward: 303.25115966796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[304.92645]
 [305.70395]
 [305.3164 ]
 [305.5145 ]
 [309.43768]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 8.] 
cards in discard: [ 8.  3.  8. 16.  0.  0.  1.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 24. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  3. 10.  0.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -10.65661907196045
desired expected reward: 298.57269287109375



buy possibilites: [-1] 
expected returns: [[293.6774]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 8.] 
cards in discard: [ 8.  3.  8. 16.  0.  0.  1.  3.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8  1  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 24. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  3. 10.  0.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -72.0 

action type: buy - action 0.0
Learning step: -12.057296752929688
desired expected reward: 292.869140625






Player: 1 
cards in hand: [ 3.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.  0.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8  1  0] -> size -> 18 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.  0.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 24. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8  1  0] -> size -> 18 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.  0.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 24. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8  1  0] -> size -> 18 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[322.89285]
 [319.07016]
 [319.07016]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  3  3  8  8  8  1  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  0.  3.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0] -> size -> 21 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -9.562472343444824
desired expected reward: 284.11492919921875



action possibilites: [-1] 
expected returns: [[290.6844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  0.  3.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0] -> size -> 21 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: trash_cards_n_from_hand - action 4
Learning step: -10.522497177124023
desired expected reward: 308.73541259765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[285.1202 ]
 [285.4942 ]
 [289.51468]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  0.  3.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0] -> size -> 21 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1
Learning step: -9.169647216796875
desired expected reward: 281.5147399902344



buy possibilites: [-1] 
expected returns: [[297.954]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  0.  3.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0] -> size -> 21 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action 0.0
Learning step: -10.152044296264648
desired expected reward: 274.9681396484375






Player: 1 
cards in hand: [ 0.  3. 16.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0. 11.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  0.  3.  3.  3. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  9.  8.  9.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  3.  3. 16.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  0.  3.  3.  3. 10.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  9.  8.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  3.  3. 16.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  0.  3.  3.  3. 10.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 24. 30.  8.  9.  8.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  3.  3. 16.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  0.  3.  3.  3. 10.  0. 11.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  9.  8.  8.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  3.  3. 16.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[287.84433]
 [283.9935 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  3. 16.] 
cards in discard: [0. 8. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  9.  8.  8.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8] -> size -> 23 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -10.557435035705566
desired expected reward: 287.3965759277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[283.24677]
 [283.733  ]
 [284.0042 ]
 [283.6208 ]
 [284.69955]
 [283.81857]
 [284.08975]
 [287.64127]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  3. 16.] 
cards in discard: [0. 8. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 24. 30.  8.  9.  8.  8.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8] -> size -> 23 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -10.073264122009277
desired expected reward: 277.671142578125



buy possibilites: [-1] 
expected returns: [[301.38782]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  3. 16.] 
cards in discard: [0. 8. 8. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 24. 30.  8.  9.  8.  8.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8] -> size -> 23 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -72.0 

action type: buy - action 0.0
Learning step: -10.981114387512207
desired expected reward: 272.26568603515625






Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  9.  8.  8.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  8.  8.  0.  1.  0.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 24. 30.  8.  9.  8.  8.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  8.  8.  0.  1.  0.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  9.  8.  8.  5. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  8.  8.  0.  1.  0.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[313.0461 ]
 [309.22342]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 0.  8.  8.  0.  1.  0.  3.  3. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  9.  8.  8.  5. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8. 10.  3. 10.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -10.180685997009277
desired expected reward: 291.2071228027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[310.15112]
 [310.6374 ]
 [310.9086 ]
 [310.52512]
 [311.60388]
 [310.7229 ]
 [310.99414]
 [314.54562]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 0.  8.  8.  0.  1.  0.  3.  3. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 24. 30.  8.  9.  8.  8.  5. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8. 10.  3. 10.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -10.68612003326416
desired expected reward: 301.42236328125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  8. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 10.  3. 10.] 
cards in discard: [29.  0.  8.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  9.  8.  8.  5. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3. 10.] 
cards in discard: [29.  0.  8.  0.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  8.  8.  8.  5. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3. 10.] 
cards in discard: [29.  0.  8.  0.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  8.  8.  8.  5. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[253.63947]
 [249.8168 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  6  3  3  8  8  8  1  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  8.  8.  8.  5. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 11.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0.  6. 11.  8. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -11.656376838684082
desired expected reward: 302.8892517089844



action possibilites: [-1] 
expected returns: [[304.62375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  8.  8.  8.  5. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 11.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0.  6. 11.  8. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: trash_cards_n_from_hand - action 5
Learning step: -7.350244998931885
desired expected reward: 242.73533630371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[297.99612]
 [298.37015]
 [302.39062]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  8.  8.  8.  5. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 11.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0.  6. 11.  8. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -10.17690658569336
desired expected reward: 294.44683837890625



buy possibilites: [-1] 
expected returns: [[352.63864]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  7.  8.  8.  5. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 11.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0.  6. 11.  8. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6] -> size -> 25 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -345.0 

action type: buy - action 6.0
Learning step: -24.23413848876953
desired expected reward: 274.1360168457031






Player: 1 
cards in hand: [ 3.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 11.] 
cards in discard: [29.  0.  8.  0.  0.  0.  6. 11.  8. 10.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  7.  8.  8.  5. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 8. 0. 6.] 
adversary cards in discard: [6. 8. 0.] 
adversary owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [29.  0.  8.  0.  0.  0.  6. 11.  8. 10.  3. 10. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 8. 0. 6.] 
adversary cards in discard: [6. 8. 0.] 
adversary owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [29.  0.  8.  0.  0.  0.  6. 11.  8. 10.  3. 10. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 8. 0. 6.] 
adversary cards in discard: [6. 8. 0.] 
adversary owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [29.  0.  8.  0.  0.  0.  6. 11.  8. 10.  3. 10. 14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 24. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 8. 0. 6.] 
adversary cards in discard: [6. 8. 0.] 
adversary owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [1. 0. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[295.4743 ]
 [291.65164]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 0. 6.] 
cards in discard: [6. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 16.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0.  6. 11.  8. 10.  3. 10. 14.  0. 11.  3.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -14.256906509399414
desired expected reward: 338.3817443847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[276.698  ]
 [277.16196]
 [277.4202 ]
 [277.0464 ]
 [277.21652]
 [278.08743]
 [277.24344]
 [278.6814 ]
 [277.71362]
 [277.50168]
 [278.29932]
 [280.90344]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 0. 6.] 
cards in discard: [6. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 24. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 16.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0.  6. 11.  8. 10.  3. 10. 14.  0. 11.  3.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -10.970489501953125
desired expected reward: 268.7613220214844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 16.] 
cards in discard: [29.  0.  8.  0.  0.  0.  6. 11.  8. 10.  3. 10. 14.  0. 11.  3.  3.  3.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [6. 8. 0. 1. 0. 8. 0. 6.] 
adversary owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 16.] 
cards in discard: [29.  0.  8.  0.  0.  0.  6. 11.  8. 10.  3. 10. 14.  0. 11.  3.  3.  3.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 24. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [6. 8. 0. 1. 0. 8. 0. 6.] 
adversary owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[260.27487]
 [256.58795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 16.] 
cards in discard: [6. 8. 0. 1. 0. 8. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -11.491856575012207
desired expected reward: 269.41162109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[256.6025 ]
 [257.32477]
 [256.95096]
 [257.14798]
 [260.808  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 16.] 
cards in discard: [6. 8. 0. 1. 0. 8. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 24. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -10.404060363769531
desired expected reward: 248.96722412109375



buy possibilites: [-1] 
expected returns: [[238.78378]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 16.] 
cards in discard: [6. 8. 0. 1. 0. 8. 0. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 23. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -46 

action type: buy - action 3.0
Learning step: -9.793601989746094
desired expected reward: 247.5311279296875






Player: 1 
cards in hand: [ 0. 16.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 23. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6  3] -> size -> 16 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 23. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6  3] -> size -> 16 
adversary victory points: 1
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[242.87354]
 [239.21353]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  6  3  3  8  8  8  1  0  0  0  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 23. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -9.201708793640137
desired expected reward: 229.5820770263672



action possibilites: [-1] 
expected returns: [[304.3115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 23. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: trash_cards_n_from_hand - action 0
Learning step: -6.176310062408447
desired expected reward: 231.29005432128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[297.6881 ]
 [298.15207]
 [298.41034]
 [298.0365 ]
 [299.07758]
 [298.23358]
 [298.49182]
 [301.8936 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 23. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1
Learning step: -9.62848949432373
desired expected reward: 294.6830139160156



buy possibilites: [-1] 
expected returns: [[259.42798]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -5 

action type: buy - action 1.0
Learning step: -9.320474624633789
desired expected reward: 288.83160400390625






Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 0. 16.  0.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 1.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1] -> size -> 16 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 16.  0.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 1.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1] -> size -> 16 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 16.  0.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 30. 23. 30.  8.  7.  8.  8.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 1.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1] -> size -> 16 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 16.  0.  3.  3. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  7.  8.  8.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 1.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1] -> size -> 16 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[342.10437]
 [338.44437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 1.] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  7.  8.  8.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8.  3.  6.  3.] 
adversary cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25] -> size -> 28 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -7.477776527404785
desired expected reward: 251.9501953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[333.87143]
 [334.33542]
 [334.59366]
 [334.2198 ]
 [334.38995]
 [335.26086]
 [334.41687]
 [335.8548 ]
 [334.8871 ]
 [334.67517]
 [335.47278]
 [338.07687]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 1.] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 23. 30.  8.  7.  8.  8.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8.  3.  6.  3.] 
adversary cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25] -> size -> 28 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -11.655099868774414
desired expected reward: 329.4969787597656



buy possibilites: [-1] 
expected returns: [[251.85786]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 1.] 
cards in discard: [ 1.  8.  0.  0.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  7.  7.  8.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8.  3.  6.  3.] 
adversary cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25] -> size -> 28 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -11 

action type: buy - action 16.0
Learning step: -11.60269832611084
desired expected reward: 322.78729248046875






Player: 1 
cards in hand: [11.  8.  3.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  6.  3.] 
cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  7.  7.  8.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  8.  6.  3.] 
adversary cards in discard: [ 1.  8.  0.  0.  0. 16.  0.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1 16] -> size -> 17 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3.  6.  3.] 
cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  7.  7.  8.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  8.  6.  3.] 
adversary cards in discard: [ 1.  8.  0.  0.  0. 16.  0.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1 16] -> size -> 17 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3.  6.  3.] 
cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  7.  7.  8.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  8.  6.  3.] 
adversary cards in discard: [ 1.  8.  0.  0.  0. 16.  0.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1 16] -> size -> 17 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 3. 16.  8.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[246.41232]
 [242.7254 ]
 [242.75232]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  8.  6.  3.] 
cards in discard: [ 1.  8.  0.  0.  0. 16.  0.  3.  0.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  7.  7.  8.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3. 29.] 
adversary cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0. 11.  8.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25  0] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -9.254137992858887
desired expected reward: 242.60372924804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[241.50531]
 [241.85374]
 [245.7108 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  8.  6.  3.] 
cards in discard: [ 1.  8.  0.  0.  0. 16.  0.  3.  0.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1 16] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  7.  7.  8.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3. 29.] 
adversary cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0. 11.  8.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25  0] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -8.962227821350098
desired expected reward: 236.9034881591797



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3. 29.] 
cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0. 11.  8.  3.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  7.  7.  8.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  1.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1 16] -> size -> 17 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0. 11.  8.  3.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 23. 30.  8.  7.  7.  8.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  1.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1 16] -> size -> 17 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0. 11.  8.  3.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 23. 30.  8.  7.  7.  8.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  1.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1 16] -> size -> 17 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [16.  1.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[222.40276]
 [218.71585]
 [218.74274]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  3  3  8  8  8  1  0  0  0  6  3  1 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  7.  7.  8.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 11. 14.  8.] 
adversary cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0. 11.  8.  3.  6.  3.
 29.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25  0] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -9.473494529724121
desired expected reward: 236.23728942871094



action possibilites: [-1] 
expected returns: [[204.5808]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 16  3  3  8  8  1  0  0  0  6  3  1 16 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 11. 14.  8.] 
adversary cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0. 11.  8.  3.  6.  3.
 29.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25  0] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -14 

action type: gain_card_n - action 5
Learning step: -8.178030967712402
desired expected reward: 233.44395446777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[202.83336]
 [203.26799]
 [203.50966]
 [203.1513 ]
 [203.319  ]
 [204.14226]
 [203.34569]
 [204.70308]
 [203.78392]
 [203.58734]
 [204.33882]
 [206.80446]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 16  3  3  8  8  1  0  0  0  6  3  1 16 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 11. 14.  8.] 
adversary cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0. 11.  8.  3.  6.  3.
 29.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25  0] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1
Learning step: -6.777222633361816
desired expected reward: 197.80357360839844



buy possibilites: [-1] 
expected returns: [[229.63686]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [11.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 16  3  3  8  8  1  0  0  0  6  3  1 16 11  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 11. 14.  8.] 
adversary cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0. 11.  8.  3.  6.  3.
 29.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25  0] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -18.5 

action type: buy - action 1.0
Learning step: -5.921570301055908
desired expected reward: 197.34642028808594






Player: 1 
cards in hand: [ 3.  3. 11. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 14.  8.] 
cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0. 11.  8.  3.  6.  3.
 29.  0. 10.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29
  6 14  0 25  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [11.  1. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  1  0  0  0  6  3  1 16 11  1] -> size -> 18 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.] 
cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0. 11.  8.  3.  6.  3.
 29.  0. 10.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14
  0 25  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [11.  1. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  1  0  0  0  6  3  1 16 11  1] -> size -> 18 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.] 
cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0. 11.  8.  3.  6.  3.
 29.  0. 10.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14
  0 25  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [11.  1. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  1  0  0  0  6  3  1 16 11  1] -> size -> 18 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.] 
cards in discard: [ 0. 16.  0.  3.  3. 25. 10.  0.  0.  0.  0.  0.  0. 11.  8.  3.  6.  3.
 29.  0. 10.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14
  0 25  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [11.  1. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0 16  3  3  8  8  1  0  0  0  6  3  1 16 11  1] -> size -> 18 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[204.23561]
 [200.77687]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 8.] 
cards in discard: [11.  1. 16.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  3  3  8  8  1  0  0  0  6  3  1 16 11  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14
  0 25  0  0] -> size -> 28 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.07373332977295
desired expected reward: 221.56312561035156



action possibilites: [-1] 
expected returns: [[222.68498]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [11.  1. 16.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14
  0 25  0  0] -> size -> 28 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 9
Learning step: -5.754338264465332
desired expected reward: 195.54066467285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[218.64719]
 [219.32353]
 [218.9652 ]
 [219.15956]
 [222.61829]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [11.  1. 16.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14
  0 25  0  0] -> size -> 28 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -6.876091003417969
desired expected reward: 215.80889892578125






Player: 1 
cards in hand: [10.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14
  0 25  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  6.  8.  0.] 
adversary cards in discard: [11.  1. 16.  1.  0.  0.  8.  1.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1] -> size -> 15 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14
  0 25  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  6.  8.  0.] 
adversary cards in discard: [11.  1. 16.  1.  0.  0.  8.  1.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1] -> size -> 15 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0. 11.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14
  0 25  0  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  6.  8.  0.] 
adversary cards in discard: [11.  1. 16.  1.  0.  0.  8.  1.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1] -> size -> 15 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3. 16.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[262.56766]
 [259.08218]
 [259.1089 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.  8.  0.] 
cards in discard: [11.  1. 16.  1.  0.  0.  8.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14
  0 25  0  0  0] -> size -> 29 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -6.970666408538818
desired expected reward: 215.6476287841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[259.79614]
 [260.11414]
 [263.76724]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  6.  8.  0.] 
cards in discard: [11.  1. 16.  1.  0.  0.  8.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 23. 30.  8.  7.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14
  0 25  0  0  0] -> size -> 29 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.92365550994873
desired expected reward: 253.3476104736328



buy possibilites: [-1] 
expected returns: [[207.49945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  6.  8.  0.] 
cards in discard: [11.  1. 16.  1.  0.  0.  8.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 23. 30.  8.  6.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14
  0 25  0  0  0] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -345.0 

action type: buy - action 6.0
Learning step: -25.58696937561035
desired expected reward: 234.52716064453125






Player: 1 
cards in hand: [ 0.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  0.] 
cards in discard: [ 0. 10.  3.  0.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14
  0 25  0  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8.  6.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6] -> size -> 16 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  3.  0.  0. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 23. 30.  8.  6.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6] -> size -> 16 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  3.  0.  0. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 23. 30.  8.  6.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6] -> size -> 16 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 27. 30. 23. 30.  8.  6.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6] -> size -> 16 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[241.74348]
 [239.08128]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 23. 30.  8.  6.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  0. 25.  3.  3.] 
adversary cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -7.208705902099609
desired expected reward: 200.29074096679688



action possibilites: [-1] 
expected returns: [[231.33699]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 23. 30.  8.  5.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  0. 25.  3.  3.] 
adversary cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0  0] -> size -> 30 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -50    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -336 

action type: gain_card_n - action 3
Learning step: -23.68505859375
desired expected reward: 218.11778259277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[229.00124]
 [229.4359 ]
 [229.67755]
 [229.31923]
 [229.4869 ]
 [230.31018]
 [229.51358]
 [230.87097]
 [229.95183]
 [229.75525]
 [230.50674]
 [232.97235]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 27. 30. 23. 30.  8.  5.  7.  7.  5.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  0. 25.  3.  3.] 
adversary cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0  0] -> size -> 30 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -8.176254272460938
desired expected reward: 223.16073608398438



buy possibilites: [-1] 
expected returns: [[219.84668]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [6. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 27. 30. 23. 30.  8.  5.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  0. 25.  3.  3.] 
adversary cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0  0] -> size -> 30 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -34.0 

action type: buy - action 8.0
Learning step: -7.892300605773926
desired expected reward: 221.6212921142578






Player: 1 
cards in hand: [14.  0. 25.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 25.  3.  3.] 
cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 23. 30.  8.  5.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 16.  1.  8.  3.] 
adversary cards in discard: [ 6.  8. 11.  0.  1.  3.  0.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8] -> size -> 18 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 25.  3.  3.] 
cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 23. 30.  8.  5.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 16.  1.  8.  3.] 
adversary cards in discard: [ 6.  8. 11.  0.  1.  3.  0.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8] -> size -> 18 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 6. 16.  1.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[198.31335]
 [194.97299]
 [194.9975 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  1.  8.  3.] 
cards in discard: [ 6.  8. 11.  0.  1.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 23. 30.  8.  5.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 29.  0.  3.] 
adversary cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0. 14.  0. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0  0] -> size -> 30 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -9.388494491577148
desired expected reward: 210.45819091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[194.23697]
 [194.87735]
 [194.53123]
 [194.72414]
 [198.04002]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  1.  8.  3.] 
cards in discard: [ 6.  8. 11.  0.  1.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 23. 30.  8.  5.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 29.  0.  3.] 
adversary cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0. 14.  0. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0  0] -> size -> 30 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -8.266115188598633
desired expected reward: 189.20059204101562



buy possibilites: [-1] 
expected returns: [[224.12376]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  1.  8.  3.] 
cards in discard: [ 6.  8. 11.  0.  1.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 29.  0.  3.] 
adversary cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0. 14.  0. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0  0] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -367.0 

action type: buy - action 6.0
Learning step: -23.033777236938477
desired expected reward: 171.4974365234375






Player: 1 
cards in hand: [ 8.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  0.  3.] 
cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0. 14.  0. 25.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  1. 16.  0.] 
adversary cards in discard: [ 6.  8. 11.  0.  1.  3.  0.  6.  6. 16.  1.  8.  3.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6] -> size -> 19 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0. 14.  0. 25.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0
 25  0  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  1. 16.  0.] 
adversary cards in discard: [ 6.  8. 11.  0.  1.  3.  0.  6.  6. 16.  1.  8.  3.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6] -> size -> 19 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0. 14.  0. 25.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  1. 16.  0.] 
adversary cards in discard: [ 6.  8. 11.  0.  1.  3.  0.  6.  6. 16.  1.  8.  3.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6] -> size -> 19 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0. 14.  0. 25.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  1. 16.  0.] 
adversary cards in discard: [ 6.  8. 11.  0.  1.  3.  0.  6.  6. 16.  1.  8.  3.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6] -> size -> 19 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0. 14.  0. 25.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  1. 16.  0.] 
adversary cards in discard: [ 6.  8. 11.  0.  1.  3.  0.  6.  6. 16.  1.  8.  3.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6] -> size -> 19 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  1. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[227.30328]
 [223.96289]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1. 16.  0.] 
cards in discard: [ 6.  8. 11.  0.  1.  3.  0.  6.  6. 16.  1.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 11.  6.] 
adversary cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0. 14.  0. 25.  3.  3.  0.
 29.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -9.471343040466309
desired expected reward: 214.6524200439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[225.43036]
 [225.84204]
 [226.07074]
 [225.7246 ]
 [225.89304]
 [226.67798]
 [225.91754]
 [227.2176 ]
 [226.33183]
 [226.14621]
 [226.86359]
 [229.2334 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1. 16.  0.] 
cards in discard: [ 6.  8. 11.  0.  1.  3.  0.  6.  6. 16.  1.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 11.  6.] 
adversary cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0. 14.  0. 25.  3.  3.  0.
 29.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -9.606614112854004
desired expected reward: 217.6966552734375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 10. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11.  6.] 
cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0. 14.  0. 25.  3.  3.  0.
 29.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6] -> size -> 19 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 11.  6.] 
cards in discard: [ 0. 10.  3.  0.  0. 11.  0.  0. 16.  0.  0.  0. 14.  0. 25.  3.  3.  0.
 29.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6] -> size -> 19 
adversary victory points: -2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 3. 16. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.  8.] 
expected returns: [[218.16069]
 [214.82031]
 [214.82031]
 [214.84482]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 16.  0.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -9.94677734375
desired expected reward: 219.28662109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[214.33206]
 [214.62633]
 [218.1351 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16. 16.  0.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -9.393872261047363
desired expected reward: 208.7840118408203



buy possibilites: [-1] 
expected returns: [[248.4465]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16. 16.  0.  8.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -97.0 

action type: buy - action 0.0
Learning step: -9.976556777954102
desired expected reward: 204.35549926757812






Player: 1 
cards in hand: [25.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [ 0.  3. 16. 16.  0.  8.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0] -> size -> 20 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 23. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [ 0.  3. 16. 16.  0.  8.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0] -> size -> 20 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  8.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 22. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [ 0.  3. 16. 16.  0.  8.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0] -> size -> 20 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[201.18993]
 [197.87405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [ 0.  3. 16. 16.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 22. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  0.  0.  3.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -11.793864250183105
desired expected reward: 236.6526336669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[198.22333]
 [198.635  ]
 [198.86371]
 [198.51758]
 [199.47093]
 [198.7105 ]
 [198.9392 ]
 [202.02637]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [ 0.  3. 16. 16.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 22. 30.  8.  4.  7.  7.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  0.  0.  3.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -9.371927261352539
desired expected reward: 190.9713592529297



buy possibilites: [-1] 
expected returns: [[221.19516]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [ 0.  3. 16. 16.  0.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 22. 30.  8.  4.  7.  6.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  0.  0.  3.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -59 

action type: buy - action 11.0
Learning step: -7.9466552734375
desired expected reward: 191.52427673339844






Player: 1 
cards in hand: [10.  6.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  0.  3.] 
cards in discard: [ 3. 25.  0.  0.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 22. 30.  8.  4.  7.  6.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  1.  6.  1.] 
adversary cards in discard: [ 0.  3. 16. 16.  0.  8. 11.  0.  0.  6.  0.  8.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11] -> size -> 21 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 3. 25.  0.  0.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 22. 30.  8.  4.  7.  6.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  1.  6.  1.] 
adversary cards in discard: [ 0.  3. 16. 16.  0.  8. 11.  0.  0.  6.  0.  8.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11] -> size -> 21 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 3. 25.  0.  0.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 22. 30.  8.  4.  7.  6.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  1.  6.  1.] 
adversary cards in discard: [ 0.  3. 16. 16.  0.  8. 11.  0.  0.  6.  0.  8.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11] -> size -> 21 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 3. 25.  0.  0.  0.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 21. 30.  8.  4.  7.  6.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  1.  6.  1.] 
adversary cards in discard: [ 0.  3. 16. 16.  0.  8. 11.  0.  0.  6.  0.  8.] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11] -> size -> 21 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11.  6.  1.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[183.46494]
 [180.90952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  1.  6.  1.] 
cards in discard: [ 0.  3. 16. 16.  0.  8. 11.  0.  0.  6.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  4.  7.  6.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8.  3.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3] -> size -> 30 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -11.304348945617676
desired expected reward: 209.89080810546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[180.40558]
 [180.81725]
 [181.04594]
 [180.69981]
 [180.86821]
 [181.65318]
 [180.89276]
 [182.19281]
 [181.30705]
 [181.12143]
 [181.83879]
 [184.20862]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  1.  6.  1.] 
cards in discard: [ 0.  3. 16. 16.  0.  8. 11.  0.  0.  6.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 21. 30.  8.  4.  7.  6.  4.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8.  3.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3] -> size -> 30 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -9.427756309509277
desired expected reward: 174.03720092773438



buy possibilites: [-1] 
expected returns: [[154.26062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  1.  6.  1.] 
cards in discard: [ 0.  3. 16. 16.  0.  8. 11.  0.  0.  6.  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 21. 30.  8.  4.  7.  6.  3.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8.  3.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3] -> size -> 30 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -80.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -85.0 

action type: buy - action 8.0
Learning step: -9.823773384094238
desired expected reward: 171.0689697265625






Player: 1 
cards in hand: [11.  3.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  8.  3.] 
cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  4.  7.  6.  3.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  8.  6.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8] -> size -> 22 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  8.  3.] 
cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 21. 30.  8.  4.  7.  6.  3.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  8.  6.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8] -> size -> 22 
adversary victory points: -2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [16.  8.  6.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[187.34253]
 [184.00215]
 [184.02666]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  6.  1.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  4.  7.  6.  3.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0. 11.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3] -> size -> 30 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -7.893399715423584
desired expected reward: 146.36721801757812



action possibilites: [-1] 
expected returns: [[191.167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 1.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8.  4.  7.  6.  3.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0. 11.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3] -> size -> 30 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -63 

action type: gain_card_n - action 2
Learning step: -10.18405818939209
desired expected reward: 216.52224731445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[187.60152]
 [188.20116]
 [187.8682 ]
 [188.06065]
 [191.20738]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 1.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 20. 30.  8.  4.  7.  6.  3.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0. 11.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3] -> size -> 30 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -8.652420043945312
desired expected reward: 182.51458740234375






Player: 1 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0. 11.  3.  0.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8.  4.  7.  6.  3.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  8.  8.] 
adversary cards in discard: [ 3. 16.  8.  6.  1.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3] -> size -> 22 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0. 11.  3.  0.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 20. 30.  8.  4.  7.  6.  3.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  8.  8.] 
adversary cards in discard: [ 3. 16.  8.  6.  1.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3] -> size -> 22 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0. 11.  3.  0.  8.  3.
  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  4.  7.  6.  3.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  8.  8.] 
adversary cards in discard: [ 3. 16.  8.  6.  1.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3] -> size -> 22 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 16.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
expected returns: [[191.28041]
 [188.10992]
 [188.13368]
 [188.13368]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 16.  8.  8.] 
cards in discard: [ 3. 16.  8.  6.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  4.  7.  6.  3.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16. 10.  0. 11. 14.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0. 11.  3.  0.  8.  3.
  1. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -9.65673542022705
desired expected reward: 181.55064392089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[187.61911]
 [188.21877]
 [187.88579]
 [188.07825]
 [191.22499]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 16.  8.  8.] 
cards in discard: [ 3. 16.  8.  6.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 20. 30.  8.  4.  7.  6.  3.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16. 10.  0. 11. 14.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0. 11.  3.  0.  8.  3.
  1. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -9.638992309570312
desired expected reward: 181.26739501953125



buy possibilites: [-1] 
expected returns: [[131.05147]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 16.  8.  8.] 
cards in discard: [ 3. 16.  8.  6.  1.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  4.  7.  6.  2.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16. 10.  0. 11. 14.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0. 11.  3.  0.  8.  3.
  1. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -79 

action type: buy - action 8.0
Learning step: -10.405255317687988
desired expected reward: 177.67300415039062






Player: 1 
cards in hand: [16. 10.  0. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  0. 11. 14.] 
cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0. 11.  3.  0.  8.  3.
  1. 29.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  4.  7.  6.  2.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [ 3. 16.  8.  6.  1.  8.  3.  1. 16.  8.  8.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8] -> size -> 23 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 10.  0. 11. 14.] 
cards in discard: [ 3. 25.  0.  0.  0.  8.  3. 10.  6.  0.  0.  3.  0. 11.  3.  0.  8.  3.
  1. 29.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 20. 30.  8.  4.  7.  6.  2.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [ 3. 16.  8.  6.  1.  8.  3.  1. 16.  8.  8.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8] -> size -> 23 
adversary victory points: -2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[157.52281]
 [155.09485]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  1.] 
cards in discard: [ 3. 16.  8.  6.  1.  8.  3.  1. 16.  8.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  4.  7.  6.  2.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -7.379736423492432
desired expected reward: 123.6717300415039



action possibilites: [-1] 
expected returns: [[152.67883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 3. 16.  8.  6.  1.  8.  3.  1. 16.  8.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  4.  7.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -51 

action type: gain_card_n - action 10
Learning step: -6.844189643859863
desired expected reward: 147.7450714111328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[152.72836]
 [153.11482]
 [153.328  ]
 [152.78366]
 [152.99503]
 [153.16374]
 [153.90628]
 [153.18748]
 [154.24757]
 [154.42018]
 [153.57329]
 [154.05513]
 [153.4007 ]
 [153.54955]
 [154.07887]
 [156.33421]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 3. 16.  8.  6.  1.  8.  3.  1. 16.  8.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 26. 30. 20. 30.  8.  4.  7.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -7.513282775878906
desired expected reward: 145.16555786132812



buy possibilites: [-1] 
expected returns: [[184.17148]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 3. 16.  8.  6.  1.  8.  3.  1. 16.  8.  8. 15. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 20. 30.  8.  4.  6.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -80.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -59.0 

action type: buy - action 16.0
Learning step: -6.464328765869141
desired expected reward: 146.6994171142578






Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  4.  6.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  6.  6.] 
adversary cards in discard: [ 3. 16.  8.  6.  1.  8.  3.  1. 16.  8.  8. 15. 16. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16] -> size -> 25 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 20. 30.  8.  4.  6.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  6.  6.] 
adversary cards in discard: [ 3. 16.  8.  6.  1.  8.  3.  1. 16.  8.  8. 15. 16. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16] -> size -> 25 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 19. 30.  8.  4.  6.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  6.  6.] 
adversary cards in discard: [ 3. 16.  8.  6.  1.  8.  3.  1. 16.  8.  8. 15. 16. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16] -> size -> 25 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[188.25352]
 [185.82555]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  6.  6.] 
cards in discard: [ 3. 16.  8.  6.  1.  8.  3.  1. 16.  8.  8. 15. 16. 11.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 19. 30.  8.  4.  6.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11. 14.  0.  6.  3.] 
adversary cards in discard: [3. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -9.8442964553833
desired expected reward: 174.32717895507812



action possibilites: [-1] 
expected returns: [[199.71404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [ 3. 16.  8.  6.  1.  8.  3.  1. 16.  8.  8. 15. 16. 11.  0.  0.  0.  1.
 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 19. 30.  8.  4.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11. 14.  0.  6.  3.] 
adversary cards in discard: [3. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -61 

action type: gain_card_n - action 4
Learning step: -7.7915825843811035
desired expected reward: 176.911376953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[195.28256]
 [195.88223]
 [195.54924]
 [195.74171]
 [198.88843]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [ 3. 16.  8.  6.  1.  8.  3.  1. 16.  8.  8. 15. 16. 11.  0.  0.  0.  1.
 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 19. 30.  8.  4.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11. 14.  0.  6.  3.] 
adversary cards in discard: [3. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -9.406947135925293
desired expected reward: 190.3070831298828






Player: 1 
cards in hand: [11. 14.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  0.  6.  3.] 
cards in discard: [3. 0. 3. 3. 3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 19. 30.  8.  4.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 1. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16] -> size -> 26 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  0.  6.  3.] 
cards in discard: [3. 0. 3. 3. 3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 19. 30.  8.  4.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 1. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16] -> size -> 26 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  0.  6.  3.] 
cards in discard: [3. 0. 3. 3. 3. 0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 19. 30.  8.  4.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 1. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16] -> size -> 26 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [6. 1. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[166.21324]
 [163.06653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 19. 30.  8.  4.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 10.  0.] 
adversary cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3  0] -> size -> 33 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1.0
Learning step: -11.08239459991455
desired expected reward: 187.80604553222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[152.41473]
 [152.78337]
 [152.98541]
 [152.66179]
 [153.54373]
 [152.85399]
 [153.05606]
 [155.88719]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 30. 19. 30.  8.  4.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 10.  0.] 
adversary cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3  0] -> size -> 33 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -9.116320610046387
desired expected reward: 145.43661499023438



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 10.  0.] 
cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 19. 30.  8.  4.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  8. 16.  3. 16.] 
adversary cards in discard: [6. 1. 0. 8. 6.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16] -> size -> 26 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 10.  0.] 
cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 30. 19. 30.  8.  4.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  8. 16.  3. 16.] 
adversary cards in discard: [6. 1. 0. 8. 6.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16] -> size -> 26 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 10.  0.] 
cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 18. 30.  8.  4.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  8. 16.  3. 16.] 
adversary cards in discard: [6. 1. 0. 8. 6.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16] -> size -> 26 
adversary victory points: -2
player victory points: 8 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [16.  8. 16.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 16. 16.] 
expected returns: [[120.82071]
 [117.76502]
 [117.78752]
 [117.76502]
 [117.76502]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 16.  3. 16.] 
cards in discard: [6. 1. 0. 8. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 18. 30.  8.  4.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3  0  3] -> size -> 34 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1.0
Learning step: -10.468960762023926
desired expected reward: 145.41822814941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[117.81589]
 [118.06294]
 [121.28835]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8. 16.  3. 16.] 
cards in discard: [6. 1. 0. 8. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 18. 30.  8.  4.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3  0  3] -> size -> 34 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: take_action - action -1.0
Learning step: -8.70145320892334
desired expected reward: 112.11925506591797



buy possibilites: [-1] 
expected returns: [[166.9829]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8. 16.  3. 16.] 
cards in discard: [6. 1. 0. 8. 6. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 18. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3  0  3] -> size -> 34 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -418 

action type: buy - action 6.0
Learning step: -23.04603385925293
desired expected reward: 95.01691436767578






Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0
  0  0  0  0  3  3  1  3  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 18. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 15. 11.  0.  8.] 
adversary cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16  6] -> size -> 27 
adversary victory points: -3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0
  0  3  3  1  3  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 18. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 15. 11.  0.  8.] 
adversary cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16  6] -> size -> 27 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0
  0  3  3  1  3  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 18. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 15. 11.  0.  8.] 
adversary cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16  6] -> size -> 27 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 8. 15. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 11.  8.] 
expected returns: [[132.26254]
 [129.22935]
 [130.08311]
 [129.91908]
 [129.22935]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 11.  0.  8.] 
cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 18. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  8. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0.] 
adversary owned cards: [ 0  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0
  0  3  3  1  3  0  3] -> size -> 31 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -10.81061840057373
desired expected reward: 156.17227172851562



action possibilites: [-1] 
expected returns: [[144.39766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.  8.] 
cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16  6  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 18. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  8. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0.] 
adversary owned cards: [ 0  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0
  0  3  3  1  3  0  3] -> size -> 31 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -79 

action type: gain_card_n - action 1
Learning step: -7.1589884757995605
desired expected reward: 121.99971771240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[141.52675]
 [141.77382]
 [144.99924]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.  8.] 
cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16  6  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 18. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  8. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0.] 
adversary owned cards: [ 0  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0
  0  3  3  1  3  0  3] -> size -> 31 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action -1
Learning step: -8.396806716918945
desired expected reward: 136.0008544921875



buy possibilites: [-1] 
expected returns: [[61.77764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.  8.] 
cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16  6  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 30. 18. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  8. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0.] 
adversary owned cards: [ 0  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0
  0  3  3  1  3  0  3] -> size -> 31 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -100.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -118.0 

action type: buy - action 0.0
Learning step: -11.58634090423584
desired expected reward: 129.9404296875






Player: 1 
cards in hand: [ 0.  0. 25.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  8. 10.] 
cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0
  0  3  3  1  3  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 18. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  6. 16.  6.  1.] 
adversary cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16  6  1  0] -> size -> 29 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  8.  1.] 
cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 10  0 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0
  0  3  3  1  3  0  3] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 18. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  6. 16.  6.  1.] 
adversary cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16  6  1  0] -> size -> 29 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.] 
cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 18. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  6. 16.  6.  1.] 
adversary cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16  6  1  0] -> size -> 29 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.] 
cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 25. 30. 18. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  6. 16.  6.  1.] 
adversary cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16  6  1  0] -> size -> 29 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 3.  6. 16.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[130.62987]
 [127.57419]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 16.  6.  1.] 
cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  6  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15
 16 16  6  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 18. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 11.  0.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0. 10.  8. 25.  1.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3] -> size -> 29 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -5.576676368713379
desired expected reward: 56.200965881347656



action possibilites: [-1] 
expected returns: [[103.69206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 1.] 
cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 17. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 11.  0.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0. 10.  8. 25.  1.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -62 

action type: gain_card_n - action 1
Learning step: -6.289099216461182
desired expected reward: 104.15431213378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[100.37238 ]
 [100.943085]
 [100.61946 ]
 [100.81167 ]
 [103.84486 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1.] 
cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 25. 30. 17. 30.  8.  3.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 11.  0.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0. 10.  8. 25.  1.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -6.192687511444092
desired expected reward: 97.49937438964844



buy possibilites: [-1] 
expected returns: [[123.588135]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1.] 
cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.
  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 25. 30. 17. 30.  8.  2.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 11.  0.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0. 10.  8. 25.  1.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -90.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -377.0 

action type: buy - action 6.0
Learning step: -21.10024070739746
desired expected reward: 79.51920318603516






Player: 1 
cards in hand: [16.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11.  0.  3.] 
cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0. 10.  8. 25.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 17. 30.  8.  2.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  8.  1.  0.  0.] 
adversary cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.
  3.  6. 16.  3.  6.  1.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3  6] -> size -> 30 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 11.  0.  3.] 
cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0. 10.  8. 25.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 25. 30. 17. 30.  8.  2.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  8.  1.  0.  0.] 
adversary cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.
  3.  6. 16.  3.  6.  1.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3  6] -> size -> 30 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 11.  0.  3.] 
cards in discard: [ 3.  0.  3.  3.  3.  0.  0. 11. 14.  0.  6.  3.  3.  3.  0. 29. 10.  0.
  8.  0. 10.  8. 25.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 25. 30. 17. 30.  8.  2.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  8.  1.  0.  0.] 
adversary cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.
  3.  6. 16.  3.  6.  1.] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3  6] -> size -> 30 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [11.  8.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[110.258446]
 [107.91498 ]
 [107.22525 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  1.  0.  0.] 
cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.
  3.  6. 16.  3.  6.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 17. 30.  8.  2.  5.  6.  2.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -8.580224990844727
desired expected reward: 115.0079116821289



action possibilites: [-1] 
expected returns: [[110.91992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 0.] 
cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.
  3.  6. 16.  3.  6.  1. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3  6 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 17. 30.  8.  2.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -61 

action type: gain_card_n - action 10
Learning step: -5.325042247772217
desired expected reward: 90.08975982666016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[107.94546 ]
 [108.29163 ]
 [108.480644]
 [108.16772 ]
 [108.33825 ]
 [109.01507 ]
 [108.360535]
 [109.490746]
 [108.70213 ]
 [108.549545]
 [109.16763 ]
 [111.25172 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0.] 
cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.
  3.  6. 16.  3.  6.  1. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3  6 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 25. 30. 17. 30.  8.  2.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -6.935868263244629
desired expected reward: 103.98405456542969



buy possibilites: [-1] 
expected returns: [[101.98496]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0.] 
cards in discard: [ 6.  1.  0.  8.  6.  6. 16.  8. 16.  3. 16.  1.  0. 11.  8. 15.  0.  8.
  3.  6. 16.  3.  6.  1. 15.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3  6 15  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 17. 30.  8.  2.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5.    0.   -2.  -90.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -72.5 

action type: buy - action 1.0
Learning step: -6.744920253753662
desired expected reward: 101.54671478271484






Player: 1 
cards in hand: [ 0. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 17. 30.  8.  2.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [16.  8.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3  6 15  1] -> size -> 32 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 17. 30.  8.  1.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [16.  8.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3  6 15  1] -> size -> 32 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 30. 17. 30.  8.  1.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [16.  8.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3  6 15  1] -> size -> 32 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [6. 3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 16. 30.  8.  1.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [16.  8.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3  6 15  1] -> size -> 32 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [16.  8.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 16.] 
expected returns: [[142.05443]
 [139.14096]
 [139.16324]
 [139.14096]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0. 16.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  8  1  0  0  0  3  1 16 11  1  6  6  8  6  0 11  8  3  8 15 16
 16  6  1  0  3  6 15  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 16. 30.  8.  1.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [25.  8.  3. 16.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -6.791491985321045
desired expected reward: 95.19347381591797



action possibilites: [-1] 
expected returns: [[148.07616]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 16. 30.  8.  1.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [25.  8.  3. 16.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: trash_cards_n_from_hand - action 3
Learning step: -7.500859260559082
desired expected reward: 132.1505889892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[144.4945 ]
 [145.0297 ]
 [144.71677]
 [144.90959]
 [147.80077]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 30. 16. 30.  8.  1.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [25.  8.  3. 16.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -7.970836162567139
desired expected reward: 140.10531616210938






Player: 1 
cards in hand: [25.  8.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 16.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  3. 16.  0.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 16. 30.  8.  1.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [1. 1. 0. 3. 6.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1] -> size -> 30 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 16.  0. 10.  3.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 16. 30.  8.  0.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [1. 1. 0. 3. 6.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6] -> size -> 31 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 16.  0. 10.  3.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 24. 30. 16. 30.  8.  0.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [1. 1. 0. 3. 6.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6] -> size -> 31 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 16.  0. 10.  3.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 24. 30. 16. 30.  8.  0.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [1. 1. 0. 3. 6.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6] -> size -> 31 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [1. 1. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[131.92392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 3. 6.] 
cards in discard: [8. 0. 0. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 16. 30.  8.  0.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0] -> size -> 33 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -408 

action type: buy - action -1.0
Learning step: -24.82175064086914
desired expected reward: 122.97901916503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[127.496544]
 [127.842705]
 [128.03171 ]
 [127.535545]
 [127.88933 ]
 [128.56613 ]
 [127.91162 ]
 [128.88925 ]
 [129.04182 ]
 [128.2532  ]
 [128.69643 ]
 [128.10062 ]
 [128.23093 ]
 [128.7187  ]
 [130.80278 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 3. 6.] 
cards in discard: [8. 0. 0. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 24. 30. 16. 30.  8.  0.  5.  6.  2.  9.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0] -> size -> 33 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -9.09553337097168
desired expected reward: 122.82838439941406



buy possibilites: [-1] 
expected returns: [[151.93004]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 3. 6.] 
cards in discard: [ 8.  0.  0.  6. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 24. 30. 16. 30.  8.  0.  5.  6.  2.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0] -> size -> 33 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -100.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    8.    0.] 
sum of rewards: -100.0 

action type: buy - action 14.0
Learning step: -7.994234561920166
desired expected reward: 120.25897216796875






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 16. 30.  8.  0.  5.  6.  2.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [1. 0. 3. 3. 1.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14] -> size -> 32 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 24. 30. 16. 30.  8.  0.  5.  6.  2.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [1. 0. 3. 3. 1.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14] -> size -> 32 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 24. 30. 15. 30.  8.  0.  5.  6.  2.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [1. 0. 3. 3. 1.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14] -> size -> 32 
adversary victory points: -3
player victory points: 8 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[173.38037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 15. 30.  8.  0.  5.  6.  2.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0. 3. 3. 6.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.  0.  0.
  0.  3.  0.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3] -> size -> 34 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1
Learning step: -9.595443725585938
desired expected reward: 142.3345947265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[175.14441]
 [175.49059]
 [175.67957]
 [175.18338]
 [175.53719]
 [176.21397]
 [175.55946]
 [176.53712]
 [176.6897 ]
 [175.90108]
 [176.34428]
 [175.74849]
 [175.8788 ]
 [176.36656]
 [178.45068]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 24. 30. 15. 30.  8.  0.  5.  6.  2.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0. 3. 3. 6.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.  0.  0.
  0.  3.  0.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3] -> size -> 34 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action -1.0
Learning step: -10.596278190612793
desired expected reward: 162.78408813476562



buy possibilites: [-1] 
expected returns: [[168.33556]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0. 3. 3. 6.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.  0.  0.
  0.  3.  0.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3] -> size -> 34 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -110.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    8.    0.] 
sum of rewards: -110.0 

action type: buy - action 16.0
Learning step: -10.489310264587402
desired expected reward: 165.0478973388672






Player: 1 
cards in hand: [8. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 6.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.  0.  0.
  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [16. 15.  0.  0.  1.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16] -> size -> 33 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 6.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.  0.  0.
  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [16. 15.  0.  0.  1.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16] -> size -> 33 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 6.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.  0.  0.
  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [16. 15.  0.  0.  1.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16] -> size -> 33 
adversary victory points: -3
player victory points: 8 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [16. 15.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
expected returns: [[161.13467]
 [158.2212 ]
 [159.05058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.  0.  0.  1.] 
cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.  0.  0.
  0.  3.  0.  0.  8.  0.  3.  3.  6.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0] -> size -> 35 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1
Learning step: -10.720649719238281
desired expected reward: 157.61489868164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[158.0949 ]
 [158.44106]
 [158.63007]
 [158.48769]
 [159.16447]
 [158.50996]
 [159.64017]
 [158.85156]
 [158.69897]
 [159.31706]
 [161.40115]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.  0.  0.  1.] 
cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.  0.  0.
  0.  3.  0.  0.  8.  0.  3.  3.  6.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0] -> size -> 35 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action -1.0
Learning step: -10.367207527160645
desired expected reward: 150.76747131347656



buy possibilites: [-1] 
expected returns: [[137.7375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.  0.  0.  1.] 
cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.  0.  0.
  0.  3.  0.  0.  8.  0.  3.  3.  6.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0] -> size -> 35 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5.     0.    -3.  -110.     0.     0.     0.     0.     0.     0.
    0.     0.     0.     0.     4.5    0. ] 
sum of rewards: -113.5 

action type: buy - action 10.0
Learning step: -9.499321937561035
desired expected reward: 128.96897888183594






Player: 1 
cards in hand: [ 1.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 11.  0.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.  0.  0.
  0.  3.  0.  0.  8.  0.  3.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 11.  8. 15.  8.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10. 16.
 15.  0.  0.  1.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16 10] -> size -> 34 
adversary victory points: -3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.  0.  0.
  0.  3.  0.  0.  8.  0.  3.  3.  6. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 11.  8. 15.  8.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10. 16.
 15.  0.  0.  1.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16 10] -> size -> 34 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.  0.  0.
  0.  3.  0.  0.  8.  0.  3.  3.  6. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 11.  8. 15.  8.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10. 16.
 15.  0.  0.  1.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16 10] -> size -> 34 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.  0. 25.  8.  3. 16.  0. 10.  3.  3.  0.  0.
  0.  3.  0.  0.  8.  0.  3.  3.  6. 10. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 11.  8. 15.  8.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10. 16.
 15.  0.  0.  1.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16 10] -> size -> 34 
adversary victory points: -3
player victory points: 8 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  8. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.  8.] 
expected returns: [[143.34381]
 [141.25609]
 [140.64972]
 [141.39377]
 [140.64972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  8. 15.  8.] 
cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10. 16.
 15.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 25. 14. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14] -> size -> 37 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1
Learning step: -9.5949125289917
desired expected reward: 128.14259338378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[140.36363]
 [143.43857]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  8. 15.  8.] 
cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10. 16.
 15.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16 10] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 25. 14. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14] -> size -> 37 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action -1.0
Learning step: -9.866960525512695
desired expected reward: 133.47686767578125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6. 25. 14. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14. 10. 29.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25. 14. 10. 29.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [16.  6.  8. 11.  8.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10. 16.
 15.  0.  0.  1.  6. 11.  8. 15.  8.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16 10] -> size -> 34 
adversary victory points: -3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 10. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [16.  6.  8. 11.  8.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10. 16.
 15.  0.  0.  1.  6. 11.  8. 15.  8.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16 10] -> size -> 34 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14. 10. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [16.  6.  8. 11.  8.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10. 16.
 15.  0.  0.  1.  6. 11.  8. 15.  8.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16 10] -> size -> 34 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14. 10. 29.  3.  0.] 
cards in discard: [0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [16.  6.  8. 11.  8.] 
adversary cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10. 16.
 15.  0.  0.  1.  6. 11.  8. 15.  8.] 
adversary owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16 10] -> size -> 34 
adversary victory points: -3
player victory points: 8 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [16.  6.  8. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 11.  8.] 
expected returns: [[62.917458]
 [60.202366]
 [60.22336 ]
 [60.829754]
 [60.22336 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  8. 11.  8.] 
cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10. 16.
 15.  0.  0.  1.  6. 11.  8. 15.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6
  1  0  3  6 15  1  6 14 16 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  0. 11.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0] -> size -> 38 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1.0
Learning step: -11.692259788513184
desired expected reward: 131.74630737304688



action possibilites: [-1] 
expected returns: [[81.432274]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  8.] 
cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10. 16.
 15.  0.  0.  1.  6. 11.  8. 15.  8. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  0. 11.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0] -> size -> 38 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -82 

action type: gain_card_n - action 7
Learning step: -7.42840576171875
desired expected reward: 95.78422546386719





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[78.24927]
 [81.3242 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  8.] 
cards in discard: [ 8.  0.  0.  6. 14.  1.  1.  0.  3.  6. 16.  1.  0.  3.  3.  1. 10. 16.
 15.  0.  0.  1.  6. 11.  8. 15.  8. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  0. 11.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0] -> size -> 38 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -98 

action type: take_action - action -1
Learning step: -7.168955326080322
desired expected reward: 74.26332092285156






Player: 1 
cards in hand: [ 0.  3. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0. 11.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [1. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
adversary victory points: -3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [1. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [1. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
adversary victory points: -3
player victory points: 8 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[142.46309]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  6. 10.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0  0] -> size -> 39 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1.0
Learning step: -6.760791301727295
desired expected reward: 74.56341552734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[139.01123]
 [139.32701]
 [139.49858]
 [139.99844]
 [139.39206]
 [139.56363]
 [142.08615]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  6. 10.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0  0] -> size -> 39 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action -1.0
Learning step: -9.865867614746094
desired expected reward: 132.59722900390625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 10.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  6. 10.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 1. 15.  1.  0. 16.] 
adversary cards in discard: [1. 0. 3. 6. 6.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  6. 10.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 1. 15.  1.  0. 16.] 
adversary cards in discard: [1. 0. 3. 6. 6.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  6. 10.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 1. 15.  1.  0. 16.] 
adversary cards in discard: [1. 0. 3. 6. 6.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
adversary victory points: -3
player victory points: 8 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 1. 15.  1.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
expected returns: [[96.07144 ]
 [94.1214  ]
 [93.356346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  1.  0. 16.] 
cards in discard: [1. 0. 3. 6. 6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0  0  0] -> size -> 40 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1.0
Learning step: -10.870146751403809
desired expected reward: 131.21600341796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[92.97668 ]
 [93.29248 ]
 [93.46404 ]
 [93.004074]
 [93.33652 ]
 [93.96392 ]
 [93.35751 ]
 [94.271194]
 [94.40886 ]
 [93.666756]
 [94.080574]
 [93.52909 ]
 [93.64576 ]
 [94.10157 ]
 [96.05162 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  1.  0. 16.] 
cards in discard: [1. 0. 3. 6. 6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.] 
adversary owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0  0  0] -> size -> 40 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action -1.0
Learning step: -8.581974029541016
desired expected reward: 87.48947143554688



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 8.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 16  3 10  8  3 11  3  0 11  8 29  6 14  0 25  0  0  0  0  0  0  3
  3  1  3  0  3  0  6  3  0  3  0 10 14  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [16. 15.  8.  1.  0.] 
adversary cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
adversary victory points: -3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [16. 15.  8.  1.  0.] 
adversary cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [16. 15.  8.  1.  0.] 
adversary cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [16. 15.  8.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.  8.] 
expected returns: [[114.64159 ]
 [111.92648 ]
 [112.69154 ]
 [111.947495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.  8.  1.  0.] 
cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0] -> size -> 36 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1.0
Learning step: -7.655617713928223
desired expected reward: 88.39600372314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[109.61229]
 [109.92807]
 [110.09964]
 [110.59951]
 [109.99312]
 [110.16469]
 [112.68721]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.  8.  1.  0.] 
cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0] -> size -> 36 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -8.636268615722656
desired expected reward: 106.00531768798828



buy possibilites: [-1] 
expected returns: [[136.42091]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.  8.  1.  0.] 
cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0] -> size -> 36 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -100.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -138.0 

action type: buy - action 0.0
Learning step: -9.311144828796387
desired expected reward: 100.3011474609375






Player: 1 
cards in hand: [14.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0] -> size -> 35 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 24. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0] -> size -> 35 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0] -> size -> 35 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[98.06021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.  1. 14.  3.  0.  0.  0.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0  1] -> size -> 37 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -10.014691352844238
desired expected reward: 126.40621948242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[81.268555]
 [81.719315]
 [81.62343 ]
 [84.16    ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 23. 30. 15. 30.  8.  0.  4.  6.  2.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.  1. 14.  3.  0.  0.  0.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0  1] -> size -> 37 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -7.795983791351318
desired expected reward: 77.30128479003906



buy possibilites: [-1] 
expected returns: [[69.756905]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.  1. 14.  3.  0.  0.  0.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0  1] -> size -> 37 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0   -1    0    0
    8    0] 
sum of rewards: -101 

action type: buy - action 8.0
Learning step: -7.561641216278076
desired expected reward: 74.0617904663086






Player: 1 
cards in hand: [3. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.  1. 14.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 14.  8. 16.] 
adversary cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.  8.  3.
  0.  0.  3.  6.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8] -> size -> 36 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.  1. 14.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 14.  8. 16.] 
adversary cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.  8.  3.
  0.  0.  3.  6.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8] -> size -> 36 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.  1. 14.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0  1  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 14.  8. 16.] 
adversary cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.  8.  3.
  0.  0.  3.  6.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8] -> size -> 36 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 14.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 16.] 
expected returns: [[33.686863]
 [31.722939]
 [31.47508 ]
 [31.456865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14.  8. 16.] 
cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.  8.  3.
  0.  0.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  1.  0. 16.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.  1. 14.  3.  0.  0.  0.  0.  3.  3.  0.  3.  3.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0  1  0] -> size -> 38 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -8.158156394958496
desired expected reward: 61.59874725341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.250435]
 [32.77151 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 14.  8. 16.] 
cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.  8.  3.
  0.  0.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  1.  0. 16.] 
adversary cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.  1. 14.  3.  0.  0.  0.  0.  3.  3.  0.  3.  3.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0  1  0] -> size -> 38 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -6.369232654571533
desired expected reward: 27.31763458251953



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  1.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  0. 16.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.  1. 14.  3.  0.  0.  0.  0.  3.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  1  3  0
  3  0  6  3  0  3  0 10 14  0  0  0  1  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [10. 11. 11.  6. 14.] 
adversary cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.  8.  3.
  0.  0.  3.  6.  6.  0. 14.  8. 16.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8] -> size -> 36 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.  1. 14.  3.  0.  0.  0.  0.  3.  3.  0.  3.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [10. 11. 11.  6. 14.] 
adversary cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.  8.  3.
  0.  0.  3.  6.  6.  0. 14.  8. 16.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8] -> size -> 36 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0. 25.  6. 14. 10. 29.  3.  0.  0. 11.  0.  3.  0. 11.  0.  3. 10.  0.
  6. 10.  8.  1. 14.  3.  0.  0.  0.  0.  3.  3.  0.  3.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [10. 11. 11.  6. 14.] 
adversary cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.  8.  3.
  0.  0.  3.  6.  6.  0. 14.  8. 16.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8] -> size -> 36 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [10. 11. 11.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 14.] 
expected returns: [[72.74914 ]
 [70.37094 ]
 [70.78138 ]
 [70.78138 ]
 [70.496765]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  6. 14.] 
cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.  8.  3.
  0.  0.  3.  6.  6.  0. 14.  8. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10] -> size -> 38 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1.0
Learning step: -5.431958198547363
desired expected reward: 27.339553833007812



action possibilites: [-1] 
expected returns: [[78.26837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  6. 14.] 
cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.  8.  3.
  0.  0.  3.  6.  6.  0. 14.  8. 16. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10] -> size -> 38 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0   -2    0    0
   16    0] 
sum of rewards: -74 

action type: gain_card_n - action 7
Learning step: -5.397852420806885
desired expected reward: 63.77995681762695





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[75.00412]
 [77.89555]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  6. 14.] 
cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.  8.  3.
  0.  0.  3.  6.  6.  0. 14.  8. 16. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10] -> size -> 38 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action -1
Learning step: -6.586285591125488
desired expected reward: 71.68208312988281



buy possibilites: [-1] 
expected returns: [[72.49717]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  6. 14.] 
cards in discard: [ 1.  0.  3.  6.  6.  1. 15.  1.  0. 16.  0. 16. 15.  8.  1.  0.  8.  3.
  0.  0.  3.  6.  6.  0. 14.  8. 16. 14.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10] -> size -> 38 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20  -30    0    0    0   -3    0    0
    0    0] 
sum of rewards: -121 

action type: buy - action 0.0
Learning step: -8.16901969909668
desired expected reward: 66.83509063720703






Player: 1 
cards in hand: [ 0.  0. 14.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 6. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14  0] -> size -> 38 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0. 25.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 6. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14  0] -> size -> 38 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0. 25.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 23. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 6. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14  0] -> size -> 38 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0. 25.] 
cards in discard: [1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 6. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14  0] -> size -> 38 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [0. 8. 6. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[99.03063 ]
 [96.494064]
 [96.494064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 1. 8.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  0. 11.  0.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1] -> size -> 39 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -6.826516151428223
desired expected reward: 65.670654296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 97.22847 ]
 [ 97.52084 ]
 [ 97.67923 ]
 [ 98.152145]
 [ 97.583336]
 [ 97.74172 ]
 [100.1199  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 1. 8.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  0. 11.  0.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1] -> size -> 39 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -8.136184692382812
desired expected reward: 90.89444732666016



buy possibilites: [-1] 
expected returns: [[93.367546]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 1. 8.] 
cards in discard: [0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  0. 11.  0.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1] -> size -> 39 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -100.    0.    0.    0.  -30.    0.    0.    0.   -4.
    0.    0.    0.    0.] 
sum of rewards: -142.0 

action type: buy - action 0.0
Learning step: -9.8606538772583
desired expected reward: 87.36781311035156






Player: 1 
cards in hand: [ 0.  1.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 11.  0.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  8.] 
adversary cards in hand: [ 8.  0.  0. 14. 16.] 
adversary cards in discard: [0. 0. 8. 6. 1. 8.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14  0  0] -> size -> 39 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 11.  0.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  8.] 
adversary cards in hand: [ 8.  0.  0. 14. 16.] 
adversary cards in discard: [0. 0. 8. 6. 1. 8.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14  0  0] -> size -> 39 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 11.  0.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  7.] 
adversary cards in hand: [ 8.  0.  0. 14. 16.] 
adversary cards in discard: [0. 0. 8. 6. 1. 8.] 
adversary owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14  0  0] -> size -> 39 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 16.] 
expected returns: [[110.020294]
 [107.48372 ]
 [107.76792 ]
 [107.462906]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 14. 16.] 
cards in discard: [0. 0. 8. 6. 1. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16 16  6  1
  0  3  6 15  1  6 14 16 10 14  0  8 14  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15] -> size -> 40 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -7.625336647033691
desired expected reward: 85.7422103881836



action possibilites: [-1] 
expected returns: [[103.891426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 0. 8. 6. 1. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15] -> size -> 40 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: trash_cards_n_from_hand - action 8
Learning step: -7.40071439743042
desired expected reward: 99.36471557617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[102.94791]
 [105.83934]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 0. 8. 6. 1. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15] -> size -> 40 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action -1
Learning step: -7.23870325088501
desired expected reward: 96.65272521972656



buy possibilites: [-1] 
expected returns: [[71.902405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 0. 8. 6. 1. 8. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15] -> size -> 40 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -100.    0.    0.   20.  -30.    0.    0.    0.   -2.
    0.    0.    0.    0.] 
sum of rewards: -120.0 

action type: buy - action 0.0
Learning step: -8.82897663116455
desired expected reward: 80.10662078857422






Player: 1 
cards in hand: [ 3.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  3.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  7.] 
adversary cards in hand: [11. 10. 11.  0. 16.] 
adversary cards in discard: [0. 0. 8. 6. 1. 8. 0. 8. 0.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0] -> size -> 37 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  7.] 
adversary cards in hand: [11. 10. 11.  0. 16.] 
adversary cards in discard: [0. 0. 8. 6. 1. 8. 0. 8. 0.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0] -> size -> 37 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  7.] 
adversary cards in hand: [11. 10. 11.  0. 16.] 
adversary cards in discard: [0. 0. 8. 6. 1. 8. 0. 8. 0.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0] -> size -> 37 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  7.] 
adversary cards in hand: [11. 10. 11.  0. 16.] 
adversary cards in discard: [0. 0. 8. 6. 1. 8. 0. 8. 0.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0] -> size -> 37 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [11. 10. 11.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 16.] 
expected returns: [[56.259285]
 [54.454586]
 [54.079525]
 [54.454586]
 [53.919395]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0. 16.] 
cards in discard: [0. 0. 8. 6. 1. 8. 0. 8. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  7.] 
adversary cards in hand: [6. 3. 8. 3. 3.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 41 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -7.757981777191162
desired expected reward: 64.14442443847656



action possibilites: [-1. 11. 11. 16.] 
expected returns: [[59.395092]
 [57.55581 ]
 [57.55581 ]
 [57.00782 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 16.  6.] 
cards in discard: [0. 0. 8. 6. 1. 8. 0. 8. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  5. 10.  7.] 
adversary cards in hand: [6. 3. 8. 3. 3.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 41 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action 10.0
Learning step: -5.794352054595947
desired expected reward: 48.2851676940918



action possibilites: [-1. 11. 16.] 
expected returns: [[67.0609 ]
 [65.19972]
 [64.64514]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.  6.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  1.  9.  9.  5. 10.  4. 10.  7.] 
adversary cards in hand: [6. 3. 8. 3. 3.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 41 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   40    0    0    0    0   -3    0    0
    9    0] 
sum of rewards: -62 

action type: gain_card_n - action 8
Learning step: -4.467628002166748
desired expected reward: 52.55908203125



action possibilites: [-1] 
expected returns: [[97.6687]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  9.  5. 10.  4. 10.  7.] 
adversary cards in hand: [6. 3. 8. 3. 3.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 41 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   60    0    0    0    0   -4    0    0
    4    0] 
sum of rewards: -48 

action type: gain_card_n - action 5
Learning step: -3.4385030269622803
desired expected reward: 61.282466888427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[94.55641]
 [97.28323]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  9.  5. 10.  4. 10.  7.] 
adversary cards in hand: [6. 3. 8. 3. 3.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.] 
adversary owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 41 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -48 

action type: take_action - action -1
Learning step: -5.118626594543457
desired expected reward: 92.5500717163086






Player: 1 
cards in hand: [6. 3. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 3. 3.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  3 10  3 11  3 11  8 29  6 14 25  0  0  0  0  0  0  3  3  3  0  3
  0  6  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  9.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 6. 14.  1.  6.  1.] 
adversary cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8] -> size -> 39 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  9.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 6. 14.  1.  6.  1.] 
adversary cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8] -> size -> 39 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  9.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 6. 14.  1.  6.  1.] 
adversary cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8] -> size -> 39 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 6. 14.  1.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[67.12836]
 [64.99441]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  1.  6.  1.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  9.  5. 10.  4. 10.  7.] 
adversary cards in hand: [29.  0.  3.  0. 14.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 39 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1.0
Learning step: -8.772605895996094
desired expected reward: 88.5106430053711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[63.7588 ]
 [64.02994]
 [64.17684]
 [64.06985]
 [64.62443]
 [65.02172]
 [64.35167]
 [64.23591]
 [64.74019]
 [66.48562]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  1.  6.  1.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  9.  5. 10.  4. 10.  7.] 
adversary cards in hand: [29.  0.  3.  0. 14.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 39 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -7.294663906097412
desired expected reward: 59.833702087402344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0. 14.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  9.  5. 10.  4. 10.  7.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8] -> size -> 39 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  9.  5. 10.  4. 10.  7.] 
adversary cards in hand: [1. 0. 0.] 
adversary cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8] -> size -> 39 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  9.  5. 10.  4. 10.  7.] 
adversary cards in hand: [1. 0. 0.] 
adversary cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8] -> size -> 39 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  9.  5. 10.  3. 10.  7.] 
adversary cards in hand: [1. 0. 0.] 
adversary cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8] -> size -> 39 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[64.7708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  9.  5. 10.  3. 10.  7.] 
adversary cards in hand: [10.  0.  6. 16. 11.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3. 10. 14. 29.  0.  3.  0.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10] -> size -> 40 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: discard_down_to_3_cards - action 3
Learning step: -5.094350337982178
desired expected reward: 17.93950653076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[61.561283]
 [61.832424]
 [61.979324]
 [61.872337]
 [62.42692 ]
 [62.82421 ]
 [62.15415 ]
 [62.038395]
 [62.54268 ]
 [64.2881  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  9.  5. 10.  3. 10.  7.] 
adversary cards in hand: [10.  0.  6. 16. 11.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3. 10. 14. 29.  0.  3.  0.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10] -> size -> 40 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -7.226230144500732
desired expected reward: 57.5445671081543



buy possibilites: [-1] 
expected returns: [[73.972916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [10.  0.  6. 16. 11.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3. 10. 14. 29.  0.  3.  0.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10] -> size -> 40 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0   -5    0    0
   32    0] 
sum of rewards: -81 

action type: buy - action 29.0
Learning step: -5.526820182800293
desired expected reward: 57.29738998413086






Player: 1 
cards in hand: [10.  0.  6. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6. 16. 11.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3. 10. 14. 29.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 3.  3.  8.  6. 14.] 
adversary cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0. 29.  1.  0.  0.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29] -> size -> 40 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6. 16. 11.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3. 10. 14. 29.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 3.  3.  8.  6. 14.] 
adversary cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0. 29.  1.  0.  0.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29] -> size -> 40 
adversary victory points: -3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  8.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[41.076454]
 [38.864685]
 [39.10595 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8.  6. 14.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0. 29.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3. 10. 14. 29.  0.  3.  0. 10.  0.  6. 16. 11.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10] -> size -> 40 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -8.199030876159668
desired expected reward: 65.77388763427734



action possibilites: [-1] 
expected returns: [[22.322039]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 6.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0. 29.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3. 10. 14. 29.  0.  3.  0. 10.  0.  6. 16. 11.  3.  3.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10] -> size -> 40 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action 14.0
Learning step: -5.6449761390686035
desired expected reward: 33.46097183227539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[20.105373]
 [20.43814 ]
 [22.322037]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 6.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0. 29.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 22. 30. 15. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3. 10. 14. 29.  0.  3.  0. 10.  0.  6. 16. 11.  3.  3.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10] -> size -> 40 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action -1
Learning step: -5.037980556488037
desired expected reward: 17.2840576171875



buy possibilites: [-1] 
expected returns: [[22.964502]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 6.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0. 29.  1.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 14. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.] 
adversary cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3. 10. 14. 29.  0.  3.  0. 10.  0.  6. 16. 11.  3.  3.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10] -> size -> 40 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0  -6   0   0   8   0] 
sum of rewards: -75 

action type: buy - action 3.0
Learning step: -4.255206108093262
desired expected reward: 16.182937622070312






Player: 1 
cards in hand: [ 0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3. 10. 14. 29.  0.  3.  0. 10.  0.  6. 16. 11.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 14. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [16.  0. 15.  6.  8.] 
adversary cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0. 29.  1.  0.  0.  3. 14.  3.  3.  8.  6.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3] -> size -> 41 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3. 10. 14. 29.  0.  3.  0. 10.  0.  6. 16. 11.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 22. 30. 14. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [16.  0. 15.  6.  8.] 
adversary cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0. 29.  1.  0.  0.  3. 14.  3.  3.  8.  6.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3] -> size -> 41 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 1. 10.  0.  0. 14.  0. 25. 15.  0.  1.  0. 11.  0.  0. 10.  3.  0.  0.
  3.  0.  8.  3.  3. 10. 14. 29.  0.  3.  0. 10.  0.  6. 16. 11.  3.  3.
  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 13. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [16.  0. 15.  6.  8.] 
adversary cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0. 29.  1.  0.  0.  3. 14.  3.  3.  8.  6.] 
adversary owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3] -> size -> 41 
adversary victory points: -2
player victory points: 8 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [16.  0. 15.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.  8.] 
expected returns: [[36.514053]
 [34.44661 ]
 [35.01008 ]
 [34.462196]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 15.  6.  8.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0. 29.  1.  0.  0.  3. 14.  3.  3.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3
  6 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 13. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3] -> size -> 41 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1
Learning step: -5.701471328735352
desired expected reward: 17.263031005859375



action possibilites: [-1] 
expected returns: [[47.19333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  8.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0. 29.  1.  0.  0.  3. 14.  3.  3.  8.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 12. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3] -> size -> 41 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0  -6   0   0   4   0] 
sum of rewards: -78 

action type: gain_card_n - action 1
Learning step: -5.200453281402588
desired expected reward: 42.04561233520508





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[44.67858]
 [47.19333]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  8.] 
cards in discard: [ 0.  0.  8.  6.  1.  8.  0.  8.  0. 10.  8. 10. 11. 11.  0. 16.  6.  6.
 14.  1.  6.  1.  3.  0. 29.  1.  0.  0.  3. 14.  3.  3.  8.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 22. 30. 12. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3] -> size -> 41 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -5.120008945465088
desired expected reward: 42.07331848144531






Player: 1 
cards in hand: [ 0. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 12. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 11. 10.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3] -> size -> 41 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 12. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 11. 10.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3] -> size -> 41 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3] -> size -> 41 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 12. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 11. 10.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3] -> size -> 41 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 22. 30. 12. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 11. 10.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3] -> size -> 41 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 25.] 
cards in discard: [1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 21. 30. 12. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 11. 10.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3] -> size -> 41 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 6. 11. 10.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15.] 
expected returns: [[19.33828 ]
 [17.896687]
 [17.601683]
 [17.98254 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 10.  1. 15.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 30. 12. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [14.  3.  0.  1.  3.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1] -> size -> 42 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -6.744561195373535
desired expected reward: 40.448768615722656



action possibilites: [-1. 11. 15.] 
expected returns: [[15.474907]
 [14.169898]
 [14.247278]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  1. 15.  1.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 21. 30. 12. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [14.  3.  0.  1.  3.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1] -> size -> 42 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -74 

action type: take_action - action 10.0
Learning step: -4.246798992156982
desired expected reward: 13.354883193969727



action possibilites: [-1. 11.] 
expected returns: [[8.136349 ]
 [7.1963415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  1.  1.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 30. 12. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [14.  3.  0.  1.  3.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1] -> size -> 42 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action 15.0
Learning step: -3.3375916481018066
desired expected reward: 10.909687042236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[8.3958645]
 [8.536991 ]
 [8.613991 ]
 [8.558441 ]
 [8.858064 ]
 [9.076758 ]
 [8.707386 ]
 [8.645787 ]
 [8.9196615]
 [9.918702 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.  1.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 21. 30. 12. 30.  8.  0.  4.  6.  0.  9.  8.  5. 10.  3. 10.  7.] 
adversary cards in hand: [14.  3.  0.  1.  3.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1] -> size -> 42 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -3.0029828548431396
desired expected reward: 5.133365631103516



buy possibilites: [-1] 
expected returns: [[45.80011]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.  1.] 
cards in discard: [29.] 
cards in deck: 35 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 21. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  3. 10.  7.] 
adversary cards in hand: [14.  3.  0.  1.  3.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1] -> size -> 42 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  40   0   0   0   0  -7   0   0  32   0] 
sum of rewards: -31 

action type: buy - action 29.0
Learning step: -0.9733354449272156
desired expected reward: 8.103422164916992






Player: 1 
cards in hand: [14.  3.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  1.  3.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  3. 10.  7.] 
adversary cards in hand: [11.  0. 14. 16. 16.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  1.  3.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 21. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  3. 10.  7.] 
adversary cards in hand: [11.  0. 14. 16. 16.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  1.  3.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 21. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [11.  0. 14. 16. 16.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [11.  0. 14. 16. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 16. 16.] 
expected returns: [[0.5341221 ]
 [0.26811588]
 [0.23167783]
 [0.19698681]
 [0.19698681]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 14. 16. 16.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10.  1.  8.  0.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10] -> size -> 43 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -7.082374572753906
desired expected reward: 38.717735290527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[0.1618216]
 [0.5385898]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 14. 16. 16.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 21. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10.  1.  8.  0.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10] -> size -> 43 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -4.817912578582764
desired expected reward: -4.283790588378906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10. 10.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  1.  8.  0.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  8. 14. 15.  3.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  1.  8.  0.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 21. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  8. 14. 15.  3.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  1.  8.  0.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 20. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  8. 14. 15.  3.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 14. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 15.] 
expected returns: [[10.932058]
 [ 9.549104]
 [ 9.697503]
 [ 9.921987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 14. 15.  3.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 20. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11. 14.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -4.5969648361206055
desired expected reward: -4.058375358581543





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.139632 ]
 [10.7013035]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 14. 15.  3.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 20. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11. 14.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -5.119605541229248
desired expected reward: 5.8124518394470215



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 14.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 20. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 20. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 20. 30. 12. 30.  8.  0.  4.  6.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 20. 30. 12. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[0.31656918]
 [0.06237927]
 [0.06237927]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 20. 30. 12. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  3. 16.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11] -> size -> 45 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: discard_down_to_3_cards - action 3
Learning step: -5.383638858795166
desired expected reward: 6.371772289276123





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[0.03329707]
 [0.33301285]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 20. 30. 12. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  3. 16.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11] -> size -> 45 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -4.810980796813965
desired expected reward: -4.494411468505859



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  3. 16.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  0  3  3  3  0  3  0  6
  3  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 20. 30. 12. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 6. 1. 6.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  3  3  3  0  3  0  6  3
  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 20. 30. 11. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 6. 1. 6.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  3  3  3  0  3  0  6  3
  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 20. 30. 11. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 6. 1. 6.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  3  3  3  0  3  0  6  3
  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 20. 30. 11. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 6. 1. 6.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
adversary victory points: -1
player victory points: 9 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [6. 0. 6. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[2.959569]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 1. 6.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 20. 30. 11. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  3. 15.  0.  0.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0. 16.  3.  3.  3.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  3  3  3  0  3  0  6  3
  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0] -> size -> 46 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1.0
Learning step: -5.250060558319092
desired expected reward: -4.917047500610352





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[1.6293589]
 [1.699118 ]
 [1.7377139]
 [1.8606313]
 [1.7541144]
 [2.3742664]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 1. 6.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 20. 30. 11. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  3. 15.  0.  0.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0. 16.  3.  3.  3.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  3  3  3  0  3  0  6  3
  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0] -> size -> 46 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: take_action - action -1.0
Learning step: -5.403942584991455
desired expected reward: -2.444373607635498



buy possibilites: [-1] 
expected returns: [[10.652913]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 1. 6.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 20. 30. 10. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  3. 15.  0.  0.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0. 16.  3.  3.  3.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  3  3  3  0  3  0  6  3
  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.  -8.   0.   0.
   2.   0.] 
sum of rewards: -101.0 

action type: buy - action 3.0
Learning step: -4.897195339202881
desired expected reward: -3.1594810485839844






Player: 1 
cards in hand: [ 0.  3. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  0.  0.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0. 16.  3.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  0  3  3  3  0  3  0  6  3
  0  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 20. 30. 10. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8. 8. 6. 6.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3] -> size -> 43 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0. 16.  3.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 20. 30. 10. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8. 8. 6. 6.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3] -> size -> 43 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0. 16.  3.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 2. 20. 30. 10. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8. 8. 6. 6.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3] -> size -> 43 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0. 16.  3.  3.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 19. 30. 10. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8. 8. 6. 6.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3] -> size -> 43 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [0. 8. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[2.3216863]
 [1.6740628]
 [1.6740628]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 6. 6.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 19. 30. 10. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  0.  6. 29.  3.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0. 16.  3.  3.  3.  1. 15.  3.  0.
  0.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -5.238028526306152
desired expected reward: 5.414884567260742





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[1.5982958]
 [2.3216863]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 6. 6.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 19. 30. 10. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  0.  6. 29.  3.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0. 16.  3.  3.  3.  1. 15.  3.  0.
  0.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -4.820230007171631
desired expected reward: -2.4985432624816895



buy possibilites: [-1] 
expected returns: [[0.4853097]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 6. 6.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 19. 30. 10. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  0.  6. 29.  3.] 
adversary cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0. 16.  3.  3.  3.  1. 15.  3.  0.
  0.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0. -30.   0.   0.   0.  -9.   0.   0.
   0.   0.] 
sum of rewards: -134.0 

action type: buy - action 0.0
Learning step: -6.768995761871338
desired expected reward: -5.1707000732421875






Player: 1 
cards in hand: [ 0.  0.  6. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 29.  3.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0. 16.  3.  3.  3.  1. 15.  3.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 19. 30. 10. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [29.  3.  1.  8. 10.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.  0.  0.  8.  8.  6.  6.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3  0] -> size -> 44 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 29.  3.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0. 16.  3.  3.  3.  1. 15.  3.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 19. 30. 10. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [29.  3.  1.  8. 10.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.  0.  0.  8.  8.  6.  6.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3  0] -> size -> 44 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 29.  3.] 
cards in discard: [ 1. 10. 10.  0.  0.  0.  3. 25. 10. 14.  3.  0.  1.  3.  1. 10. 10.  1.
  8.  0. 11. 14.  0.  0.  0. 11.  3.  0. 16.  3.  3.  3.  1. 15.  3.  0.
  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 19. 30.  9. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [29.  3.  1.  8. 10.] 
adversary cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.  0.  0.  8.  8.  6.  6.] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3  0] -> size -> 44 
adversary victory points: 0
player victory points: 10 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [29.  3.  1.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
expected returns: [[3.587905 ]
 [3.0521066]
 [2.7340484]
 [2.7816927]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  8. 10.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.  0.  0.  8.  8.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 19. 30.  9. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [14.  3.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1  3] -> size -> 47 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -5.2032270431518555
desired expected reward: -4.717917442321777



action possibilites: [-1.  8.] 
expected returns: [[23.120218]
 [21.245165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 1.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.  0.  0.  8.  8.  6.  6. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 19. 30.  9. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [14.  3.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1  3] -> size -> 47 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: discard_n_cards - action 7
Learning step: -3.886281728744507
desired expected reward: -1.087496280670166





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[20.99561 ]
 [21.19877 ]
 [21.308954]
 [21.658916]
 [21.355349]
 [23.12022 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.  0.  0.  8.  8.  6.  6. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 19. 30.  9. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [14.  3.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1  3] -> size -> 47 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -4.912526607513428
desired expected reward: 18.207691192626953



buy possibilites: [-1] 
expected returns: [[6.34006]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1.] 
cards in discard: [29. 10. 15.  6. 11.  1.  1. 11.  0. 14. 16. 16.  3.  8. 14. 15.  3.  0.
  3.  8.  0.  8.  3.  6.  0.  6.  1.  6.  0.  0.  8.  8.  6.  6. 10.  1.
  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3  0  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 18. 30.  9. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [14.  3.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1  3] -> size -> 47 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0  -10    0    0
   18    0] 
sum of rewards: -77 

action type: buy - action 1.0
Learning step: -4.767287254333496
desired expected reward: 16.43148422241211






Player: 1 
cards in hand: [14.  3.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 18. 30.  9. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3  0  1] -> size -> 45 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 18. 30.  9. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3  0  1] -> size -> 45 
adversary victory points: 0
player victory points: 10 


Player 1 won the game! 



Player 0 bought cards:
Copper: 10 
Silver: 5 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 6 

Remodel: 4 
Workshop: 1 
Chapel: 7 
Witch: 0 
Poacher: 2 
Militia: 1 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0  0  3  1 11  1  6  6  8  6  0 11  8  3  8 15 16  6  1  0  3  6
 15  1  6 16 10 14  0  8 14  0  0  0 10  8 29  3  3 29  3  0  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30.  9. 30.  8.  0.  4.  5.  0.  9.  7.  5. 10.  2. 10.  7.] 
adversary cards in hand: [14.  3.  0. 11. 10.] 
adversary cards in discard: [0.] 
adversary owned cards: [10 16 10  3 11  3 11  8 29 14 25  0  0  0  0  3  3  3  0  3  0  6  3  0
  3  0 10 14  0  0  0  1  0 10  1 15  0 10  3  1 10  1 11  3  0  1  3  0] -> size -> 48 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -605 

action type: buy - action -1
Learning step: -30.567005157470703
desired expected reward: -24.226943969726562



