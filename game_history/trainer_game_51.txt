 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[311.41296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0  -50    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -555 

action type: buy - action -1.0
Learning step: -37.19521713256836
desired expected reward: 151.70909118652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[283.64093]
 [294.4755 ]
 [291.88782]
 [264.6409 ]
 [303.40656]
 [293.13123]
 [290.81766]
 [310.176  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.041075706481934
desired expected reward: 304.4149475097656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[333.13882]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.06591796875
desired expected reward: 302.1100769042969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[302.6347 ]
 [313.20355]
 [311.11002]
 [284.41318]
 [306.89847]
 [322.46158]
 [311.7984 ]
 [315.8473 ]
 [295.6362 ]
 [310.00107]
 [308.0657 ]
 [329.7307 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.713581085205078
desired expected reward: 325.5256042480469



buy possibilites: [-1] 
expected returns: [[372.09857]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -8.359519004821777
desired expected reward: 294.27520751953125






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[307.74225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -11.782984733581543
desired expected reward: 360.3155822753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[290.7617 ]
 [298.05164]
 [295.5127 ]
 [277.63284]
 [303.648  ]
 [297.40985]
 [295.01288]
 [307.63828]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.718352317810059
desired expected reward: 298.9236145019531



buy possibilites: [-1] 
expected returns: [[288.88733]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 10.0
Learning step: -7.450679302215576
desired expected reward: 287.56219482421875






Player: 1 
cards in hand: [ 8. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.  0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[300.6813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  8. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.748335361480713
desired expected reward: 281.1390075683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[282.64688]
 [293.38107]
 [291.35715]
 [270.32715]
 [264.9605 ]
 [286.84525]
 [303.09973]
 [291.79068]
 [311.13947]
 [296.0132 ]
 [275.8899 ]
 [282.68582]
 [290.06982]
 [270.72043]
 [287.97348]
 [311.1243 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  8. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.506660461425781
desired expected reward: 293.5391845703125



buy possibilites: [-1] 
expected returns: [[316.58752]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  8. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -8.609125137329102
desired expected reward: 274.0377502441406






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0.  8. 10.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0.  8. 10.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0.  8. 10.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[304.74454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.05127239227295
desired expected reward: 307.5362548828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[276.25934]
 [287.02866]
 [284.13464]
 [257.77884]
 [295.27365]
 [285.68546]
 [283.06647]
 [301.40546]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.836007118225098
desired expected reward: 296.8575439453125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[319.83044]
 [303.01666]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.06103515625
desired expected reward: 293.34442138671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[303.0252 ]
 [312.63464]
 [310.29874]
 [287.6776 ]
 [320.45917]
 [311.43848]
 [309.33908]
 [326.15286]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.019404411315918
desired expected reward: 311.8897399902344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  8.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[290.0975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.814375877380371
desired expected reward: 316.3385009765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[266.85272]
 [277.28278]
 [274.66638]
 [248.62996]
 [285.54816]
 [275.97125]
 [273.59354]
 [291.36734]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.422953605651855
desired expected reward: 284.61114501953125



buy possibilites: [-1] 
expected returns: [[264.9619]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -6.385498046875
desired expected reward: 251.55731201171875






Player: 1 
cards in hand: [ 0.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[314.09006]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -5.749610900878906
desired expected reward: 259.2123107910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[292.24747]
 [300.37027]
 [297.39108]
 [282.0987 ]
 [277.35495]
 [295.2604 ]
 [305.93134]
 [299.66446]
 [312.64847]
 [301.68118]
 [285.8708 ]
 [290.3414 ]
 [296.8381 ]
 [281.2482 ]
 [294.96396]
 [308.75333]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.41041088104248
desired expected reward: 304.8555908203125



buy possibilites: [-1] 
expected returns: [[265.14343]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  0.  0.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 59 

action type: buy - action 25.0
Learning step: -6.716696262359619
desired expected reward: 305.9317626953125






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16.  0.  0. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16.  0.  0. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16.  0.  0. 10.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25] -> size -> 15 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[281.86856]
 [263.10428]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  3. 11.] 
adversary cards in discard: [16.  0.  0. 10.  0.  0.  1.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16  1] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -6.569770812988281
desired expected reward: 258.57366943359375



action possibilites: [-1.] 
expected returns: [[245.01366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  3. 11.] 
adversary cards in discard: [16.  0.  0. 10.  0.  0.  1.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16  1] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 30 

action type: take_action - action 10.0
Learning step: -6.174705505371094
desired expected reward: 257.5755310058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[232.51775]
 [239.79411]
 [236.47096]
 [219.34706]
 [235.16125]
 [243.81677]
 [239.25372]
 [240.34148]
 [226.44539]
 [236.0051 ]
 [234.02147]
 [244.87466]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  3. 11.] 
adversary cards in discard: [16.  0.  0. 10.  0.  0.  1.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16  1] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -5.412988185882568
desired expected reward: 239.6006622314453



buy possibilites: [-1] 
expected returns: [[288.58258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  3. 11.] 
adversary cards in discard: [16.  0.  0. 10.  0.  0.  1.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16  1] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  10.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 33.5 

action type: buy - action 1.0
Learning step: -3.821598768234253
desired expected reward: 235.9725341796875






Player: 1 
cards in hand: [10.  0.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3. 11.] 
cards in discard: [16.  0.  0. 10.  0.  0.  1.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 1. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3. 11.] 
cards in discard: [16.  0.  0. 10.  0.  0.  1.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 1. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3. 11.] 
cards in discard: [16.  0.  0. 10.  0.  0.  1.  0.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 1. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[290.91644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 1. 10.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.436860084533691
desired expected reward: 281.1457214355469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[274.1329 ]
 [283.7354 ]
 [282.31445]
 [258.40604]
 [293.37683]
 [282.39453]
 [281.32446]
 [301.65085]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 1. 10.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -7.55946683883667
desired expected reward: 283.2080383300781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[284.32254]
 [286.23077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -8.22136402130127
desired expected reward: 293.429443359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[258.52545]
 [268.46115]
 [265.98898]
 [240.3888 ]
 [276.18555]
 [267.20493]
 [264.96115]
 [281.6361 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -7.607875823974609
desired expected reward: 275.9871520996094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [8. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [ 0. 25.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [8. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [ 0. 25.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [ 8.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [ 0. 25.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[287.95532]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [ 0. 25.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 16. 11. 10.] 
adversary cards in discard: [ 8.  3. 10.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -7.173572063446045
desired expected reward: 274.46246337890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[261.1476 ]
 [270.70688]
 [268.0701 ]
 [245.46439]
 [264.7999 ]
 [278.31207]
 [269.51996]
 [272.52383]
 [254.36804]
 [267.10446]
 [264.97345]
 [283.44717]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [ 0. 25.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 16. 11. 10.] 
adversary cards in discard: [ 8.  3. 10.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -7.745982646942139
desired expected reward: 279.2864990234375



buy possibilites: [-1] 
expected returns: [[280.8902]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [ 0. 25.  3.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 16. 11. 10.] 
adversary cards in discard: [ 8.  3. 10.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 13.5 

action type: buy - action 1.0
Learning step: -6.540313243865967
desired expected reward: 264.1665344238281






Player: 1 
cards in hand: [ 0.  0. 16. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16. 11. 10.] 
cards in discard: [ 8.  3. 10.  3.  0.  1.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [ 0. 25.  3.  0.  0.  1.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16. 11. 10.] 
cards in discard: [ 8.  3. 10.  3.  0.  1.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [ 0. 25.  3.  0.  0.  1.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[327.90784]
 [307.20117]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [ 0. 25.  3.  0.  0.  1.  0.  3.  3.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -6.301159858703613
desired expected reward: 274.58905029296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[282.545  ]
 [294.2461 ]
 [290.94693]
 [261.60663]
 [303.55695]
 [292.9161 ]
 [289.90775]
 [310.23364]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [ 0. 25.  3.  0.  0.  1.  0.  3.  3.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.708130836486816
desired expected reward: 308.8936462402344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[241.9489]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10. 11. 10.  3.  3.] 
adversary cards in discard: [15.  0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -9.606941223144531
desired expected reward: 300.626708984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[216.94719]
 [226.07578]
 [213.44333]
 [224.15755]
 [207.33182]
 [202.96068]
 [220.56291]
 [234.10158]
 [224.89769]
 [240.93558]
 [228.34108]
 [211.20512]
 [216.79953]
 [223.24654]
 [206.94014]
 [221.51569]
 [240.27687]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 27. 30. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10. 11. 10.  3.  3.] 
adversary cards in discard: [15.  0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -6.5126824378967285
desired expected reward: 235.92025756835938



buy possibilites: [-1] 
expected returns: [[275.8828]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [2.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10. 11. 10.  3.  3.] 
adversary cards in discard: [15.  0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[  -5    0    4   10    0    0    0    0    0 1700    0    0    0    0
   72    0] 
sum of rewards: 1781 

action type: buy - action 2.0
Learning step: 84.58519744873047
desired expected reward: 298.02850341796875






Player: 1 
cards in hand: [10. 11. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  3.  3.] 
cards in discard: [15.  0. 10.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 29. 30.  8. 10.  9.  9.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  3.] 
cards in discard: [15.  0. 10.  0.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  3.] 
cards in discard: [15.  0. 10.  0.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  3.] 
cards in discard: [15.  0. 10.  0.  0.  0. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15 11  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [1. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[312.93692]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [2. 0. 1. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [16.  8.  3.  0.  1.] 
adversary cards in discard: [15.  0. 10.  0.  0.  0. 11.  0. 11. 10. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -6.356466770172119
desired expected reward: 269.5263366699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[288.8878 ]
 [298.9622 ]
 [296.3404 ]
 [271.00098]
 [292.84836]
 [307.10895]
 [297.75745]
 [300.96024]
 [281.60443]
 [295.38028]
 [293.22617]
 [312.8088 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [2. 0. 1. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [16.  8.  3.  0.  1.] 
adversary cards in discard: [15.  0. 10.  0.  0.  0. 11.  0. 11. 10. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.279438972473145
desired expected reward: 302.2838439941406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  8.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  3.  0.  1.] 
cards in discard: [15.  0. 10.  0.  0.  0. 11.  0. 11. 10. 10.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15 11  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [2. 0. 1. 0. 0. 0. 1. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3.  0.  1.] 
cards in discard: [15.  0. 10.  0.  0.  0. 11.  0. 11. 10. 10.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15 11  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [2. 0. 1. 0. 0. 0. 1. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[264.5191 ]
 [244.59227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [2. 0. 1. 0. 0. 0. 1. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -9.46826457977295
desired expected reward: 303.3405456542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[237.80986]
 [245.38905]
 [222.33759]
 [245.55829]
 [265.06873]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [2. 0. 1. 0. 0. 0. 1. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -6.877967834472656
desired expected reward: 253.17416381835938



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10 11  0 16  1  0 10 15 11  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [22.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[219.94524]
 [220.38419]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 25.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [22.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -7.850314617156982
desired expected reward: 257.21844482421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[193.91096]
 [179.22946]
 [219.84322]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 25.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [22.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -5.888981342315674
desired expected reward: 213.94021606445312



buy possibilites: [-1] 
expected returns: [[260.1175]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 25.  0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [22.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -21.0 

action type: buy - action 0.0
Learning step: -4.892903804779053
desired expected reward: 189.01805114746094






Player: 1 
cards in hand: [ 8.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  0. 10.] 
cards in discard: [22.  1. 16.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  3.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0] -> size -> 19 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0.  0. 10.] 
cards in discard: [22.  1. 16.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 29. 29. 30.  8. 10.  9.  8.  9.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  3.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0] -> size -> 19 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0.  0. 10.] 
cards in discard: [22.  1. 16.  0.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 29. 30.  8. 10.  9.  8.  8.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  3.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0] -> size -> 19 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[250.81245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  3. 25.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 29. 30.  8. 10.  9.  8.  8.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 15. 11.] 
adversary cards in discard: [22.  1. 16.  0.  0.  0.  8.  8.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.049205303192139
desired expected reward: 253.0682830810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[222.09961]
 [233.14713]
 [230.51901]
 [209.15326]
 [203.73618]
 [226.35037]
 [242.43776]
 [231.64949]
 [251.004  ]
 [235.3895 ]
 [214.62128]
 [221.48239]
 [229.303  ]
 [209.31029]
 [226.87875]
 [249.16418]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  3. 25.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 26. 29. 29. 30.  8. 10.  9.  8.  8.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 15. 11.] 
adversary cards in discard: [22.  1. 16.  0.  0.  0.  8.  8.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -6.454078674316406
desired expected reward: 238.28677368164062



buy possibilites: [-1] 
expected returns: [[231.85732]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  3. 25.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 25. 29. 29. 30.  8. 10.  9.  8.  8.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 15. 11.] 
adversary cards in discard: [22.  1. 16.  0.  0.  0.  8.  8.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 13.5 

action type: buy - action 1.0
Learning step: -5.765567302703857
desired expected reward: 227.38157653808594






Player: 1 
cards in hand: [ 0.  0.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15. 11.] 
cards in discard: [22.  1. 16.  0.  0.  0.  8.  8.  3.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 29. 30.  8. 10.  9.  8.  8.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [ 0.  3.  3.  3. 25.  0.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1] -> size -> 20 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [22.  1. 16.  0.  0.  0.  8.  8.  3.  0.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 29. 30.  8. 10.  9.  8.  8.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [ 0.  3.  3.  3. 25.  0.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1] -> size -> 20 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [22.  1. 16.  0.  0.  0.  8.  8.  3.  0.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 29. 29. 30.  8. 10.  9.  8.  8.  9. 10. 10. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [ 0.  3.  3.  3. 25.  0.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1] -> size -> 20 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [22.  1. 16.  0.  0.  0.  8.  8.  3.  0.  0. 10.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 29. 30.  8. 10.  9.  8.  8.  9. 10. 10. 10.  5.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [ 0.  3.  3.  3. 25.  0.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1] -> size -> 20 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[268.52698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [ 0.  3.  3.  3. 25.  0.  1.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 29. 30.  8. 10.  9.  8.  8.  9. 10. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  1. 10. 10.  3.] 
adversary cards in discard: [22.  1. 16.  0.  0.  0.  8.  8.  3.  0.  0. 10.  0. 10. 11.  0.  0.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -5.15142297744751
desired expected reward: 226.7058868408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[258.24496]
 [267.30716]
 [254.68446]
 [265.0548 ]
 [245.70848]
 [239.60297]
 [261.87784]
 [274.464  ]
 [266.13916]
 [281.32294]
 [268.91495]
 [251.68564]
 [257.49945]
 [264.0936 ]
 [246.19464]
 [262.056  ]
 [279.41595]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [ 0.  3.  3.  3. 25.  0.  1.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 7 
card supply: [22. 25. 29. 29. 30.  8. 10.  9.  8.  8.  9. 10. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  1. 10. 10.  3.] 
adversary cards in discard: [22.  1. 16.  0.  0.  0.  8.  8.  3.  0.  0. 10.  0. 10. 11.  0.  0.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -6.79824161529541
desired expected reward: 259.4881286621094



buy possibilites: [-1] 
expected returns: [[167.59052]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [ 0.  3.  3.  3. 25.  0.  1.  0.  0.  0.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 25. 29. 29. 30.  8. 10.  9.  8.  8.  9.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  1. 10. 10.  3.] 
adversary cards in discard: [22.  1. 16.  0.  0.  0.  8.  8.  3.  0.  0. 10.  0. 10. 11.  0.  0.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 17.0 

action type: buy - action 29.0
Learning step: -8.47831916809082
desired expected reward: 253.50379943847656






Player: 1 
cards in hand: [ 3.  1. 10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10. 10.  3.] 
cards in discard: [22.  1. 16.  0.  0.  0.  8.  8.  3.  0.  0. 10.  0. 10. 11.  0.  0.  0.
 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 29. 30.  8. 10.  9.  8.  8.  9.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  2.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29] -> size -> 21 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10. 10.  3.] 
cards in discard: [22.  1. 16.  0.  0.  0.  8.  8.  3.  0.  0. 10.  0. 10. 11.  0.  0.  0.
 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 29. 29. 30.  8. 10.  9.  8.  8.  9.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  2.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29] -> size -> 21 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  2.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[191.02765]
 [176.58234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  2.  3. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 29. 30.  8. 10.  9.  8.  8.  9.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [16.  8.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -3.7651870250701904
desired expected reward: 163.82533264160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[170.89996]
 [178.60477]
 [176.63968]
 [161.3686 ]
 [157.21129]
 [173.93181]
 [185.17691]
 [177.67097]
 [191.47823]
 [180.16394]
 [165.3329 ]
 [170.24428]
 [175.89975]
 [161.31696]
 [174.26022]
 [189.87318]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  2.  3. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 25. 29. 29. 30.  8. 10.  9.  8.  8.  9.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [16.  8.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -4.935173988342285
desired expected reward: 184.40109252929688



buy possibilites: [-1] 
expected returns: [[230.10437]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  2.  3. 10.] 
cards in discard: [25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 29. 30.  8. 10.  9.  8.  8.  8.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [16.  8.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 59 

action type: buy - action 25.0
Learning step: -1.446563720703125
desired expected reward: 190.03167724609375






Player: 1 
cards in hand: [16.  8.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 29. 30.  8. 10.  9.  8.  8.  8.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  0.  3. 25.  0.] 
adversary cards in discard: [25.  0.  0.  2.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25] -> size -> 22 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 29. 29. 30.  8. 10.  9.  8.  8.  8.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  0.  3. 25.  0.] 
adversary cards in discard: [25.  0.  0.  2.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25] -> size -> 22 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  0.  0.  1.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 25. 29. 29. 30.  8. 10.  9.  8.  8.  8.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  0.  3. 25.  0.] 
adversary cards in discard: [25.  0.  0.  2.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25] -> size -> 22 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[174.9794 ]
 [177.51328]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 25.  0.] 
cards in discard: [25.  0.  0.  2.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8. 10.  9.  8.  8.  8.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  3.  0.  3. 22.] 
adversary cards in discard: [ 0. 16.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0] -> size -> 25 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.1190104484558105
desired expected reward: 222.98536682128906



action possibilites: [-1] 
expected returns: [[170.36017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0.  0. 29.] 
cards in discard: [25.  0.  0.  2.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8.  9.  9.  8.  8.  8.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  3.  0.  3. 22.] 
adversary cards in discard: [ 0. 16.  8.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6] -> size -> 26 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 30 

action type: take_action - action 25.0
Learning step: -3.451340913772583
desired expected reward: 172.237548828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[155.36589]
 [165.27777]
 [163.74887]
 [138.30832]
 [174.38211]
 [163.77509]
 [162.55019]
 [181.58447]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0.  0. 29.] 
cards in discard: [25.  0.  0.  2.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 25. 29. 29. 30.  8.  9.  9.  8.  8.  8.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  3.  0.  3. 22.] 
adversary cards in discard: [ 0. 16.  8.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6] -> size -> 26 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1
Learning step: -3.2270264625549316
desired expected reward: 167.13314819335938






Player: 1 
cards in hand: [ 3.  3.  0.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 22.] 
cards in discard: [ 0. 16.  8.  0.  0.  1.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8.  9.  9.  8.  8.  8.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [25.  0.  0.  2.  3. 10. 25.  3.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25] -> size -> 22 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0. 0. 0.] 
cards in discard: [ 0. 16.  8.  0.  0.  1.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8.  9.  9.  8.  8.  8.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [25.  0.  0.  2.  3. 10. 25.  3.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25] -> size -> 22 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0. 0. 0.] 
cards in discard: [ 0. 16.  8.  0.  0.  1.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 25. 29. 29. 30.  8.  9.  9.  8.  8.  8.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [25.  0.  0.  2.  3. 10. 25.  3.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25] -> size -> 22 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[189.15375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [25.  0.  0.  2.  3. 10. 25.  3.  0.  3.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8.  9.  9.  8.  8.  8.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [11.  1.  8. 15. 10.] 
adversary cards in discard: [ 0. 16.  8.  0.  0.  1.  6. 22.  3.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -3.8732666969299316
desired expected reward: 177.7112579345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[166.1255 ]
 [173.74228]
 [171.76889]
 [157.7235 ]
 [154.1022 ]
 [168.92017]
 [180.10808]
 [172.66658]
 [186.19438]
 [175.09387]
 [161.02307]
 [165.23645]
 [170.8758 ]
 [157.56314]
 [169.00764]
 [184.51373]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [25.  0.  0.  2.  3. 10. 25.  3.  0.  3.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 25. 29. 29. 30.  8.  9.  9.  8.  8.  8.  9. 10. 10.  5.  9.  9.] 
adversary cards in hand: [11.  1.  8. 15. 10.] 
adversary cards in discard: [ 0. 16.  8.  0.  0.  1.  6. 22.  3.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -4.5373687744140625
desired expected reward: 184.6163787841797



buy possibilites: [-1] 
expected returns: [[164.94604]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [25.  0.  0.  2.  3. 10. 25.  3.  0.  3.  0.  0. 29. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 25. 29. 29. 30.  8.  9.  9.  8.  8.  8.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [11.  1.  8. 15. 10.] 
adversary cards in discard: [ 0. 16.  8.  0.  0.  1.  6. 22.  3.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 23.5 

action type: buy - action 10.0
Learning step: -3.657503843307495
desired expected reward: 167.21829223632812






Player: 1 
cards in hand: [11.  1.  8. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  8. 15. 10.] 
cards in discard: [ 0. 16.  8.  0.  0.  1.  6. 22.  3.  3.  0.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8.  9.  9.  8.  8.  8.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [3. 1. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10] -> size -> 23 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 15. 10.] 
cards in discard: [ 0. 16.  8.  0.  0.  1.  6. 22.  3.  3.  0.  3.  0.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8.  8.  9.  8.  8.  8.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [3. 1. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10] -> size -> 23 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 15. 10.] 
cards in discard: [ 0. 16.  8.  0.  0.  1.  6. 22.  3.  3.  0.  3.  0.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 29. 29. 30.  8.  8.  9.  8.  8.  8.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [3. 1. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10] -> size -> 23 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 15. 10.] 
cards in discard: [ 0. 16.  8.  0.  0.  1.  6. 22.  3.  3.  0.  3.  0.  0.  0.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8.  8.  9.  8.  7.  8.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [3. 1. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10] -> size -> 23 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [3. 1. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[192.96414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8.  8.  9.  8.  7.  8.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 10.  0. 10.  0.] 
adversary cards in discard: [ 0. 16.  8.  0.  0.  1.  6. 22.  3.  3.  0.  3.  0.  0.  0.  6.  8. 11.
  1.  8. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6  6  8] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: -2.588813066482544
desired expected reward: 162.35723876953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[178.19632]
 [187.26797]
 [174.81549]
 [185.75674]
 [166.92534]
 [162.22046]
 [181.91628]
 [194.7135 ]
 [186.09627]
 [200.7082 ]
 [189.32634]
 [172.07751]
 [178.43869]
 [184.7623 ]
 [167.49747]
 [183.01872]
 [200.6009 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 25. 29. 29. 30.  8.  8.  9.  8.  7.  8.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 10.  0. 10.  0.] 
adversary cards in discard: [ 0. 16.  8.  0.  0.  1.  6. 22.  3.  3.  0.  3.  0.  0.  0.  6.  8. 11.
  1.  8. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6  6  8] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -3.633953809738159
desired expected reward: 183.41001892089844



buy possibilites: [-1] 
expected returns: [[169.57245]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 1. 0.] 
cards in discard: [25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 29. 29. 30.  8.  8.  9.  8.  7.  7.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 10.  0. 10.  0.] 
adversary cards in discard: [ 0. 16.  8.  0.  0.  1.  6. 22.  3.  3.  0.  3.  0.  0.  0.  6.  8. 11.
  1.  8. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6  6  8] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 41.5 

action type: buy - action 25.0
Learning step: -4.145030975341797
desired expected reward: 196.5631866455078






Player: 1 
cards in hand: [ 0. 10.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.  0.] 
cards in discard: [ 0. 16.  8.  0.  0.  1.  6. 22.  3.  3.  0.  3.  0.  0.  0.  6.  8. 11.
  1.  8. 15. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8.  8.  9.  8.  7.  7.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 25.] 
adversary cards in discard: [25.  3.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25] -> size -> 24 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.  0.] 
cards in discard: [ 0. 16.  8.  0.  0.  1.  6. 22.  3.  3.  0.  3.  0.  0.  0.  6.  8. 11.
  1.  8. 15. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6  6  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 25. 29. 29. 30.  8.  8.  9.  8.  7.  7.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 25.] 
adversary cards in discard: [25.  3.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25] -> size -> 24 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.  0.] 
cards in discard: [ 0. 16.  8.  0.  0.  1.  6. 22.  3.  3.  0.  3.  0.  0.  0.  6.  8. 11.
  1.  8. 15. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6  6  8 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8.  8.  9.  7.  7.  7.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 25.] 
adversary cards in discard: [25.  3.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25] -> size -> 24 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[170.16138]
 [170.57484]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 25.] 
cards in discard: [25.  3.  1.  0.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8.  8.  9.  7.  7.  7.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6  6  8 11] -> size -> 29 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: -3.1934285163879395
desired expected reward: 166.37901306152344



action possibilites: [-1] 
expected returns: [[224.93507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 10.  0.] 
cards in discard: [25.  3.  1.  0.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8.  7.  9.  7.  7.  7.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6  6  8 11  6] -> size -> 30 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 50 

action type: take_action - action 25.0
Learning step: -0.9677032828330994
desired expected reward: 169.6071319580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[215.48412]
 [222.72293]
 [221.58327]
 [202.94037]
 [218.45595]
 [229.66818]
 [221.67384]
 [224.65112]
 [210.75223]
 [220.76627]
 [219.45428]
 [235.73259]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 10.  0.] 
cards in discard: [25.  3.  1.  0.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 25. 29. 29. 30.  8.  7.  9.  7.  7.  7.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6  6  8 11  6] -> size -> 30 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1
Learning step: -3.6969947814941406
desired expected reward: 221.2380828857422






Player: 1 
cards in hand: [16.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  0. 10.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10
  0  6  6  8 11  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 29. 30.  8.  7.  9.  7.  7.  7.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [10.  0.  3.  3. 25.] 
adversary cards in discard: [25.  3.  1.  0.  1.  0. 25.  3.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25] -> size -> 24 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [6. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 28. 30.  8.  7.  9.  7.  7.  7.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [10.  0.  3.  3. 25.] 
adversary cards in discard: [25.  3.  1.  0.  1.  0. 25.  3.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25] -> size -> 24 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [6. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 29. 28. 30.  8.  7.  9.  7.  7.  7.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [10.  0.  3.  3. 25.] 
adversary cards in discard: [25.  3.  1.  0.  1.  0. 25.  3.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25] -> size -> 24 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[170.51245]
 [159.88422]
 [172.39648]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3. 25.] 
cards in discard: [25.  3.  1.  0.  1.  0. 25.  3.  0.  0.  0. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 28. 30.  8.  7.  9.  7.  7.  7.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [3. 8. 3. 1. 0.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3] -> size -> 30 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: -5.76806116104126
desired expected reward: 224.8995361328125



action possibilites: [-1] 
expected returns: [[215.17459]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3.  2.  0.] 
cards in discard: [25.  3.  1.  0.  1.  0. 25.  3.  0.  0.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 28. 30.  8.  6.  9.  7.  7.  7.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [3. 8. 3. 1. 0.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6] -> size -> 31 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  4] 
sum of rewards: 63 

action type: take_action - action 25.0
Learning step: -0.6283974051475525
desired expected reward: 171.76809692382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[201.53862]
 [207.13535]
 [205.75456]
 [194.55734]
 [191.22641]
 [203.72987]
 [211.80826]
 [206.47588]
 [216.02577]
 [208.39821]
 [197.5526 ]
 [201.14835]
 [205.24811]
 [194.58818]
 [204.1128 ]
 [214.33328]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3.  2.  0.] 
cards in discard: [25.  3.  1.  0.  1.  0. 25.  3.  0.  0.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 25. 29. 28. 30.  8.  6.  9.  7.  7.  7.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [3. 8. 3. 1. 0.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6] -> size -> 31 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1
Learning step: -3.107840061187744
desired expected reward: 212.06675720214844



buy possibilites: [-1] 
expected returns: [[132.17838]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3.  2.  0.] 
cards in discard: [25.  3.  1.  0.  1.  0. 25.  3.  0.  0.  0. 10.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 28. 30.  8.  6.  9.  7.  7.  6.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [3. 8. 3. 1. 0.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6] -> size -> 31 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 109 

action type: buy - action 25.0
Learning step: -2.37727427482605
desired expected reward: 213.6484832763672






Player: 1 
cards in hand: [3. 8. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 1. 0.] 
cards in discard: [ 6.  3. 16.  0.  0. 10.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 28. 30.  8.  6.  9.  7.  7.  6.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 2. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25] -> size -> 25 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 1. 0.] 
cards in discard: [ 6.  3. 16.  0.  0. 10.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 25. 29. 28. 30.  8.  6.  9.  7.  7.  6.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 2. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25] -> size -> 25 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 1. 0.] 
cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 28. 30.  8.  6.  9.  7.  7.  6.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 2. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25] -> size -> 25 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 2. 29.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[143.09839]
 [134.87808]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2. 29.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 28. 30.  8.  6.  9.  7.  7.  6.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [15.  6. 10. 22.  8.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6  1] -> size -> 32 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: -1.0514755249023438
desired expected reward: 131.12689208984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[124.780975]
 [131.08293 ]
 [122.47742 ]
 [129.79509 ]
 [117.88677 ]
 [115.11831 ]
 [127.3137  ]
 [136.55194 ]
 [130.23766 ]
 [141.20335 ]
 [132.50592 ]
 [120.83271 ]
 [124.67621 ]
 [129.12796 ]
 [118.13857 ]
 [127.854515]
 [140.72623 ]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2. 29.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 7 
card supply: [21. 24. 29. 28. 30.  8.  6.  9.  7.  7.  6.  9. 10. 10.  4.  9.  9.] 
adversary cards in hand: [15.  6. 10. 22.  8.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6  1] -> size -> 32 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1.0
Learning step: -1.5788376331329346
desired expected reward: 138.95083618164062



buy possibilites: [-1] 
expected returns: [[153.07613]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2. 29.  1.  0.  0.] 
cards in discard: [23.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 24. 29. 28. 30.  8.  6.  9.  7.  7.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [15.  6. 10. 22.  8.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6  1] -> size -> 32 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 61.5 

action type: buy - action 23.0
Learning step: 0.2854042053222656
desired expected reward: 124.96156311035156






Player: 1 
cards in hand: [15.  6. 10. 22.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 22.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6. 10. 22.  8.] 
cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 28. 30.  8.  6.  9.  7.  7.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 3.  3. 25.  3.  0.] 
adversary cards in discard: [23.  2. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23] -> size -> 26 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6. 10. 22.  8.] 
cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6  1] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 24. 29. 28. 30.  8.  6.  9.  7.  7.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 3.  3. 25.  3.  0.] 
adversary cards in discard: [23.  2. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23] -> size -> 26 
adversary victory points: 4
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[123.63146]
 [125.24406]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.  3.  0.] 
cards in discard: [23.  2. 29.  1.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 28. 30.  8.  6.  9.  7.  7.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6  1] -> size -> 32 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: -2.3965015411376953
desired expected reward: 150.67962646484375



action possibilites: [-1] 
expected returns: [[109.22219]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0.  0. 25.] 
cards in discard: [23.  2. 29.  1.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 28. 30.  8.  5.  9.  7.  7.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6  1  6] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 70 

action type: take_action - action 25.0
Learning step: -0.3047046661376953
desired expected reward: 124.93936920166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 93.23175 ]
 [ 98.68914 ]
 [ 82.7144  ]
 [ 99.644516]
 [110.7031  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0.  0. 25.] 
cards in discard: [23.  2. 29.  1.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 24. 29. 28. 30.  8.  5.  9.  7.  7.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6  1  6] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1
Learning step: 0.2980480194091797
desired expected reward: 109.5202407836914



buy possibilites: [-1] 
expected returns: [[172.07745]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0.  0. 25.] 
cards in discard: [23.  2. 29.  1.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 27. 30.  8.  5.  9.  7.  7.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6  1  6] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 60  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 88 

action type: buy - action 3.0
Learning step: 3.337285280227661
desired expected reward: 102.02642822265625






Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.
  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0
  6  6  8 11  6  3  6  1  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 27. 30.  8.  5.  9.  7.  7.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [10. 25.  1.  0.  0.] 
adversary cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3] -> size -> 27 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.
  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 27. 30.  8.  5.  9.  7.  7.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [10. 25.  1.  0.  0.] 
adversary cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3] -> size -> 27 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.
  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 24. 29. 27. 30.  8.  5.  9.  7.  7.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [10. 25.  1.  0.  0.] 
adversary cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3] -> size -> 27 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.
  6.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 29. 27. 30.  8.  5.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [10. 25.  1.  0.  0.] 
adversary cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3] -> size -> 27 
adversary victory points: 5
player victory points: -2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10. 25.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[234.27618]
 [218.37006]
 [235.87512]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  1.  0.  0.] 
cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 27. 30.  8.  5.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [11.  0. 11.  0.  1.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.
  6.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8] -> size -> 33 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: buy - action -1
Learning step: 0.11891784518957138
desired expected reward: 172.1963653564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[219.33986]
 [226.98584]
 [224.9965 ]
 [207.0459 ]
 [222.1658 ]
 [234.3679 ]
 [225.82538]
 [228.38925]
 [214.22183]
 [224.0293 ]
 [222.25642]
 [240.32997]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 25.  1.  0.  0.] 
cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 24. 29. 27. 30.  8.  5.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [11.  0. 11.  0.  1.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.
  6.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8] -> size -> 33 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1.0
Learning step: -3.0206589698791504
desired expected reward: 231.2554931640625



buy possibilites: [-1] 
expected returns: [[139.05777]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 25.  1.  0.  0.] 
cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 24. 29. 27. 30.  8.  5.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [11.  0. 11.  0.  1.] 
adversary cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.
  6.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8] -> size -> 33 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5.  70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 40.0 

action type: buy - action 0.0
Learning step: -5.838193893432617
desired expected reward: 213.50167846679688






Player: 1 
cards in hand: [11.  0. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.  1.] 
cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.
  6.  8.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 27. 30.  8.  5.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  1.] 
adversary cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.  0. 10. 25.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  1.] 
cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.
  6.  8.  8.  0.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 29. 27. 30.  8.  5.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  1.] 
adversary cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.  0. 10. 25.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  1.] 
cards in discard: [ 6.  3. 16.  0.  0. 10.  6.  1.  3.  8.  3.  1.  0. 15.  6. 10. 22.  8.
  6.  8.  8.  0.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 23. 29. 27. 30.  8.  5.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  1.] 
adversary cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.  0. 10. 25.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[84.35287]
 [87.39237]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3.  1.] 
cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.  0. 10. 25.  1.
  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 29. 27. 30.  8.  5.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  6.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1] -> size -> 34 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: buy - action -1
Learning step: -1.5067024230957031
desired expected reward: 137.5510711669922



action possibilites: [-1] 
expected returns: [[64.447426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  1.  0. 10.] 
cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.  0. 10. 25.  1.
  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 29. 27. 30.  8.  4.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  6.  0. 10. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6] -> size -> 35 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 70  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 91 

action type: take_action - action 25.0
Learning step: 1.4804786443710327
desired expected reward: 88.87283325195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[64.64863 ]
 [67.78717 ]
 [65.7164  ]
 [60.913776]
 [58.885998]
 [65.58414 ]
 [69.01027 ]
 [67.777985]
 [72.17002 ]
 [67.873566]
 [61.822006]
 [62.72486 ]
 [65.71884 ]
 [59.810253]
 [64.75021 ]
 [68.30466 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  1.  0. 10.] 
cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.  0. 10. 25.  1.
  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 23. 29. 27. 30.  8.  4.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  6.  0. 10. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6] -> size -> 35 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 90 

action type: take_action - action -1
Learning step: 2.8093228340148926
desired expected reward: 67.25675201416016



buy possibilites: [-1] 
expected returns: [[127.61076]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  1.  0. 10.] 
cards in discard: [23.  2. 29.  1.  0.  0.  3. 25.  3.  3.  3.  0.  0. 25.  0. 10. 25.  1.
  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 5 
card supply: [19. 23. 29. 27. 30.  8.  4.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  6.  0. 10. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6] -> size -> 35 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5.  70.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 60.0 

action type: buy - action 0.0
Learning step: 2.6388118267059326
desired expected reward: 67.28741455078125






Player: 1 
cards in hand: [ 1.  6.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0. 10. 10.] 
cards in discard: [6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 27. 30.  8.  4.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  1. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0] -> size -> 29 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0. 10. 10.] 
cards in discard: [6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 29. 27. 30.  8.  4.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  1. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0] -> size -> 29 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0. 10. 10.] 
cards in discard: [6. 3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 29. 26. 30.  8.  4.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  1. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0] -> size -> 29 
adversary victory points: 5
player victory points: -2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 1.  1. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[83.12403]
 [85.50871]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 26. 30.  8.  4.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 0.  0. 16. 15.  0.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3] -> size -> 36 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: buy - action -1
Learning step: -0.9723953604698181
desired expected reward: 126.63836669921875



action possibilites: [-1] 
expected returns: [[190.7284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 3. 2.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 26. 30.  8.  3.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 0.  0. 16. 15.  0.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6] -> size -> 37 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 70  0  0 20  0  0  0  0  0  0  0  0  3] 
sum of rewards: 93 

action type: take_action - action 25.0
Learning step: 4.665952682495117
desired expected reward: 90.17467498779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[173.21129]
 [180.06883]
 [170.7245 ]
 [178.71837]
 [165.04388]
 [170.8705 ]
 [161.61282]
 [175.97612]
 [186.01079]
 [179.05098]
 [191.11096]
 [181.48764]
 [168.51694]
 [173.07762]
 [177.88542]
 [165.25546]
 [176.4169 ]
 [190.7129 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 3. 2.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 9 
card supply: [19. 23. 29. 26. 30.  8.  3.  9.  7.  6.  6.  9. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 0.  0. 16. 15.  0.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6] -> size -> 37 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 90 

action type: take_action - action -1
Learning step: -0.9383544921875
desired expected reward: 189.7900390625



buy possibilites: [-1] 
expected returns: [[151.8059]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 3. 2.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 6 
card supply: [19. 23. 29. 26. 30.  8.  3.  9.  7.  6.  6.  9. 10.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0. 16. 15.  0.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6] -> size -> 37 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-5.   0.   5.  70.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 94.5 

action type: buy - action 10.0
Learning step: -0.7536369562149048
desired expected reward: 177.1317596435547






Player: 1 
cards in hand: [ 0.  0. 16. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16. 15.  0.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 26. 30.  8.  3.  9.  7.  6.  6.  9. 10.  9.  3.  9.  9.] 
adversary cards in hand: [ 0. 23. 25. 10.  1.] 
adversary cards in discard: [10. 25.  1.  1.  0.  0.  3.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10] -> size -> 30 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16. 15.  0.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 29. 26. 30.  8.  3.  9.  7.  6.  6.  9. 10.  9.  3.  9.  9.] 
adversary cards in hand: [ 0. 23. 25. 10.  1.] 
adversary cards in discard: [10. 25.  1.  1.  0.  0.  3.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10] -> size -> 30 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16. 15.  0.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 23. 29. 26. 30.  8.  3.  9.  7.  6.  6.  9. 10.  9.  3.  9.  9.] 
adversary cards in hand: [ 0. 23. 25. 10.  1.] 
adversary cards in discard: [10. 25.  1.  1.  0.  0.  3.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10] -> size -> 30 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 23. 25. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 25. 10.] 
expected returns: [[103.152145]
 [ 90.560135]
 [106.23695 ]
 [ 95.25128 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23. 25. 10.  1.] 
cards in discard: [10. 25.  1.  1.  0.  0.  3.  2.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 26. 30.  8.  3.  9.  7.  6.  6.  9. 10.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  6. 11. 22.  6.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0] -> size -> 38 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 80 

action type: buy - action -1
Learning step: -1.298529028892517
desired expected reward: 150.5073699951172



action possibilites: [-1] 
expected returns: [[62.335052]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23. 10.  1.  3. 25.] 
cards in discard: [10. 25.  1.  1.  0.  0.  3.  2.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 26. 30.  8.  2.  9.  7.  6.  6.  9. 10.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  6. 11. 22.  6.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6] -> size -> 39 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 100 

action type: take_action - action 25.0
Learning step: 1.0906914472579956
desired expected reward: 107.32764434814453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[46.239986]
 [50.41107 ]
 [49.546284]
 [39.27688 ]
 [54.02894 ]
 [49.860474]
 [49.112064]
 [56.740185]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23. 10.  1.  3. 25.] 
cards in discard: [10. 25.  1.  1.  0.  0.  3.  2.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 29. 26. 30.  8.  2.  9.  7.  6.  6.  9. 10.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  6. 11. 22.  6.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6] -> size -> 39 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 100 

action type: take_action - action -1
Learning step: 3.062643051147461
desired expected reward: 65.39769744873047






Player: 1 
cards in hand: [ 6.  6. 11. 22.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 11. 22.  6.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 26. 30.  8.  2.  9.  7.  6.  6.  9. 10.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10] -> size -> 30 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 22.  6.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6 14] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 26. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10] -> size -> 30 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 22.  6.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6 14] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 23. 29. 26. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10] -> size -> 30 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[189.08528]
 [179.88293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 26. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [6. 8. 0. 3. 3.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6 14] -> size -> 40 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 90 

action type: buy - action -1.0
Learning step: 5.856426239013672
desired expected reward: 62.596614837646484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[177.052  ]
 [182.28098]
 [180.77983]
 [167.76357]
 [186.29654]
 [181.63368]
 [180.24042]
 [189.19179]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 29. 26. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [6. 8. 0. 3. 3.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6 14] -> size -> 40 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 90 

action type: take_action - action -1.0
Learning step: -0.8105942010879517
desired expected reward: 188.27467346191406



buy possibilites: [-1] 
expected returns: [[59.738853]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 23. 29. 25. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [6. 8. 0. 3. 3.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6 14] -> size -> 40 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6. 100.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: 103.0 

action type: buy - action 3.0
Learning step: -2.544867753982544
desired expected reward: 178.23497009277344






Player: 1 
cards in hand: [6. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 3. 3.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6 14] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 25. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 29. 25.] 
adversary cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.  3.  0.  0.
 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3] -> size -> 31 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 3. 3.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6 14] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 23. 29. 25. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 29. 25.] 
adversary cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.  3.  0.  0.
 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3] -> size -> 31 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 3. 3.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 23. 29. 25. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 29. 25.] 
adversary cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.  3.  0.  0.
 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3] -> size -> 31 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[14.752647]
 [11.487141]
 [14.563337]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 25.] 
cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.  3.  0.  0.
 10.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 25. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.  6.  8.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0] -> size -> 41 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: buy - action -1
Learning step: 2.3797287940979004
desired expected reward: 62.11858367919922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[14.579378]
 [17.257975]
 [16.789206]
 [10.860761]
 [20.484642]
 [17.014917]
 [16.6845  ]
 [22.751951]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 25.] 
cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.  3.  0.  0.
 10.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 23. 29. 25. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.  6.  8.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0] -> size -> 41 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: take_action - action -1.0
Learning step: 4.748753070831299
desired expected reward: 19.501399993896484



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.  6.  8.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6
  6  8 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 25. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.  3.  0.  0.
 10.  0.  3.  0.  0.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3] -> size -> 31 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.  6.  8.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 25. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.  3.  0.  0.
 10.  0.  3.  0.  0.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3] -> size -> 31 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.  6.  8.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 29. 25. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.  3.  0.  0.
 10.  0.  3.  0.  0.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3] -> size -> 31 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.  6.  8.  0.  3.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.  3.  0.  0.
 10.  0.  3.  0.  0.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3] -> size -> 31 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[43.508213]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.  3.  0.  0.
 10.  0.  3.  0.  0.  0. 29. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 3. 10.  8. 11.  1.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.  6.  8.  0.  3.  3.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 91 

action type: buy - action -1.0
Learning step: 4.391336917877197
desired expected reward: 27.14328956604004





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.751747]
 [32.80998 ]
 [32.303234]
 [27.757208]
 [35.870483]
 [32.563835]
 [32.107918]
 [39.397022]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.  3.  0.  0.
 10.  0.  3.  0.  0.  0. 29. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 23. 29. 24. 30.  8.  2.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 3. 10.  8. 11.  1.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.  6.  8.  0.  3.  3.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 91 

action type: take_action - action -1.0
Learning step: 3.175511360168457
desired expected reward: 46.68372344970703



buy possibilites: [-1] 
expected returns: [[31.19695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 25.  1.  1.  0.  0.  3.  2. 25.  0. 23. 10.  1.  3. 25.  3.  0.  0.
 10.  0.  3.  0.  0.  0. 29. 25.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 23. 29. 24. 30.  8.  1.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 3. 10.  8. 11.  1.] 
adversary cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.  6.  8.  0.  3.  3.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3] -> size -> 40 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    5.   80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -220.0 

action type: buy - action 6.0
Learning step: -11.784889221191406
desired expected reward: 17.951520919799805






Player: 1 
cards in hand: [ 3. 10.  8. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8. 11.  1.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.  6.  8.  0.  3.  3.  3.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  1.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [1. 2. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6] -> size -> 32 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  1.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.  6.  8.  0.  3.  3.  3.  8.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 23. 30.  8.  1.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [1. 2. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6] -> size -> 32 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  1.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.  6.  8.  0.  3.  3.  3.  8.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 29. 23. 30.  8.  1.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [1. 2. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6] -> size -> 32 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  1.] 
cards in discard: [ 6.  3.  1.  6.  0. 10. 10.  6.  0.  0.  0. 16. 15.  0.  6. 14. 11.  6.
  6. 22.  6.  0.  6.  8.  0.  3.  3.  3.  8.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 23. 29. 23. 30.  8.  1.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [1. 2. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6] -> size -> 32 
adversary victory points: 5
player victory points: -2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [1. 2. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[108.372025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 2. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 23. 30.  8.  1.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [0. 0. 1. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0] -> size -> 42 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: buy - action -1
Learning step: 4.378522872924805
desired expected reward: 35.57547378540039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[116.79393 ]
 [118.75774 ]
 [115.986824]
 [118.19953 ]
 [114.66261 ]
 [116.22195 ]
 [113.6648  ]
 [117.41708 ]
 [120.940735]
 [118.511116]
 [123.07174 ]
 [119.45925 ]
 [115.65852 ]
 [116.72397 ]
 [118.03122 ]
 [114.63884 ]
 [117.74366 ]
 [122.73612 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 2. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 8 
card supply: [16. 23. 29. 23. 30.  8.  1.  9.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [0. 0. 1. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0] -> size -> 42 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1.0
Learning step: 0.7797737121582031
desired expected reward: 109.15179443359375



buy possibilites: [-1] 
expected returns: [[193.98015]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 2. 0. 1. 3.] 
cards in discard: [16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 23. 29. 23. 30.  8.  1.  8.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [0. 0. 1. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0] -> size -> 42 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 70.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 78.0 

action type: buy - action 16.0
Learning step: 2.393698215484619
desired expected reward: 119.81079864501953






Player: 1 
cards in hand: [0. 0. 1. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8. 1.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 23. 30.  8.  1.  8.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0. 25. 23. 25.  1.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8. 1.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 6 
card supply: [16. 23. 29. 23. 30.  8.  1.  8.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0. 25. 23. 25.  1.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8. 1.] 
cards in discard: [4.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 23. 29. 23. 29.  8.  1.  8.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0. 25. 23. 25.  1.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 23. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 23. 25.] 
expected returns: [[136.65169]
 [139.7655 ]
 [124.5522 ]
 [139.7655 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 23. 25.  1.] 
cards in discard: [16.  1.  2.  0.  1.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 23. 29.  8.  1.  8.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [10.  0. 16.  3.  6.] 
adversary cards in discard: [4. 0. 0. 1. 8. 1.] 
adversary owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4] -> size -> 43 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: -4.615009307861328
desired expected reward: 189.36514282226562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[127.35524]
 [132.99693]
 [130.87244]
 [118.23892]
 [136.39789]
 [132.39618]
 [130.33778]
 [137.73973]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 23. 25.  1.] 
cards in discard: [16.  1.  2.  0.  1.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 23. 29. 23. 29.  8.  1.  8.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [10.  0. 16.  3.  6.] 
adversary cards in discard: [4. 0. 0. 1. 8. 1.] 
adversary owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4] -> size -> 43 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: -1.8255256414413452
desired expected reward: 134.826171875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0. 16.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 16.  3.  6.] 
cards in discard: [4. 0. 0. 1. 8. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8
 11  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 23. 29.  8.  1.  8.  7.  6.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0.  6. 10.  0.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.] 
cards in discard: [4. 0. 0. 1. 8. 1. 8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 23. 29.  8.  1.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0.  6. 10.  0.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.] 
cards in discard: [4. 0. 0. 1. 8. 1. 8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 23. 29. 23. 29.  8.  1.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0.  6. 10.  0.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.] 
cards in discard: [4. 0. 0. 1. 8. 1. 8. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 23. 29.  8.  1.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0.  6. 10.  0.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[72.61076]
 [65.41821]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 10.  0.] 
cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 23. 29.  8.  1.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 6. 10.  6.  0.  3.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0] -> size -> 44 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1.0
Learning step: -3.3009090423583984
desired expected reward: 134.4388427734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[56.999786]
 [61.068687]
 [60.111385]
 [49.831917]
 [64.44603 ]
 [60.546333]
 [59.696236]
 [67.75011 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 10.  0.] 
cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 23. 29. 23. 29.  8.  1.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 6. 10.  6.  0.  3.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0] -> size -> 44 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: -0.20813293755054474
desired expected reward: 72.40264892578125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6. 10.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6.  0.  3.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 23. 29.  8.  1.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [10.  3. 25.  0.  0.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 3. 3.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0] -> size -> 44 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 23. 29.  8.  1.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [10.  3. 25.  0.  0.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 3.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 23. 29. 23. 29.  8.  1.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [10.  3. 25.  0.  0.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10.  3. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[38.486565]
 [29.115175]
 [38.736485]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 25.  0.  0.] 
cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 23. 29.  8.  1.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 10.  0.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0] -> size -> 44 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1.0
Learning step: -0.5595449805259705
desired expected reward: 67.19056701660156



action possibilites: [-1. 25.] 
expected returns: [[59.25028]
 [59.9168 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  0.  3.] 
cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 23. 29.  8.  1.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 10.  0.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0] -> size -> 44 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action 10.0
Learning step: 2.8879528045654297
desired expected reward: 32.00312042236328



action possibilites: [-1. 25.] 
expected returns: [[8.687779]
 [8.195009]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3.  3. 25.] 
cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 23. 29.  8.  0.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 10.  0.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6] -> size -> 45 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 80 

action type: take_action - action 25.0
Learning step: 1.1963697671890259
desired expected reward: 61.11316680908203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-1.1275477 ]
 [ 0.13590717]
 [-0.3791294 ]
 [ 6.328248  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3.  3. 25.] 
cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 23. 29. 23. 29.  8.  0.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 10.  0.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6] -> size -> 45 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 80 

action type: take_action - action -1.0
Learning step: 3.640550374984741
desired expected reward: 12.328324317932129



buy possibilites: [-1] 
expected returns: [[101.482796]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3.  3. 25.] 
cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 10.  0.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6] -> size -> 45 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 40  0  0  0  0  0  0  0  8  0] 
sum of rewards: 99 

action type: buy - action 3.0
Learning step: 7.22656774520874
desired expected reward: 7.362464904785156






Player: 1 
cards in hand: [ 3.  0.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 10.  0.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [10.  0.  0.  0. 29.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.  3. 10.
 25.  3.  0.  0.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 6.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [10.  0.  0.  0. 29.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.  3. 10.
 25.  3.  0.  0.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 6.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  9.  9.  9.  3.  9.  9.] 
adversary cards in hand: [10.  0.  0.  0. 29.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.  3. 10.
 25.  3.  0.  0.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 6.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [10.  0.  0.  0. 29.] 
adversary cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.  3. 10.
 25.  3.  0.  0.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[71.1699  ]
 [59.28345 ]
 [61.961903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 29.] 
cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.  3. 10.
 25.  3.  0.  0.  3.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 1. 22.  6.  6. 14.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29] -> size -> 46 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1
Learning step: -0.5160102844238281
desired expected reward: 100.96678161621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[53.108673]
 [58.934795]
 [58.959885]
 [65.215996]
 [57.96225 ]
 [58.220394]
 [71.550995]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 29.] 
cards in discard: [16.  1.  2.  0.  1.  3.  0. 25. 23. 25.  1.  0.  0.  6. 10.  0.  3. 10.
 25.  3.  0.  0.  3.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 1. 22.  6.  6. 14.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29] -> size -> 46 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: 0.9557937979698181
desired expected reward: 72.12568664550781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1. 22.  6.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 22.  6.  6. 14.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 22.  6.  6. 14.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[126.574875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 3.  8. 11.  0.  3.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29] -> size -> 46 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1.0
Learning step: 2.320385694503784
desired expected reward: 73.87136840820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[105.60068 ]
 [112.1186  ]
 [111.05208 ]
 [117.881325]
 [111.18251 ]
 [110.28905 ]
 [122.56211 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 3.  8. 11.  0.  3.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29] -> size -> 46 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: -0.5280960202217102
desired expected reward: 123.64022064208984



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  8. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  0.  3.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [23.  1.  3.  0.  0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  0.  3.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [23.  1.  3.  0.  0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  0.  3.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [23.  1.  3.  0.  0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [23.  1.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[130.40483]
 [121.54148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  1.  3.  0.  0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 8. 11.  6.  0.  8.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.  3.  8. 11.  0.
  3.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0] -> size -> 47 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1.0
Learning step: -0.2027328461408615
desired expected reward: 122.359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[124.14235 ]
 [127.78322 ]
 [126.7159  ]
 [125.522446]
 [130.6862  ]
 [127.4368  ]
 [128.57895 ]
 [121.4719  ]
 [126.46153 ]
 [125.69647 ]
 [132.51337 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  1.  3.  0.  0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 23. 29. 22. 29.  8.  0.  8.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 8. 11.  6.  0.  8.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.  3.  8. 11.  0.
  3.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0] -> size -> 47 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: -0.5617530941963196
desired expected reward: 129.8430938720703



buy possibilites: [-1] 
expected returns: [[123.82801]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  1.  3.  0.  0.] 
cards in discard: [ 0.  3.  3.  0.  0. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 8. 11.  6.  0.  8.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.  3.  8. 11.  0.
  3.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0] -> size -> 47 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 93 

action type: buy - action 16.0
Learning step: 1.160009741783142
desired expected reward: 126.68241119384766






Player: 1 
cards in hand: [ 8. 11.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  6.  0.  8.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.  3.  8. 11.  0.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [25. 10.  3.  1.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  6.  0.  8.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.  3.  8. 11.  0.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [25. 10.  3.  1.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  6.  0.  8.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.  3.  8. 11.  0.
  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [25. 10.  3.  1.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [25. 10.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[107.03755]
 [107.77551]
 [ 94.7113 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  3.  1.  0.] 
cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 15.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.  3.  8. 11.  0.
  3.  0.  8. 11.  6.  0.  8.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0] -> size -> 48 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1
Learning step: -0.7774280905723572
desired expected reward: 123.05058288574219



action possibilites: [-1] 
expected returns: [[76.588776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.  0.  0.  3.] 
cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 15.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.  3.  8. 11.  0.
  3.  0.  8. 11.  6.  0.  8.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0] -> size -> 48 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 82 

action type: take_action - action 25.0
Learning step: 0.4344726502895355
desired expected reward: 108.20996856689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[63.737522]
 [68.21854 ]
 [67.435356]
 [65.55159 ]
 [72.257935]
 [67.57565 ]
 [69.27829 ]
 [60.748627]
 [66.92436 ]
 [66.04426 ]
 [75.419586]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.  0.  0.  3.] 
cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 15.] 
adversary cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.  3.  8. 11.  0.
  3.  0.  8. 11.  6.  0.  8.] 
adversary owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0] -> size -> 48 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1
Learning step: 1.8133713006973267
desired expected reward: 78.40214538574219






Player: 1 
cards in hand: [ 6.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  0. 15.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.  3.  8. 11.  0.
  3.  0.  8. 11.  6.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11
  6  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  1. 25.  0. 10.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.  3.  8. 11.  0.
  3.  0.  8. 11.  6.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  1. 25.  0. 10.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.  3.  8. 11.  0.
  3.  0.  8. 11.  6.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  1. 25.  0. 10.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 4.  0.  0.  1.  8.  1.  8.  0. 16. 10.  3.  6. 10.  6.  6.  0.  3.  3.
  6. 29. 10.  3.  0.  1.  0.  6.  1. 22.  6.  6. 14.  0.  3.  8. 11.  0.
  3.  0.  8. 11.  6.  0.  8. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [ 0.  1. 25.  0. 10.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 25.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[96.020615]
 [97.68283 ]
 [87.63487 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.  0. 10.] 
cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [ 6.  0.  0.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22] -> size -> 48 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1.0
Learning step: 1.4251492023468018
desired expected reward: 76.8447494506836



action possibilites: [-1] 
expected returns: [[123.96056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 10.  0.  3.] 
cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [ 6.  0.  0.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22] -> size -> 48 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 82 

action type: take_action - action 25.0
Learning step: 2.0049736499786377
desired expected reward: 99.68775939941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[105.96612 ]
 [110.31585 ]
 [108.60174 ]
 [100.56106 ]
 [107.5486  ]
 [113.120735]
 [109.94917 ]
 [116.778694]
 [110.91401 ]
 [102.47099 ]
 [104.91665 ]
 [108.27896 ]
 [100.174255]
 [107.31278 ]
 [114.80831 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 10.  0.  3.] 
cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  7.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [ 6.  0.  0.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22] -> size -> 48 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1
Learning step: 0.36466026306152344
desired expected reward: 124.32522583007812



buy possibilites: [-1] 
expected returns: [[230.28183]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 10.  0.  3.] 
cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.
 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [ 6.  0.  0.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22] -> size -> 48 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5.   0.   6.  60.   0.   0.  20.   0.   0.   0.   0.  -1.   0.   0.
  4.5  0. ] 
sum of rewards: 84.5 

action type: buy - action 11.0
Learning step: 3.750304937362671
desired expected reward: 116.87104034423828






Player: 1 
cards in hand: [ 6.  0.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  1. 10.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [16.  2.  3. 10. 29.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.
 11. 25.  0.  1.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11] -> size -> 36 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  1. 10.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 23. 29. 22. 29.  8.  0.  7.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [16.  2.  3. 10. 29.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.
 11. 25.  0.  1.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11] -> size -> 36 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  1. 10.] 
cards in discard: [3.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 23. 29. 21. 29.  8.  0.  7.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [16.  2.  3. 10. 29.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.
 11. 25.  0.  1.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11] -> size -> 36 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [16.  2.  3. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 29.] 
expected returns: [[67.06877 ]
 [59.584217]
 [60.50085 ]
 [62.506077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  2.  3. 10. 29.] 
cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.
 11. 25.  0.  1.  0. 10.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 21. 29.  8.  0.  7.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [ 1.  0. 14. 11.  1.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10.] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3] -> size -> 49 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -7.516724586486816
desired expected reward: 222.76510620117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[56.70359 ]
 [62.03748 ]
 [60.737103]
 [65.74618 ]
 [61.319958]
 [60.15934 ]
 [67.65007 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  2.  3. 10. 29.] 
cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.
 11. 25.  0.  1.  0. 10.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 23. 29. 21. 29.  8.  0.  7.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [ 1.  0. 14. 11.  1.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10.] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3] -> size -> 49 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: 0.6444728970527649
desired expected reward: 67.71324920654297



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0. 14. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 14. 11.  1.] 
cards in discard: [ 3.  6.  0.  0.  1. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 21. 29.  8.  0.  7.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [ 0.  0. 25. 25.  6.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.
 11. 25.  0.  1.  0. 10.  0.  3. 16.  2.  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11] -> size -> 36 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  1.] 
cards in discard: [ 3.  6.  0.  0.  1. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 23. 29. 21. 29.  8.  0.  7.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [ 0.  0. 25.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.
 11. 25.  0.  1.  0. 10.  0.  3. 16.  2.  3. 10. 29. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11] -> size -> 36 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  1.] 
cards in discard: [ 3.  6.  0.  0.  1. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 7 
card supply: [13. 23. 29. 21. 29.  8.  0.  7.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [ 0.  0. 25.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.
 11. 25.  0.  1.  0. 10.  0.  3. 16.  2.  3. 10. 29. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11] -> size -> 36 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  1.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16.] 
cards in deck: 38 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 23. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [ 0.  0. 25.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.
 11. 25.  0.  1.  0. 10.  0.  3. 16.  2.  3. 10. 29. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11] -> size -> 36 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[46.88313]
 [46.49725]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.] 
cards in discard: [ 0.  3.  3.  0.  0. 16. 23.  1.  3.  0.  0. 25. 10.  3.  1.  0.  0.  3.
 11. 25.  0.  1.  0. 10.  0.  3. 16.  2.  3. 10. 29. 25.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [10. 15.  3.  8.  0.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1.] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: discard_down_to_3_cards - action 1
Learning step: -0.15605317056179047
desired expected reward: 75.01127624511719



action possibilites: [-1] 
expected returns: [[102.3271]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [10. 15.  3.  8.  0.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1.] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 72 

action type: take_action - action 25.0
Learning step: 3.5658531188964844
desired expected reward: 50.06310272216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[92.59057 ]
 [95.988106]
 [94.79039 ]
 [98.31155 ]
 [95.6707  ]
 [94.532974]
 [99.42021 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 23. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [10. 15.  3.  8.  0.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1.] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1
Learning step: 0.6239520907402039
desired expected reward: 102.95105743408203



buy possibilites: [-1] 
expected returns: [[103.061104]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [10. 15.  3.  8.  0.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1.] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0 -2  0  0 18  0] 
sum of rewards: 87 

action type: buy - action 1.0
Learning step: 1.8694686889648438
desired expected reward: 97.85758209228516






Player: 1 
cards in hand: [10. 15.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3.  8.  0.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [ 3.  6. 11. 25.  1.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  3.  8.  0.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [ 3.  6. 11. 25.  1.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 3.  6. 11. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[96.14073]
 [93.07913]
 [97.91786]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11. 25.  1.] 
cards in discard: [ 1. 25.  0.  0.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [29.  8.  6.  6.  6.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -0.42913171648979187
desired expected reward: 102.63197326660156



action possibilites: [-1] 
expected returns: [[151.96739]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11.  1.  0.  0.] 
cards in discard: [ 1. 25.  0.  0.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [29.  8.  6.  6.  6.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 73 

action type: take_action - action 25.0
Learning step: 2.1733739376068115
desired expected reward: 100.0912094116211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[135.8459 ]
 [142.39029]
 [141.22842]
 [138.3402 ]
 [148.61113]
 [141.38226]
 [144.04695]
 [131.76482]
 [140.42451]
 [139.09264]
 [153.59792]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.  1.  0.  0.] 
cards in discard: [ 1. 25.  0.  0.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [29.  8.  6.  6.  6.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1
Learning step: -0.7524879574775696
desired expected reward: 151.21490478515625






Player: 1 
cards in hand: [29.  8.  6.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  6.  6.  6.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [25.  0.  3.  0.  1.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  6. 22.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [25.  0.  3.  0.  1.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 0. 1. 8.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 22.] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [25.  0.  3.  0.  1.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 0. 1. 8.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 22.] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16] -> size -> 50 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  9.  3.  8.  9.] 
adversary cards in hand: [25.  0.  3.  0.  1.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 0. 1. 8.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 22.] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16 23] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [25.  0.  3.  0.  1.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [25.  0.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[39.93422 ]
 [38.996162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  0.  1.] 
cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [ 8.  6.  3.  8. 16.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16 23] -> size -> 51 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: -4.2375922203063965
desired expected reward: 149.36032104492188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.193295]
 [23.540195]
 [22.458155]
 [20.82082 ]
 [28.75564 ]
 [22.892792]
 [24.562315]
 [16.51454 ]
 [21.966   ]
 [20.972727]
 [33.884193]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  3.  0.  1.] 
cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [ 8.  6.  3.  8. 16.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.] 
adversary owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16 23] -> size -> 51 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: 1.1745128631591797
desired expected reward: 41.108734130859375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  6.  3.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  3.  8. 16.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 10  0 16  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6
  3  6  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22
  3 16 23] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [ 0. 10. 29.  0. 23.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [ 0. 10. 29.  0. 23.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [ 0. 10. 29.  0. 23.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [ 0. 10. 29.  0. 23.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 29.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 23.] 
expected returns: [[58.868477]
 [42.141853]
 [46.75882 ]
 [35.74842 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  0. 23.] 
cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [ 3.  0.  0. 22.  0.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0] -> size -> 50 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1.0
Learning step: 2.5081775188446045
desired expected reward: 36.392372131347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[36.827705]
 [43.972397]
 [44.57715 ]
 [60.42031 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29.  0. 23.] 
cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [ 3.  0.  0. 22.  0.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0] -> size -> 50 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: 1.2808685302734375
desired expected reward: 60.14930725097656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  0. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 22.  0.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [10. 25.  3.  1.  3.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.
  0. 10. 29.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 22.  0.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 22. 29. 21. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [10. 25.  3.  1.  3.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.
  0. 10. 29.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 22.  0.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 22. 29. 20. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [10. 25.  3.  1.  3.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.
  0. 10. 29.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [10. 25.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[-4.9464316]
 [-7.1152763]
 [-6.625348 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  3.  1.  3.] 
cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.
  0. 10. 29.  0. 23.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 20. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [ 3.  3.  6. 10.  6.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.  3.  0.  0.
 22.  0.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3] -> size -> 51 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: -0.59930819272995
desired expected reward: 59.820980072021484



action possibilites: [-1. 25.] 
expected returns: [[2.7422504]
 [4.183476 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  1.  3.  0.] 
cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.
  0. 10. 29.  0. 23.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 20. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [ 3.  3.  6. 10.  6.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.  3.  0.  0.
 22.  0.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3] -> size -> 51 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 72 

action type: take_action - action 10.0
Learning step: 4.040341377258301
desired expected reward: -3.0749316215515137



action possibilites: [-1. 10.] 
expected returns: [[102.544426]
 [ 98.725876]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3.  0. 10.  3.] 
cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.
  0. 10. 29.  0. 23.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 20. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [ 3.  3.  6. 10.  6.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.  3.  0.  0.
 22.  0.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3] -> size -> 51 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 91 

action type: take_action - action 25.0
Learning step: 6.6227707862854
desired expected reward: 10.806249618530273



action possibilites: [-1.] 
expected returns: [[107.00564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 3. 3.] 
cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.
  0. 10. 29.  0. 23.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 25. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 20. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [ 3.  3.  6. 10.  6.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.  3.  0.  0.
 22.  0.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3] -> size -> 51 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 111 

action type: take_action - action 10.0
Learning step: 3.0213334560394287
desired expected reward: 101.7471923828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 97.08114 ]
 [ 98.99382 ]
 [ 98.086235]
 [100.204735]
 [ 98.93806 ]
 [ 98.06607 ]
 [100.52124 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 3. 3.] 
cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.
  0. 10. 29.  0. 23.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 25. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 22. 29. 20. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [ 3.  3.  6. 10.  6.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.  3.  0.  0.
 22.  0.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3] -> size -> 51 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 111 

action type: take_action - action -1.0
Learning step: 2.4391849040985107
desired expected reward: 109.44482421875






Player: 1 
cards in hand: [ 3.  3.  6. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 10.  6.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.  3.  0.  0.
 22.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 20. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [16.  0. 16.  0.  2.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.
  0. 10. 29.  0. 23. 10. 25. 10.  3.  1.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6. 10.  6.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.  3.  0.  0.
 22.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3] -> size -> 51 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 22. 29. 20. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [16.  0. 16.  0.  2.] 
adversary cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.
  0. 10. 29.  0. 23. 10. 25. 10.  3.  1.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
adversary victory points: 6
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [16.  0. 16.  0.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
expected returns: [[69.64838 ]
 [62.968903]
 [62.968903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 16.  0.  2.] 
cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.
  0. 10. 29.  0. 23. 10. 25. 10.  3.  1.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 20. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.  3.  0.  0.
 22.  0.  3.  3.  6. 10.  6.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3] -> size -> 51 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: -0.9679927825927734
desired expected reward: 99.55326080322266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[61.37172 ]
 [65.34306 ]
 [64.30026 ]
 [56.503296]
 [62.968903]
 [68.238396]
 [64.8178  ]
 [71.18472 ]
 [65.877525]
 [58.414192]
 [60.940514]
 [63.83217 ]
 [56.484688]
 [62.87274 ]
 [69.64838 ]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 16.  0.  2.] 
cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.
  0. 10. 29.  0. 23. 10. 25. 10.  3.  1.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 22. 29. 20. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  8.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.  3.  0.  0.
 22.  0.  3.  3.  6. 10.  6.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3] -> size -> 51 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: 0.5676490664482117
desired expected reward: 70.2160415649414



buy possibilites: [-1] 
expected returns: [[30.931616]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 16.  0.  2.] 
cards in discard: [ 1. 25.  0.  0.  0.  3. 25.  3.  6. 11.  1.  0.  0. 25.  0.  3.  0.  1.
  0. 10. 29.  0. 23. 10. 25. 10.  3.  1.  3.  0.  3.  3. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 20. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  7.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.  3.  0.  0.
 22.  0.  3.  3.  6. 10.  6.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3] -> size -> 51 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0 -3  0  0 50  0] 
sum of rewards: 98 

action type: buy - action 22.0
Learning step: 2.7510809898376465
desired expected reward: 59.64868927001953






Player: 1 
cards in hand: [6. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.  3.  0.  0.
 22.  0.  3.  3.  6. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 20. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  7.  9.] 
adversary cards in hand: [ 0. 25.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22] -> size -> 38 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.  3.  0.  0.
 22.  0.  3.  3.  6. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 22. 29. 20. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  7.  9.] 
adversary cards in hand: [ 0. 25.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22] -> size -> 38 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [ 3.  6.  0.  0.  1. 10. 16. 14.  1.  0. 11.  1. 10. 15.  3.  8.  0.  8.
 23. 29. 22.  6.  6.  6.  0.  0.  1.  8.  0.  8.  6.  8.  3.  3.  0.  0.
 22.  0.  3.  3.  6. 10.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  7.  9.] 
adversary cards in hand: [ 0. 25.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22] -> size -> 38 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[107.69168 ]
 [108.445816]
 [104.63205 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  1. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  3.  7.  9.] 
adversary cards in hand: [ 3.  6.  0.  4. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3] -> size -> 52 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1
Learning step: 2.923269271850586
desired expected reward: 33.85488510131836



action possibilites: [-1] 
expected returns: [[66.64311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  1.] 
cards in discard: [10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  2.  7.  9.] 
adversary cards in hand: [ 3.  6.  0.  4. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3] -> size -> 52 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0 20  0  0  0  0 -4  0  0  9  0] 
sum of rewards: 66 

action type: gain_card_n - action 8
Learning step: -0.18437805771827698
desired expected reward: 99.4925765991211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[60.426254]
 [65.33024 ]
 [63.964344]
 [62.34167 ]
 [69.106   ]
 [64.75134 ]
 [66.19393 ]
 [56.777405]
 [63.496525]
 [62.386898]
 [71.5155  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  1.] 
cards in discard: [10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  2.  7.  9.] 
adversary cards in hand: [ 3.  6.  0.  4. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3] -> size -> 52 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1
Learning step: 1.2300941944122314
desired expected reward: 67.87320709228516






Player: 1 
cards in hand: [ 3.  6.  0.  4. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  4. 11.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  2.  7.  9.] 
adversary cards in hand: [ 3.  6. 25.  0.  0.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10] -> size -> 39 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0.  4. 11.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  2.  7.  9.] 
adversary cards in hand: [ 3.  6. 25.  0.  0.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10] -> size -> 39 
adversary victory points: 6
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 3.  6. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[185.32326]
 [187.76282]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 25.  0.  0.] 
cards in discard: [10. 11.  0. 25.  0.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  2.  7.  9.] 
adversary cards in hand: [ 6.  3.  0.  3. 11.] 
adversary cards in discard: [ 3.  6.  0.  4. 11.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3] -> size -> 52 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1.0
Learning step: 2.6827213764190674
desired expected reward: 74.19822692871094



action possibilites: [-1] 
expected returns: [[97.85462]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 0. 0.] 
cards in discard: [10. 11.  0. 25.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  2.  7.  9.] 
adversary cards in hand: [ 6.  3.  0.  3. 11.] 
adversary cards in discard: [ 3.  6.  0.  4. 11.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3] -> size -> 52 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 63 

action type: take_action - action 25.0
Learning step: -4.036412715911865
desired expected reward: 183.72642517089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[78.56573 ]
 [86.039536]
 [84.53501 ]
 [81.59728 ]
 [92.40095 ]
 [84.99315 ]
 [87.53443 ]
 [73.61918 ]
 [83.684265]
 [82.072205]
 [97.05503 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0. 0.] 
cards in discard: [10. 11.  0. 25.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  2.  7.  9.] 
adversary cards in hand: [ 6.  3.  0.  3. 11.] 
adversary cards in discard: [ 3.  6.  0.  4. 11.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3] -> size -> 52 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1
Learning step: 0.1777351349592209
desired expected reward: 98.03235626220703



buy possibilites: [-1] 
expected returns: [[139.65073]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0. 0.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  2.  7.  8.] 
adversary cards in hand: [ 6.  3.  0.  3. 11.] 
adversary cards in discard: [ 3.  6.  0.  4. 11.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3] -> size -> 52 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0 20  0  0  0  0 -5  0  0 32  0] 
sum of rewards: 88 

action type: buy - action 15.0
Learning step: 3.4385316371917725
desired expected reward: 85.51073455810547






Player: 1 
cards in hand: [ 6.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  3. 11.] 
cards in discard: [ 3.  6.  0.  4. 11.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  6.  5.  6.  8.  9.  8.  2.  7.  8.] 
adversary cards in hand: [ 0. 23. 16.  1.  0.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15] -> size -> 40 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3.] 
cards in discard: [ 3.  6.  0.  4. 11. 11.] 
cards in deck: 42 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  5.  5.  6.  8.  9.  8.  2.  7.  8.] 
adversary cards in hand: [ 0. 23. 16.  1.  0.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15] -> size -> 40 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3.] 
cards in discard: [ 3.  6.  0.  4. 11. 11.] 
cards in deck: 42 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  5.  5.  6.  8.  9.  8.  2.  7.  8.] 
adversary cards in hand: [ 0. 23. 16.  1.  0.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15] -> size -> 40 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 0. 23. 16.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 16.] 
expected returns: [[137.34204 ]
 [124.393524]
 [127.3244  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23. 16.  1.  0.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  5.  5.  6.  8.  9.  8.  2.  7.  8.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11] -> size -> 53 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1
Learning step: -1.9438027143478394
desired expected reward: 137.70692443847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[119.55389]
 [125.10846]
 [123.55373]
 [121.73901]
 [129.27065]
 [124.42128]
 [125.94591]
 [115.37064]
 [122.98212]
 [121.65917]
 [131.8366 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23. 16.  1.  0.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 29. 19. 29.  8.  0.  6.  5.  5.  6.  8.  9.  8.  2.  7.  8.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11] -> size -> 53 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: -1.9577255249023438
desired expected reward: 135.38430786132812



buy possibilites: [-1] 
expected returns: [[124.485565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23. 16.  1.  0.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  8.  2.  7.  8.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11] -> size -> 53 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0 -6  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 16.0
Learning step: 0.0639747604727745
desired expected reward: 121.802978515625






Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  8.  2.  7.  8.] 
adversary cards in hand: [ 0.  0. 16.  3.  1.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11] -> size -> 53 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  8.  2.  7.  8.] 
adversary cards in hand: [ 0.  0. 16.  3.  1.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11 15] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  8.  2.  7.  7.] 
adversary cards in hand: [ 0.  0. 16.  3.  1.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 16.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[27.011072]
 [21.054247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  1.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  8.  2.  7.  7.] 
adversary cards in hand: [ 8.  1. 22.  0. 10.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11 15] -> size -> 54 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1
Learning step: -3.606004476547241
desired expected reward: 120.87956237792969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.595512]
 [26.528513]
 [25.667507]
 [24.70377 ]
 [28.865635]
 [26.228155]
 [27.155678]
 [21.588009]
 [25.441702]
 [24.831417]
 [30.345976]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  1.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  8.  2.  7.  7.] 
adversary cards in hand: [ 8.  1. 22.  0. 10.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11 15] -> size -> 54 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: 1.3233675956726074
desired expected reward: 28.334440231323242



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  1. 22.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 22.  0. 10.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11 15] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  8.  2.  7.  7.] 
adversary cards in hand: [10.  3. 25.  3. 25.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 22.  0.  1.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11 15] -> size -> 54 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  8.  2.  7.  7.] 
adversary cards in hand: [10.  3. 25.  3. 25.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 22.  0.  1.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11 15] -> size -> 54 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  8.  2.  7.  7.] 
adversary cards in hand: [10.  3. 25.  3. 25.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 22.  0.  1.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11 15 23] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  7.  2.  7.  7.] 
adversary cards in hand: [10.  3. 25.  3. 25.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [10.  3. 25.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 25.] 
expected returns: [[-4.803185 ]
 [-4.656595 ]
 [-6.4292254]
 [-6.4292254]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 25.  3. 25.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11 15 23] -> size -> 55 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1.0
Learning step: 0.41569527983665466
desired expected reward: 30.761667251586914



action possibilites: [-1. 25. 25.] 
expected returns: [[21.133793]
 [21.380672]
 [21.380672]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3. 25.  0.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11 15 23] -> size -> 55 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 62 

action type: take_action - action 10.0
Learning step: 3.8009860515594482
desired expected reward: -0.8556063175201416



action possibilites: [-1. 25.] 
expected returns: [[-6.276482]
 [-7.35003 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.  0.  3.  3.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11 15 23] -> size -> 55 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action 25.0
Learning step: 2.832631826400757
desired expected reward: 24.213289260864258





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.9312897]
 [-6.276482 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25.  0.  3.  3.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11 15 23] -> size -> 55 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1.0
Learning step: 4.228082656860352
desired expected reward: -2.048400402069092



buy possibilites: [-1] 
expected returns: [[-1.1416092]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25.  0.  3.  3.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.] 
adversary owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11 15 23] -> size -> 55 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  40.   0.   0.  40. -30.   0.   0.   0.  -7.   0.   0.
   0.   0.] 
sum of rewards: 44.0 

action type: buy - action 0.0
Learning step: 2.4708783626556396
desired expected reward: -3.460411310195923






Player: 1 
cards in hand: [ 0.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 10  0  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6
  1  6  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16
 23  0  3  3 11 15 23] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 1.  3.  2. 10. 29.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.  0. 10. 25.  3.  3. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0] -> size -> 42 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 1.  3.  2. 10. 29.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.  0. 10. 25.  3.  3. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0] -> size -> 42 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 1.  3.  2. 10. 29.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.  0. 10. 25.  3.  3. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0] -> size -> 42 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 1.  3.  2. 10. 29.] 
adversary cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.  0. 10. 25.  3.  3. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0] -> size -> 42 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  2. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[-5.6245756]
 [-7.6964684]
 [-7.866478 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  2. 10. 29.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.  0. 10. 25.  3.  3. 25.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 6.  1. 10. 15. 29.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10.] 
adversary owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0] -> size -> 54 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1
Learning step: 1.9614696502685547
desired expected reward: 0.8198604583740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-8.101749 ]
 [-8.408206 ]
 [-7.729819 ]
 [-6.5876575]
 [-8.260941 ]
 [-7.076978 ]
 [-8.4307   ]
 [-7.2355604]
 [-7.866478 ]
 [-6.804264 ]
 [-7.3009067]
 [-7.696468 ]
 [-6.267846 ]
 [-7.498427 ]
 [-5.6245756]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  2. 10. 29.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.  0. 10. 25.  3.  3. 25.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  8.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 6.  1. 10. 15. 29.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10.] 
adversary owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0] -> size -> 54 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: 2.181241750717163
desired expected reward: -3.4433348178863525



buy possibilites: [-1] 
expected returns: [[93.562675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  2. 10. 29.] 
cards in discard: [10. 11.  0. 25.  0.  1. 15. 25.  3.  6.  0.  0.  0.  0. 16.  0. 23. 16.
  1.  0.  0.  0. 16.  3.  1.  0. 10. 25.  3.  3. 25.  0.  3.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 6.  1. 10. 15. 29.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10.] 
adversary owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0] -> size -> 54 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5.  0.  6. 40.  0.  0.  0.  0.  0.  0.  0. -8.  0.  0.  8.  0.] 
sum of rewards: 41.0 

action type: buy - action 29.0
Learning step: 4.5484843254089355
desired expected reward: -3.3179945945739746






Player: 1 
cards in hand: [ 6.  1. 10. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 10. 15. 29.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [10.  0.  0. 10. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29] -> size -> 43 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 10. 29.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [10.  0.  0. 10. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29] -> size -> 43 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 10. 29.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [10.  0.  0. 10. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29] -> size -> 43 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 10. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 22.] 
expected returns: [[49.31774 ]
 [44.12948 ]
 [44.12948 ]
 [38.296257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10. 22.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [6. 6. 1. 3. 6.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.] 
adversary owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0] -> size -> 54 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1
Learning step: -1.5893853902816772
desired expected reward: 91.9732894897461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[40.199547]
 [42.26969 ]
 [42.930115]
 [46.685913]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10. 22.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [6. 6. 1. 3. 6.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.] 
adversary owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0] -> size -> 54 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: 0.5859764218330383
desired expected reward: 49.903717041015625



buy possibilites: [-1] 
expected returns: [[144.94907]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10. 22.] 
cards in discard: [0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [6. 6. 1. 3. 6.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.] 
adversary owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0] -> size -> 54 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  40.   0.   0.   0. -30.   0.   0.   0.  -9.   0.   0.
   0.   0.] 
sum of rewards: 2.0 

action type: buy - action 0.0
Learning step: 1.351375937461853
desired expected reward: 41.55093765258789






Player: 1 
cards in hand: [6. 6. 1. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 1. 3. 6.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [23.  1.  3.  0.  2.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0] -> size -> 44 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 1. 3. 6.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [23.  1.  3.  0.  2.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0] -> size -> 44 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 1. 3. 6.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [23.  1.  3.  0.  2.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0] -> size -> 44 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [23.  1.  3.  0.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[68.39291 ]
 [56.501694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  1.  3.  0.  2.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 3.  0.  8.  0. 23.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.] 
adversary owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0  0] -> size -> 55 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1
Learning step: -3.7374141216278076
desired expected reward: 141.21165466308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[55.954597]
 [60.22387 ]
 [54.570564]
 [59.773125]
 [50.735565]
 [57.746574]
 [64.55174 ]
 [59.54223 ]
 [67.924446]
 [61.427757]
 [53.283485]
 [56.477867]
 [59.238586]
 [51.27529 ]
 [58.486053]
 [68.62382 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  1.  3.  0.  2.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 8. 22. 29. 19. 29.  8.  0.  5.  5.  5.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 3.  0.  8.  0. 23.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.] 
adversary owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0  0] -> size -> 55 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: 0.043389130383729935
desired expected reward: 68.4363021850586



buy possibilites: [-1] 
expected returns: [[94.43437]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  1.  3.  0.  2.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 8. 22. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 3.  0.  8.  0. 23.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.] 
adversary owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0  0] -> size -> 55 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  40.   0.   0.   0.   0.   0.   0.   0. -10.   0.   0.
   2.   0.] 
sum of rewards: 33.0 

action type: buy - action 8.0
Learning step: 0.7976616024971008
desired expected reward: 60.33989715576172






Player: 1 
cards in hand: [ 3.  0.  8.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  0. 23.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10  1  0 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6
  8  1  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0
  3  3 11 15 23  0  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 3. 10.  3.  0. 25.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 3. 10.  3.  0. 25.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 22. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 3. 10.  3.  0. 25.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 22. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 3. 10.  3.  0. 25.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[25.038605]
 [18.24026 ]
 [25.592428]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0. 25.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 8.  8.  0. 14. 22.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.  8.  0. 23.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0] -> size -> 54 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -1.6308168172836304
desired expected reward: 92.80355834960938



action possibilites: [-1] 
expected returns: [[37.741287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0. 29. 25.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 8.  8.  0. 14. 22.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.  8.  0. 23.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0] -> size -> 54 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action 25.0
Learning step: 3.1195571422576904
desired expected reward: 28.71199607849121





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[29.290236]
 [37.622787]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0. 29. 25.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 22. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 8.  8.  0. 14. 22.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.  8.  0. 23.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0] -> size -> 54 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1
Learning step: 2.4542298316955566
desired expected reward: 40.195518493652344






Player: 1 
cards in hand: [ 8.  8.  0. 14. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14. 22.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 14. 22.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.  8.  0. 23.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 22.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.  8.  0. 23.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 22. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  0. 22.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.  8.  0. 23.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 22. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  0. 22.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.  8.  0. 23.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 21. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[80.89486]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 3. 16.  6.  3.  3.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.  8.  0. 23.  1. 14.  8.  8.  0. 22.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0  1] -> size -> 55 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: discard_down_to_3_cards - action 1
Learning step: 2.1359071731567383
desired expected reward: 46.82044219970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[59.44054 ]
 [65.025406]
 [63.46301 ]
 [69.29304 ]
 [64.333534]
 [62.898853]
 [72.006935]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 21. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  2.  7.  7.] 
adversary cards in hand: [ 3. 16.  6.  3.  3.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.  8.  0. 23.  1. 14.  8.  8.  0. 22.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0  1] -> size -> 55 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: 0.03531188890337944
desired expected reward: 80.93016815185547



buy possibilites: [-1] 
expected returns: [[58.685547]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 21. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  1.  7.  7.] 
adversary cards in hand: [ 3. 16.  6.  3.  3.] 
adversary cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.  8.  0. 23.  1. 14.  8.  8.  0. 22.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0  1] -> size -> 55 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  50   0   0   0   0   0   0   0 -11   0   0  18   0] 
sum of rewards: 58 

action type: buy - action 10.0
Learning step: 1.0754820108413696
desired expected reward: 63.974334716796875






Player: 1 
cards in hand: [ 3. 16.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.  3.  3.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.  8.  0. 23.  1. 14.  8.  8.  0. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0  1] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  1.  7.  7.] 
adversary cards in hand: [ 0.  3.  0.  1. 10.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10] -> size -> 46 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  6.  3.  3.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.  8.  0. 23.  1. 14.  8.  8.  0. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0  1] -> size -> 55 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 21. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  1.  7.  7.] 
adversary cards in hand: [ 0.  3.  0.  1. 10.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10] -> size -> 46 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  6.  3.  3.] 
cards in discard: [ 3.  6.  0.  4. 11. 11. 11.  6.  3.  0.  3. 15.  0.  0.  0.  0.  6. 23.
 10.  8.  1. 22.  0.  1.  0.  8.  0. 10. 15.  6.  1. 10. 29.  0.  6.  6.
  1.  3.  6.  0.  8.  0. 23.  1. 14.  8.  8.  0. 22.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0  1  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  1.  7.  7.] 
adversary cards in hand: [ 0.  3.  0.  1. 10.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10] -> size -> 46 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-5.010338]
 [-5.468732]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  1. 10.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  1.  7.  7.] 
adversary cards in hand: [23.  0. 16.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0  1  0] -> size -> 56 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -0.5000476837158203
desired expected reward: 58.18550109863281



action possibilites: [-1. 16.] 
expected returns: [[-4.937454 ]
 [-5.8605185]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  1. 16.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25
 25 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 21. 29. 19. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  1.  7.  7.] 
adversary cards in hand: [23.  0. 16.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0  1  0] -> size -> 56 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action 10.0
Learning step: 3.7062270641326904
desired expected reward: -1.7625048160552979



action possibilites: [-1.] 
expected returns: [[66.42199]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25 25
 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 29. 18. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  1.  7.  7.] 
adversary cards in hand: [23.  0. 16.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0  1  0] -> size -> 56 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   7  60   0   0  40   0   0   0   0 -11   0   0   4   0] 
sum of rewards: 95 

action type: gain_card_n - action 1
Learning step: 2.5029923915863037
desired expected reward: 77.33303833007812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[63.13351 ]
 [65.017944]
 [64.13862 ]
 [66.101395]
 [64.89777 ]
 [64.04296 ]
 [66.42199 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25 25
 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 21. 29. 18. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  1.  7.  7.] 
adversary cards in hand: [23.  0. 16.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0  1  0] -> size -> 56 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 102 

action type: take_action - action -1.0
Learning step: 3.252190113067627
desired expected reward: 69.67417907714844






Player: 1 
cards in hand: [23.  0. 16.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 16.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0. 16.  3.  6.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0  1  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 29. 18. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  1.  7.  7.] 
adversary cards in hand: [15.  6. 16. 29. 16.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25 25
 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3] -> size -> 46 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 50 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  6  8 11  6  3  6  1  6  8  1
  6  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3
 11 15 23  0  0  0  1  0] -> size -> 56 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 6. 21. 29. 18. 29.  8.  0.  5.  5.  4.  6.  7.  9.  7.  1.  7.  7.] 
adversary cards in hand: [15.  6. 16. 29. 16.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25 25
 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3] -> size -> 46 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 50 
card top of deck: [] 
played cards: [23. 16.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8] -> size -> 56 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 21. 29. 18. 29.  8.  0.  5.  5.  3.  6.  7.  9.  7.  1.  7.  7.] 
adversary cards in hand: [15.  6. 16. 29. 16.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25 25
 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3] -> size -> 46 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 50 
card top of deck: [] 
played cards: [23. 16.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8] -> size -> 56 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 6. 21. 29. 18. 29.  8.  0.  5.  5.  3.  6.  7.  9.  7.  1.  7.  7.] 
adversary cards in hand: [15.  6. 16. 29. 16.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25 25
 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3] -> size -> 46 
adversary victory points: 7
player victory points: 2 


buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 10.] 
cards in deck: 50 
card top of deck: [] 
played cards: [23. 16.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10] -> size -> 57 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 21. 29. 18. 29.  8.  0.  5.  5.  3.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [15.  6. 16. 29. 16.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25 25
 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3] -> size -> 46 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 10.  0.] 
cards in deck: 50 
card top of deck: [] 
played cards: [23. 16.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 18. 29.  8.  0.  5.  5.  3.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [15.  6. 16. 29. 16.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25 25
 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3] -> size -> 46 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [15.  6. 16. 29. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 29. 16.] 
expected returns: [[-14.5263  ]
 [-14.826076]
 [-15.895258]
 [-15.400833]
 [-15.895258]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6. 16. 29. 16.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 29 25 10 25 25
 23  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 18. 29.  8.  0.  5.  5.  3.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [ 0.  1. 11.  0.  0.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0] -> size -> 58 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: buy - action -1.0
Learning step: -1.0583114624023438
desired expected reward: 65.36367797851562



action possibilites: [-1] 
expected returns: [[-6.6177444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6. 16.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.  2.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  5.  3.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [ 0.  1. 11.  0.  0.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0] -> size -> 58 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[  -5    0    7   50    0    0   20    0    0 1700    0  -11    0    0
   36    0] 
sum of rewards: 1797 

action type: gain_card_n - action 2
Learning step: 88.95980072021484
desired expected reward: 103.7857894897461





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-7.032093 ]
 [-6.6177454]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6. 16.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.  2.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2] -> size -> 46 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  5.  3.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [ 0.  1. 11.  0.  0.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0] -> size -> 58 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1
Learning step: 3.7792422771453857
desired expected reward: -2.8385021686553955






Player: 1 
cards in hand: [ 0.  1. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  0.  0.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  5.  3.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.  2. 16. 15.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2] -> size -> 46 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.] 
cards in deck: 45 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  4.  3.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.  2. 16. 15.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2] -> size -> 46 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.] 
cards in deck: 45 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11] -> size -> 59 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  4.  3.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.  2. 16. 15.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2] -> size -> 46 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8.] 
cards in deck: 45 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8] -> size -> 60 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  4.  2.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.  2. 16. 15.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2] -> size -> 46 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[9.973907]
 [7.456978]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.  3.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.  2. 16. 15.  6. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  4.  2.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [ 0.  6.  6. 10. 11.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8] -> size -> 60 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: buy - action -1.0
Learning step: 3.1386208534240723
desired expected reward: -3.479123592376709



action possibilites: [-1] 
expected returns: [[55.331886]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0. 1.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.  2. 16. 15.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  4.  2.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [ 0.  6.  6. 10. 11.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8] -> size -> 60 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0 20  0  0  0  0  0  0  0  0  3] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 4.602519512176514
desired expected reward: 12.059537887573242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[51.04958 ]
 [52.473454]
 [50.67879 ]
 [52.500107]
 [49.38941 ]
 [51.66036 ]
 [54.08042 ]
 [52.224354]
 [54.867027]
 [52.984383]
 [50.295612]
 [51.450184]
 [49.674767]
 [52.10513 ]
 [55.3319  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0. 1.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.  2. 16. 15.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2] -> size -> 46 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  4.  2.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [ 0.  6.  6. 10. 11.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8] -> size -> 60 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1
Learning step: 2.0348896980285645
desired expected reward: 57.36677551269531



buy possibilites: [-1] 
expected returns: [[5.839702]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0. 1.] 
cards in discard: [ 0. 10.  0.  0. 10. 22.  8. 23.  1.  3.  0.  2. 25.  3. 10.  3.  0. 29.
 25. 11.  3. 10.  0.  0.  0.  3. 10. 16.  3.  0.  1.  2. 16. 15.  6. 16.
 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [ 0.  6.  6. 10. 11.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8] -> size -> 60 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5.    0.    7.   50.    0.    0.   20.    0.    0.    0.    0.  -12.
   0.    0.    4.5   0. ] 
sum of rewards: 64.5 

action type: buy - action 11.0
Learning step: 0.6523729562759399
desired expected reward: 54.732784271240234






Player: 1 
cards in hand: [ 0.  6.  6. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 10. 11.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  9.  7.  0.  7.  7.] 
adversary cards in hand: [25. 29.  3.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2 11] -> size -> 47 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 10.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  8.  7.  0.  7.  7.] 
adversary cards in hand: [25. 29.  3.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2 11] -> size -> 47 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 10.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14] -> size -> 61 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  8.  7.  0.  7.  7.] 
adversary cards in hand: [25. 29.  3.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2 11] -> size -> 47 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [25. 29.  3.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[52.12729 ]
 [53.158978]
 [48.296906]
 [53.158978]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  3.  1. 25.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  8.  7.  0.  7.  7.] 
adversary cards in hand: [ 1. 11.  1.  0.  1.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14] -> size -> 61 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: buy - action -1
Learning step: 3.4845635890960693
desired expected reward: 9.324265480041504



action possibilites: [-1] 
expected returns: [[129.1035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1. 25.  3. 23.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  8.  7.  0.  7.  7.] 
adversary cards in hand: [ 1. 11.  1.  0.  1.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14] -> size -> 61 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action 25.0
Learning step: 3.846879720687866
desired expected reward: 57.005859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[120.608665]
 [124.76157 ]
 [124.826645]
 [133.64122 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1. 25.  3. 23.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  8.  7.  0.  7.  7.] 
adversary cards in hand: [ 1. 11.  1.  0.  1.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14] -> size -> 61 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1
Learning step: 0.049941252917051315
desired expected reward: 129.1534423828125



buy possibilites: [-1] 
expected returns: [[94.75468]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1. 25.  3. 23.] 
cards in discard: [0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2 11  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  8.  7.  0.  7.  7.] 
adversary cards in hand: [ 1. 11.  1.  0.  1.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14] -> size -> 61 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7.  50.   0.   0.  20. -30.   0.   0.   0. -13.   0.   0.
   0.   0.] 
sum of rewards: 29.0 

action type: buy - action 0.0
Learning step: -2.448453187942505
desired expected reward: 118.16020965576172






Player: 1 
cards in hand: [ 1. 11.  1.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  1.  0.  1.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  8.  7.  0.  7.  7.] 
adversary cards in hand: [ 3.  3.  8. 16.  0.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2 11  0] -> size -> 48 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 1.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  7.  7.  0.  7.  7.] 
adversary cards in hand: [ 3.  3.  8. 16.  0.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2 11  0] -> size -> 48 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 1.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14] -> size -> 62 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  7.  7.  0.  7.  7.] 
adversary cards in hand: [ 3.  3.  8. 16.  0.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2 11  0] -> size -> 48 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 1.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22] -> size -> 63 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  7.  7.  0.  6.  7.] 
adversary cards in hand: [ 3.  3.  8. 16.  0.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2 11  0] -> size -> 48 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  8. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[13.081812 ]
 [ 7.275844 ]
 [ 6.2899613]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 16.  0.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0  8 10  3  2 11  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  7.  7.  0.  6.  7.] 
adversary cards in hand: [ 0.  0.  3. 23.  8.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22] -> size -> 63 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: buy - action -1
Learning step: -1.8990490436553955
desired expected reward: 92.85562896728516



action possibilites: [-1] 
expected returns: [[72.17325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14.] 
cards in deck: 35 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 0.  0.  3. 23.  8.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22] -> size -> 63 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   7  50   0   0  20   0   0   0   0 -13   0   0  16   0] 
sum of rewards: 75 

action type: gain_card_n - action 7
Learning step: 3.154930830001831
desired expected reward: 47.534278869628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[62.960373]
 [74.39056 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14.] 
cards in deck: 35 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 0.  0.  3. 23.  8.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22] -> size -> 63 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1
Learning step: 1.5893791913986206
desired expected reward: 73.76262664794922






Player: 1 
cards in hand: [ 0.  0.  3. 23.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 23.  8.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  6.  7.  0.  6.  7.] 
adversary cards in hand: [25.  0.  0.  0. 11.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14] -> size -> 48 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 23.  8.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22] -> size -> 63 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  6.  7.  0.  6.  7.] 
adversary cards in hand: [25.  0.  0.  0. 11.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14] -> size -> 48 
adversary victory points: 7
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[17.803698]
 [17.562706]
 [16.064205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0. 11.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 6.  8.  3. 15.  0.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22] -> size -> 63 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: buy - action -1.0
Learning step: -0.7276937365531921
desired expected reward: 73.66285705566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[11.842535 ]
 [14.467743 ]
 [14.1478405]
 [16.63943  ]
 [14.059748 ]
 [18.378923 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0. 11.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 6.  8.  3. 15.  0.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22] -> size -> 63 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: take_action - action -1.0
Learning step: 2.077533721923828
desired expected reward: 19.881223678588867



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  8.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  3. 15.  0.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14] -> size -> 48 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  3. 15.  0.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22] -> size -> 63 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14] -> size -> 48 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  3. 15.  0.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0] -> size -> 64 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14] -> size -> 48 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-6.380805 ]
 [-7.7420063]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  6.  7.  0.  6.  7.] 
adversary cards in hand: [6. 0. 6. 0. 3.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0] -> size -> 64 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: buy - action -1.0
Learning step: 1.528465747833252
desired expected reward: 19.907377243041992



action possibilites: [-1.] 
expected returns: [[-5.5674233]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 1.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  6.  7.  0.  6.  7.] 
adversary cards in hand: [6. 0. 6. 0. 3.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0] -> size -> 64 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 74 

action type: take_action - action 10.0
Learning step: 3.9618332386016846
desired expected reward: -3.7801730632781982





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[-6.100392 ]
 [-6.497037 ]
 [-5.8407316]
 [-5.671337 ]
 [-6.1978493]
 [-6.0962887]
 [-6.4540844]
 [-6.7513876]
 [-6.2162714]
 [-5.451291 ]
 [-5.3967924]
 [-5.348274 ]
 [-5.592806 ]
 [-5.438316 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 1.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  7.  6.  7.  0.  6.  7.] 
adversary cards in hand: [6. 0. 6. 0. 3.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0] -> size -> 64 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1.0
Learning step: 3.750293731689453
desired expected reward: -1.8171296119689941



buy possibilites: [-1] 
expected returns: [[35.799572]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 1.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [6. 0. 6. 0. 3.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0] -> size -> 64 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7.  50.   0.   0.  20.   0.   0.   0.   0. -14.   0.   0.
   8.   0.] 
sum of rewards: 66.0 

action type: buy - action 29.0
Learning step: 4.385616302490234
desired expected reward: -1.2169113159179688






Player: 1 
cards in hand: [6. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 3.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [25. 16.  0.  3.  1.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29] -> size -> 49 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 3.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0] -> size -> 64 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [25. 16.  0.  3.  1.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29] -> size -> 49 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 3.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 65 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [25. 16.  0.  3.  1.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29] -> size -> 49 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [25. 16.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16.] 
expected returns: [[48.05292 ]
 [48.318348]
 [44.079967]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 16.  0.  3.  1.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 6.  8.  3. 10. 22.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 65 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: buy - action -1
Learning step: 1.8772867918014526
desired expected reward: 37.676856994628906



action possibilites: [-1] 
expected returns: [[78.41581]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  1.  3. 10.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 6.  8.  3. 10. 22.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 65 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action 25.0
Learning step: 2.948437452316284
desired expected reward: 51.26679611206055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[71.42927 ]
 [73.764114]
 [73.60813 ]
 [76.19917 ]
 [73.36418 ]
 [78.415825]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  1.  3. 10.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  3.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 6.  8.  3. 10. 22.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 65 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1
Learning step: 1.3911819458007812
desired expected reward: 79.80699157714844



buy possibilites: [-1] 
expected returns: [[55.006927]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  1.  3. 10.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 6.  8.  3. 10. 22.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 65 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   7  50   0   0  20   0   0   0   0 -15   0   0  18   0] 
sum of rewards: 75 

action type: buy - action 11.0
Learning step: 1.1776974201202393
desired expected reward: 77.37686157226562






Player: 1 
cards in hand: [ 6.  8.  3. 10. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  3. 10. 22.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 1.  2. 10. 10.  3.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11] -> size -> 50 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  3. 10.  0.  0. 14.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 1.  2. 10. 10.  3.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11] -> size -> 50 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  3. 10.  0.  0. 14.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 65 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [ 1.  2. 10. 10.  3.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11] -> size -> 50 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [ 1.  2. 10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-7.3337517]
 [-8.133135 ]
 [-8.133135 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  2. 10. 10.  3.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [22.  8.  6. 15.  4.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 65 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: buy - action -1
Learning step: -0.3224189877510071
desired expected reward: 54.68450927734375



action possibilites: [-1. 10.] 
expected returns: [[-7.5506926]
 [-8.780793 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  2. 10.  3.  0.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11] -> size -> 50 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [22.  8.  6. 15.  4.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 65 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 73 

action type: take_action - action 10.0
Learning step: 3.8786144256591797
desired expected reward: -4.254520416259766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[-8.739881 ]
 [-9.899922 ]
 [-8.121573 ]
 [-8.949851 ]
 [-6.94703  ]
 [-9.184462 ]
 [-8.811077 ]
 [-9.806198 ]
 [-8.08563  ]
 [-9.496045 ]
 [-7.452854 ]
 [-7.7942467]
 [-6.566332 ]
 [-8.274426 ]
 [-7.5506916]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  2. 10.  3.  0.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11] -> size -> 50 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  6.  7.] 
adversary cards in hand: [22.  8.  6. 15.  4.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 65 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1.0
Learning step: 3.805772542953491
desired expected reward: -3.7449305057525635



buy possibilites: [-1] 
expected returns: [[7.9695425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  2. 10.  3.  0.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [22.  8.  6. 15.  4.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 65 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5.    0.    7.   50.    0.    0.   20.    0.    0.    0.    0.  -16.
   0.    0.   12.5   0. ] 
sum of rewards: 68.5 

action type: buy - action 22.0
Learning step: 3.932631254196167
desired expected reward: -2.6337015628814697






Player: 1 
cards in hand: [22.  8.  6. 15.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  8.  6. 15.  4.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  6  8 11  6  3  6  1  6  8  1  6
  3  6  0  6 14  0  3  3  0  4  8  0  6 29  0  0 22  3 16 23  0  3  3 11
 15 23  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [16. 22.  2. 11.  0.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10. 22. 10.  1.
  2. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22] -> size -> 51 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 15.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  8 11  6  3  6  1  6  8  1  6  3
  6  0  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23
  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [16. 22.  2. 11.  0.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10. 22. 10.  1.
  2. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22] -> size -> 51 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 15.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  8 11  6  3  6  1  6  8  1  6  3
  6  0  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23
  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0] -> size -> 63 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [16. 22.  2. 11.  0.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10. 22. 10.  1.
  2. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22] -> size -> 51 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 15.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  8 11  6  3  6  1  6  8  1  6  3
  6  0  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23
  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0  0] -> size -> 64 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [16. 22.  2. 11.  0.] 
adversary cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10. 22. 10.  1.
  2. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22] -> size -> 51 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [16. 22.  2. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22. 11.] 
expected returns: [[-4.610173 ]
 [-5.970829 ]
 [-5.7921047]
 [-5.305929 ]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 22.  2. 11.  0.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10. 22. 10.  1.
  2. 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [ 3. 10.  1.  6.  8.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.
  0.  8. 22. 15.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  8 11  6  3  6  1  6  8  1  6  3
  6  0  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23
  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0  0] -> size -> 64 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: buy - action -1
Learning step: 3.087064027786255
desired expected reward: 11.05660629272461



action possibilites: [-1] 
expected returns: [[19.951181]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  2. 11.  0.  0.  3.  0.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10. 22. 10.  1.
  2. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [ 3. 10.  1.  6.  8.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.
  0.  8. 22. 15.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  8 11  6  3  6  1  6  8  1  6  3
  6  0  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23
  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0  0] -> size -> 64 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 112 

action type: LIBRARY: skip_action_card - action 0
Learning step: 6.349303722381592
desired expected reward: 0.3412590026855469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[10.034065]
 [13.116686]
 [ 9.393572]
 [13.374249]
 [ 6.231472]
 [11.381693]
 [16.699802]
 [12.566795]
 [18.210144]
 [14.192067]
 [ 8.510945]
 [11.089498]
 [ 7.080741]
 [12.480431]
 [19.951187]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  2. 11.  0.  0.  3.  0.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10. 22. 10.  1.
  2. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22] -> size -> 51 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  2.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [ 3. 10.  1.  6.  8.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.
  0.  8. 22. 15.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  8 11  6  3  6  1  6  8  1  6  3
  6  0  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23
  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0  0] -> size -> 64 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 112 

action type: take_action - action -1
Learning step: 4.949771404266357
desired expected reward: 24.90095329284668



buy possibilites: [-1] 
expected returns: [[0.7067268]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  2. 11.  0.  0.  3.  0.] 
cards in discard: [ 0. 25. 29.  3.  1. 25.  3. 23. 14. 16.  3.  3.  0. 25.  0.  0.  0. 11.
 29. 10.  6.  0.  0.  0.  1. 11. 25. 16.  0.  3.  1.  3. 10. 22. 10.  1.
  2. 10.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22  8] -> size -> 52 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  1.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [ 3. 10.  1.  6.  8.] 
adversary cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.
  0.  8. 22. 15.] 
adversary owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  8 11  6  3  6  1  6  8  1  6  3
  6  0  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23
  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0  0] -> size -> 64 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7.  70.   0.   0.  40.   0.   0.   0.   0. -17.   0.   0.
   2.   0.] 
sum of rewards: 97.0 

action type: buy - action 8.0
Learning step: 4.2375617027282715
desired expected reward: 16.804351806640625






Player: 1 
cards in hand: [ 3. 10.  1.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1.  6.  8.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.
  0.  8. 22. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  1 10 15 11  0 22  1  8  0 10  0  8 11  6  3  6  1  6  8  1  6  3
  6  0  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23
  0  0  0  1  0  8 10  0 11  8 14 14 22  0  0  0] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  1.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [11. 22.  3.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22  8] -> size -> 52 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.
  0.  8. 22. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10 10 15 11  0 22  1  8  0 10  0  8 11  6  6  1  6  8  1  6  3  6  0
  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23  0  0
  0  1  0  8 10  0 11  8 14 14 22  0  0  0] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  1.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [11. 22.  3.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22  8] -> size -> 52 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.] 
cards in discard: [ 8. 10.  0. 23. 16.  0.  3.  0. 11.  8. 11.  0.  1.  0.  0. 14. 11.  0.
  6.  6. 10. 14. 22. 11.  1.  1.  0.  1.  0.  0.  3. 23.  8.  0.  6.  8.
  3. 15.  0.  0.  6.  0.  6.  0.  3. 22. 29.  6.  8.  3. 10.  0.  0. 14.
  0.  8. 22. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10 10 15 11  0 22  1  8  0 10  0  8 11  6  6  1  6  8  1  6  3  6  0
  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23  0  0
  0  1  0  8 10  0 11  8 14 14 22  0  0  0] -> size -> 62 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  1.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [11. 22.  3.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22  8] -> size -> 52 
adversary victory points: 7
player victory points: -1 





         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [11. 22.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22. 15.] 
expected returns: [[105.254364]
 [102.6823  ]
 [ 92.72648 ]
 [ 98.22709 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 22.  3.  0. 15.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22  8] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  1.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [ 0. 23. 14.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 10 15 11  0 22  1  8  0 10  0  8 11  6  6  1  6  8  1  6  3  6  0
  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23  0  0
  0  1  0  8 10  0 11  8 14 14 22  0  0  0] -> size -> 62 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 82 

action type: buy - action -1
Learning step: 6.359570026397705
desired expected reward: 7.066296577453613





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 93.45446]
 [102.32853]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 22.  3.  0. 15.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22  8] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  1.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [ 0. 23. 14.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 10 15 11  0 22  1  8  0 10  0  8 11  6  6  1  6  8  1  6  3  6  0
  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23  0  0
  0  1  0  8 10  0 11  8 14 14 22  0  0  0] -> size -> 62 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 82 

action type: take_action - action -1.0
Learning step: 1.0808662176132202
desired expected reward: 106.3352279663086



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 23. 14.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23. 14.  6.  3.] 
cards in discard: [] 
cards in deck: 57 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 10 15 11  0 22  1  8  0 10  0  8 11  6  6  1  6  8  1  6  3  6  0
  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23  0  0
  0  1  0  8 10  0 11  8 14 14 22  0  0  0] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  1.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [ 0. 14.  1.  3. 22.] 
adversary cards in discard: [11. 22.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22  8] -> size -> 52 
adversary victory points: 7
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  6.  3.] 
cards in discard: [] 
cards in deck: 57 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 10 10 15 11  0 22  1  8  0 10  0  8 11  6  6  1  6  8  1  6  3  6  0
  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23  0  0
  0  1  0  8 10  0 11  8 14 14 22  0  0  0] -> size -> 62 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  1.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [ 0. 14.  3.] 
adversary cards in discard: [11. 22.  3.  0. 15.  1. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22  8] -> size -> 52 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  6.  3.] 
cards in discard: [] 
cards in deck: 57 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 10 10 15 11  0 22  1  8  0 10  0  8 11  6  6  1  6  8  1  6  3  6  0
  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23  0  0
  0  1  0  8 10  0 11  8 14 14 22  0  0  0] -> size -> 62 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  1.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [ 0. 14.  3.] 
adversary cards in discard: [11. 22.  3.  0. 15.  1. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22  8] -> size -> 52 
adversary victory points: 7
player victory points: -1 


Player 0 won the game! 



Player 0 bought cards:
Copper: 8 
Silver: 4 
Gold: 1 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 1 

Remodel: 3 
Workshop: 3 
Chapel: 2 
Witch: 4 
Poacher: 3 
Militia: 0 
Market: 1 
Village: 4 
Library: 2 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 14.  3.] 
cards in discard: [11. 22.  3.  0. 15.  1. 22.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 10  0  3 25  1  1  2  0  1 25 10 25 25 23
  3  0  0 10  3  6 16  3 16 11  1 22 10 15 16  0 29  0 10  3  2 11  0 14
 29 11 22  8] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 21. 28. 18. 29.  8.  0.  5.  2.  0.  6.  6.  6.  7.  0.  5.  7.] 
adversary cards in hand: [ 0. 23.  6.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 8 10 10 15 11  0 22  1  8  0 10  0  8 11  6  6  1  6  8  1  6  3  6  0
  6 14  0  3  3  0  8  0  6 29  0  0 22  3 16 23  0  3  3 11 15 23  0  0
  0  1  0  8 10  0 11  8 14 14 22  0  0  0  8] -> size -> 63 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5 500   7  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 582 

action type: discard_down_to_3_cards - action 9
Learning step: 27.882001876831055
desired expected reward: 52.24201965332031



