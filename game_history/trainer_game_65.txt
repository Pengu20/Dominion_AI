 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[300.46088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -1  -80    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -586 

action type: buy - action -1
Learning step: -29.773284912109375
desired expected reward: -20.307605743408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[276.11325]
 [289.2369 ]
 [285.39417]
 [251.58395]
 [282.12015]
 [298.82645]
 [285.82355]
 [288.65332]
 [263.88297]
 [283.5735 ]
 [278.97604]
 [305.31262]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.842235565185547
desired expected reward: 294.4333801269531



buy possibilites: [-1] 
expected returns: [[272.10962]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -8.16871166229248
desired expected reward: 277.65484619140625






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[304.45877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.7852020263671875
desired expected reward: 265.32440185546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[285.66986]
 [297.9142 ]
 [292.35153]
 [263.3511 ]
 [304.5715 ]
 [295.0833 ]
 [290.39667]
 [307.6111 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.86082935333252
desired expected reward: 298.7071228027344



buy possibilites: [-1] 
expected returns: [[302.9761]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  0.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 10.0
Learning step: -6.902871131896973
desired expected reward: 283.4938049316406






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[301.88583]
 [287.6668 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.59978199005127
desired expected reward: 294.3763122558594



action possibilites: [-1] 
expected returns: [[293.91]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: trash_cards_n_from_hand - action 2
Learning step: -7.741560459136963
desired expected reward: 297.3491516113281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[266.87863]
 [248.53859]
 [287.83698]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -7.712881565093994
desired expected reward: 286.1971130371094






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  3. 10.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  3. 10.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  3. 10.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[311.81082]
 [294.21356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  3. 10.] 
cards in discard: [8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 29.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.656670570373535
desired expected reward: 280.1803283691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[291.1434 ]
 [270.61072]
 [313.4475 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  3. 10.] 
cards in discard: [8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 29.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.050475120544434
desired expected reward: 302.49786376953125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 10.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0. 29.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  3.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16] -> size -> 13 
action values: 2 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [16.  0.  0.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[305.0847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.873517990112305
desired expected reward: 304.57403564453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[287.31662]
 [298.10526]
 [294.23074]
 [267.38187]
 [305.26874]
 [295.48975]
 [292.81223]
 [309.85013]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.773646354675293
desired expected reward: 297.8423156738281



buy possibilites: [-1] 
expected returns: [[318.6328]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 10  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -7.605247497558594
desired expected reward: 287.88446044921875






Player: 1 
cards in hand: [ 0.  0. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10  8] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10  8] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  3.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10  8] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[302.82275]
 [288.18695]
 [285.86426]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 10  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 10.  0.] 
adversary cards in discard: [ 1.  0.  0. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.444190979003906
desired expected reward: 309.1886291503906



action possibilites: [-1.  8.] 
expected returns: [[283.20135]
 [268.55676]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  8 10  8] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 10.  0.] 
adversary cards in discard: [ 1.  0.  0. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 19 

action type: take_action - action 10.0
Learning step: -6.985835552215576
desired expected reward: 278.0060729980469



action possibilites: [-1.] 
expected returns: [[257.50186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  8 10  8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 10.  0.] 
adversary cards in discard: [ 1.  0.  0. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: trash_cards_n_from_hand - action 1
Learning step: -6.564756870269775
desired expected reward: 267.606201171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[230.66727]
 [236.892  ]
 [212.01962]
 [237.70958]
 [251.59065]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  8 10  8] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 10.  0.] 
adversary cards in discard: [ 1.  0.  0. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: -6.21350622177124
desired expected reward: 251.28836059570312



buy possibilites: [-1] 
expected returns: [[284.53577]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  8 10  8  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 10.  0.] 
adversary cards in discard: [ 1.  0.  0. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -3.0 

action type: buy - action 0.0
Learning step: -5.281308174133301
desired expected reward: 225.3859405517578






Player: 1 
cards in hand: [ 3.  0. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 10.  0.] 
cards in discard: [ 1.  0.  0. 16.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 10  8  0] -> size -> 10 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  3.] 
cards in discard: [ 1.  0.  0. 16.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 10  8  0] -> size -> 10 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1.  0.  0. 16.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1] -> size -> 15 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 10  8  0] -> size -> 10 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1.  0.  0. 16.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 10  8  0] -> size -> 10 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1.  0.  0. 16.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 10  8  0] -> size -> 10 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [8. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[311.81766]
 [294.43274]
 [294.43274]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 10  8  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.040510177612305
desired expected reward: 276.4952697753906



action possibilites: [-1] 
expected returns: [[306.43488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8 10  8  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 0
Learning step: -7.173295497894287
desired expected reward: 281.18829345703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[274.7844 ]
 [251.80923]
 [298.08954]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8 10  8  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -8.719395637512207
desired expected reward: 297.7154846191406



buy possibilites: [-1] 
expected returns: [[252.2438]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8 10  8  0  6] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -22.114974975585938
desired expected reward: 229.6942138671875






Player: 1 
cards in hand: [ 0. 10.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [6. 8. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  8 10  8  0  6] -> size -> 10 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [6. 8. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  8 10  8  0  6] -> size -> 10 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [6. 8. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  8 10  8  0  6] -> size -> 10 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[309.01694]
 [292.40958]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [6. 8. 8. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 10  8  0  6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [10.  0.  0. 10.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -7.044014930725098
desired expected reward: 245.1997833251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[285.58093]
 [297.88602]
 [292.6353 ]
 [261.06677]
 [304.35825]
 [295.00888]
 [290.74573]
 [307.3531 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [6. 8. 8. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 10  8  0  6] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [10.  0.  0. 10.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -9.99094009399414
desired expected reward: 298.0509033203125



buy possibilites: [-1] 
expected returns: [[250.76797]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [ 6.  8.  8.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 10  8  0  6 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  9.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [10.  0.  0. 10.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -6 

action type: buy - action 11.0
Learning step: -9.875635147094727
desired expected reward: 294.4826354980469






Player: 1 
cards in hand: [ 3.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  3.] 
cards in discard: [10.  0.  0. 10.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  9.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 10  8  0  6 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  3.] 
cards in discard: [10.  0.  0. 10.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  9.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 10  8  0  6 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  3.] 
cards in discard: [10.  0.  0. 10.  0. 16.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 10  8  0  6 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10.  8.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[221.88503]
 [202.40578]
 [205.01036]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 10  8  0  6 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 29.  0.] 
adversary cards in discard: [10.  0.  0. 10.  0. 16.  8.  3.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -9.039460182189941
desired expected reward: 241.728515625



action possibilites: [-1.  8.] 
expected returns: [[226.75703]
 [211.56325]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  8 10  8  0  6 11] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 29.  0.] 
adversary cards in discard: [10.  0.  0. 10.  0. 16.  8.  3.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -3 

action type: take_action - action 10.0
Learning step: -5.205175399780273
desired expected reward: 194.96075439453125



action possibilites: [-1.] 
expected returns: [[258.9819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  8 10  8  0 11] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 29.  0.] 
adversary cards in discard: [10.  0.  0. 10.  0. 16.  8.  3.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: trash_cards_n_from_hand - action 8
Learning step: -3.8514046669006348
desired expected reward: 209.57180786132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[235.16249]
 [242.25755]
 [215.16705]
 [243.01498]
 [256.94257]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  8 10  8  0 11] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 29.  0.] 
adversary cards in discard: [10.  0.  0. 10.  0. 16.  8.  3.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: -6.729219913482666
desired expected reward: 252.252685546875



buy possibilites: [-1] 
expected returns: [[207.38411]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  8 10  8  0 11  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 29.  0.] 
adversary cards in discard: [10.  0.  0. 10.  0. 16.  8.  3.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  40   0   0   0   0   0   0   0   8   0] 
sum of rewards: 35 

action type: buy - action 3.0
Learning step: -5.6967363357543945
desired expected reward: 236.5608367919922






Player: 1 
cards in hand: [ 3.  1.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 29.  0.] 
cards in discard: [10.  0.  0. 10.  0. 16.  8.  3.  0.  0. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8.  0.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8 10  8  0 11  3] -> size -> 10 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8.  0.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8 10  8  0 11  3] -> size -> 10 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8.  0.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8 10  8  0 11  3] -> size -> 10 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [4.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 29.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8.  0.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8 10  8  0 11  3] -> size -> 10 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[285.68872]
 [281.19003]
 [268.1545 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  8.  0.] 
cards in discard: [ 3. 10.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 10  8  0 11  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [ 4. 29.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -6.253921031951904
desired expected reward: 201.13018798828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[256.9886 ]
 [267.00894]
 [228.8985 ]
 [268.826  ]
 [286.43915]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  8.  0.] 
cards in discard: [ 3. 10.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 10  8  0 11  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 29.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [ 4. 29.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -10.433070182800293
desired expected reward: 274.4007568359375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  0.] 
cards in discard: [ 4. 29.  3.  1.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8 10  8  0 11  3] -> size -> 10 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.  0.] 
cards in discard: [ 4. 29.  3.  1.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 29.  8.  9.  9.  9.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8 10  8  0 11  3] -> size -> 10 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.  0.] 
cards in discard: [ 4. 29.  3.  1.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8.  9.  9.  9.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8 10  8  0 11  3] -> size -> 10 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[232.6059 ]
 [216.38002]
 [216.38002]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 10  8  0 11  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8.  9.  9.  9.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0. 10.] 
adversary cards in discard: [ 4. 29.  3.  1.  0.  0.  0.  8.  0.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -11.447052001953125
desired expected reward: 274.99212646484375



action possibilites: [-1] 
expected returns: [[216.08144]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  8  0 11  3] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8.  9.  9.  9.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0. 10.] 
adversary cards in discard: [ 4. 29.  3.  1.  0.  0.  0.  8.  0.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: trash_cards_n_from_hand - action 5
Learning step: -6.272871017456055
desired expected reward: 193.4211883544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[188.91321]
 [169.34216]
 [209.69969]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  8  0 11  3] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 29.  8.  9.  9.  9.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0. 10.] 
adversary cards in discard: [ 4. 29.  3.  1.  0.  0.  0.  8.  0.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1
Learning step: -7.635339260101318
desired expected reward: 208.4460906982422



buy possibilites: [-1] 
expected returns: [[201.21153]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  8  0 11  3  6] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 29.  8.  8.  9.  9.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0. 10.] 
adversary cards in discard: [ 4. 29.  3.  1.  0.  0.  0.  8.  0.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -334.0 

action type: buy - action 6.0
Learning step: -20.639850616455078
desired expected reward: 148.70233154296875






Player: 1 
cards in hand: [10.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0. 10.] 
cards in discard: [ 4. 29.  3.  1.  0.  0.  0.  8.  0.  3. 29.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8.  8.  9.  9.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 10.  3.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  3 10  8  0 11  3  6] -> size -> 9 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.  8. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10. 16.] 
cards in discard: [ 4. 29.  3.  1.  0.  0.  0.  8.  0.  3. 29.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8.  8.  9.  9.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 10.  3.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  3 10  8  0 11  3  6] -> size -> 9 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 10. 16.] 
cards in discard: [ 4. 29.  3.  1.  0.  0.  0.  8.  0.  3. 29.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 29.  8.  8.  9.  9.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 10.  3.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  3 10  8  0 11  3  6] -> size -> 9 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[239.45496]
 [234.41089]
 [220.6607 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.  3.] 
cards in discard: [6. 8. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  8  0 11  3  6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8.  8.  9.  9.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -7.568780422210693
desired expected reward: 193.6427459716797



action possibilites: [-1] 
expected returns: [[263.4921]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [ 6.  8.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 10  8  0 11  3  6 11] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8.  8.  9.  8.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -25 

action type: gain_card_n - action 5
Learning step: -5.652575969696045
desired expected reward: 200.9703826904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[240.27202]
 [246.73613]
 [218.73828]
 [249.13751]
 [261.85587]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [ 6.  8.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 10  8  0 11  3  6 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 29.  8.  8.  9.  8.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -9.345636367797852
desired expected reward: 254.14645385742188



buy possibilites: [-1] 
expected returns: [[241.46962]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [ 6.  8.  3.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 10  8  0 11  3  6 11  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 29.  8.  8.  9.  8.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -64.0 

action type: buy - action 0.0
Learning step: -9.780532836914062
desired expected reward: 230.491455078125






Player: 1 
cards in hand: [ 0. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 29.  8.  8.  9.  8.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  8  0 11  3  6 11  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 29.  8.  8.  9.  8.  6. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  8  0 11  3  6 11  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 29.  8.  8.  9.  8.  6. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  8  0 11  3  6 11  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[200.71175]
 [182.59769]
 [185.65929]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  8  0 11  3  6 11  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 29.  8.  8.  9.  8.  6. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 29.  3.  1.] 
adversary cards in discard: [10.  0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8 10] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -10.490608215332031
desired expected reward: 230.97900390625



action possibilites: [-1] 
expected returns: [[202.59726]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11  3  6 11  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 29.  8.  8.  9.  8.  6. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 29.  3.  1.] 
adversary cards in discard: [10.  0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8 10] -> size -> 20 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 3
Learning step: -6.425065517425537
desired expected reward: 168.24501037597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[173.6909 ]
 [155.72893]
 [193.07541]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11  3  6 11  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 29. 29.  8.  8.  9.  8.  6. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 29.  3.  1.] 
adversary cards in discard: [10.  0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8 10] -> size -> 20 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -8.406343460083008
desired expected reward: 194.19091796875



buy possibilites: [-1] 
expected returns: [[221.82945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 29.  8.  7.  9.  8.  6. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 29.  3.  1.] 
adversary cards in discard: [10.  0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8 10] -> size -> 20 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -70.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -356.0 

action type: buy - action 6.0
Learning step: -20.595285415649414
desired expected reward: 135.13365173339844






Player: 1 
cards in hand: [ 3.  8. 29.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29.  3.  1.] 
cards in discard: [10.  0. 10.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 29.  8.  7.  9.  8.  6. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6] -> size -> 10 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3.  1. 10.] 
cards in discard: [10.  0. 10.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 10 16 10  1 29  8  4  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 29.  8.  7.  9.  8.  6. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6] -> size -> 10 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [10.  0. 10.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 29.  8.  7.  9.  8.  6. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6] -> size -> 10 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10.  0. 10.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 29.  8.  7.  9.  8.  6. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6] -> size -> 10 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10.  0. 10.  0.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 29.  8.  7.  9.  8.  5. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6] -> size -> 10 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[201.76172]
 [198.54497]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  6.  0.] 
cards in discard: [6. 8. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 29.  8.  7.  9.  8.  5. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  4. 16.] 
adversary cards in discard: [10.  0. 10.  0.  0.  0.  8. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -9.377327919006348
desired expected reward: 212.45211791992188



action possibilites: [-1] 
expected returns: [[192.94974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 6.  8.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 29.  8.  7.  9.  8.  5. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  4. 16.] 
adversary cards in discard: [10.  0. 10.  0.  0.  0.  8. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -20 

action type: gain_card_n - action 8
Learning step: -6.160011291503906
desired expected reward: 183.86758422851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[175.76636]
 [184.83223]
 [180.92827]
 [157.25365]
 [189.87677]
 [182.71333]
 [179.49023]
 [192.3015 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 6.  8.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 29.  8.  7.  9.  8.  5. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  4. 16.] 
adversary cards in discard: [10.  0. 10.  0.  0.  0.  8. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -7.354086399078369
desired expected reward: 185.5956573486328



buy possibilites: [-1] 
expected returns: [[155.55792]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 6.  8.  3.  0. 14.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 29.  8.  7.  9.  8.  5. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  4. 16.] 
adversary cards in discard: [10.  0. 10.  0.  0.  0.  8. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -23.0 

action type: buy - action 3.0
Learning step: -6.696361064910889
desired expected reward: 174.23190307617188






Player: 1 
cards in hand: [ 8.  0.  0.  4. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  4. 16.] 
cards in discard: [10.  0. 10.  0.  0.  0.  8. 29.  8.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 29.  8.  7.  9.  8.  5. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3] -> size -> 12 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  4. 16.] 
cards in discard: [10.  0. 10.  0.  0.  0.  8. 29.  8.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 29.  8.  7.  9.  8.  5. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3] -> size -> 12 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  4. 16.] 
cards in discard: [10.  0. 10.  0.  0.  0.  8. 29.  8.  1.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 29.  8.  7.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3] -> size -> 12 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [14.  3. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 11.] 
expected returns: [[160.67781]
 [133.66035]
 [157.78458]
 [157.78458]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 29.  8.  7.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 4.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8  8] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -6.58089017868042
desired expected reward: 148.97703552246094



action possibilites: [-1] 
expected returns: [[163.03743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0. 11.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 29.  8.  7.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 4.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8  8] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -10 

action type: gain_card_n - action 2
Learning step: -3.701681137084961
desired expected reward: 133.69879150390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[145.26573 ]
 [125.524155]
 [164.04567 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0. 11.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 27. 29.  8.  7.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 4.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8  8] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -5.535247802734375
desired expected reward: 157.50218200683594



buy possibilites: [-1] 
expected returns: [[141.7285]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0. 11.] 
cards in discard: [3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 4.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8  8] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -325.0 

action type: buy - action 6.0
Learning step: -19.337316513061523
desired expected reward: 106.18683624267578






Player: 1 
cards in hand: [ 4.  8. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  8. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [ 3.  6. 11. 14.  3.  0. 11.] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  8. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [ 3.  6. 11. 14.  3.  0. 11.] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  8. 29.  3.  0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [ 3.  6. 11. 14.  3.  0. 11.] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[138.3303 ]
 [127.08852]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 6. 0.] 
cards in discard: [ 3.  6. 11. 14.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 10.  8.] 
adversary cards in discard: [ 0.  4.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -6.33609676361084
desired expected reward: 135.3924102783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[117.6458 ]
 [123.4133 ]
 [ 98.3038 ]
 [124.77164]
 [136.07968]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 6. 0.] 
cards in discard: [ 3.  6. 11. 14.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 10.  8.] 
adversary cards in discard: [ 0.  4.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -6.410774230957031
desired expected reward: 131.7535400390625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0. 29. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 10.  8.] 
cards in discard: [ 0.  4.  8. 29.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3. 14.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  8.  0.] 
cards in discard: [ 0.  4.  8. 29.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 16 10  1 29  8  4  8 10  8  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3. 14.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 0.  4.  8. 29.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  8  4  8 10  8  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3. 14.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 0.  4.  8. 29.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  8  4  8 10  8  8  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3. 14.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 0.  4.  8. 29.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  8  4  8 10  8  8  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3. 14.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11.  3. 14.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[169.61043]
 [166.25209]
 [141.8746 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 14.  6.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [ 0.  4.  8. 29.  3.  0.  0. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  8  4  8 10  8  8  0  0] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -5.4268927574157715
desired expected reward: 130.65280151367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[140.74779]
 [124.10671]
 [158.4741 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 14.  6.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [ 0.  4.  8. 29.  3.  0.  0. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  8  4  8 10  8  8  0  0] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -6.903663158416748
desired expected reward: 150.6754150390625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [ 0.  4.  8. 29.  3.  0.  0. 29.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  8  4  8 10  8  8  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 11.] 
adversary cards in discard: [11.  3. 14.  6.  0.] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  4.  8. 29.  3.  0.  0. 29.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  4  8 10  8  8  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 11.] 
adversary cards in discard: [11.  3. 14.  6.  0.] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  4.  8. 29.  3.  0.  0. 29.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  4  8 10  8  8  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 11.] 
adversary cards in discard: [11.  3. 14.  6.  0.] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  4.  8. 29.  3.  0.  0. 29.  8. 10.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  4  8 10  8  8  0  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 11.] 
adversary cards in discard: [11.  3. 14.  6.  0.] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[113.24811]
 [109.77505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  0. 11.] 
cards in discard: [11.  3. 14.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 4. 29.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  4  8 10  8  8  0  0  1] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -7.679968357086182
desired expected reward: 150.7941436767578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 98.76378]
 [103.62171]
 [ 84.39584]
 [104.33561]
 [114.07644]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  0. 11.] 
cards in discard: [11.  3. 14.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 27. 29.  8.  6.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 4. 29.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  4  8 10  8  8  0  0  1] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -5.553905010223389
desired expected reward: 106.74732208251953



buy possibilites: [-1] 
expected returns: [[63.816162]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  0. 11.] 
cards in discard: [11.  3. 14.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 27. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 4. 29.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  4  8 10  8  8  0  0  1] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -356.0 

action type: buy - action 6.0
Learning step: -20.58392906188965
desired expected reward: 63.811912536621094






Player: 1 
cards in hand: [ 4. 29.  0. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 29.  0. 10. 16.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  4  8 10  8  8  0  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6  6] -> size -> 15 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 29.  0. 10. 16.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  4  8 10  8  8  0  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 27. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6  6] -> size -> 15 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [6. 6. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[120.112724]
 [111.09551 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  3  6 11  0  6 14  3  3  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [ 4. 29.  0. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  4  8 10  8  8  0  0  1] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -3.3749566078186035
desired expected reward: 60.44120407104492



action possibilites: [-1] 
expected returns: [[137.65338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [ 4. 29.  0. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  4  8 10  8  8  0  0  1] -> size -> 18 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: trash_cards_n_from_hand - action 2
Learning step: -4.3861236572265625
desired expected reward: 98.2803726196289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[116.27961]
 [ 98.7917 ]
 [131.99712]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 27. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [ 4. 29.  0. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  4  8 10  8  8  0  0  1] -> size -> 18 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -6.582393169403076
desired expected reward: 131.07098388671875






Player: 1 
cards in hand: [3. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 8. 0.] 
cards in discard: [ 4. 29.  0. 10. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  4  8 10  8  8  0  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [8. 6. 6. 0.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6] -> size -> 14 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 4. 29.  0. 10. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [8. 6. 6. 0.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6] -> size -> 14 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 4. 29.  0. 10. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 27. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [8. 6. 6. 0.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6] -> size -> 14 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[131.19778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [8. 6. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [ 4. 29.  0. 10. 16.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1] -> size -> 17 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -6.993565559387207
desired expected reward: 125.0035629272461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[109.76265 ]
 [115.018364]
 [ 90.69059 ]
 [117.45117 ]
 [126.54098 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [8. 6. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 27. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [ 4. 29.  0. 10. 16.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1] -> size -> 17 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -7.359495639801025
desired expected reward: 124.03121948242188



buy possibilites: [-1] 
expected returns: [[140.25185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [8. 6. 6. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [ 4. 29.  0. 10. 16.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -48 

action type: buy - action 3.0
Learning step: -4.995251655578613
desired expected reward: 110.02310943603516






Player: 1 
cards in hand: [0. 1. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 0. 0.] 
cards in discard: [ 4. 29.  0. 10. 16.  8.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 11. 11. 14.] 
adversary cards in discard: [8. 6. 6. 0. 3. 0. 3. 0. 6. 3.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3] -> size -> 15 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0. 0.] 
cards in discard: [ 4. 29.  0. 10. 16.  8.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 26. 29.  8.  5.  9.  8.  4. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 11. 11. 14.] 
adversary cards in discard: [8. 6. 6. 0. 3. 0. 3. 0. 6. 3.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3] -> size -> 15 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0. 0.] 
cards in discard: [ 4. 29.  0. 10. 16.  8.  3.  0.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 11. 11. 14.] 
adversary cards in discard: [8. 6. 6. 0. 3. 0. 3. 0. 6. 3.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3] -> size -> 15 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 11. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 14.] 
expected returns: [[148.64227]
 [145.06085]
 [145.06085]
 [118.80392]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11. 11. 14.] 
cards in discard: [8. 6. 6. 0. 3. 0. 3. 0. 6. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -6.751853942871094
desired expected reward: 133.5



action possibilites: [-1] 
expected returns: [[96.70556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11. 14.] 
cards in discard: [8. 6. 6. 0. 3. 0. 3. 0. 6. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: gain_card_n - action 0
Learning step: -7.341668128967285
desired expected reward: 117.00919342041016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[84.04767 ]
 [67.984695]
 [98.27502 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11. 14.] 
cards in discard: [8. 6. 6. 0. 3. 0. 3. 0. 6. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -4.714965343475342
desired expected reward: 91.99059295654297



buy possibilites: [-1] 
expected returns: [[80.707054]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11. 14.] 
cards in discard: [8. 6. 6. 0. 3. 0. 3. 0. 6. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -66.0 

action type: buy - action 0.0
Learning step: -5.531271934509277
desired expected reward: 78.5163803100586






Player: 1 
cards in hand: [ 8.  0.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0] -> size -> 17 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0] -> size -> 17 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0] -> size -> 17 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0] -> size -> 17 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[78.79962 ]
 [57.951466]
 [75.76443 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  6. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0. 10.  8.  1.] 
adversary cards in discard: [29.  8.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -5.213659763336182
desired expected reward: 75.49339294433594



action possibilites: [-1] 
expected returns: [[98.561134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0.  8.] 
adversary cards in discard: [29.  8.  0. 10.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action 14.0
Learning step: -2.515868663787842
desired expected reward: 56.15401077270508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[77.48463 ]
 [85.45807 ]
 [82.506996]
 [62.38982 ]
 [90.37061 ]
 [83.50952 ]
 [81.35142 ]
 [92.99886 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0.  8.] 
adversary cards in discard: [29.  8.  0. 10.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -4.851008892059326
desired expected reward: 93.71012878417969



buy possibilites: [-1] 
expected returns: [[94.877045]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 11.] 
cards in discard: [1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0.  8.] 
adversary cards in discard: [29.  8.  0. 10.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -18 

action type: buy - action 1.0
Learning step: -3.03817081451416
desired expected reward: 82.41991424560547






Player: 1 
cards in hand: [16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.] 
cards in discard: [29.  8.  0. 10.  3. 10.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [ 1. 14.  0.  3.  6. 11.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1] -> size -> 18 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.] 
cards in discard: [29.  8.  0. 10.  3. 10.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [ 1. 14.  0.  3.  6. 11.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1] -> size -> 18 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [8. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[113.61892]
 [103.97488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 0.] 
cards in discard: [ 1. 14.  0.  3.  6. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  4. 29.] 
adversary cards in discard: [29.  8.  0. 10.  3. 10.  1. 16.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -5.160594940185547
desired expected reward: 89.71644592285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 95.54971 ]
 [103.782166]
 [100.741394]
 [ 79.79274 ]
 [108.349815]
 [101.66724 ]
 [ 99.26941 ]
 [111.32242 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 0. 0.] 
cards in discard: [ 1. 14.  0.  3.  6. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  4. 29.] 
adversary cards in discard: [29.  8.  0. 10.  3. 10.  1. 16.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -6.027454376220703
desired expected reward: 104.20120239257812



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 25.  0.  4. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  4. 29.] 
cards in discard: [29.  8.  0. 10.  3. 10.  1. 16.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  6.] 
adversary cards in discard: [ 1. 14.  0.  3.  6. 11.  8.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1] -> size -> 18 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  4.  0.] 
cards in discard: [29.  8.  0. 10.  3. 10.  1. 16.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 29.  8.  5.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  6.] 
adversary cards in discard: [ 1. 14.  0.  3.  6. 11.  8.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1] -> size -> 18 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 4. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 29.  8.  4.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  6.] 
adversary cards in discard: [ 1. 14.  0.  3.  6. 11.  8.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6] -> size -> 19 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 27. 30. 26. 29.  8.  4.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  6.] 
adversary cards in discard: [ 1. 14.  0.  3.  6. 11.  8.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6] -> size -> 19 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 27. 30. 25. 29.  8.  4.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  6.] 
adversary cards in discard: [ 1. 14.  0.  3.  6. 11.  8.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[126.27165]
 [121.54392]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  6.] 
cards in discard: [ 1. 14.  0.  3.  6. 11.  8.  6.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 29.  8.  4.  9.  8.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  1. 29. 10.  8.] 
adversary cards in discard: [ 3. 29. 25.  0.  0.  4.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25  3] -> size -> 18 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -70    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -377 

action type: buy - action -1.0
Learning step: -21.740171432495117
desired expected reward: 89.58223724365234



action possibilites: [-1] 
expected returns: [[63.102955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [ 1. 14.  0.  3.  6. 11.  8.  6.  0.  0.  0.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 29.  8.  4.  9.  7.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  1. 29. 10.  8.] 
adversary cards in discard: [ 3. 29. 25.  0.  0.  4.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25  3] -> size -> 18 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -48 

action type: gain_card_n - action 5
Learning step: -5.763070583343506
desired expected reward: 89.89466857910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[48.84391 ]
 [55.38584 ]
 [32.89452 ]
 [55.270313]
 [67.61802 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [ 1. 14.  0.  3.  6. 11.  8.  6.  0.  0.  0.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 25. 29.  8.  4.  9.  7.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  1. 29. 10.  8.] 
adversary cards in discard: [ 3. 29. 25.  0.  0.  4.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25  3] -> size -> 18 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1
Learning step: -4.789834022521973
desired expected reward: 58.3131217956543



buy possibilites: [-1] 
expected returns: [[82.31617]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [ 1. 14.  0.  3.  6. 11.  8.  6.  0.  0.  0.  6. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 25. 29.  8.  4.  9.  7.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  1. 29. 10.  8.] 
adversary cards in discard: [ 3. 29. 25.  0.  0.  4.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25  3] -> size -> 18 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -70.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -87.0 

action type: buy - action 0.0
Learning step: -4.940081596374512
desired expected reward: 43.9038200378418






Player: 1 
cards in hand: [10.  1. 29. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 29. 10.  8.] 
cards in discard: [ 3. 29. 25.  0.  0.  4.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 25. 29.  8.  4.  9.  7.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  8.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0] -> size -> 21 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 29. 10.  8.] 
cards in discard: [ 3. 29. 25.  0.  0.  4.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 25. 29.  8.  4.  9.  7.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  8.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0] -> size -> 21 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 29. 10.  8.] 
cards in discard: [ 3. 29. 25.  0.  0.  4.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  4.  9.  7.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  8.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0] -> size -> 21 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11.  8.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[23.489325]
 [21.24513 ]
 [17.086948]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  4.  9.  7.  4.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 19 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -7.989974498748779
desired expected reward: 74.3261947631836



action possibilites: [-1] 
expected returns: [[54.253414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  4.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 19 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -58 

action type: gain_card_n - action 9
Learning step: -2.7746639251708984
desired expected reward: 19.132648468017578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.562891]
 [17.012087]
 [55.48868 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 24. 29.  8.  4.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 19 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -5.221908092498779
desired expected reward: 49.0315055847168



buy possibilites: [-1] 
expected returns: [[54.298904]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 3.] 
cards in discard: [10.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 24. 29.  8.  3.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 19 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -90.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -378.0 

action type: buy - action 6.0
Learning step: -18.446481704711914
desired expected reward: -1.4343986511230469






Player: 1 
cards in hand: [ 3.  3.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  8. 16.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 16 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  3.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  6. 14.  0.  6.] 
adversary cards in discard: [10.  6. 11.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6] -> size -> 23 
adversary victory points: -3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  3.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  6. 14.  0.  6.] 
adversary cards in discard: [10.  6. 11.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6] -> size -> 23 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 24. 29.  8.  3.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  6. 14.  0.  6.] 
adversary cards in discard: [10.  6. 11.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6] -> size -> 23 
adversary victory points: -3
player victory points: 5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [11.  6. 14.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[27.053696]
 [26.773932]
 [13.451036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 14.  0.  6.] 
cards in discard: [10.  6. 11.  8.  0.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  3.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3. 29.  0. 10.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 17 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: buy - action -1
Learning step: -6.59474515914917
desired expected reward: 47.704158782958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.533289]
 [11.24235 ]
 [28.944113]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 14.  0.  6.] 
cards in discard: [10.  6. 11.  8.  0.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 24. 29.  8.  3.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3. 29.  0. 10.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 17 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: take_action - action -1.0
Learning step: -5.2783203125
desired expected reward: 22.031261444091797



buy possibilites: [-1] 
expected returns: [[-15.48468]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 14.  0.  6.] 
cards in discard: [10.  6. 11.  8.  0.  6.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 24. 29.  8.  2.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3. 29.  0. 10.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 17 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -90.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -399.0 

action type: buy - action 6.0
Learning step: -20.860525131225586
desired expected reward: -9.61816692352295






Player: 1 
cards in hand: [25.  3. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29.  0. 10.] 
cards in discard: [8. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  2.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 11.  1.  0.  0.] 
adversary cards in discard: [10.  6. 11.  8.  0.  6.  3.  6. 11.  6. 14.  0.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 5 


action possibilites: [-1. 25. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29.  0.  1.] 
cards in discard: [8. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 29.  8.  2.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 11.  1.  0.  0.] 
adversary cards in discard: [10.  6. 11.  8.  0.  6.  3.  6. 11.  6. 14.  0.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3. 29.  0.  1.] 
cards in discard: [8. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 24. 29.  8.  2.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 11.  1.  0.  0.] 
adversary cards in discard: [10.  6. 11.  8.  0.  6.  3.  6. 11.  6. 14.  0.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3. 29.  0.  1.] 
cards in discard: [8. 3. 0. 1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  2.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 11.  1.  0.  0.] 
adversary cards in discard: [10.  6. 11.  8.  0.  6.  3.  6. 11.  6. 14.  0.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 5 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[6.769169]
 [6.335931]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  1.  0.  0.] 
cards in discard: [10.  6. 11.  8.  0.  6.  3.  6. 11.  6. 14.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  2.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  4.  0.  0. 29.] 
adversary cards in discard: [ 8.  3.  0.  1. 10. 25.  3. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1] -> size -> 18 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1
Learning step: -4.038424015045166
desired expected reward: -19.523103713989258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.6188903 ]
 [ 3.6825817 ]
 [ 2.4887874 ]
 [-8.650471  ]
 [ 1.3407905 ]
 [ 5.911646  ]
 [ 2.6203773 ]
 [ 3.26871   ]
 [-4.919596  ]
 [ 1.9417231 ]
 [ 0.30469203]
 [ 6.384507  ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.  0.  0.] 
cards in discard: [10.  6. 11.  8.  0.  6.  3.  6. 11.  6. 14.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 24. 29.  8.  2.  9.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  4.  0.  0. 29.] 
adversary cards in discard: [ 8.  3.  0.  1. 10. 25.  3. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1] -> size -> 18 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: take_action - action -1.0
Learning step: -5.224982738494873
desired expected reward: 1.0941071510314941



buy possibilites: [-1] 
expected returns: [[19.639612]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.  0.  0.] 
cards in discard: [10.  6. 11.  8.  0.  6.  3.  6. 11.  6. 14.  0.  6. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  4.  0.  0. 29.] 
adversary cards in discard: [ 8.  3.  0.  1. 10. 25.  3. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1] -> size -> 18 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -67 

action type: buy - action 16.0
Learning step: -2.975148916244507
desired expected reward: -1.634342908859253






Player: 1 
cards in hand: [ 0.  4.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4.  0.  0. 29.] 
cards in discard: [ 8.  3.  0.  1. 10. 25.  3. 29.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [10.  6. 11.  8.  0.  6.  3.  6. 11.  6. 14.  0.  6. 16.  6. 11.  1.  0.
  0.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16] -> size -> 25 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  0.  0. 29.] 
cards in discard: [ 8.  3.  0.  1. 10. 25.  3. 29.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 24. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [10.  6. 11.  8.  0.  6.  3.  6. 11.  6. 14.  0.  6. 16.  6. 11.  1.  0.
  0.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16] -> size -> 25 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  0.  0. 29.] 
cards in discard: [ 8.  3.  0.  1. 10. 25.  3. 29.  0.  1.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [10.  6. 11.  8.  0.  6.  3.  6. 11.  6. 14.  0.  6. 16.  6. 11.  1.  0.
  0.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16] -> size -> 25 
adversary victory points: -4
player victory points: 6 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[8.729394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [10.  6. 11.  8.  0.  6.  3.  6. 11.  6. 14.  0.  6. 16.  6. 11.  1.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1  3] -> size -> 19 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: buy - action -1
Learning step: -6.235569000244141
desired expected reward: 13.404043197631836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-2.2660792 ]
 [ 0.9996779 ]
 [ 0.68699265]
 [-3.1675904 ]
 [ 4.70807   ]
 [-0.26822066]
 [-0.05156517]
 [ 6.620906  ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [10.  6. 11.  8.  0.  6.  3.  6. 11.  6. 14.  0.  6. 16.  6. 11.  1.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1  3] -> size -> 19 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: take_action - action -1.0
Learning step: -5.849486827850342
desired expected reward: 2.8799071311950684



buy possibilites: [-1] 
expected returns: [[7.908698]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [10.  6. 11.  8.  0.  6.  3.  6. 11.  6. 14.  0.  6. 16.  6. 11.  1.  0.
  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1  3] -> size -> 19 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -91 

action type: buy - action 10.0
Learning step: -4.369476318359375
desired expected reward: -4.421038627624512






Player: 1 
cards in hand: [ 1.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10] -> size -> 26 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10] -> size -> 26 
adversary victory points: -4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  8. 10.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10] -> size -> 26 
adversary victory points: -4
player victory points: 6 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[67.92026 ]
 [59.48522 ]
 [59.378204]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 16.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  8.] 
adversary cards in discard: [10.  1.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10] -> size -> 20 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: buy - action -1
Learning step: -4.452326774597168
desired expected reward: 3.456371307373047



action possibilites: [-1. 16.] 
expected returns: [[98.527985]
 [91.14695 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  3.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  8.] 
adversary cards in discard: [10.  1.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10] -> size -> 20 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -89 

action type: take_action - action 10.0
Learning step: -5.2253313064575195
desired expected reward: 53.172061920166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 92.17872]
 [ 81.59749]
 [102.4203 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  3.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  8.] 
adversary cards in discard: [10.  1.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10] -> size -> 20 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -89 

action type: take_action - action -1.0
Learning step: -7.2749152183532715
desired expected reward: 91.2530746459961



buy possibilites: [-1] 
expected returns: [[103.215546]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  3.  3.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  8.] 
adversary cards in discard: [10.  1.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10] -> size -> 20 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -100.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -119.0 

action type: buy - action 0.0
Learning step: -8.236586570739746
desired expected reward: 83.942138671875






Player: 1 
cards in hand: [ 3.  0. 29.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.  8.] 
cards in discard: [10.  1.  0.  0.  8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [ 0. 10.  0.  3. 16.  3.  3.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0] -> size -> 27 
adversary victory points: -4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [10.  1.  0.  0.  8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [ 0. 10.  0.  3. 16.  3.  3.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0] -> size -> 27 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [10.  1.  0.  0.  8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [ 0. 10.  0.  3. 16.  3.  3.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0] -> size -> 27 
adversary victory points: -4
player victory points: 6 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [0. 6. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[61.41394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [ 0. 10.  0.  3. 16.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  4. 10.] 
adversary cards in discard: [10.  1.  0.  0.  8. 10.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10] -> size -> 19 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: buy - action -1
Learning step: -9.277204513549805
desired expected reward: 93.93833923339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[48.547157]
 [52.56574 ]
 [35.963417]
 [52.339767]
 [60.818222]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [ 0. 10.  0.  3. 16.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 23. 29.  8.  2.  8.  7.  4.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  4. 10.] 
adversary cards in discard: [10.  1.  0.  0.  8. 10.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10] -> size -> 19 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: take_action - action -1.0
Learning step: -7.256224155426025
desired expected reward: 52.01369857788086



buy possibilites: [-1] 
expected returns: [[32.477257]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  2.  8.  7.  3.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  4. 10.] 
adversary cards in discard: [10.  1.  0.  0.  8. 10.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10] -> size -> 19 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -101 

action type: buy - action 8.0
Learning step: -6.819077968597412
desired expected reward: 45.520687103271484






Player: 1 
cards in hand: [ 0.  0.  3.  4. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  4. 10.] 
cards in discard: [10.  1.  0.  0.  8. 10.  8.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 29.  8.  2.  8.  7.  3.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14.  1. 11.  6.] 
adversary cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8] -> size -> 28 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  4. 10.] 
cards in discard: [10.  1.  0.  0.  8. 10.  8.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 23. 29.  8.  2.  8.  7.  3.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14.  1. 11.  6.] 
adversary cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8] -> size -> 28 
adversary victory points: -4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  4. 10.] 
cards in discard: [10.  1.  0.  0.  8. 10.  8.  3.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 23. 29.  8.  2.  8.  7.  3.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14.  1. 11.  6.] 
adversary cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8] -> size -> 28 
adversary victory points: -4
player victory points: 6 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  1. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[44.343044]
 [32.69772 ]
 [41.80904 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1. 11.  6.] 
cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 29.  8.  2.  8.  7.  3.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0] -> size -> 20 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: buy - action -1
Learning step: -6.1687912940979
desired expected reward: 26.3084659576416



action possibilites: [-1] 
expected returns: [[-6.380448]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  6.] 
cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 29.  8.  2.  8.  7.  3.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0] -> size -> 20 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -73 

action type: gain_card_n - action 8
Learning step: -5.672111511230469
desired expected reward: 31.898921966552734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-7.572862 ]
 [-7.0600767]
 [-7.1866555]
 [-7.6235685]
 [-5.351902 ]
 [-7.295373 ]
 [-7.201749 ]
 [-4.0350065]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  6.] 
cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 23. 29.  8.  2.  8.  7.  3.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0] -> size -> 20 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -89 

action type: take_action - action -1
Learning step: -4.2733354568481445
desired expected reward: -10.653783798217773






Player: 1 
cards in hand: [10.  0.  1. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1. 25. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 29.  8.  2.  8.  7.  3.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8. 11. 11.  6.] 
adversary cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6. 14. 11.  0. 14.  1.
  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14] -> size -> 29 
adversary victory points: -4
player victory points: 6 


action possibilites: [-1. 25. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25. 29.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 29.  8.  2.  8.  7.  3.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8. 11. 11.  6.] 
adversary cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6. 14. 11.  0. 14.  1.
  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14] -> size -> 29 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25. 29.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 23. 29.  8.  2.  8.  7.  3.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8. 11. 11.  6.] 
adversary cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6. 14. 11.  0. 14.  1.
  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14] -> size -> 29 
adversary victory points: -4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25. 29.  3.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 29.  8.  2.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  8. 11. 11.  6.] 
adversary cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6. 14. 11.  0. 14.  1.
  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14] -> size -> 29 
adversary victory points: -4
player victory points: 6 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 11. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[50.58407 ]
 [41.915794]
 [48.42598 ]
 [48.42598 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11. 11.  6.] 
cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6. 14. 11.  0. 14.  1.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 29.  8.  2.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  3. 10.  0.  0.] 
adversary cards in discard: [10. 10.  0.  1. 25. 29.  3.] 
adversary owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0 10] -> size -> 21 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: buy - action -1.0
Learning step: -4.1737380027771
desired expected reward: -8.208744049072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.387993]
 [24.760147]
 [48.256725]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11. 11.  6.] 
cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6. 14. 11.  0. 14.  1.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 23. 29.  8.  2.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  3. 10.  0.  0.] 
adversary cards in discard: [10. 10.  0.  1. 25. 29.  3.] 
adversary owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0 10] -> size -> 21 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: take_action - action -1.0
Learning step: -7.131035804748535
desired expected reward: 43.45303726196289



buy possibilites: [-1] 
expected returns: [[50.293613]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11. 11.  6.] 
cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6. 14. 11.  0. 14.  1.
  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 23. 29.  8.  1.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  3. 10.  0.  0.] 
adversary cards in discard: [10. 10.  0.  1. 25. 29.  3.] 
adversary owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0 10] -> size -> 21 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -110.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -420.0 

action type: buy - action 6.0
Learning step: -21.106401443481445
desired expected reward: 3.6537513732910156






Player: 1 
cards in hand: [ 8.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  0.  0.] 
cards in discard: [10. 10.  0.  1. 25. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 29.  8.  1.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 6.  6. 10.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6. 14. 11.  0. 14.  1.
  6.  6.  0.  8. 11. 11.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6] -> size -> 30 
adversary victory points: -5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 10.  0.  0.] 
cards in discard: [10. 10.  0.  1. 25. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 23. 29.  8.  1.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 6.  6. 10.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6. 14. 11.  0. 14.  1.
  6.  6.  0.  8. 11. 11.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6] -> size -> 30 
adversary victory points: -5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 10.  0.  0.] 
cards in discard: [10. 10.  0.  1. 25. 29.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0 10  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 29.  8.  1.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 6.  6. 10.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6. 14. 11.  0. 14.  1.
  6.  6.  0.  8. 11. 11.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6] -> size -> 30 
adversary victory points: -5
player victory points: 7 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6.  6. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[26.838022]
 [20.092026]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10.  0.  0.] 
cards in discard: [ 0. 10.  0.  3. 16.  3.  3.  8.  0.  6.  6.  0.  6. 14. 11.  0. 14.  1.
  6.  6.  0.  8. 11. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 29.  8.  1.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  1.] 
adversary cards in discard: [10. 10.  0.  1. 25. 29.  3.  3.  8.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0 10  3] -> size -> 22 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -130 

action type: buy - action -1
Learning step: -8.47694206237793
desired expected reward: 41.816673278808594



action possibilites: [-1. 14.] 
expected returns: [[-7.0773535]
 [-7.8519225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 29.  8.  1.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  1.] 
adversary cards in discard: [10. 10.  0.  1. 25. 29.  3.  3.  8.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0 10  3] -> size -> 22 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action 10.0
Learning step: -6.6714324951171875
desired expected reward: 13.420585632324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -9.964056 ]
 [-10.024904 ]
 [ -7.2137384]
 [-10.596827 ]
 [ -9.501028 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 22. 29.  8.  1.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  1.] 
adversary cards in discard: [10. 10.  0.  1. 25. 29.  3.  3.  8.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0 10  3] -> size -> 22 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -5.352474212646484
desired expected reward: -12.429826736450195



buy possibilites: [-1] 
expected returns: [[-7.452389]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 14.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 22. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  1.] 
adversary cards in discard: [10. 10.  0.  1. 25. 29.  3.  3.  8.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0 10  3] -> size -> 22 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -130.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -421.0 

action type: buy - action 6.0
Learning step: -20.856992721557617
desired expected reward: -28.070730209350586






Player: 1 
cards in hand: [10.  0.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8.  1.] 
cards in discard: [10. 10.  0.  1. 25. 29.  3.  3.  8.  3. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0 10  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  3.  6.  6.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6] -> size -> 31 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 1. 3.] 
cards in discard: [10. 10.  0.  1. 25. 29.  3.  3.  8.  3. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 10 29  4 10  8  8  0  0  1 25  3  3  1  3 10  0 10  3] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  3.  6.  6.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6] -> size -> 31 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [10. 10.  0.  1. 25. 29.  3.  3.  8.  3. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  3.  6.  6.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6] -> size -> 31 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10. 10.  0.  1. 25. 29.  3.  3.  8.  3. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 22. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  3.  6.  6.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6] -> size -> 31 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10. 10.  0.  1. 25. 29.  3.  3.  8.  3. 10.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  3.  6.  6.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6] -> size -> 31 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[32.772446]
 [32.387333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  6.  6.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3] -> size -> 20 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -5.94454288482666
desired expected reward: -13.396931648254395





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[27.510876]
 [32.58811 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  6.  6.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 21. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3] -> size -> 20 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action -1.0
Learning step: -8.003445625305176
desired expected reward: 24.734886169433594



buy possibilites: [-1] 
expected returns: [[1.8948007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  6.  6.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 21. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3] -> size -> 20 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -130.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -171.0 

action type: buy - action 0.0
Learning step: -9.88291072845459
desired expected reward: 17.627967834472656






Player: 1 
cards in hand: [ 0. 25.  0.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.  4.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 21. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  6.  6.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0] -> size -> 32 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  0.  4.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 21. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  6.  6.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0] -> size -> 32 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  0.  4.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 21. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  6.  6.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0] -> size -> 32 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-4.7902336]
 [-5.3451033]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  6.  6.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 21. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [10.  1.  1.  0. 10.] 
adversary cards in discard: [ 0.  0. 25.  0.  0.  4.] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0] -> size -> 21 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -7.257958889007568
desired expected reward: -5.363158226013184



action possibilites: [-1] 
expected returns: [[-12.116377]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 21. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [10.  1.  1.  0. 10.] 
adversary cards in discard: [ 0.  0. 25.  0.  0.  4.] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0] -> size -> 21 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -112 

action type: gain_card_n - action 1
Learning step: -5.498310089111328
desired expected reward: -12.984479904174805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-13.462347]
 [-13.661781]
 [-14.222355]
 [-13.413143]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 30. 21. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [10.  1.  1.  0. 10.] 
adversary cards in discard: [ 0.  0. 25.  0.  0.  4.] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0] -> size -> 21 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: take_action - action -1
Learning step: -5.751401901245117
desired expected reward: -17.867778778076172



buy possibilites: [-1] 
expected returns: [[26.81424]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0  1  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 20. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [10.  1.  1.  0. 10.] 
adversary cards in discard: [ 0.  0. 25.  0.  0.  4.] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0] -> size -> 21 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0   20    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -102 

action type: buy - action 3.0
Learning step: -3.8135907649993896
desired expected reward: -17.475374221801758






Player: 1 
cards in hand: [10.  1.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  1.  0. 10.] 
cards in discard: [ 0.  0. 25.  0.  0.  4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 20. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  0.  6.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3. 11.  0.  0.
  6.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0  1  3] -> size -> 34 
adversary victory points: -5
player victory points: 7 


action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0. 10. 10.] 
cards in discard: [ 0.  0. 25.  0.  0.  4.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 20. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  0.  6.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3. 11.  0.  0.
  6.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0  1  3] -> size -> 34 
adversary victory points: -5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0. 10. 10.] 
cards in discard: [ 0.  0. 25.  0.  0.  4.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 25. 30. 20. 29.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  0.  6.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3. 11.  0.  0.
  6.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0  1  3] -> size -> 34 
adversary victory points: -5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0. 10. 10.] 
cards in discard: [ 0.  0. 25.  0.  0.  4.  4.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  0.  6.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3. 11.  0.  0.
  6.  6.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0  1  3] -> size -> 34 
adversary victory points: -5
player victory points: 10 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-10.189014]
 [-10.083977]
 [-10.909969]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  0.  6.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3. 11.  0.  0.
  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0  1  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  3.  3.] 
adversary cards in discard: [ 0.  0. 25.  0.  0.  4.  4. 10.  1.  1.  0. 10. 10.] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 22 
adversary victory points: 10
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -160 

action type: buy - action -1
Learning step: -9.573684692382812
desired expected reward: 17.240554809570312



action possibilites: [-1.  8.] 
expected returns: [[-11.649324]
 [-11.785713]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 6. 3.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3. 11.  0.  0.
  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  3  6  6  3  0  0  1  6 11  0 10  6  6
 16 10  0  8 14  6  6  0  1  3] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  3.  3.] 
adversary cards in discard: [ 0.  0. 25.  0.  0.  4.  4. 10.  1.  1.  0. 10. 10.] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 22 
adversary victory points: 10
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -140 

action type: take_action - action 10.0
Learning step: -6.75924825668335
desired expected reward: -16.843223571777344



action possibilites: [-1.] 
expected returns: [[27.899021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3. 11.  0.  0.
  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  3.  3.] 
adversary cards in discard: [ 0.  0. 25.  0.  0.  4.  4. 10.  1.  1.  0. 10. 10.] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 22 
adversary victory points: 10
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -160    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -131 

action type: trash_cards_n_from_hand - action 2
Learning step: -5.378622055053711
desired expected reward: -16.251623153686523





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.039139]
 [25.619625]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3. 11.  0.  0.
  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  3.  3.] 
adversary cards in discard: [ 0.  0. 25.  0.  0.  4.  4. 10.  1.  1.  0. 10. 10.] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 22 
adversary victory points: 10
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -160    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -131 

action type: take_action - action -1.0
Learning step: -7.423203468322754
desired expected reward: 20.475818634033203






Player: 1 
cards in hand: [ 8.  3. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  3.  3.] 
cards in discard: [ 0.  0. 25.  0.  0.  4.  4. 10.  1.  1.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 16.  0.  6. 11.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3. 11.  0.  0.
  6.  6. 10.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3] -> size -> 33 
adversary victory points: -6
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29.  3.  3.] 
cards in discard: [ 0.  0. 25.  0.  0.  4.  4. 10.  1.  1.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 16.  0.  6. 11.] 
adversary cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3. 11.  0.  0.
  6.  6. 10.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3] -> size -> 33 
adversary victory points: -6
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 1. 16.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[-12.3331375]
 [-14.18396  ]
 [-13.205473 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0.  6. 11.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3. 11.  0.  0.
  6.  6. 10.  8.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 4.  0.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 22 
adversary victory points: 10
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -171 

action type: buy - action -1.0
Learning step: -10.126270294189453
desired expected reward: 15.493362426757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-10.929382]
 [-11.12392 ]
 [ -9.75297 ]
 [ -9.907808]
 [-11.293476]
 [ -9.774234]
 [ -9.09135 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  0.  6. 11.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3. 11.  0.  0.
  6.  6. 10.  8.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 4.  0.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 22 
adversary victory points: 10
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -171 

action type: take_action - action -1.0
Learning step: -8.160955429077148
desired expected reward: -20.494089126586914



buy possibilites: [-1] 
expected returns: [[-8.2683325]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  0.  6. 11.] 
cards in discard: [ 6. 10.  6.  6.  0.  0. 14.  0. 11.  0.  3.  6.  6.  1.  3. 11.  0.  0.
  6.  6. 10.  8.  0.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 4.  0.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 22 
adversary victory points: 10
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -160.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -201.0 

action type: buy - action 0.0
Learning step: -9.689568519592285
desired expected reward: -20.61894989013672






Player: 1 
cards in hand: [ 4.  0.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3  0] -> size -> 34 
adversary victory points: -6
player victory points: 10 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 10 29  4 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3  0] -> size -> 34 
adversary victory points: -6
player victory points: 10 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3  0] -> size -> 34 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3  0] -> size -> 34 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3  0] -> size -> 34 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
expected returns: [[20.721115]
 [17.077263]
 [14.077572]
 [17.187191]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 14.  8.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0] -> size -> 21 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -6.2500739097595215
desired expected reward: -14.51840591430664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[15.37483 ]
 [16.82601 ]
 [16.770758]
 [20.293884]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 14.  8.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0] -> size -> 21 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action -1.0
Learning step: -7.6626176834106445
desired expected reward: 12.55469036102295



buy possibilites: [-1] 
expected returns: [[-11.327187]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 14.  8.] 
cards in discard: [8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  2.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0] -> size -> 21 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -133 

action type: buy - action 8.0
Learning step: -7.743399143218994
desired expected reward: 9.02735710144043






Player: 1 
cards in hand: [ 3.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [ 0. 10.  8.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  2.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 6. 16.  0. 11.  3.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3  0  8] -> size -> 35 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [ 0. 10.  8.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  2.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 6. 16.  0. 11.  3.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3  0  8] -> size -> 35 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [ 0. 10.  8.  3.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  2.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 16.  0. 11.  3.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8.] 
adversary owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3  0  8] -> size -> 35 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 6. 16.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[-6.625389 ]
 [-6.1726904]
 [-6.4808598]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0. 11.  3.] 
cards in discard: [ 8.  0. 10.  0. 14.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16
 10  0  8 14  6  6  0  1  3  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  2.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  4.  1. 29.] 
adversary cards in discard: [ 0. 10.  8.  3.  0. 10.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10] -> size -> 22 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -6.627498149871826
desired expected reward: -17.95468521118164



action possibilites: [-1] 
expected returns: [[19.85783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  2.  9.  8.  7. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  4.  1. 29.] 
adversary cards in discard: [ 0. 10.  8.  3.  0. 10.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10] -> size -> 22 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -105 

action type: gain_card_n - action 9
Learning step: -5.9316325187683105
desired expected reward: 16.637035369873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.833431]
 [20.250631]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  2.  9.  8.  7. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  4.  1. 29.] 
adversary cards in discard: [ 0. 10.  8.  3.  0. 10.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10] -> size -> 22 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: take_action - action -1
Learning step: -6.659947395324707
desired expected reward: 13.197882652282715






Player: 1 
cards in hand: [ 8.  0.  4.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  4.  1. 29.] 
cards in discard: [ 0. 10.  8.  3.  0. 10.  3.  0.  0. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  2.  9.  8.  7. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  1.  6. 11.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14] -> size -> 35 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 3.] 
cards in discard: [ 0. 10.  8.  3.  0. 10.  3.  0.  0. 10.  0.  4.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  2.  9.  8.  7. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  1.  6. 11.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14] -> size -> 35 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 3.] 
cards in discard: [ 0. 10.  8.  3.  0. 10.  3.  0.  0. 10.  0.  4.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  2.  9.  8.  7. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  1.  6. 11.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14] -> size -> 35 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 3.] 
cards in discard: [ 0. 10.  8.  3.  0. 10.  3.  0.  0. 10.  0.  4. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  1.  6. 11.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14] -> size -> 35 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [10.  0.  1.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-7.00736  ]
 [-6.552871 ]
 [-7.3579464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  6. 11.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10. 10. 25.  3.  1.] 
adversary cards in discard: [ 0. 10.  8.  3.  0. 10.  3.  0.  0. 10.  0.  4. 15. 29.  8.  0.  1.  3.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15] -> size -> 23 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1.0
Learning step: -8.21820068359375
desired expected reward: 12.032419204711914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-7.1458135]
 [-7.8772883]
 [-6.6168747]
 [-7.259729 ]
 [-7.924257 ]
 [-6.5114837]
 [-7.5262   ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  6. 11.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  7.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10. 10. 25.  3.  1.] 
adversary cards in discard: [ 0. 10.  8.  3.  0. 10.  3.  0.  0. 10.  0.  4. 15. 29.  8.  0.  1.  3.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15] -> size -> 23 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action -1.0
Learning step: -6.8609299659729
desired expected reward: -13.8682861328125



buy possibilites: [-1] 
expected returns: [[7.378422]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  6. 11.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  6.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10. 10. 25.  3.  1.] 
adversary cards in discard: [ 0. 10.  8.  3.  0. 10.  3.  0.  0. 10.  0.  4. 15. 29.  8.  0.  1.  3.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15] -> size -> 23 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0   -1    0    0
   18    0] 
sum of rewards: -124 

action type: buy - action 11.0
Learning step: -5.670999050140381
desired expected reward: -12.930730819702148






Player: 1 
cards in hand: [10. 10. 25.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 25.  3.  1.] 
cards in discard: [ 0. 10.  8.  3.  0. 10.  3.  0.  0. 10.  0.  4. 15. 29.  8.  0.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  6.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11] -> size -> 36 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1. 10. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  3.  1.  4.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  6.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11] -> size -> 36 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 25.  3.  1.  4.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  6.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11] -> size -> 36 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-3.6690989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  6.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [8. 1. 3. 8. 0.] 
adversary cards in discard: [10. 10. 25.  3.  1.  4.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15] -> size -> 23 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -7.501475811004639
desired expected reward: -0.12305402755737305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-4.7613897]
 [-5.583132 ]
 [-4.9112353]
 [-5.071512 ]
 [-5.3486853]
 [-4.7778807]
 [-5.0607033]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  6.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [8. 1. 3. 8. 0.] 
adversary cards in discard: [10. 10. 25.  3.  1.  4.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15] -> size -> 23 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action -1.0
Learning step: -6.979794502258301
desired expected reward: -10.648893356323242



buy possibilites: [-1] 
expected returns: [[12.960322]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  5.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [8. 1. 3. 8. 0.] 
adversary cards in discard: [10. 10. 25.  3.  1.  4.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15] -> size -> 23 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0   -2    0    0
   18    0] 
sum of rewards: -125 

action type: buy - action 11.0
Learning step: -5.704816818237305
desired expected reward: -10.776338577270508






Player: 1 
cards in hand: [8. 1. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 3. 8. 0.] 
cards in discard: [10. 10. 25.  3.  1.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  5.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 11.  6. 14.  6.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11] -> size -> 37 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 3. 8. 0.] 
cards in discard: [10. 10. 25.  3.  1.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  5.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 11.  6. 14.  6.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11] -> size -> 37 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 3. 8. 0.] 
cards in discard: [10. 10. 25.  3.  1.  4. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  4.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 11.  6. 14.  6.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11] -> size -> 37 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[-11.241333]
 [-10.450305]
 [ -8.227624]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6. 14.  6.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  4.  2.  9.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10. 29.  0.  0. 10.] 
adversary cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11] -> size -> 24 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -7.917352199554443
desired expected reward: 5.042970180511475



action possibilites: [-1] 
expected returns: [[-6.2347355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 14.  6.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29.  0.  0. 10.] 
adversary cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11] -> size -> 24 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0   -3    0    0
    9    0] 
sum of rewards: -115 

action type: gain_card_n - action 8
Learning step: -5.345864295959473
desired expected reward: -16.234214782714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-9.242384]
 [-6.391288]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 14.  6.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 30. 20. 28.  8.  0.  8.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29.  0.  0. 10.] 
adversary cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11] -> size -> 24 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: take_action - action -1
Learning step: -5.910010814666748
desired expected reward: -12.144746780395508



buy possibilites: [-1] 
expected returns: [[-7.0430317]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 14.  6.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 20. 28.  8.  0.  8.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29.  0.  0. 10.] 
adversary cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0.] 
adversary owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11] -> size -> 24 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -130.    0.    0.   20.  -30.    0.    0.    0.   -4.
    0.    0.    0.    0.] 
sum of rewards: -155.0 

action type: buy - action 0.0
Learning step: -7.446348667144775
desired expected reward: -16.688730239868164






Player: 1 
cards in hand: [10. 29.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  0. 10.] 
cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 28.  8.  0.  8.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0. 10.  0. 11.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 39 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 20. 28.  8.  0.  8.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0. 10.  0. 11.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 39 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.] 
cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0 10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11] -> size -> 24 
action values: 2 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 20. 28.  8.  0.  8.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0. 10.  0. 11.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 39 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 10. 15.] 
owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 4 
card supply: [16. 25. 30. 20. 28.  8.  0.  8.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0. 10.  0. 11.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 39 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 10. 15.] 
owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 25. 30. 20. 28.  8.  0.  8.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0. 10.  0. 11.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 39 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0. 10.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 10. 15.] 
owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 20. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0. 10.  0. 11.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 39 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [6. 6. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[ 2.5250263 ]
 [-0.65949655]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 8.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0. 10.  0. 11.  0.  6. 14.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6 11  0  6 14  3  6  6  3  0  0  1  6 11  0 10  6  6 16 10
  0  8 14  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0. 10.  0. 16. 29. 10. 15.
  0.] 
adversary owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11 16] -> size -> 24 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -6.67224645614624
desired expected reward: -13.715278625488281



action possibilites: [-1] 
expected returns: [[-12.681032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0. 10.  0. 11.  0.  6. 14.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0. 10.  0. 16. 29. 10. 15.
  0.] 
adversary owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11 16] -> size -> 24 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: trash_cards_n_from_hand - action 6
Learning step: -4.454742431640625
desired expected reward: -9.066361427307129





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ -9.73247 ]
 [-12.515282]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0. 10.  0. 14.  8. 14. 16.  6.  0.  3. 11. 10.  0.  1.  6. 11. 11.
  3.  3.  0.  0.  0. 10.  0. 11.  0.  6. 14.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 20. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0. 10.  0. 16. 29. 10. 15.
  0.] 
adversary owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11 16] -> size -> 24 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action -1
Learning step: -4.012203216552734
desired expected reward: -16.693235397338867






Player: 1 
cards in hand: [ 0.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  3.] 
cards in discard: [10. 10. 25.  3.  1.  4. 11.  8.  1.  3.  8.  0. 10.  0. 16. 29. 10. 15.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 1. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 36 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 4.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11 16] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 1. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 36 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 4.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 20. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 1. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 36 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 4.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11 16
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 25. 30. 20. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 1. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 36 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [6. 0. 1. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-7.9755964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 6. 6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10.  8. 16.  1.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  4.] 
adversary owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11 16
  0] -> size -> 25 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1.0
Learning step: -4.9536871910095215
desired expected reward: -17.468969345092773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[-7.8822985]
 [-8.8216915]
 [-7.2841225]
 [-8.214687 ]
 [-8.810137 ]
 [-7.975597 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 6. 6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 25. 30. 20. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10.  8. 16.  1.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  4.] 
adversary owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11 16
  0] -> size -> 25 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -5.182374954223633
desired expected reward: -13.157971382141113



buy possibilites: [-1] 
expected returns: [[-4.2509885]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 6. 6.] 
cards in discard: [3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 30. 19. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10.  8. 16.  1.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  4.] 
adversary owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11 16
  0] -> size -> 25 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -90.   0.   0.   0.   0.   0.   0.   0.  -2.   0.   0.
   2.   0.] 
sum of rewards: -97.0 

action type: buy - action 3.0
Learning step: -4.581441402435303
desired expected reward: -11.865565299987793






Player: 1 
cards in hand: [ 3. 10.  8. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8. 16.  1.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  4.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11 16
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 19. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  8. 11.  0.] 
adversary cards in discard: [3. 6. 0. 1. 6. 6.] 
adversary owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1.  8. 16. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 16.  1. 29.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 29 10  8  8  0  0  1 25  3  1  3 10  0 10  3  3  0  4  0 10 15 11 16
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 19. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  8. 11.  0.] 
adversary cards in discard: [3. 6. 0. 1. 6. 6.] 
adversary owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 19. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  8. 11.  0.] 
adversary cards in discard: [3. 6. 0. 1. 6. 6.] 
adversary owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8. 16.] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 19. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  8. 11.  0.] 
adversary cards in discard: [3. 6. 0. 1. 6. 6.] 
adversary owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8. 16.] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 25. 30. 19. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  8. 11.  0.] 
adversary cards in discard: [3. 6. 0. 1. 6. 6.] 
adversary owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[5.20561 ]
 [2.664415]
 [4.45767 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8. 11.  0.] 
cards in discard: [3. 6. 0. 1. 6. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14
  6  6  0  1  3  0  8 14 11 11 10  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 19. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8. 15.  0. 11.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.] 
adversary owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0] -> size -> 22 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -4.041815280914307
desired expected reward: -8.292803764343262



action possibilites: [-1] 
expected returns: [[-7.9755964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.] 
cards in discard: [3. 6. 0. 1. 6. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 19. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8. 15.  0. 11.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.] 
adversary owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0] -> size -> 22 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: trash_cards_n_from_hand - action 4
Learning step: -3.550558090209961
desired expected reward: -3.128417491912842





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-7.385538 ]
 [-7.095762 ]
 [-8.279079 ]
 [-7.9755964]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [3. 6. 0. 1. 6. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 25. 30. 19. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8. 15.  0. 11.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.] 
adversary owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0] -> size -> 22 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -3.1224050521850586
desired expected reward: -11.098001480102539



buy possibilites: [-1] 
expected returns: [[-11.474985]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [3. 6. 0. 1. 6. 6. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 25. 30. 19. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8. 15.  0. 11.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.] 
adversary owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0] -> size -> 22 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -80.   0.   0.  20. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: -98.0 

action type: buy - action 0.0
Learning step: -4.788910388946533
desired expected reward: -12.174449920654297






Player: 1 
cards in hand: [10.  8. 15.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 15.  0. 11.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 19. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  8. 14. 11.  6.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 15.  0.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  8. 14. 11.  6.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 15.  0.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  8. 14. 11.  6.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 15.  0.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  8. 14. 11.  6.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 6.  8. 14. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 11.] 
expected returns: [[ -9.600307]
 [-10.002291]
 [ -8.284046]
 [ -9.747213]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 14. 11.  6.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  8.  7. 10.  0. 10.  9.] 
adversary cards in hand: [25.  0.  0. 10.  3.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.  3.  0. 11. 10.  8. 15.  0.] 
adversary owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0] -> size -> 24 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -4.484682559967041
desired expected reward: -15.959667205810547



action possibilites: [-1] 
expected returns: [[-17.918827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 14.  6.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [25.  0.  0. 10.  3.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.  3.  0. 11. 10.  8. 15.  0.] 
adversary owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0] -> size -> 24 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0  -2   0   0  16   0] 
sum of rewards: -63 

action type: gain_card_n - action 6
Learning step: -3.180393695831299
desired expected reward: -10.635992050170898





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-17.131428]
 [-17.689774]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 14.  6.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [25.  0.  0. 10.  3.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.  3.  0. 11. 10.  8. 15.  0.] 
adversary owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0] -> size -> 24 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -3.3449883460998535
desired expected reward: -21.26381492614746






Player: 1 
cards in hand: [25.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 10.  3.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.  3.  0. 11. 10.  8. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 11.  0.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3. 10.  1.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.  3.  0. 11. 10.  8. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 11.  0.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3. 10.  1.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.  3.  0. 11. 10.  8. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 11.  0.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3. 10.  1.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  4. 10.  8. 16.  3.  0. 11. 10.  8. 15.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [12. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 11.  0.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-14.145493]
 [-17.30335 ]
 [-16.670683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.  0.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  4. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0
  0] -> size -> 25 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1.0
Learning step: -4.32091760635376
desired expected reward: -22.010690689086914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[-18.17185 ]
 [-18.285353]
 [-14.646328]
 [-14.80724 ]
 [-19.143652]
 [-13.261171]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.  0.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  4. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0
  0] -> size -> 25 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -4.502352714538574
desired expected reward: -18.647842407226562



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0.  4. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  4. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  6.  0.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 4. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  6.  0.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 4. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 25. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  6.  0.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 4. 0.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0
  0  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  6.  0.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-7.2087345]
 [-6.907368 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  6.  0.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0. 16.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  4.  0.] 
adversary owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0
  0  1] -> size -> 26 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1.0
Learning step: -4.294681549072266
desired expected reward: -18.56844139099121





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ -9.347438]
 [ -8.634703]
 [-10.092669]
 [ -7.404247]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  6.  0.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 30. 18. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0. 16.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  4.  0.] 
adversary owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0
  0  1] -> size -> 26 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -4.684885501861572
desired expected reward: -11.893622398376465



buy possibilites: [-1] 
expected returns: [[-17.311695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  6.  0.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0. 16.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  4.  0.] 
adversary owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0
  0  1] -> size -> 26 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0  -3   0   0   8   0] 
sum of rewards: -81 

action type: buy - action 3.0
Learning step: -4.007777690887451
desired expected reward: -12.642484664916992






Player: 1 
cards in hand: [ 8.  0. 15.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  0. 16.] 
cards in discard: [ 1. 10.  0.  3.  0.  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8  0  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11 16  0  3  0
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  3.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3] -> size -> 38 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [ 1. 10.  0.  3.  0.  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  3.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3] -> size -> 38 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 1. 10.  0.  3.  0.  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  3.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3] -> size -> 38 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 24. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  3.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3] -> size -> 38 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-19.998734]
 [-21.269793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  3.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  3. 10. 10.  0.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0.] 
adversary owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0] -> size -> 25 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -3.8968446254730225
desired expected reward: -21.208539962768555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-23.646711]
 [-21.020397]
 [-24.498676]
 [-19.287079]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  3.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 24. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  3. 10. 10.  0.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0.] 
adversary owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0] -> size -> 25 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -3.7894203662872314
desired expected reward: -23.788143157958984



buy possibilites: [-1] 
expected returns: [[-0.57132244]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  3.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 24. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  3. 10. 10.  0.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0.] 
adversary owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0] -> size -> 25 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -80.   0.   0.   0. -30.   0.   0.   0.  -4.   0.   0.
   0.   0.] 
sum of rewards: -120.0 

action type: buy - action 0.0
Learning step: -4.830519676208496
desired expected reward: -28.47722625732422






Player: 1 
cards in hand: [ 1.  3. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10. 10.  0.] 
cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 14. 10.  8.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.  0.  0.  0.  3. 11.  3.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3  0] -> size -> 39 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  0. 11.] 
cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 14. 10.  8.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.  0.  0.  0.  3. 11.  3.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3  0] -> size -> 39 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  0.] 
cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 14. 10.  8.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.  0.  0.  0.  3. 11.  3.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3  0] -> size -> 39 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  0.] 
cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 24. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 14. 10.  8.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.  0.  0.  0.  3. 11.  3.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3  0] -> size -> 39 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  0.] 
cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0. 14.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 14. 10.  8.] 
adversary cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.  0.  0.  0.  3. 11.  3.] 
adversary owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3  0] -> size -> 39 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [10.  0. 14. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 10.  8.] 
expected returns: [[-10.474922 ]
 [ -7.9513464]
 [ -9.188209 ]
 [ -7.9513464]
 [ -9.972802 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14. 10.  8.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.  0.  0.  0.  3. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 11  0 14  3  6  3  0  0  1  6 11  0 10  6  6 16 10  0  8 14  6  6
  0  1  3  0  8 14 11 11 10  0  3  0 29  3  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0.  3.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0. 14.  1. 10. 11.  1.  3. 10.
  0.] 
adversary owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.473006725311279
desired expected reward: -5.0443291664123535



action possibilites: [-1] 
expected returns: [[-4.058143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.  0.  0.  0.  3. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  0 14  3  6  3  0  0  1  6 11  0  6  6 16 10  0  8 14  6  6  0  1
  3  0  8 14 11 11 10  0  3  0 29  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0.  3.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0. 14.  1. 10. 11.  1.  3. 10.
  0.] 
adversary owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: trash_cards_n_from_hand - action 3
Learning step: -3.00471830368042
desired expected reward: -10.736518859863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-4.058143]
 [-4.058143]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.  0.  0.  0.  3. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  0 14  3  6  3  0  0  1  6 11  0  6  6 16 10  0  8 14  6  6  0  1
  3  0  8 14 11 11 10  0  3  0 29  3  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0.  3.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0. 14.  1. 10. 11.  1.  3. 10.
  0.] 
adversary owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -3.188400983810425
desired expected reward: -7.246543884277344



buy possibilites: [-1] 
expected returns: [[-3.8149252]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.] 
cards in discard: [ 3.  6.  0.  1.  6.  6.  0.  8.  1. 11. 29. 11.  6.  8. 14.  6.  0. 10.
  0. 11.  0.  3.  0. 14.  3.  6.  0.  0.  0.  0.  3. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  0 14  3  6  3  0  0  1  6 11  0  6  6 16 10  0  8 14  6  6  0  1
  3  0  8 14 11 11 10  0  3  0 29  3  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0.  3.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0. 14.  1. 10. 11.  1.  3. 10.
  0.] 
adversary owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20 -30   0   0   0  -3   0   0   0   0] 
sum of rewards: -99 

action type: buy - action 0.0
Learning step: -4.832928657531738
desired expected reward: -8.891071319580078






Player: 1 
cards in hand: [10.  8.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.  3.] 
cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0. 14.  1. 10. 11.  1.  3. 10.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0 14  3  6  3  0  0  1  6 11  0  6  6 16 10  0  8 14  6  6  0  1
  3  0  8 14 11 11 10  0  3  0 29  3  0  0] -> size -> 38 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.  3.] 
cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0. 14.  1. 10. 11.  1.  3. 10.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0 14  3  6  3  0  0  1  6 11  0  6  6 16 10  0  8 14  6  6  0  1
  3  0  8 14 11 11 10  0  3  0 29  3  0  0] -> size -> 38 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.  3.] 
cards in discard: [ 1. 10.  0.  3.  0.  4.  0.  0.  8. 15.  0. 14.  1. 10. 11.  1.  3. 10.
  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0 14  3  6  3  0  0  1  6 11  0  6  6 16 10  0  8 14  6  6  0  1
  3  0  8 14 11 11 10  0  3  0 29  3  0  0] -> size -> 38 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[-3.89398  ]
 [-6.1376133]
 [-6.9945383]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  0. 16.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0 14  3  6  3  0  0  1  6 11  0  6  6 16 10  0  8 14  6  6  0  1
  3  0  8 14 11 11 10  0  3  0 29  3  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1  0] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.231786727905273
desired expected reward: -8.046711921691895



action possibilites: [-1] 
expected returns: [[-17.955553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1  0] -> size -> 28 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: trash_cards_n_from_hand - action 8
Learning step: -3.91081166267395
desired expected reward: -10.774578094482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-15.735971]
 [-18.871447]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1  0] -> size -> 28 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -3.3370120525360107
desired expected reward: -21.292564392089844






Player: 1 
cards in hand: [ 0.  0.  3. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10. 25.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  6.  1.  6. 11.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25.  1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  6.  1.  6. 11.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 3. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [10 10  8  8  0 25  1  3 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1
  0 14  1  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  6.  1.  6. 11.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 25.  8.] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  6.  1.  6. 11.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 25.  8.] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  6.  1.  6. 11.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 25.  8.] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  6.  1.  6. 11.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  1.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-2.578322 ]
 [-2.4719038]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  1.  6. 11.] 
cards in discard: [8. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0. 10. 10.  1.] 
adversary cards in discard: [ 0. 10. 25.  8.  0.  3.] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0] -> size -> 26 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -3.4630887508392334
desired expected reward: -22.334531784057617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-3.2601576]
 [-3.1620123]
 [-3.6715617]
 [-3.760501 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  1.  6. 11.] 
cards in discard: [8. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0. 10. 10.  1.] 
adversary cards in discard: [ 0. 10. 25.  8.  0.  3.] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0] -> size -> 26 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -4.252462387084961
desired expected reward: -7.744339942932129



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0. 10. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10. 10.  1.] 
cards in discard: [ 0. 10. 25.  8.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [14.  6. 14.  0.  8.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  1.  0.] 
cards in discard: [ 0. 10. 25.  8.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [14.  6. 14.  0.  8.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  1.  0.] 
cards in discard: [ 0. 10. 25.  8.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 7. 23. 30. 17. 28.  8.  0.  7.  4.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [14.  6. 14.  0.  8.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  1.  0.] 
cards in discard: [ 0. 10. 25.  8.  0.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 23. 30. 17. 28.  8.  0.  7.  3.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [14.  6. 14.  0.  8.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [14.  6. 14.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.  8.] 
expected returns: [[-9.887419 ]
 [-5.7100997]
 [-5.7100997]
 [-9.272562 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 14.  0.  8.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 17. 28.  8.  0.  7.  3.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10. 25.  8.  0.  3. 11. 10.  1.  0. 10.  1.  0.] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11] -> size -> 27 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -4.328380107879639
desired expected reward: -8.088883399963379



action possibilites: [-1] 
expected returns: [[8.926646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  8.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 23. 30. 17. 28.  8.  0.  7.  3.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0. 10. 25.  8.  0.  3. 11. 10.  1.  0. 10.  1.  0.  0.  0.] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11] -> size -> 27 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 14.0
Learning step: -2.863645553588867
desired expected reward: -8.573745727539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[4.4376507]
 [6.240467 ]
 [5.9000864]
 [7.682436 ]
 [5.6635466]
 [8.545529 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0.  8.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 23. 30. 17. 28.  8.  0.  7.  3.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0. 10. 25.  8.  0.  3. 11. 10.  1.  0. 10.  1.  0.  0.  0.] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11] -> size -> 27 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -3.645886182785034
desired expected reward: 5.280759811401367






Player: 1 
cards in hand: [0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 10. 25.  8.  0.  3. 11. 10.  1.  0. 10.  1.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 17. 28.  8.  0.  7.  3.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 14.  0.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 10. 25.  8.  0.  3. 11. 10.  1.  0. 10.  1.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 23. 30. 17. 28.  8.  0.  7.  3.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 14.  0.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 10. 25.  8.  0.  3. 11. 10.  1.  0. 10.  1.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 23. 30. 17. 28.  8.  0.  7.  3.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 14.  0.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-13.305765]
 [ -7.724928]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 14.  0.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 17. 28.  8.  0.  7.  3.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 15.  3. 10.  4.] 
adversary cards in discard: [ 0. 10. 25.  8.  0.  3. 11. 10.  1.  0. 10.  1.  0.  0.  0.  0.  0.  3.
  0.] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -5.005784511566162
desired expected reward: 3.5397496223449707



action possibilites: [-1] 
expected returns: [[-14.9839735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 23. 30. 17. 28.  8.  0.  7.  3.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10.  4.] 
adversary cards in discard: [ 0. 10. 25.  8.  0.  3. 11. 10.  1.  0. 10.  1.  0.  0.  0.  0.  0.  3.
  0.  0. 15.] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 14.0
Learning step: -3.3008930683135986
desired expected reward: -11.025819778442383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[-11.26132  ]
 [-13.573455 ]
 [ -9.751763 ]
 [-12.253533 ]
 [ -8.187541 ]
 [-12.381864 ]
 [-14.282874 ]
 [-13.003945 ]
 [-16.608738 ]
 [-13.246102 ]
 [ -8.274102 ]
 [ -9.912527 ]
 [ -7.3233175]
 [-10.767215 ]
 [-14.842346 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 6. 23. 30. 17. 28.  8.  0.  7.  3.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10.  4.] 
adversary cards in discard: [ 0. 10. 25.  8.  0.  3. 11. 10.  1.  0. 10.  1.  0.  0.  0.  0.  0.  3.
  0.  0. 15.] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -2.8515899181365967
desired expected reward: -17.83556365966797



buy possibilites: [-1] 
expected returns: [[-17.834059]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 23. 30. 17. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10.  4.] 
adversary cards in discard: [ 0. 10. 25.  8.  0.  3. 11. 10.  1.  0. 10.  1.  0.  0.  0.  0.  0.  3.
  0.  0. 15.] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.    0.   -2.  -80.    0.    0.   20.    0.    0.    0.    0.   -1.
   0.    0.    4.5   0. ] 
sum of rewards: -63.5 

action type: buy - action 11.0
Learning step: -2.8621227741241455
desired expected reward: -17.14499855041504






Player: 1 
cards in hand: [ 3. 10.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  4.] 
cards in discard: [ 0. 10. 25.  8.  0.  3. 11. 10.  1.  0. 10.  1.  0.  0.  0.  0.  0.  3.
  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 17. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  0. 11. 11. 29.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11] -> size -> 36 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  4.] 
cards in discard: [ 0. 10. 25.  8.  0.  3. 11. 10.  1.  0. 10.  1.  0.  0.  0.  0.  0.  3.
  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 6. 23. 30. 17. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  0. 11. 11. 29.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11] -> size -> 36 
adversary victory points: -2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 11. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[-15.417909]
 [-15.476581]
 [-15.476581]
 [-14.782099]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11. 11. 29.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 17. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 14. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -3.800816297531128
desired expected reward: -21.63487434387207





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-13.551157]
 [-15.4218  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11. 11. 29.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 23. 30. 17. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 14. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -3.9023396968841553
desired expected reward: -19.320247650146484



buy possibilites: [-1] 
expected returns: [[-16.691525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11. 11. 29.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 23. 30. 17. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 14. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -80.   0.   0.   0. -30.   0.   0.   0.  -2.   0.   0.
   0.   0.] 
sum of rewards: -119.0 

action type: buy - action 0.0
Learning step: -5.648001670837402
desired expected reward: -19.19915771484375






Player: 1 
cards in hand: [ 0. 11. 14. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 10.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 14. 10.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 17. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  6. 11.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0] -> size -> 37 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 23. 30. 17. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.  6. 11.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0] -> size -> 37 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 23. 30. 17. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.  6. 11.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0] -> size -> 37 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  8.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.  6. 11.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0] -> size -> 37 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-8.082033 ]
 [-7.6627407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.  6. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [15. 10.  0.  0. 25.] 
adversary cards in discard: [ 3. 14.  0. 11. 10.  8.] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0  3] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[   -5     0    -2   -90     0     0     0   -30     0     0     0    -2
     0 -1800    83     0] 
sum of rewards: -1846 

action type: discard_down_to_3_cards - action 1
Learning step: -93.07953643798828
desired expected reward: -81.01921081542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-6.429641 ]
 [-5.9865212]
 [-6.582218 ]
 [-6.7623262]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.  6. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [15. 10.  0.  0. 25.] 
adversary cards in discard: [ 3. 14.  0. 11. 10.  8.] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0  3] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -4.5894880294799805
desired expected reward: -12.671509742736816



buy possibilites: [-1] 
expected returns: [[2.924074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.  6. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [15. 10.  0.  0. 25.] 
adversary cards in discard: [ 3. 14.  0. 11. 10.  8.] 
adversary owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0  3] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -90.   0.   0.   0. -30.   0.   0.   0.  -3.   0.   0.
   0.   0.] 
sum of rewards: -130.0 

action type: buy - action 0.0
Learning step: -6.11272668838501
desired expected reward: -12.542366981506348






Player: 1 
cards in hand: [15. 10.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 25.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  0. 25.] 
cards in discard: [ 3. 14.  0. 11. 10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  6. 10.  0.  3.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.  6. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0] -> size -> 38 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1. 15. 25. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 25. 10.] 
cards in discard: [ 3. 14.  0. 11. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10  8  8 25 10  0 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1
  0  0 11  0  3] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  6. 10.  0.  3.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.  6. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0] -> size -> 38 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1. 25. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 10.] 
cards in discard: [ 3. 14.  0. 11. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [10 10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1  0
  0 11  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [ 4. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  6. 10.  0.  3.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.  6. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0] -> size -> 38 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 10.] 
cards in discard: [ 3. 14.  0. 11. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [10 10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1  0
  0 11  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  6. 10.  0.  3.] 
adversary cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.  6. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0] -> size -> 38 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [10.  6. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[16.987854]
 [14.883458]
 [14.883458]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 10.  0.  3.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.  6. 11.  0.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [3. 4. 0. 0. 3.] 
adversary cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.] 
adversary owned cards: [10 10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1  0
  0 11  0  3] -> size -> 28 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -4.641477108001709
desired expected reward: -1.7174031734466553



action possibilites: [-1. 10.] 
expected returns: [[14.852748]
 [12.239981]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  3.  0.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.  6. 11.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [3. 4. 0. 0. 3.] 
adversary cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.] 
adversary owned cards: [10 10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1  0
  0 11  0  3] -> size -> 28 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -76 

action type: take_action - action 10.0
Learning step: -4.169793605804443
desired expected reward: 9.397668838500977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[11.466117]
 [12.233053]
 [12.467496]
 [14.852748]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  3.  0.] 
cards in discard: [ 8.  0.  3.  6.  1.  6. 11. 14.  6. 14.  0.  8. 11. 14.  0.  1.  3.  0.
  0.  6.  0. 11. 11. 29.  6. 11.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [3. 4. 0. 0. 3.] 
adversary cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.] 
adversary owned cards: [10 10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1  0
  0 11  0  3] -> size -> 28 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -4.2995734214782715
desired expected reward: 10.553182601928711






Player: 1 
cards in hand: [3. 4. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 4. 0. 0. 3.] 
cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1  0
  0 11  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0] -> size -> 38 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4. 0. 0. 3.] 
cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1  0
  0 11  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0] -> size -> 38 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4. 0. 0. 3.] 
cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1  0
  0 11  0  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0] -> size -> 38 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-10.917427]
 [ -5.914873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8.  1.  0.  0.] 
adversary cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.  0.  3.  4.  0.  0.  3.] 
adversary owned cards: [10 10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1  0
  0 11  0  3  0] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1.0
Learning step: -5.774751663208008
desired expected reward: 9.078003883361816





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[ -8.603755]
 [-10.2575  ]
 [ -8.956402]
 [-10.725605]
 [ -9.867878]
 [-10.917427]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 23. 30. 16. 28.  8.  0.  7.  2.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8.  1.  0.  0.] 
adversary cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.  0.  3.  4.  0.  0.  3.] 
adversary owned cards: [10 10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1  0
  0 11  0  3  0] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -4.522888660430908
desired expected reward: -15.440315246582031



buy possibilites: [-1] 
expected returns: [[-10.906932]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  3.] 
cards in discard: [11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 16. 28.  8.  0.  7.  1.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8.  1.  0.  0.] 
adversary cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.  0.  3.  4.  0.  0.  3.] 
adversary owned cards: [10 10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1  0
  0 11  0  3  0] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0  -4   0   0  18   0] 
sum of rewards: -83 

action type: buy - action 11.0
Learning step: -3.8591256141662598
desired expected reward: -14.584732055664062






Player: 1 
cards in hand: [10.  8.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  1.  0.  0.] 
cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.  0.  3.  4.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  1  0 14  1  0
  0 11  0  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 16. 28.  8.  0.  7.  1.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [11.  0. 14.  0.  0.  3.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0 11] -> size -> 39 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.  0.  3.  4.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  0 14  1  0  0 11
  0  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 16. 28.  8.  0.  7.  1.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [11.  0. 14.  0.  0.  3.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0 11] -> size -> 39 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.  0.  3.  4.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  0 14  1  0  0 11
  0  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 23. 30. 16. 28.  8.  0.  7.  1.  2.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [11.  0. 14.  0.  0.  3.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0 11] -> size -> 39 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.  0.  3.  4.  0.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  0 14  1  0  0 11
  0  3  0  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 16. 28.  8.  0.  7.  1.  1.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [11.  0. 14.  0.  0.  3.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0 11] -> size -> 39 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[23.098179]
 [22.034218]
 [22.328861]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 11.  0.] 
cards in discard: [11.  0. 14.  0.  0.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 16. 28.  8.  0.  7.  1.  1.  9.  7.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.  0.  3.  4.  0.  0.  3.  8.
  8.  0.  0.] 
adversary owned cards: [10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  0 14  1  0  0 11
  0  3  0  8] -> size -> 28 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -3.7969231605529785
desired expected reward: -14.703855514526367



action possibilites: [-1] 
expected returns: [[6.8572607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [11.  0. 14.  0.  0.  3. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0 11 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 16. 28.  8.  0.  7.  1.  1.  9.  6.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.  0.  3.  4.  0.  0.  3.  8.
  8.  0.  0.] 
adversary owned cards: [10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  0 14  1  0  0 11
  0  3  0  8] -> size -> 28 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0  -5   0   0  16   0] 
sum of rewards: -66 

action type: gain_card_n - action 6
Learning step: -4.322010517120361
desired expected reward: 19.203964233398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[3.3445358]
 [4.728188 ]
 [4.143205 ]
 [7.070321 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [11.  0. 14.  0.  0.  3. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0 11 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 23. 30. 16. 28.  8.  0.  7.  1.  1.  9.  6.  6. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.  0.  3.  4.  0.  0.  3.  8.
  8.  0.  0.] 
adversary owned cards: [10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  0 14  1  0  0 11
  0  3  0  8] -> size -> 28 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -4.0778608322143555
desired expected reward: 2.779399871826172






Player: 1 
cards in hand: [ 0.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.  0.  3.  4.  0.  0.  3.  8.
  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  0 14  1  0  0 11
  0  3  0  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 16. 28.  8.  0.  7.  1.  1.  9.  6.  6. 10.  0. 10.  9.] 
adversary cards in hand: [14. 29. 11.  0.  6.] 
adversary cards in discard: [11.  0. 14.  0.  0.  3. 29. 11.  8.  3.  0.  0.] 
adversary owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0 11 29] -> size -> 40 
adversary victory points: -2
player victory points: 7 


Player 1 won the game! 



Player 0 bought cards:
Copper: 13 
Silver: 1 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 1 
Workshop: 5 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [14. 29. 11.  0.  6.] 
cards in discard: [11.  0. 14.  0.  0.  3. 29. 11.  8.  3.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 14  6  3  0  0  1  6 11  0  6  6 10  0  8 14  6  6  0  1  3  0  8
 14 11 11 10  0  3  0 29  3  0  0 11  0  0 11 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 16. 28.  8.  0.  7.  1.  0.  9.  6.  6. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0.] 
adversary cards in discard: [ 3. 14.  0. 11. 10.  8. 10. 15.  0. 25. 10.  0.  3.  4.  0.  0.  3.  8.
  8.  0.  0.  8.] 
adversary owned cards: [10  8  8 25 10 10  3  3  0  4  0 10 15 11  0  3  0  0  0 14  1  0  0 11
  0  3  0  8  8] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5 -500   -2  -90    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -597 

action type: buy - action -1.0
Learning step: -30.203516006469727
desired expected reward: -23.133195877075195



