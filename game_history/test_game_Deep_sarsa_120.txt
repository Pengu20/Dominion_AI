 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[50.222733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      30       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000025 

action type: buy - action -1.0
Learning step: 299997.75
desired expected reward: 300045.21875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[50.92643 ]
 [87.85645 ]
 [68.06018 ]
 [28.367754]
 [89.633965]
 [69.84435 ]
 [53.4533  ]
 [49.097603]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 50.020225524902344



buy possibilites: [-1] 
expected returns: [[21.526957]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 89.63396453857422






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [14.  0.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[40.610252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.52695655822754





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 41.700493]
 [ 71.45903 ]
 [ 56.93937 ]
 [ 20.209711]
 [ 66.130264]
 [ 74.04951 ]
 [ 58.08983 ]
 [112.07234 ]
 [ 33.861816]
 [ 44.398254]
 [ 62.3804  ]
 [ 40.858376]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.301849365234375



buy possibilites: [-1] 
expected returns: [[11.249805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 112.07231140136719






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[12.028673]
 [61.803917]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 14.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.249805450439453



action possibilites: [-1. 11.] 
expected returns: [[32.82676 ]
 [63.921158]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 14.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 60.491302490234375



action possibilites: [-1] 
expected returns: [[32.341507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 14.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 84.2357406616211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 44.714584]
 [ 82.78475 ]
 [ 62.3953  ]
 [ 33.694412]
 [ 19.4393  ]
 [ 77.754555]
 [ 83.38771 ]
 [ 65.19951 ]
 [141.07875 ]
 [126.68979 ]
 [ 32.70565 ]
 [ 82.52274 ]
 [ 45.46396 ]
 [ 44.441544]
 [ 69.58123 ]
 [ 37.66926 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 14.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.34150695800781



buy possibilites: [-1] 
expected returns: [[13.687193]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 14.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 141.07872009277344






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  8. 14.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  8. 14.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  8. 14.] 
cards in discard: [10.  0.  0.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[43.96572]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.687192916870117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[48.530937]
 [72.44851 ]
 [59.103134]
 [31.91179 ]
 [74.50525 ]
 [60.416473]
 [48.84874 ]
 [44.7306  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.45555877685547



buy possibilites: [-1] 
expected returns: [[32.660828]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 74.5052490234375






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.423521]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 10.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.66082763671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.923103]
 [41.42904 ]
 [ 9.489869]
 [43.15998 ]
 [24.127703]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 10.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 20.764352798461914



buy possibilites: [-1] 
expected returns: [[12.599451]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 10.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 43.15997314453125






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [14.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0. 10.] 
cards in discard: [3. 0. 0. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 29.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0. 10.] 
cards in discard: [3. 0. 0. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 29.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0. 10.] 
cards in discard: [ 3.  0.  0.  0.  3.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8  3 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 29.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 10.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[40.3425 ]
 [44.74449]
 [99.26726]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 29.] 
cards in discard: [8. 3. 3. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  3.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8  3 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.599451065063477



action possibilites: [-1. 10.] 
expected returns: [[74.23939 ]
 [80.301895]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [8. 3. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  3.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8  3 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 92.47557830810547



action possibilites: [-1.] 
expected returns: [[74.56405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 3. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8] -> size -> 16 
action values: 2 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  3.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8  3 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 80.3018798828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 93.08343 ]
 [124.831665]
 [ 77.239136]
 [107.22742 ]
 [ 84.09046 ]
 [ 69.400635]
 [120.63166 ]
 [124.12776 ]
 [109.63193 ]
 [179.72028 ]
 [166.60568 ]
 [ 82.80335 ]
 [124.85066 ]
 [ 93.300674]
 [ 92.967476]
 [113.1565  ]
 [ 85.75058 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 3. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  3.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8  3 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 74.56404876708984



buy possibilites: [-1] 
expected returns: [[12.358839]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  7.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  3.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8  3 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 67.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 179.72027587890625






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [14.  3.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8 10  8  3 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  7.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 25. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  7.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 25. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  7.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 25. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  8. 25. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11. 11.] 
expected returns: [[ 1.8058949]
 [ 8.722634 ]
 [47.266487 ]
 [19.806454 ]
 [19.806454 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 25. 11. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  7.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [ 8. 14.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.35883903503418



action possibilites: [-1] 
expected returns: [[-19.631102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  7.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [ 8. 14.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 44.27142333984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-28.782192]
 [-20.783482]
 [-37.355453]
 [-20.706396]
 [-24.989073]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  7.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [ 8. 14.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.631101608276367



buy possibilites: [-1] 
expected returns: [[-12.537114]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11. 11.  0.  3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  6.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [ 8. 14.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -20.70640754699707






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0. 11.] 
cards in discard: [ 8. 14.  8.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  6.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3. 29.] 
adversary cards in discard: [ 8. 25.  0.  8. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 8. 14.  8.  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  6.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3. 29.] 
adversary cards in discard: [ 8. 25.  0.  8. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 8. 14.  8.  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  6.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3. 29.] 
adversary cards in discard: [ 8. 25.  0.  8. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 8. 14.  8.  0.  6.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  9. 10.  7.  6.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3. 29.] 
adversary cards in discard: [ 8. 25.  0.  8. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 25.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-25.533148]
 [ 34.883965]
 [ 27.38167 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3. 29.] 
cards in discard: [ 8. 25.  0.  8. 11. 11.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  9. 10.  7.  6.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 14.  8.  0.  6.  3.  3. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.537114143371582



action possibilites: [-1] 
expected returns: [[14.831976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29. 10.  0.] 
cards in discard: [ 8. 25.  0.  8. 11. 11.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  8. 10.  7.  6.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 14.  8.  0.  6.  3.  3. 11.  3. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.959257125854492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.446585 ]
 [44.387436 ]
 [32.737785 ]
 [ 7.8230286]
 [45.611526 ]
 [34.176765 ]
 [23.228191 ]
 [19.061756 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29. 10.  0.] 
cards in discard: [ 8. 25.  0.  8. 11. 11.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 27. 30.  8.  8. 10.  7.  6.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 14.  8.  0.  6.  3.  3. 11.  3. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.831975936889648



buy possibilites: [-1] 
expected returns: [[27.26198]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29. 10.  0.] 
cards in discard: [ 8. 25.  0.  8. 11. 11.  0.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  8. 10.  6.  6.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 14.  8.  0.  6.  3.  3. 11.  3. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 45.611534118652344






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8. 14.  8.  0.  6.  3.  3. 11.  3. 10.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  8. 10.  6.  6.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8. 14.  8.  0.  6.  3.  3. 11.  3. 10.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 27. 30.  8.  8. 10.  6.  6.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8. 14.  8.  0.  6.  3.  3. 11.  3. 10.  0.  0.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  6.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11.  8.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[16.14254 ]
 [45.806458]
 [33.865295]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  6.  8.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.261980056762695



action possibilites: [-1] 
expected returns: [[38.171715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  6.  8.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 52.841094970703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[54.182755]
 [65.850235]
 [34.633896]
 [68.40004 ]
 [48.062576]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  6.  8.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.171714782714844



buy possibilites: [-1] 
expected returns: [[42.565758]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [10.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  5.  8.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 68.40003967285156






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  5.  8.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0. 10.  0.] 
adversary cards in discard: [10.  8. 11.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  5.  8.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0. 10.  0.] 
adversary cards in discard: [10.  8. 11.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[20.78727 ]
 [47.53456 ]
 [26.013134]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 10.  0.] 
cards in discard: [10.  8. 11.  8.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  5.  8.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  6. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.565757751464844



action possibilites: [-1] 
expected returns: [[0.83730555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [10.  8. 11.  8.  3.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  5.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  6. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 51.53483581542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 0.73819876]
 [ 9.216979  ]
 [-9.336094  ]
 [ 9.29974   ]
 [ 2.924492  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [10.  8. 11.  8.  3.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  5.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  6. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.8373055458068848



buy possibilites: [-1] 
expected returns: [[22.71473]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [10.  8. 11.  8.  3.  0.  0. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  4.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  6. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 9.299736022949219






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 11.  0.] 
cards in discard: [ 6.  0. 10.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  4.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29. 25.] 
adversary cards in discard: [10.  8. 11.  8.  3.  0.  0. 10.  8. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 6.  0. 10.  3.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  3.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29. 25.] 
adversary cards in discard: [10.  8. 11.  8.  3.  0.  0. 10.  8. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 6.  0. 10.  3.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 26. 30.  8.  8. 10.  6.  3.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29. 25.] 
adversary cards in discard: [10.  8. 11.  8.  3.  0.  0. 10.  8. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 6.  0. 10.  3.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  6.  3.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29. 25.] 
adversary cards in discard: [10.  8. 11.  8.  3.  0.  0. 10.  8. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[50.099724]
 [72.32301 ]
 [83.8073  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29. 25.] 
cards in discard: [10.  8. 11.  8.  3.  0.  0. 10.  8. 11.  3.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  6.  3.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.71472930908203



action possibilites: [-1] 
expected returns: [[24.77077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29. 11.  0.] 
cards in discard: [10.  8. 11.  8.  3.  0.  0. 10.  8. 11.  3.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  7. 10.  6.  3.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 83.80729675292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[16.839132 ]
 [44.269638 ]
 [35.389984 ]
 [ 3.3572865]
 [52.60211  ]
 [33.794983 ]
 [24.985132 ]
 [28.65999  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29. 11.  0.] 
cards in discard: [10.  8. 11.  8.  3.  0.  0. 10.  8. 11.  3.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8.  7. 10.  6.  3.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.770769119262695



buy possibilites: [-1] 
expected returns: [[47.020844]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29. 11.  0.] 
cards in discard: [10.  8. 11.  8.  3.  0.  0. 10.  8. 11.  3.  0. 10.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  7. 10.  5.  3.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 52.602142333984375






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [8. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  7. 10.  5.  3.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 26. 30.  8.  7. 10.  5.  3.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  7. 10.  5.  3.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11] -> size -> 24 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[ 43.201805]
 [ 59.38817 ]
 [101.53877 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 25.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  7. 10.  5.  3.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  3.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.  6.  3.  8.  8.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 47.020843505859375



action possibilites: [-1] 
expected returns: [[45.98983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  6. 10.  5.  3.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  3.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.  6.  3.  8.  8.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 90.07714080810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 54.265686]
 [ 79.515205]
 [ 64.657974]
 [ 47.199875]
 [ 37.004257]
 [ 76.617294]
 [ 79.20568 ]
 [ 67.103   ]
 [119.692665]
 [110.24352 ]
 [ 45.723175]
 [ 79.65201 ]
 [ 53.567528]
 [ 54.418983]
 [ 69.52607 ]
 [ 47.145294]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 25. 30.  8.  6. 10.  5.  3.  8.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  3.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.  6.  3.  8.  8.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.989830017089844



buy possibilites: [-1] 
expected returns: [[25.29425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0. 0.] 
cards in discard: [25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  6. 10.  5.  3.  7.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  3.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.  6.  3.  8.  8.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 119.69264221191406






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  3.] 
cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.  6.  3.  8.  8.  0.  0.
  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  6. 10.  5.  3.  7.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25. 10. 29.  8.  0.] 
adversary cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25] -> size -> 25 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  3.] 
cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.  6.  3.  8.  8.  0.  0.
  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 25. 30.  8.  6. 10.  5.  3.  7.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25. 10. 29.  8.  0.] 
adversary cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25] -> size -> 25 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  3.] 
cards in discard: [ 6.  0. 10.  3.  0.  8.  0. 11.  3.  3.  6.  0.  6.  3.  8.  8.  0.  0.
  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  6. 10.  5.  3.  7.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25. 10. 29.  8.  0.] 
adversary cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25] -> size -> 25 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [25. 10. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29.  8.] 
expected returns: [[53.068398]
 [94.1828  ]
 [39.374672]
 [74.76595 ]
 [43.147186]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 29.  8.  0.] 
cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  6. 10.  5.  3.  7.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.29425048828125



action possibilites: [-1] 
expected returns: [[1.95221]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  8.  0.  0.  3.] 
cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 14.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6  0  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 94.18283081054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -8.828318 ]
 [ 21.358204 ]
 [-26.493532 ]
 [ 18.274145 ]
 [  4.8803205]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  8.  0.  0.  3.] 
cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 14.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6  0  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.9522099494934082



buy possibilites: [-1] 
expected returns: [[45.064583]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  8.  0.  0.  3.] 
cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 14.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6  0  6] -> size -> 27 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 21.358203887939453






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  8. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 14.  3.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 11. 11.  8.  3.] 
adversary cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.  3. 25. 10. 29.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3] -> size -> 26 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 14.  3.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 11. 11.  8.  3.] 
adversary cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.  3. 25. 10. 29.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3] -> size -> 26 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 11. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.  8.] 
expected returns: [[45.919632]
 [68.74597 ]
 [68.74597 ]
 [68.74597 ]
 [49.245438]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  8.  3.] 
cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.  3. 25. 10. 29.  8.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  0. 11.] 
adversary cards in discard: [ 6.  0.  3.  8. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 45.06458282470703



action possibilites: [-1] 
expected returns: [[86.49146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8.  3.] 
cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.  3. 25. 10. 29.  8.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  0. 11.] 
adversary cards in discard: [ 6.  0.  3.  8. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 74.84539031982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[69.0093  ]
 [44.123642]
 [85.68322 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  8.  3.] 
cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.  3. 25. 10. 29.  8.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  0. 11.] 
adversary cards in discard: [ 6.  0.  3.  8. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.49146270751953






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  0. 11.] 
cards in discard: [ 6.  0.  3.  8. 14.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  8 10  8  3 11  6  3  3  6  3  8  0  6  3
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 11. 10.  8.] 
adversary cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.  3. 25. 10. 29.  8.  0.  0.  3. 10. 11.
 11. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3 10] -> size -> 27 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  0.  3.  8. 14.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 11. 10.  8.] 
adversary cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.  3. 25. 10. 29.  8.  0.  0.  3. 10. 11.
 11. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3 10] -> size -> 27 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0.  3.  8. 14.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 11. 10.  8.] 
adversary cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.  3. 25. 10. 29.  8.  0.  0.  3. 10. 11.
 11. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3 10] -> size -> 27 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 3. 10. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.  8.] 
expected returns: [[49.53276 ]
 [45.874886]
 [68.424225]
 [45.874886]
 [52.92887 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10.  8.] 
cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.  3. 25. 10. 29.  8.  0.  0.  3. 10. 11.
 11. 11.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  6. 10.  8.  0.] 
adversary cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 85.68323516845703



action possibilites: [-1] 
expected returns: [[91.23357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  8.] 
cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.  3. 25. 10. 29.  8.  0.  0.  3. 10. 11.
 11. 11.  8.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  6. 10.  8.  0.] 
adversary cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 76.58265686035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.387825]
 [62.723145]
 [91.81487 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  8.] 
cards in discard: [25. 25.  0.  0.  0.  8.  0.  0.  3. 25. 10. 29.  8.  0.  0.  3. 10. 11.
 11. 11.  8.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  6. 10.  8.  0.] 
adversary cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.23356628417969






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 6.  6. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10.  8.  0.] 
cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  8.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3 10 10] -> size -> 28 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 0. 0.] 
cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  8.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3 10 10] -> size -> 28 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 0. 0.] 
cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  8.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3 10 10] -> size -> 28 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [10.  8.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
expected returns: [[18.823769]
 [21.891521]
 [31.374266]
 [31.374266]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 25  8 11 10  8 10  8 11
 25  3 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0. 10.  6.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 91.81486511230469



action possibilites: [-1] 
expected returns: [[-1.2853806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0. 10.  6.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 45.97087097167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -8.334578 ]
 [-18.844387 ]
 [ -1.9585806]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0. 10.  6.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.2853806018829346






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0. 10.  6.  6.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [25. 11. 10. 11. 11.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0. 10.  6.  6.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [25. 11. 10. 11. 11.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0. 10.  6.  6.  8.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [25. 11. 10. 11. 11.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [25. 11. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10. 11. 11.] 
expected returns: [[-44.95376 ]
 [ 19.590528]
 [-12.045273]
 [-27.2229  ]
 [-12.045273]
 [-12.045273]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 10. 11. 11.] 
cards in discard: [ 8. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  5. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0. 10.  6.  6.  8.  0.  0.  0.  0.  3.  0.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6
  0] -> size -> 25 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -1.9585778713226318



action possibilites: [-1] 
expected returns: [[2.6314077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 11. 11.  0.] 
cards in discard: [ 8. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  4. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0. 10.  6.  6.  8.  0.  0.  0.  0.  3.  0.
  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6
  0  6] -> size -> 26 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 7.2634992599487305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -2.8066692]
 [-12.010231 ]
 [ -1.822709 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11. 11. 11.  0.] 
cards in discard: [ 8. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 24. 30.  8.  4. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0. 10.  6.  6.  8.  0.  0.  0.  0.  3.  0.
  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6
  0  6] -> size -> 26 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.6314077377319336






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0. 10.  6.  6.  8.  0.  0.  0.  0.  3.  0.
  3.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  4. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 29.] 
adversary cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0. 10.  6.  6.  8.  0.  0.  0.  0.  3.  0.
  3.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 24. 30.  8.  4. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 29.] 
adversary cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [ 6.  0.  3.  8. 14.  3.  8.  0. 10.  6.  6.  8.  0.  0.  0.  0.  3.  0.
  3.  3.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6
  0  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  4. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 29.] 
adversary cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-58.757538]
 [ 37.783447]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 29.] 
cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  4. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6
  0  6  3] -> size -> 27 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -1.8227035999298096



action possibilites: [-1. 10.] 
expected returns: [[60.842896]
 [63.42134 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 10.] 
cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 23. 30.  8.  4. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6
  0  6  3] -> size -> 27 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.78346252441406



action possibilites: [-1.] 
expected returns: [[63.906166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 23. 30.  8.  4. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6
  0  6  3] -> size -> 27 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 63.42133331298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 80.68278 ]
 [109.26589 ]
 [ 99.63163 ]
 [ 42.02047 ]
 [101.44331 ]
 [116.19078 ]
 [ 99.471375]
 [121.64633 ]
 [ 68.94881 ]
 [ 86.26923 ]
 [104.82533 ]
 [ 75.15257 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 23. 30.  8.  4. 10.  5.  3.  7.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6
  0  6  3] -> size -> 27 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 63.906166076660156



buy possibilites: [-1] 
expected returns: [[-53.236908]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  4. 10.  5.  3.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6
  0  6  3] -> size -> 27 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 121.64630126953125






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [6. 8. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  8 10  8  3  3  3  6  3  8  0  6  3  6  0  6
  0  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  4. 10.  5.  3.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3. 10.] 
adversary cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0. 29. 29. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29] -> size -> 26 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  4. 10.  5.  3.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3. 10.] 
adversary cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0. 29. 29. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29] -> size -> 26 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  4. 10.  5.  3.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3. 10.] 
adversary cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0. 29. 29. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29] -> size -> 26 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 3. 25.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[-28.895643]
 [ 58.809097]
 [-34.04158 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  3. 10.] 
cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0. 29. 29. 10.  3.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  4. 10.  5.  3.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 6. 6. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -53.236907958984375



action possibilites: [-1] 
expected returns: [[21.363214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10. 10. 25.] 
cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0. 29. 29. 10.  3.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  3. 10.  5.  3.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 6. 6. 0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 58.80906677246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.906372]
 [-7.909233]
 [20.389425]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10. 10. 25.] 
cards in discard: [ 8. 10. 25. 11. 10. 11. 11. 11.  0. 29. 29. 10.  3.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 23. 30.  8.  3. 10.  5.  3.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 6. 6. 0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.36321449279785






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 6. 0.] 
cards in discard: [8. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  3. 10.  5.  3.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0. 25.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29] -> size -> 26 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 0.] 
cards in discard: [8. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 23. 30.  8.  3. 10.  5.  3.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0. 25.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29] -> size -> 26 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 0.] 
cards in discard: [8. 3. 6. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 22. 30.  8.  3. 10.  5.  3.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0. 25.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29] -> size -> 26 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [29.  0. 25.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8.  8.] 
expected returns: [[ 8.996972]
 [32.431313]
 [40.766403]
 [15.247028]
 [15.247028]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  8.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 22. 30.  8.  3. 10.  5.  3.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [8. 3. 6. 3. 0. 3. 6. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3] -> size -> 26 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.389440536499023



action possibilites: [-1] 
expected returns: [[22.859491]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.  8.  0. 25.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 22. 30.  8.  2. 10.  5.  3.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [8. 3. 6. 3. 0. 3. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.21031188964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.070156]
 [27.164175]
 [12.395813]
 [27.530363]
 [22.106964]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  8.  8.  0. 25.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 22. 30.  8.  2. 10.  5.  3.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [8. 3. 6. 3. 0. 3. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.8594913482666



buy possibilites: [-1] 
expected returns: [[21.99106]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  8.  8.  0. 25.] 
cards in discard: [8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 22. 30.  8.  2. 10.  5.  2.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [8. 3. 6. 3. 0. 3. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 27.530359268188477






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [8. 3. 6. 3. 0. 3. 6. 6. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 22. 30.  8.  2. 10.  5.  2.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10. 25.  3.  3. 11.] 
adversary cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8] -> size -> 27 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [8. 3. 6. 3. 0. 3. 6. 6. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 22. 30.  8.  2. 10.  5.  2.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10. 25.  3.  3. 11.] 
adversary cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8] -> size -> 27 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [8. 3. 6. 3. 0. 3. 6. 6. 0. 6. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 21. 30.  8.  2. 10.  5.  2.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10. 25.  3.  3. 11.] 
adversary cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8] -> size -> 27 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [10. 25.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11.] 
expected returns: [[ 54.14247 ]
 [ 52.536087]
 [136.07884 ]
 [ 85.40598 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  3.  3. 11.] 
cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 21. 30.  8.  2. 10.  5.  2.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  3.  0.  3.] 
adversary cards in discard: [8. 3. 6. 3. 0. 3. 6. 6. 0. 6. 3. 0. 0. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3] -> size -> 28 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.991060256958008



action possibilites: [-1] 
expected returns: [[-31.08148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 11. 11. 10.] 
cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  3.  0.  3.] 
adversary cards in discard: [8. 3. 6. 3. 0. 3. 6. 6. 0. 6. 3. 0. 0. 6. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 136.07882690429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-45.781578]
 [-68.16029 ]
 [-32.478516]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3. 11. 11. 10.] 
cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  3.  0.  3.] 
adversary cards in discard: [8. 3. 6. 3. 0. 3. 6. 6. 0. 6. 3. 0. 0. 6. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -31.081480026245117






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [14.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0.  3.] 
cards in discard: [8. 3. 6. 3. 0. 3. 6. 6. 0. 6. 3. 0. 0. 6. 6. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 10. 10.  3.] 
adversary cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25. 25. 10.  3.  3. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8] -> size -> 27 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [8. 3. 6. 3. 0. 3. 6. 6. 0. 6. 3. 0. 0. 6. 6. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10.  3.] 
adversary cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25. 25. 10.  3.  3. 11. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8] -> size -> 27 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [8. 3. 6. 3. 0. 3. 6. 6. 0. 6. 3. 0. 0. 6. 6. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10.  3.] 
adversary cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25. 25. 10.  3.  3. 11. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8] -> size -> 27 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[66.4743 ]
 [86.15048]
 [65.18439]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.] 
cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25. 25. 10.  3.  3. 11. 11. 10.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  3.] 
adversary cards in discard: [ 8.  3.  6.  3.  0.  3.  6.  6.  0.  6.  3.  0.  0.  6.  6.  3.  6. 14.
  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 64.9092788696289



action possibilites: [-1] 
expected returns: [[60.0598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25. 25. 10.  3.  3. 11. 11. 10.  0. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  3.] 
adversary cards in discard: [ 8.  3.  6.  3.  0.  3.  6.  6.  0.  6.  3.  0.  0.  6.  6.  3.  6. 14.
  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 92.22843933105469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.834755]
 [30.342997]
 [60.316933]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25. 25. 10.  3.  3. 11. 11. 10.  0. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  3.] 
adversary cards in discard: [ 8.  3.  6.  3.  0.  3.  6.  6.  0.  6.  3.  0.  0.  6.  6.  3.  6. 14.
  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.05979919433594






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [10.  8.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0.  3.] 
cards in discard: [ 8.  3.  6.  3.  0.  3.  6.  6.  0.  6.  3.  0.  0.  6.  6.  3.  6. 14.
  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29.  8. 11. 10.  3.] 
adversary cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25. 25. 10.  3.  3. 11. 11. 10.  0. 10. 10.
 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10] -> size -> 28 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  0.  3.] 
cards in discard: [ 8.  3.  6.  3.  0.  3.  6.  6.  0.  6.  3.  0.  0.  6.  6.  3.  6. 14.
  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29.  8. 11. 10.  3.] 
adversary cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25. 25. 10.  3.  3. 11. 11. 10.  0. 10. 10.
 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10] -> size -> 28 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  8. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11. 10.] 
expected returns: [[-25.682747 ]
 [ 70.236206 ]
 [  1.3273659]
 [ 21.104755 ]
 [-18.869453 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 11. 10.  3.] 
cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25. 25. 10.  3.  3. 11. 11. 10.  0. 10. 10.
 11. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [14.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 60.316864013671875



action possibilites: [-1.  8. 11. 10.] 
expected returns: [[12.501692]
 [37.793785]
 [48.229996]
 [21.53504 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  3.  0.] 
cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25. 25. 10.  3.  3. 11. 11. 10.  0. 10. 10.
 11. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [14.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 70.23616027832031



action possibilites: [-1] 
expected returns: [[108.577385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  0.] 
cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25. 25. 10.  3.  3. 11. 11. 10.  0. 10. 10.
 11. 10.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [14.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 66.70186614990234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 94.30634]
 [116.05571]
 [ 71.77652]
 [114.14027]
 [110.0674 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  0.] 
cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25. 25. 10.  3.  3. 11. 11. 10.  0. 10. 10.
 11. 10.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 21. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [14.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.57738494873047



buy possibilites: [-1] 
expected returns: [[130.60437]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  0.] 
cards in discard: [ 8. 25. 29.  0.  8.  8.  0. 25. 25. 10.  3.  3. 11. 11. 10.  0. 10. 10.
 11. 10.  3. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [14.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 111 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 116.05569458007812






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [14.  3.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3] -> size -> 30 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3] -> size -> 30 
adversary victory points: 5
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[43.320343]
 [57.54857 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 3.] 
adversary cards in discard: [14.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 130.6043701171875



action possibilites: [-1] 
expected returns: [[66.98237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 3.] 
adversary cards in discard: [14.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 66.06776428222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[62.197113]
 [86.77127 ]
 [78.542114]
 [37.82126 ]
 [92.547905]
 [77.99711 ]
 [67.938805]
 [69.9486  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  5.  2.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 3.] 
adversary cards in discard: [14.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.98236846923828



buy possibilites: [-1] 
expected returns: [[141.9141]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  4.  2.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 3.] 
adversary cards in discard: [14.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 92.54791259765625






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [6. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0. 3.] 
cards in discard: [14.  3.  8.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  4.  2.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0. 25. 10. 10.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11] -> size -> 32 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 3.] 
cards in discard: [14.  3.  8.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  4.  2.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0. 25. 10. 10.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11] -> size -> 32 
adversary victory points: 5
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0. 25. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10.] 
expected returns: [[27.723766]
 [92.17955 ]
 [27.113905]
 [27.113905]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25. 10. 10.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  4.  2.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 8. 0. 6. 3.] 
adversary cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6] -> size -> 29 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 141.91409301757812



action possibilites: [-1] 
expected returns: [[62.3387]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 10. 10.  8.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  0. 10.  4.  2.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 8. 0. 6. 3.] 
adversary cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6  6] -> size -> 30 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 92.17953491210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[55.038887]
 [63.395645]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 10. 10.  8.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 20. 30.  8.  0. 10.  4.  2.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 8. 0. 6. 3.] 
adversary cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6  6] -> size -> 30 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.33869934082031






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 6. 3.] 
cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3
  6  3  6  3  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  0. 10.  4.  2.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 11. 10.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11] -> size -> 32 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  0. 10.  4.  2.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 11. 10.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11] -> size -> 32 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 20. 30.  8.  0. 10.  4.  2.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 11. 10.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11] -> size -> 32 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  4.  2.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 11. 10.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11] -> size -> 32 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [ 8.  3. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11. 10.] 
expected returns: [[51.874176]
 [63.548912]
 [80.381134]
 [80.381134]
 [48.245483]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11. 11. 10.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  4.  2.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0] -> size -> 29 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 63.39563751220703



action possibilites: [-1] 
expected returns: [[140.69005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11. 10.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  4.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0] -> size -> 29 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 89.06195831298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[121.5574 ]
 [140.80267]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11. 10.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  4.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0] -> size -> 29 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 140.69004821777344






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 6. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  4.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [29.  0.  3. 29. 10.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15. 11.  8.  3.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15] -> size -> 33 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  4.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [29.  0.  3. 29. 10.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15. 11.  8.  3.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15] -> size -> 33 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  3.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [29.  0.  3. 29. 10.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15. 11.  8.  3.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15] -> size -> 33 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [29.  0.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[ 74.27994 ]
 [111.33897 ]
 [111.33897 ]
 [ 70.209656]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 29. 10.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15. 11.  8.  3.
 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  3.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6. 11.  6. 10.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0 11] -> size -> 30 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 140.80267333984375



action possibilites: [-1. 29.  8.] 
expected returns: [[129.74185]
 [145.02934]
 [122.54376]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  8.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15. 11.  8.  3.
 11. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  3.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6. 11.  6. 10.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0 11] -> size -> 30 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 87.37936401367188



action possibilites: [-1.] 
expected returns: [[171.37982]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15. 11.  8.  3.
 11. 10. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  3.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6. 11.  6. 10.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0 11] -> size -> 30 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 128.23683166503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[159.63112]
 [170.86948]
 [169.4464 ]
 [177.06609]
 [167.50095]
 [165.76224]
 [170.632  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15. 11.  8.  3.
 11. 10. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  3.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6. 11.  6. 10.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0 11] -> size -> 30 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 171.37982177734375



buy possibilites: [-1] 
expected returns: [[174.20195]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15. 11.  8.  3.
 11. 10. 10.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6. 11.  6. 10.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0 11] -> size -> 30 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 239 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 177.06607055664062






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [3. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 3.] 
cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6. 11.  6. 10.
  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [25. 10. 11. 10.  8.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15. 11.  8.  3.
 11. 10. 10.  8. 11. 29. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11] -> size -> 34 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 3.] 
cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6. 11.  6. 10.
  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [25. 10. 11. 10.  8.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15. 11.  8.  3.
 11. 10. 10.  8. 11. 29. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11] -> size -> 34 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 3.] 
cards in discard: [14.  3.  8.  3.  0.  6.  3.  6.  0.  3.  6.  0.  8.  0.  6. 11.  6. 10.
  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0 11  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [25. 10. 11. 10.  8.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15. 11.  8.  3.
 11. 10. 10.  8. 11. 29. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11] -> size -> 34 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [25. 10. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11. 10.  8.] 
expected returns: [[38.62123 ]
 [69.97878 ]
 [24.565058]
 [58.965347]
 [24.565058]
 [29.252237]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 11. 10.  8.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.  3.  0. 10. 10. 10.  8. 15. 11.  8.  3.
 11. 10. 10.  8. 11. 29. 29.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0 11  0] -> size -> 31 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 174.2019500732422



action possibilites: [-1] 
expected returns: [[70.99712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  8.  8. 25.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0 11  0] -> size -> 31 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 69.97880554199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[63.75556 ]
 [73.215576]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.  8.  8. 25.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0 11  0] -> size -> 31 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.99712371826172






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [8. 0. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 10  8  3  3  3  3  8  0  6  3  6  0  6  0  6  3  6  3
  6  3  6  6  0 11  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [15. 10.  3. 10. 29.] 
adversary cards in discard: [25. 10. 11. 10.  8.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11] -> size -> 34 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [15. 10.  3. 10. 29.] 
adversary cards in discard: [25. 10. 11. 10.  8.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11] -> size -> 34 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [15. 10.  3. 10. 29.] 
adversary cards in discard: [25. 10. 11. 10.  8.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11] -> size -> 34 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [15. 10.  3. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 29.] 
expected returns: [[ -8.942833 ]
 [ -2.7729018]
 [-15.923026 ]
 [-15.923026 ]
 [ 43.40074  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  3. 10. 29.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  6.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 73.21559143066406



action possibilites: [-1. 15. 10. 10.] 
expected returns: [[-34.458736]
 [-26.112394]
 [-23.191025]
 [-23.191025]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10.  0.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  6.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 2.0478339195251465



action possibilites: [-1. 15. 10. 11.] 
expected returns: [[72.24631 ]
 [85.56058 ]
 [67.986275]
 [98.75065 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0. 11.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11] -> size -> 34 
action values: 2 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  6.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -23.190996170043945



action possibilites: [-1. 15. 10.] 
expected returns: [[-11.050195 ]
 [ 29.254133 ]
 [  5.0271454]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10
 10 29  8 10 10  3 10 11 15 11 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  0. 14.  6.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  64   0] 
sum of rewards: 239 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 108.28522491455078



action possibilites: [-1] 
expected returns: [[-57.220154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 10. 11. 15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  0. 14.  6.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 29.254117965698242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-65.34858  ]
 [ 17.08865  ]
 [-21.681143 ]
 [ -2.3002243]
 [ 29.815767 ]
 [-20.962307 ]
 [ 65.7821   ]
 [-78.225464 ]
 [-53.662163 ]
 [ -6.608268 ]
 [-56.81304  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 10. 11. 15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  0. 14.  6.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -57.22015380859375



buy possibilites: [-1] 
expected returns: [[-1.7337596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 10. 11. 15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  7.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  0. 14.  6.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 323 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 65.7821044921875






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 14.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  6.  3.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  7.  9. 10.  1. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0. 11.] 
adversary cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15 29] -> size -> 35 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  6.  3.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  7.  9. 10.  1. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0. 11.] 
adversary cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15 29] -> size -> 35 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  6.  3.] 
cards in discard: [8. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  7.  9. 10.  1. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0. 11.] 
adversary cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15 29] -> size -> 35 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [10.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[29.561201]
 [25.757761]
 [53.256157]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 11.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  7.  9. 10.  1. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0] -> size -> 28 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.7337596416473389



action possibilites: [-1] 
expected returns: [[83.97935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15 29 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0] -> size -> 28 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 62.837135314941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 70.53791 ]
 [ 99.83743 ]
 [ 92.304726]
 [112.49414 ]
 [ 89.40397 ]
 [ 81.10895 ]
 [ 88.98892 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15 29 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 20. 30.  8.  0. 10.  2.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0] -> size -> 28 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.9793472290039



buy possibilites: [-1] 
expected returns: [[9.13307]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0] -> size -> 28 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 112.49409484863281






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [ 8.  0.  3.  0. 14.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10.  3.  3.  8.  3.] 
adversary cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 37 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [ 8.  0.  3.  0. 14.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10.  3.  3.  8.  3.] 
adversary cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 37 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10.  3.  3.  8.  3.] 
adversary cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 37 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [10.  3.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-156.83963]
 [-152.29346]
 [-140.65567]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  8.  3.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 25 11 25  8 11 10  8 10  8 11 25  3 10 10
 29  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3. 10.  0.  3.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0] -> size -> 29 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.13306999206543



action possibilites: [-1] 
expected returns: [[67.77686]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3. 10.  0.  3.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0] -> size -> 29 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -132.956298828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[37.494675]
 [64.41007 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3. 10.  0.  3.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0] -> size -> 29 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.77686309814453






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  3.] 
cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10.  8.  3. 11. 29.] 
adversary cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.  8.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 36 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10.  8.  3. 11. 29.] 
adversary cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.  8.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 36 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10.  8.  3. 11. 29.] 
adversary cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.  8.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 36 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10.  8.  3. 11. 29.] 
adversary cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.  8.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 36 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [10.  8.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 29.] 
expected returns: [[-6.255861  ]
 [-4.9860687 ]
 [ 0.90534115]
 [ 7.1531067 ]
 [27.0178    ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3. 11. 29.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.  8.  3.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6.  0. 11.  6.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.40998840332031



action possibilites: [-1. 10. 11. 25.] 
expected returns: [[ 9.114117]
 [10.325161]
 [25.693296]
 [38.029533]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 25.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.  8.  3.  3.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6.  0. 11.  6.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 9.546407699584961



action possibilites: [-1] 
expected returns: [[14.723375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 11.  0.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.  8.  3.  3.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6.  0. 11.  6.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 38.02952575683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 6.3885403]
 [16.78362  ]
 [16.458357 ]
 [14.906908 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11. 11.  0.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.  8.  3.  3.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 20. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6.  0. 11.  6.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.72337532043457



buy possibilites: [-1] 
expected returns: [[51.01052]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11. 11.  0.] 
cards in discard: [25. 10. 11. 10.  8.  8. 25.  3. 15. 29. 29. 10. 11. 15. 10. 15. 11. 11.
 10.  0.  0.  0.  8.  3.  3.  3.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6.  0. 11.  6.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 16.783632278442383






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.  6.] 
cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10. 11. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3] -> size -> 37 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6.] 
cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10. 11. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3] -> size -> 37 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6.] 
cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10. 11. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3] -> size -> 37 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [10. 11. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 11. 10.] 
expected returns: [[ 91.03311]
 [ 88.63027]
 [117.18162]
 [139.76901]
 [117.18162]
 [ 88.63027]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29. 11. 10.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 6. 6. 3. 6.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.  0. 11.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0] -> size -> 31 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 51.010520935058594



action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[ 7.1074486]
 [32.61361  ]
 [70.056816 ]
 [70.056816 ]
 [32.61361  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 10.] 
cards in discard: [8.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 6. 6. 3. 6.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.  0. 11.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0] -> size -> 31 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 113.06403350830078



action possibilites: [-1] 
expected returns: [[129.29553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.] 
cards in discard: [ 8. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  6.] 
adversary cards in hand: [0. 6. 6. 3. 6.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.  0. 11.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0] -> size -> 31 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 92.21212768554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[126.393875]
 [129.8017  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.] 
cards in discard: [ 8. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  6.] 
adversary cards in hand: [0. 6. 6. 3. 6.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.  0. 11.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0] -> size -> 31 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.2955322265625






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [0. 6. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3. 6.] 
cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.  0. 11.  0.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  6.] 
adversary cards in hand: [10. 11. 11. 15.  3.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15] -> size -> 38 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 6.] 
cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.  0. 11.  0.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  6.] 
adversary cards in hand: [10. 11. 11. 15.  3.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15] -> size -> 38 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 6.] 
cards in discard: [ 8.  0.  3.  0. 14.  6.  3.  0.  0.  0.  8.  3.  3.  0. 10.  0.  3.  0.
  3.  0.  0. 11.  0.  6.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  6.] 
adversary cards in hand: [10. 11. 11. 15.  3.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15] -> size -> 38 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [10. 11. 11. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 15.] 
expected returns: [[48.859375]
 [51.40361 ]
 [71.44504 ]
 [71.44504 ]
 [64.4304  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 15.  3.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 3. 14.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0  0] -> size -> 32 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 129.8017120361328



action possibilites: [-1] 
expected returns: [[9.477966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15.  3.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  5.] 
adversary cards in hand: [ 3. 14.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0  0] -> size -> 32 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 82.10355377197266





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.710436 ]
 [ 7.2613754]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 15.  3.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  5.] 
adversary cards in hand: [ 3. 14.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0  0] -> size -> 32 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.47796630859375



buy possibilites: [-1] 
expected returns: [[-53.73368]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 15.  3.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  5.] 
adversary cards in hand: [ 3. 14.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0  0] -> size -> 32 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -50   0   0   0   0] 
sum of rewards: 115 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 17.71038055419922






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8.  0.  6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  5.] 
adversary cards in hand: [ 0. 11.  3. 11. 10.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0] -> size -> 40 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  8.  0.  6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  5.] 
adversary cards in hand: [ 0. 11.  3. 11. 10.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0] -> size -> 40 
adversary victory points: 6
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11.  3. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[-17.739216]
 [ 33.113235]
 [ 33.113235]
 [ -8.31852 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 11. 10.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  5.] 
adversary cards in hand: [6. 0. 6. 8. 6.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0  0] -> size -> 32 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -53.733680725097656



action possibilites: [-1] 
expected returns: [[19.754068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 10.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  4.] 
adversary cards in hand: [6. 0. 6. 8. 6.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0  0] -> size -> 32 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -60   0   0  64   0] 
sum of rewards: 169 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 43.84983825683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.096985]
 [32.558464]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 10.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  4.] 
adversary cards in hand: [6. 0. 6. 8. 6.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0  0] -> size -> 32 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.75406837463379






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [6. 0. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 8. 6.] 
cards in discard: [ 3. 14.  8.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14 10  8  3  3  3  8  0  3  0  6  0  6  3  6  3  6  3  6  6
  0 11  0  0  0  0  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  4.] 
adversary cards in hand: [29.  3. 10. 11. 10.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15] -> size -> 41 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 3. 14.  8.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  4.] 
adversary cards in hand: [29.  3. 10. 11. 10.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15] -> size -> 41 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 3. 14.  8.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  4.] 
adversary cards in hand: [29.  3. 10. 11. 10.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15] -> size -> 41 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [29.  3. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 10.] 
expected returns: [[29.56376 ]
 [67.348976]
 [25.311304]
 [48.683464]
 [25.311304]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10. 11. 10.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  4.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0] -> size -> 29 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.55845642089844



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[26.474783]
 [ 9.427841]
 [40.845497]
 [ 9.427841]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  4.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0] -> size -> 29 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 40.595680236816406



action possibilites: [-1] 
expected returns: [[-13.192717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0] -> size -> 29 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 119 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 48.68031311035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-32.48637 ]
 [-15.188292]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0] -> size -> 29 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: -13.192716598510742






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3. 14.  8.  0.  6.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [15.  3. 15.  8.  0.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15] -> size -> 42 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3. 14.  8.  0.  6.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 30. 30. 19. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [15.  3. 15.  8.  0.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15] -> size -> 42 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 18. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [15.  3. 15.  8.  0.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15] -> size -> 42 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [15.  3. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.  8.] 
expected returns: [[-63.450317]
 [-58.97042 ]
 [-58.97042 ]
 [-65.2135  ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.  8.  0.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29
  8 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 18. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [6. 3. 3. 3. 6.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3] -> size -> 30 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -15.188332557678223



action possibilites: [-1] 
expected returns: [[-30.987661]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 30. 30. 18. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [6. 3. 3. 3. 6.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3] -> size -> 30 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -58.97047424316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-34.043938]
 [-27.466314]
 [-29.706837]
 [-18.678417]
 [-30.100956]
 [-32.05804 ]
 [-30.987665]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  8.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 30. 30. 18. 30.  8.  0. 10.  1.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [6. 3. 3. 3. 6.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3] -> size -> 30 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -30.987661361694336



buy possibilites: [-1] 
expected returns: [[-140.90244]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  8.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [6. 3. 3. 3. 6.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3] -> size -> 30 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -70   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -18.678499221801758






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [6. 3. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 3. 6.] 
cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [25.  3. 10. 25. 29.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10. 11. 15.  3. 15.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 6.] 
cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [25.  3. 10. 25. 29.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10. 11. 15.  3. 15.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 6.] 
cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [25.  3. 10. 25. 29.] 
adversary cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10. 11. 15.  3. 15.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [25.  3. 10. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 25. 29.] 
expected returns: [[-46.07798 ]
 [-32.717934]
 [-40.856438]
 [-32.717934]
 [-32.614716]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 10. 25. 29.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10. 11. 15.  3. 15.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.  6.  3.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0] -> size -> 31 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -140.90243530273438



action possibilites: [-1. 25. 25.  8.] 
expected returns: [[-45.186523]
 [-33.051273]
 [-33.051273]
 [-53.9654  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  8.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10. 11. 15.  3. 15.  8.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.  6.  3.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0] -> size -> 31 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 4
Learning step: 0
desired expected reward: -32.193382263183594



action possibilites: [-1] 
expected returns: [[2.2514791]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  8.  0.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10. 11. 15.  3. 15.  8.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.  6.  3.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0] -> size -> 31 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -33.051292419433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-13.246281  ]
 [  1.5616722 ]
 [ -0.25278306]
 [  2.2514753 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  8.  0.] 
cards in discard: [ 8. 15. 29. 11. 10. 11. 10. 15.  0. 11. 10. 11. 15.  3. 15. 11.  0.  3.
 11. 10.  0. 15. 29. 11.  3. 10. 10. 11. 15.  3. 15.  8.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.  6.  3.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0] -> size -> 31 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.251479148864746






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.  6.  3.  3.  3.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [29. 11.  3.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.  6.  3.  3.  3.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  3.] 
adversary cards in hand: [29. 11.  3.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.  6.  3.  3.  3.
  6. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  2.] 
adversary cards in hand: [29. 11.  3.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [29. 11.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25.] 
expected returns: [[-26.972036]
 [123.98812 ]
 [ 68.08428 ]
 [137.02472 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3.  3. 25.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  2.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.  6.  3.  3.  3.
  6. 15. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15] -> size -> 32 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 2.251479148864746



action possibilites: [-1] 
expected returns: [[12.953215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3.  3. 29. 15.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  2.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.  6.  3.  3.  3.
  6. 15. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15] -> size -> 32 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 137.02471923828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-10.740041]
 [ 10.01126 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  3.  3. 29. 15.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  2.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.  6.  3.  3.  3.
  6. 15. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15] -> size -> 32 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.953214645385742






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.  6.  3.  3.  3.
  6. 15. 10.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 8. 11. 10.  0.  0.] 
adversary cards in discard: [25. 29. 11.  3.  3. 29. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.  6.  3.  3.  3.
  6. 15. 10.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 30. 30. 18. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 8. 11. 10.  0.  0.] 
adversary cards in discard: [25. 29. 11.  3.  3. 29. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3. 14.  8.  0.  6.  8.  6.  3.  0.  0.  3.  3.  0.  0.  6.  3.  3.  3.
  6. 15. 10.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 30. 30. 17. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 8. 11. 10.  0.  0.] 
adversary cards in discard: [25. 29. 11.  3.  3. 29. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
adversary victory points: 6
player victory points: 5 





Player: 0 
cards in hand: [ 8. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[14.388041 ]
 [ 7.662841 ]
 [50.76873  ]
 [ 1.1513848]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  0.  0.] 
cards in discard: [25. 29. 11.  3.  3. 29. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 17. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15  3] -> size -> 33 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.011107444763184



action possibilites: [-1] 
expected returns: [[41.46393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.] 
cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 17. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15  3] -> size -> 33 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -80   0   0  27   0] 
sum of rewards: -8 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 30.621870040893555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[38.804535]
 [56.19262 ]
 [56.79496 ]
 [46.45051 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.] 
cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 17. 30.  8.  0. 10.  0.  2.  7.  7.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15  3] -> size -> 33 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.46392822265625



buy possibilites: [-1] 
expected returns: [[137.48608]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.] 
cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 17. 30.  8.  0. 10.  0.  1.  7.  7.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15  3] -> size -> 33 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -90   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 56.79497528076172






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 17. 30.  8.  0. 10.  0.  1.  7.  7.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 3. 15. 11. 11.  0.] 
adversary cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8] -> size -> 44 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15  3 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 17. 30.  8.  0. 10.  0.  1.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 3. 15. 11. 11.  0.] 
adversary cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8] -> size -> 44 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15  3 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 17. 30.  8.  0. 10.  0.  1.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 3. 15. 11. 11.  0.] 
adversary cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8] -> size -> 44 
adversary victory points: 6
player victory points: 5 





Player: 0 
cards in hand: [ 3. 15. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11.] 
expected returns: [[113.00833]
 [130.18793]
 [155.10715]
 [155.10715]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 11. 11.  0.] 
cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 17. 30.  8.  0. 10.  0.  1.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  8.  0.  3. 15.] 
adversary cards in discard: [29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15  3 29] -> size -> 34 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 137.486083984375



action possibilites: [-1] 
expected returns: [[132.89473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 11.  0.] 
cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 30.  8.  0. 10.  0.  1.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  8.  0.  3. 15.] 
adversary cards in discard: [29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15  3 29] -> size -> 34 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[  -5    0    0   30    0    0   20    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: -28 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 137.71063232421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[105.86381]
 [131.66838]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 11.  0.] 
cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 17. 30.  8.  0. 10.  0.  1.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  8.  0.  3. 15.] 
adversary cards in discard: [29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15  3 29] -> size -> 34 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.8947296142578






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  3. 15.] 
cards in discard: [29. 11.  0.  3.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14 10  8  3  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0
  0  0  0  0  0  3  0 15  3 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 30.  8.  0. 10.  0.  1.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [25. 15. 15. 15. 11.] 
adversary cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.  1. 11.  3. 15.
 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8  1] -> size -> 45 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.] 
cards in discard: [29. 11.  0.  3.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14 10  8  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0  0  0
  0  0  0  3  0 15  3 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 30.  8.  0. 10.  0.  1.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [25. 15. 15. 15. 11.] 
adversary cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.  1. 11.  3. 15.
 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8  1] -> size -> 45 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [29. 11.  0.  3.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14 10  8  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0  0  0
  0  0  0  3  0 15  3 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 17. 30.  8.  0. 10.  0.  1.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [25. 15. 15. 15. 11.] 
adversary cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.  1. 11.  3. 15.
 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8  1] -> size -> 45 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [25. 15. 15. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 15. 15. 11.] 
expected returns: [[ 8.977105]
 [43.81173 ]
 [10.033685]
 [10.033685]
 [10.033685]
 [27.810616]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15. 15. 15. 11.] 
cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.  1. 11.  3. 15.
 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 30.  8.  0. 10.  0.  1.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [14.  0.  0.  6.  3.] 
adversary cards in discard: [29. 11.  0.  3.  0.  0.  8.  0. 15.] 
adversary owned cards: [ 0  0 14 10  8  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0  0  0
  0  0  0  3  0 15  3 29] -> size -> 32 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 131.66836547851562



action possibilites: [-1] 
expected returns: [[-56.236084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 11. 10. 15.] 
cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.  1. 11.  3. 15.
 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 30.  8.  0. 10.  0.  1.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [14.  0.  0.  6.  3.] 
adversary cards in discard: [29. 11.  0.  3.  0.  0.  8.  0. 15.] 
adversary owned cards: [ 0  0 14 10  8  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0  0  0
  0  0  0  3  0 15  3 29] -> size -> 32 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 43.81166076660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-73.15964 ]
 [-56.236107]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 15. 11. 10. 15.] 
cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.  1. 11.  3. 15.
 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 17. 30.  8.  0. 10.  0.  1.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [14.  0.  0.  6.  3.] 
adversary cards in discard: [29. 11.  0.  3.  0.  0.  8.  0. 15.] 
adversary owned cards: [ 0  0 14 10  8  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0  0  0
  0  0  0  3  0 15  3 29] -> size -> 32 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -56.236083984375






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [14.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  6.  3.] 
cards in discard: [29. 11.  0.  3.  0.  0.  8.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14 10  8  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0  0  0
  0  0  0  3  0 15  3 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 30.  8.  0. 10.  0.  1.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 3. 10. 11. 10.  0.] 
adversary cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.  1. 11.  3. 15.
 11.  0. 25. 15. 15. 15. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8  1] -> size -> 45 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  6.  3.] 
cards in discard: [29. 11.  0.  3.  0.  0.  8.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14 10  8  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0  0  0
  0  0  0  3  0 15  3 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 17. 30.  8.  0. 10.  0.  1.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 3. 10. 11. 10.  0.] 
adversary cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.  1. 11.  3. 15.
 11.  0. 25. 15. 15. 15. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8  1] -> size -> 45 
adversary victory points: 6
player victory points: 4 


Player 0 won the game! 



Player 0 bought cards:
Copper: 1 
Silver: 0 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 6 
Witch: 3 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3. 10. 11. 10.  0.] 
cards in discard: [25. 29. 11.  3.  3. 29. 15.  1.  8. 11.  8. 10.  0.  0.  1. 11.  3. 15.
 11.  0. 25. 15. 15. 15. 11. 10. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 25 11 25  8 11 10  8 10  8 11 25  3 10 10 29  8
 10 10  3 10 11 15 11 15 29 15 11  3 15 15  0 15 15 11  1  8  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 30.  8.  0. 10.  0.  0.  7.  6.  9. 10.  1. 10.  2.] 
adversary cards in hand: [14.  0.  0.  6.  3.] 
adversary cards in discard: [29. 11.  0.  3.  0.  0.  8.  0. 15.  8.] 
adversary owned cards: [ 0  0 14 10  8  3  3  8  0  3  0  0  3  6  3  6  3  6  6  0 11  0  0  0
  0  0  0  3  0 15  3 29  8] -> size -> 33 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[     -5 3000000       0      60       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000055 

action type: buy - action -1.0
Learning step: 300011.125
desired expected reward: 299954.875



