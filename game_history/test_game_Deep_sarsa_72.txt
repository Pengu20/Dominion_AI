 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[54.658768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -4.4374589920043945
desired expected reward: 34.937129974365234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 52.860275]
 [ 82.073715]
 [ 71.31217 ]
 [ 36.00096 ]
 [ 69.69682 ]
 [ 90.263275]
 [ 69.77426 ]
 [111.096756]
 [ 51.208313]
 [ 60.051758]
 [ 79.73928 ]
 [ 52.38887 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.40406036376953



buy possibilites: [-1] 
expected returns: [[28.628965]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 111.09676361083984






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[44.337486]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.628965377807617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[43.909554]
 [67.30432 ]
 [59.545517]
 [28.37049 ]
 [73.910255]
 [58.217278]
 [50.482117]
 [44.32923 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 42.774864196777344



buy possibilites: [-1] 
expected returns: [[26.482756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 73.9102554321289






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  3.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[19.64091]
 [40.29117]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.482755661010742



action possibilites: [-1] 
expected returns: [[26.244053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 48.606842041015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.533546]
 [37.637703]
 [11.861119]
 [36.4758  ]
 [26.198181]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.24405288696289



buy possibilites: [-1] 
expected returns: [[22.568777]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 37.63770294189453






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[36.08741]
 [85.28518]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.568777084350586



action possibilites: [-1.] 
expected returns: [[68.024124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 84.09956359863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 69.013054]
 [104.37476 ]
 [ 91.62205 ]
 [ 58.999817]
 [ 47.899918]
 [ 89.846565]
 [113.2852  ]
 [ 89.91873 ]
 [149.56377 ]
 [136.84235 ]
 [ 67.05158 ]
 [101.64425 ]
 [ 78.01922 ]
 [ 66.629814]
 [101.59859 ]
 [ 69.15745 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 68.02412414550781



buy possibilites: [-1] 
expected returns: [[49.43506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 295 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 149.56378173828125






Player: 1 
cards in hand: [ 3. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [0. 3. 0. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25] -> size -> 15 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.64639]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.43505859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.685411]
 [49.516655]
 [42.61242 ]
 [17.088688]
 [55.19496 ]
 [41.508675]
 [34.83654 ]
 [29.93128 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.995386123657227



buy possibilites: [-1] 
expected returns: [[22.355164]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 55.19496154785156






Player: 1 
cards in hand: [0. 3. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10. 25. 11.  3.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10. 25. 11.  3.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 25. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11.] 
expected returns: [[15.669592]
 [19.330822]
 [54.647278]
 [35.077957]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25. 11.  3.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [0. 3. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.35516357421875



action possibilites: [-1] 
expected returns: [[54.079666]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3.  0.  0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [0. 3. 3. 8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 52.674049377441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[65.54858 ]
 [90.43735 ]
 [81.71317 ]
 [48.60759 ]
 [97.29903 ]
 [80.5736  ]
 [71.87676 ]
 [63.740646]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  3.  0.  0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [0. 3. 3. 8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.07966613769531



buy possibilites: [-1] 
expected returns: [[46.242043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  3.  0.  0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [0. 3. 3. 8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 97.29902648925781






Player: 1 
cards in hand: [ 0.  0.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  0.] 
cards in discard: [0. 3. 3. 8. 3. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 8. 3. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 8. 3. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  8.  3.  6. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.552309]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [11. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6 10] -> size -> 15 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  60   0   0   0   0   0   0   0   0   0   0 305   0] 
sum of rewards: 360 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 111.36727905273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.863562]
 [36.479492]
 [13.184568]
 [35.16507 ]
 [26.569017]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [11. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6 10] -> size -> 15 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.89348793029785



buy possibilites: [-1] 
expected returns: [[31.82718]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [11. 29.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6 10] -> size -> 15 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 101 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 36.4794921875






Player: 1 
cards in hand: [3. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 10.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3] -> size -> 18 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 10.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3] -> size -> 18 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 10.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3] -> size -> 18 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[40.735153]
 [69.74869 ]
 [47.13794 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 10.] 
cards in discard: [11. 29.  3.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0. 10.] 
adversary cards in discard: [8. 3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6 10  8] -> size -> 16 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.827180862426758



action possibilites: [-1] 
expected returns: [[31.818811]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0. 10.] 
adversary cards in discard: [8. 3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6 10  8] -> size -> 16 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 72.18692016601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[37.536003]
 [58.572327]
 [50.97544 ]
 [26.040981]
 [64.56109 ]
 [49.946205]
 [42.962685]
 [37.342415]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0. 10.] 
adversary cards in discard: [8. 3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6 10  8] -> size -> 16 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.818811416625977



buy possibilites: [-1] 
expected returns: [[41.563744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0. 10.] 
adversary cards in discard: [8. 3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6 10  8] -> size -> 16 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 64.56108856201172






Player: 1 
cards in hand: [14.  8.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  0. 10.] 
cards in discard: [8. 3. 0. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  8  6 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3. 11.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [8. 3. 0. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3. 11.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 3. 0. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3. 11.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[30.14696 ]
 [48.546295]
 [41.074753]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3. 11.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 11. 11.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [8. 3. 0. 8. 0. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8] -> size -> 13 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.563743591308594



action possibilites: [-1] 
expected returns: [[53.992928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  3.  3.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 11. 11.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [8. 3. 0. 8. 0. 0. 8. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8 6] -> size -> 14 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.520233154296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[54.549614]
 [68.304214]
 [44.878166]
 [66.74032 ]
 [59.322784]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  3.  3.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 11. 11.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [8. 3. 0. 8. 0. 0. 8. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8 6] -> size -> 14 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.99292755126953



buy possibilites: [-1] 
expected returns: [[56.12805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  3.  3.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 11. 11.  0.  0.  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [8. 3. 0. 8. 0. 0. 8. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8 6] -> size -> 14 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 68.30419921875






Player: 1 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [8. 3. 0. 8. 0. 0. 8. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3] -> size -> 21 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [8. 3. 0. 8. 0. 0. 8. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3] -> size -> 21 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [8. 3. 0. 8. 0. 0. 8. 0. 6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8 6 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3] -> size -> 21 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[43.02529]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8 6 0] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.1280517578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[44.280045]
 [56.22323 ]
 [32.591003]
 [55.517616]
 [41.750137]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8 6 0] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 40.97404479980469



buy possibilites: [-1] 
expected returns: [[41.72895]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8 6 0] -> size -> 15 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: 221 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 56.22322082519531






Player: 1 
cards in hand: [0. 0. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8 6 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0. 11.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3] -> size -> 22 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 6 8 6 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0. 11.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3] -> size -> 22 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0. 11.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3] -> size -> 22 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[29.133593]
 [55.496468]
 [33.054337]
 [55.496468]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0. 11.] 
cards in discard: [3. 3. 0. 3. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [10.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10] -> size -> 16 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.72895050048828



action possibilites: [-1] 
expected returns: [[39.872177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [ 3.  3.  0.  3.  0.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [10.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10] -> size -> 16 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 252 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 55.61768341064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[47.636665]
 [62.780983]
 [32.613396]
 [61.583138]
 [47.180313]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [ 3.  3.  0.  3.  0.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [10.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10] -> size -> 16 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.87217712402344



buy possibilites: [-1] 
expected returns: [[64.42056]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [ 3.  3.  0.  3.  0.  3. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [10.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10] -> size -> 16 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 62.780967712402344






Player: 1 
cards in hand: [0. 0. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 6.] 
cards in discard: [10.  0.  0.  8.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29. 11.  3. 10.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  3. 10.  3. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3] -> size -> 24 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 6.] 
cards in discard: [10.  0.  0.  8.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 25. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29. 11.  3. 10.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  3. 10.  3. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3] -> size -> 24 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 6.] 
cards in discard: [10.  0.  0.  8.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29. 11.  3. 10.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  3. 10.  3. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3] -> size -> 24 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [29. 11.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[26.777063]
 [56.305428]
 [50.938583]
 [24.033445]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3. 10.  0.] 
cards in discard: [ 3.  3.  0.  3.  0.  3. 10.  3. 11.  0. 10.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  8.  0.  6.  0.  0.  0.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10  0] -> size -> 17 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.42056274414062



action possibilites: [-1. 11. 10.] 
expected returns: [[48.805046]
 [59.8472  ]
 [46.475662]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  0.  3.] 
cards in discard: [ 3.  3.  0.  3.  0.  3. 10.  3. 11.  0. 10.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  8.  0.  6.  0.  0.  0.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10  0] -> size -> 17 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 56.01744079589844



action possibilites: [-1] 
expected returns: [[110.541565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.] 
cards in discard: [ 3.  3.  0.  3.  0.  3. 10.  3. 11.  0. 10.  0. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  8.  0.  6.  0.  0.  0.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10  0] -> size -> 17 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 302 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 63.404457092285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 96.682274]
 [112.51021 ]
 [ 82.74447 ]
 [109.86174 ]
 [113.26546 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.] 
cards in discard: [ 3.  3.  0.  3.  0.  3. 10.  3. 11.  0. 10.  0. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  8.  0.  6.  0.  0.  0.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10  0] -> size -> 17 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.54156494140625






Player: 1 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [10.  0.  0.  8.  0.  6.  0.  0.  0.  8.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 11.  3.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  3. 10.  3. 11.  0. 10.  0. 11. 10. 29. 11.  3. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10] -> size -> 25 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [10.  0.  0.  8.  0.  6.  0.  0.  0.  8.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 25. 30.  8.  8. 10.  6.  7.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 11.  3.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  3. 10.  3. 11.  0. 10.  0. 11. 10. 29. 11.  3. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10] -> size -> 25 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [10.  0.  0.  8.  0.  6.  0.  0.  0.  8.  3.  6.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8.  8. 10.  6.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 11.  3.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  3. 10.  3. 11.  0. 10.  0. 11. 10. 29. 11.  3. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10] -> size -> 25 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[38.523537]
 [91.63994 ]
 [66.95932 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 11.  3.] 
cards in discard: [ 3.  3.  0.  3.  0.  3. 10.  3. 11.  0. 10.  0. 11. 10. 29. 11.  3. 10.
  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  8. 10.  6.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10  0  8] -> size -> 18 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 113.26544952392578



action possibilites: [-1] 
expected returns: [[40.94348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  7. 10.  6.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10  0  8  6] -> size -> 19 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 91.63995361328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[51.682068]
 [77.13101 ]
 [68.55663 ]
 [34.77262 ]
 [84.127625]
 [67.19873 ]
 [58.624344]
 [51.474747]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 25. 30.  8.  7. 10.  6.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10  0  8  6] -> size -> 19 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.9434814453125



buy possibilites: [-1] 
expected returns: [[69.40962]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  3.  0.] 
cards in discard: [11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10  0  8  6] -> size -> 19 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 84.12761688232422






Player: 1 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  6  8  6  0 10  0  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3. 10.  0.  3.] 
adversary cards in discard: [11. 25.  0.  0. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11] -> size -> 26 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  8  6  8  6  0 10  0  8  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3. 10.  0.  3.] 
adversary cards in discard: [11. 25.  0.  0. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11] -> size -> 26 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  8  6  8  6  0 10  0  8  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3. 10.  0.  3.] 
adversary cards in discard: [11. 25.  0.  0. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11] -> size -> 26 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [10.  3. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[55.003494]
 [53.458244]
 [53.458244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  0.  3.] 
cards in discard: [11. 25.  0.  0. 11.  3.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 0.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  6  8  6  0 10  0  8  6] -> size -> 17 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.40962219238281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[48.44919 ]
 [38.545235]
 [56.28164 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  0.  3.] 
cards in discard: [11. 25.  0.  0. 11.  3.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 0.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  6  8  6  0 10  0  8  6] -> size -> 17 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 56.933937072753906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 6. 0.] 
cards in discard: [6. 8. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  6  8  6  0 10  0  8  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 11.  3.] 
adversary cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11] -> size -> 26 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [6. 8. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  8  8  6  0 10  0  8  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 11.  3.] 
adversary cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11] -> size -> 26 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [6. 8. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  8  8  6  0 10  0  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 11.  3.] 
adversary cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11] -> size -> 26 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [6. 8. 3. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  8  8  6  0 10  0  8  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 11.  3.] 
adversary cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11] -> size -> 26 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[33.310463]
 [35.51805 ]
 [35.470596]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 11.  3.] 
cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [6. 8. 3. 0. 0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  8  6  0 10  0  8  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 56.281639099121094



action possibilites: [-1] 
expected returns: [[50.872704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3.] 
cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [6. 8. 3. 0. 0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  8  6  0 10  0  8  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 39.901580810546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[39.245132]
 [35.847534]
 [51.137123]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  3.] 
cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [6. 8. 3. 0. 0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  8  6  0 10  0  8  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.872703552246094






Player: 1 
cards in hand: [ 0.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [6. 8. 3. 0. 0. 8. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  8  8  6  0 10  0  8  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 10.  0. 11.  3.] 
adversary cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3. 10. 11.  3. 29.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10] -> size -> 27 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [6. 8. 3. 0. 0. 8. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  8  8  8  6  0 10  0  8  6  0] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 10.  0. 11.  3.] 
adversary cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3. 10. 11.  3. 29.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10] -> size -> 27 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [6. 8. 3. 0. 0. 8. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3  3  8  8  8  6  0 10  0  8  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 10.  0. 11.  3.] 
adversary cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3. 10. 11.  3. 29.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10] -> size -> 27 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [6. 8. 3. 0. 0. 8. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3  3  8  8  8  6  0 10  0  8  6  0] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 10.  0. 11.  3.] 
adversary cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3. 10. 11.  3. 29.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10] -> size -> 27 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [6. 8. 3. 0. 0. 8. 6. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3  3  8  8  8  6  0 10  0  8  6  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 10.  0. 11.  3.] 
adversary cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3. 10. 11.  3. 29.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10] -> size -> 27 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10. 10.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[72.97689 ]
 [69.105705]
 [69.105705]
 [82.085594]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 11.  3.] 
cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3. 10. 11.  3. 29.  0.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  8  8  6  0 10  0  8  6  0  0] -> size -> 14 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 51.137123107910156



action possibilites: [-1] 
expected returns: [[139.76212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3.] 
cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3. 10. 11.  3. 29.  0.
  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  8  8  6  0 10  0  8  6  0  0] -> size -> 14 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 86.90827178955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[126.687126]
 [109.962776]
 [138.47737 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  3.] 
cards in discard: [11. 25.  0.  0. 11.  3.  3.  0. 10.  3. 10.  0.  3. 10. 11.  3. 29.  0.
  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  8  8  6  0 10  0  8  6  0  0] -> size -> 14 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.76211547851562






Player: 1 
cards in hand: [10.  0.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  8  8  6  0 10  0  8  6  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10] -> size -> 28 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8  8  8  6  0 10  0  8  6  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10] -> size -> 28 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8  8  8  6  0 10  0  8  6  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10] -> size -> 28 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8  8  8  6  0 10  0  8  6  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10] -> size -> 28 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11. 10. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[58.827324]
 [76.924995]
 [58.593315]
 [76.924995]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [3. 8. 8. 0. 6.] 
adversary cards in discard: [ 0.  8. 10.  0.  0.] 
adversary owned cards: [ 0  3  8  8  8  6  0 10  0  8  6  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 138.47735595703125



action possibilites: [-1] 
expected returns: [[70.54089]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 8. 8. 0. 6.] 
adversary cards in discard: [ 0.  8. 10.  0.  0.] 
adversary owned cards: [ 0  3  8  8  8  6  0 10  0  8  6  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 312 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 84.60125732421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[70.89881 ]
 [58.690544]
 [76.166595]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  0.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 8. 8. 0. 6.] 
adversary cards in discard: [ 0.  8. 10.  0.  0.] 
adversary owned cards: [ 0  3  8  8  8  6  0 10  0  8  6  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.5408935546875






Player: 1 
cards in hand: [3. 8. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 0. 6.] 
cards in discard: [ 0.  8. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  8  8  6  0 10  0  8  6  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  1. 10. 10.] 
adversary cards in hand: [10. 11. 10.  3.  0.] 
adversary cards in discard: [10. 11. 10. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10] -> size -> 29 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8. 0. 6.] 
cards in discard: [ 0.  8. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  8  8  6  0 10  0  8  6  0  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  1. 10. 10.] 
adversary cards in hand: [10. 11. 10.  3.  0.] 
adversary cards in discard: [10. 11. 10. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10] -> size -> 29 
adversary victory points: 8
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10. 11. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[37.620964]
 [37.8368  ]
 [56.41107 ]
 [37.8368  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  3.  0.] 
cards in discard: [10. 11. 10. 11.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  1. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  8  8  6  0 10  0  8  6  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 76.16659545898438



action possibilites: [-1] 
expected returns: [[38.08539]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.] 
cards in discard: [10. 11. 10. 11.  3.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  8  8  6  0 10  0  8  6  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 312 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 55.44580078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.62867]
 [23.03634]
 [41.28112]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.] 
cards in discard: [10. 11. 10. 11.  3.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  8  8  6  0 10  0  8  6  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.08538818359375






Player: 1 
cards in hand: [6. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  8  8  6  0 10  0  8  6  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3. 11.] 
adversary cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  8 10  0  8  6  0  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3. 11.] 
adversary cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  8 10  0  8  6  0  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3. 11.] 
adversary cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  8 10  0  8  6  0  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3. 11.] 
adversary cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[62.809113]
 [90.53084 ]
 [75.92338 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  3. 11.] 
cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  7. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [0. 8. 6.] 
adversary owned cards: [ 3  8  8  8 10  0  8  6  0  0  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 41.28112030029297



action possibilites: [-1] 
expected returns: [[131.299]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  3. 10.] 
cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [0. 8. 6. 6.] 
adversary owned cards: [ 3  8  8  8 10  0  8  6  0  0  0  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 87.51996612548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[100.061104]
 [ 78.635704]
 [126.69326 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.  3. 10.] 
cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [0. 8. 6. 6.] 
adversary owned cards: [ 3  8  8  8 10  0  8  6  0  0  0  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 131.2989959716797






Player: 1 
cards in hand: [0. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [0. 8. 6. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  8 10  0  8  6  0  0  0  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [0. 8. 6. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 10  8  6  0  0  6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 8. 6. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 10  8  6  0  0  6] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 8. 6. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 10  8  6  0  0  6  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[119.037766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  0.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 10  8  6  0  0  6  0] -> size -> 10 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 126.6932601928711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[115.147224]
 [135.47533 ]
 [130.74724 ]
 [101.58065 ]
 [125.1267  ]
 [146.29042 ]
 [128.35191 ]
 [153.26115 ]
 [115.42813 ]
 [136.26077 ]
 [123.391754]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  0.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 10  8  6  0  0  6  0] -> size -> 10 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 119.03776550292969



buy possibilites: [-1] 
expected returns: [[122.024376]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  8.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  0.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 10  8  6  0  0  6  0] -> size -> 10 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 423 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 153.2611541748047






Player: 1 
cards in hand: [ 6.  0.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 10.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 10  8  6  0  0  6  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  8.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 29. 11. 10.  3.] 
adversary cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29] -> size -> 31 
adversary victory points: 8
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 10  8  6  0  6  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  8.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 29. 11. 10.  3.] 
adversary cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29] -> size -> 31 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 10  8  6  0  6  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  8.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 29. 11. 10.  3.] 
adversary cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29] -> size -> 31 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[199.97049]
 [232.20541]
 [227.68822]
 [189.48875]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11. 10.  3.] 
cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10. 29.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  8.  9. 10.  0. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 8.] 
adversary cards in discard: [ 8.  6. 10.  8.] 
adversary owned cards: [ 8  8  8 10  8  6  0  6  0] -> size -> 9 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.02437591552734



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[230.6318 ]
 [241.52846]
 [215.63557]
 [215.63557]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3. 10.] 
cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10. 29.  0.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  8.  9. 10.  0. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 8.] 
adversary cards in discard: [ 8.  6. 10.  8.] 
adversary owned cards: [ 8  8  8 10  8  6  0  6  0] -> size -> 9 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 208.32359313964844



action possibilites: [-1] 
expected returns: [[155.21727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.] 
cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10. 29.  0.  3.  0.  0.  0.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 0. 6. 8.] 
adversary cards in discard: [ 8.  6. 10.  8.] 
adversary owned cards: [ 8  8  8 10  8  6  0  6  0] -> size -> 9 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 399 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 243.2946319580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[133.12372]
 [114.89689]
 [152.48482]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.] 
cards in discard: [10. 11. 10. 11.  3.  0. 10. 11. 10. 10.  3.  0. 25.  3.  0.  3. 11.  3.
 10. 29.  0.  3.  0.  0.  0.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 0. 6. 8.] 
adversary cards in discard: [ 8.  6. 10.  8.] 
adversary owned cards: [ 8  8  8 10  8  6  0  6  0] -> size -> 9 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 155.21726989746094






Player: 1 
cards in hand: [8. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 8.] 
cards in discard: [ 8.  6. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 10  8  6  0  6  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 10. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15] -> size -> 32 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6. 8.] 
cards in discard: [ 8.  6. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 10  8  6  0  6  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 10. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15] -> size -> 32 
adversary victory points: 8
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10. 10. 25.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25. 11.] 
expected returns: [[ 62.62574 ]
 [ 64.30872 ]
 [ 64.30872 ]
 [102.66171 ]
 [ 84.384834]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 25.  0. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  6. 10.  5.  6.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 10  8  6  0  6  0] -> size -> 9 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 152.4848175048828



action possibilites: [-1] 
expected returns: [[76.04572]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 11.  0. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  8  8 10  8  6  0  6  0  6] -> size -> 10 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 98.71839904785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[76.3012  ]
 [88.57374 ]
 [66.68092 ]
 [87.104355]
 [81.57726 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 11.  0. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 25. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  8  8 10  8  6  0  6  0  6] -> size -> 10 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.04572296142578



buy possibilites: [-1] 
expected returns: [[78.590324]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 11.  0. 15.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  8  8 10  8  6  0  6  0  6] -> size -> 10 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 361 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 88.57373046875






Player: 1 
cards in hand: [ 8.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  8.  0.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 10  8  6  0  6  0  6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 29. 10.  3. 11.] 
adversary cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3] -> size -> 33 
adversary victory points: 9
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 6 6 0 6] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 29. 10.  3. 11.] 
adversary cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3] -> size -> 33 
adversary victory points: 9
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 6 6 0 6] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 29. 10.  3. 11.] 
adversary cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3] -> size -> 33 
adversary victory points: 9
player victory points: -3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11. 29. 10.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 11.] 
expected returns: [[118.83244]
 [134.63754]
 [136.1015 ]
 [114.28479]
 [134.63754]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10.  3. 11.] 
cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 0 6] -> size -> 7 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.59032440185547



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[136.46758]
 [158.36534]
 [134.8828 ]
 [158.36534]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  3.] 
cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 0 6] -> size -> 7 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 125.08206939697266



action possibilites: [-1] 
expected returns: [[144.19084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.] 
cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [6. 6. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 0 6] -> size -> 7 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 459 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 162.0085906982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[123.85469]
 [111.95385]
 [143.70201]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.] 
cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [6. 6. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 0 6] -> size -> 7 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1
Learning step: 0
desired expected reward: 144.1908416748047






Player: 1 
cards in hand: [6. 6. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 6 6 0 6] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 11.  0.] 
adversary cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15] -> size -> 34 
adversary victory points: 9
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 6 6 0 6] -> size -> 7 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 11.  0.] 
adversary cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15] -> size -> 34 
adversary victory points: 9
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 8. 8.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 6 6 0 6 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 11.  0.] 
adversary cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15] -> size -> 34 
adversary victory points: 9
player victory points: -3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[76.267845]
 [67.074875]
 [82.09843 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11.  0.] 
cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [8. 8. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 0 6 0] -> size -> 8 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 143.7020263671875



action possibilites: [-1] 
expected returns: [[142.53967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [8. 8. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 0 6 0] -> size -> 8 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 439 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 86.73560333251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[123.89761]
 [137.26349]
 [114.65313]
 [133.41942]
 [151.81596]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [8. 8. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 0 6 0] -> size -> 8 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 142.5396728515625






Player: 1 
cards in hand: [8. 8. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 6 6 0 6 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10.  3.  3. 10.  3.] 
adversary cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15. 11.  0.
  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15] -> size -> 35 
adversary victory points: 9
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 0 6 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10.  3.  3. 10.  3.] 
adversary cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15. 11.  0.
  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15] -> size -> 35 
adversary victory points: 9
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 0 6 0] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10.  3.  3. 10.  3.] 
adversary cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15. 11.  0.
  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15] -> size -> 35 
adversary victory points: 9
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 0 6 0 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10.  3.  3. 10.  3.] 
adversary cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15. 11.  0.
  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15] -> size -> 35 
adversary victory points: 9
player victory points: -2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10.  3.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[162.1884 ]
 [145.76134]
 [145.76134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 10.  3.] 
cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15. 11.  0.
  3. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [8. 8. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 0 6 0 0] -> size -> 7 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 151.8159637451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[129.16582]
 [121.0713 ]
 [159.94035]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3. 10.  3.] 
cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15. 11.  0.
  3. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [8. 8. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 0 6 0 0] -> size -> 7 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 162.1884002685547



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 8. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 0 6 0 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0.  0. 10. 10.] 
adversary cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15. 11.  0.
  3. 10.  0. 10.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15] -> size -> 35 
adversary victory points: 9
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0.  0. 10. 10.] 
adversary cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15. 11.  0.
  3. 10.  0. 10.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15] -> size -> 35 
adversary victory points: 9
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0.  0. 10. 10.] 
adversary cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15. 11.  0.
  3. 10.  0. 10.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15] -> size -> 35 
adversary victory points: 9
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[ 83.35546]
 [105.75126]
 [ 81.09258]
 [ 81.09258]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 10.] 
cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15. 11.  0.
  3. 10.  0. 10.  3.  3. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 159.94033813476562



action possibilites: [-1] 
expected returns: [[23.185844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15. 11.  0.
  3. 10.  0. 10.  3.  3. 10.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 339 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 112.05482482910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[18.90929 ]
 [23.63419 ]
 [17.215979]
 [22.717463]
 [20.66523 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15. 11.  0.
  3. 10.  0. 10.  3.  3. 10.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 24. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.18584442138672



buy possibilites: [-1] 
expected returns: [[28.008373]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [ 3. 25. 10. 10.  0. 11.  0. 15.  3. 15. 29. 11. 10. 11.  3. 15. 11.  0.
  3. 10.  0. 10.  3.  3. 10.  3. 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 311 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 23.634187698364258






Player: 1 
cards in hand: [0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3] -> size -> 37 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3] -> size -> 37 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3] -> size -> 37 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 88.41761]
 [117.86358]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.008373260498047



action possibilites: [-1.] 
expected returns: [[123.13116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 96.94937896728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[122.23859]
 [140.42133]
 [136.30087]
 [110.2306 ]
 [131.66093]
 [147.67622]
 [134.28378]
 [157.36278]
 [122.78926]
 [141.01256]
 [130.3998 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 123.13115692138672



buy possibilites: [-1] 
expected returns: [[133.96887]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 3. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  6.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -30   0   0 128   0] 
sum of rewards: 413 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 157.36277770996094






Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11. 10. 15. 29.  3.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29] -> size -> 38 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11. 10. 15. 29.  3.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29] -> size -> 38 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11. 10. 15. 29.  3.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29] -> size -> 38 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11. 10. 15. 29.  3.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29] -> size -> 38 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11. 10. 15. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15. 29.] 
expected returns: [[ 99.5487  ]
 [117.94862 ]
 [ 99.58964 ]
 [111.073296]
 [126.01765 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 15. 29.  3.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 133.9688720703125



action possibilites: [-1. 11. 10. 15.] 
expected returns: [[70.07363]
 [93.32573]
 [71.71409]
 [85.53417]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 15.  3.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 105.36750030517578



action possibilites: [-1] 
expected returns: [[123.168816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 359 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 100.21247100830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[115.34091]
 [104.78573]
 [124.54893]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  3.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 123.16881561279297






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 25.  0. 10. 15.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15] -> size -> 39 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 25.  0. 10. 15.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15] -> size -> 39 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 25.  0. 10. 15.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15] -> size -> 39 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 25.  0. 10. 15.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15] -> size -> 39 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 15.] 
expected returns: [[ 82.45313]
 [137.31903]
 [ 85.81243]
 [103.05143]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0. 10. 15.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 23. 30.  8.  5. 10.  5.  6.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 124.54894256591797



action possibilites: [-1] 
expected returns: [[92.52549]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 15. 10. 11.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 132.38685607910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 89.9647  ]
 [ 84.445404]
 [111.76873 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 15. 10. 11.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.5254898071289






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10.  3.  3. 11. 15.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15] -> size -> 39 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10.  3.  3. 11. 15.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15] -> size -> 39 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10.  3.  3. 11. 15.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15] -> size -> 39 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [10.  3.  3. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
expected returns: [[75.85111 ]
 [71.697426]
 [93.417244]
 [83.865715]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 11. 15.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 111.76871490478516



action possibilites: [-1] 
expected returns: [[127.57813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 15.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  4.] 
adversary cards in hand: [8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 359 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 100.12506866455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 90.70922 ]
 [ 68.33288 ]
 [121.355034]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3. 15.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  4.] 
adversary cards in hand: [8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.57813262939453






Player: 1 
cards in hand: [8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11. 15. 11. 10.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15] -> size -> 40 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11. 15. 11. 10.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15] -> size -> 40 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11. 15. 11. 10.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15] -> size -> 40 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [11.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[19.17412 ]
 [45.177467]
 [45.177467]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  3.  0.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11. 15. 11. 10.  3.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  4.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0 0] -> size -> 5 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 121.35516357421875



action possibilites: [-1] 
expected returns: [[-26.779978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11. 15. 11. 10.  3.  3. 15. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0 0] -> size -> 5 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -60   0   0  64   0] 
sum of rewards: 349 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 54.02740478515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-34.78485 ]
 [-28.437937]
 [-35.088562]
 [-30.093504]
 [-26.779978]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11. 15. 11. 10.  3.  3. 15. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0 0] -> size -> 5 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -26.779977798461914






Player: 1 
cards in hand: [0. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [15. 10. 10. 10. 10.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11. 15. 11. 10.  3.  3. 15. 15. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15] -> size -> 41 
adversary victory points: 10
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [15. 10. 10. 10. 10.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11. 15. 11. 10.  3.  3. 15. 15. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15] -> size -> 41 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [15. 10. 10. 10. 10.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11. 15. 11. 10.  3.  3. 15. 15. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15] -> size -> 41 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [15. 10. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 10. 10.] 
expected returns: [[-14.400656]
 [-16.13017 ]
 [-21.218813]
 [-21.218813]
 [-21.218813]
 [-21.218813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10. 10. 10.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11. 15. 11. 10.  3.  3. 15. 15. 11.  0. 11.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -26.779977798461914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-24.211775]
 [-24.139925]
 [-14.400655]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 10. 10. 10.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.  3. 15. 29. 11. 10. 15.  3. 25.  3.  0. 10.
 15. 10. 11. 15. 11. 10.  3.  3. 15. 15. 11.  0. 11.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.400654792785645



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [29.  3.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15] -> size -> 41 
adversary victory points: 10
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [29.  3.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15] -> size -> 41 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [29.  3.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15] -> size -> 41 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [29.  3.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[159.23158]
 [190.03726]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -14.400654792785645



action possibilites: [-1.] 
expected returns: [[157.63188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 171.82591247558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[148.71806]
 [164.46935]
 [135.31247]
 [161.96924]
 [158.56436]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 23. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 157.6318817138672



buy possibilites: [-1] 
expected returns: [[175.68141]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [3. 3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -70   0   0  16   0] 
sum of rewards: 291 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 164.46939086914062






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 10.  3.  3.  3.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3] -> size -> 42 
adversary victory points: 11
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 10.  3.  3.  3.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3] -> size -> 42 
adversary victory points: 11
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10. 10.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[129.40358]
 [133.11308]
 [133.11308]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  3.  3.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 175.68141174316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[123.15792 ]
 [104.037254]
 [130.45403 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  3.  3.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 131.03973388671875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [15.  0. 10. 10. 29.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3] -> size -> 42 
adversary victory points: 11
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [15.  0. 10. 10. 29.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3] -> size -> 42 
adversary victory points: 11
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [15.  0. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 29.] 
expected returns: [[ 89.241135]
 [ 96.433266]
 [ 88.02111 ]
 [ 88.02111 ]
 [106.4027  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10. 10. 29.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 130.4540252685547



action possibilites: [-1. 15. 10. 10.] 
expected returns: [[94.00108]
 [97.15865]
 [89.23642]
 [89.23642]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10. 10.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3
 10 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 93.5347671508789



action possibilites: [-1] 
expected returns: [[114.17987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 97.15865325927734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[103.439384]
 [131.38547 ]
 [123.462845]
 [ 88.86841 ]
 [117.12247 ]
 [143.0943  ]
 [120.57477 ]
 [156.63058 ]
 [104.09329 ]
 [131.55545 ]
 [114.39202 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.17987060546875



buy possibilites: [-1] 
expected returns: [[94.6234]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0 -70   0   0 128   0] 
sum of rewards: 423 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 156.630615234375






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [11. 15. 15. 25. 11.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
adversary victory points: 11
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [11. 15. 15. 25. 11.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
adversary victory points: 11
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [11. 15. 15. 25. 11.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
adversary victory points: 11
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [11. 15. 15. 25. 11.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
adversary victory points: 11
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11. 15. 15. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 15. 25. 11.] 
expected returns: [[ 97.79479]
 [106.915  ]
 [ 99.70957]
 [ 99.70957]
 [120.10505]
 [106.915  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 15. 25. 11.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 22. 30.  8.  4. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.62339782714844



action possibilites: [-1] 
expected returns: [[180.13316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 15. 11. 10.  0.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 120.10509490966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[138.45335]
 [124.61727]
 [178.92035]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15. 15. 11. 10.  0.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 180.13316345214844






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 3. 29.  0. 15. 15.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
adversary victory points: 11
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 3. 29.  0. 15. 15.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
adversary victory points: 11
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 3. 29.  0. 15. 15.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
adversary victory points: 11
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 3. 29.  0. 15. 15.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
adversary victory points: 11
player victory points: -1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 15.] 
expected returns: [[-0.9936662]
 [19.026812 ]
 [ 3.9981933]
 [ 3.9981933]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 15. 15.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 178.92034912109375



action possibilites: [-1. 15. 15. 15.] 
expected returns: [[-67.64267 ]
 [-62.542976]
 [-62.542976]
 [-62.542976]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 15. 15.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10
 11 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 1.9665260314941406



action possibilites: [-1] 
expected returns: [[17.654959]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 4 
card supply: [15. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -62.54298400878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[-18.476608 ]
 [ 24.958961 ]
 [ 17.894775 ]
 [-44.92045  ]
 [  1.3991222]
 [ 47.46296  ]
 [ 11.418529 ]
 [ 55.890587 ]
 [-14.982423 ]
 [ 29.163599 ]
 [ 16.310528 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.654958724975586



buy possibilites: [-1] 
expected returns: [[-75.36716]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0 -70   0   0 128   0] 
sum of rewards: 453 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 55.89060974121094






Player: 1 
cards in hand: [6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  0. 11.  3. 10.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29. 29. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29] -> size -> 42 
adversary victory points: 11
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  0. 11.  3. 10.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29. 29. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29] -> size -> 42 
adversary victory points: 11
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  0. 11.  3. 10.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29. 29. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29] -> size -> 42 
adversary victory points: 11
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  0. 11.  3. 10.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29. 29. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29] -> size -> 42 
adversary victory points: 11
player victory points: -1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[63.41253 ]
 [88.93328 ]
 [57.565643]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3. 10.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29. 29. 15. 15. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: -75.36715698242188



action possibilites: [-1] 
expected returns: [[-41.5531]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29. 29. 15. 15. 15. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0 -80   0   0  64   0] 
sum of rewards: 359 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 95.2672348022461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-50.051155]
 [-41.466095]
 [-53.487038]
 [-43.748314]
 [-41.55311 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29. 29. 15. 15. 15. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 30. 30. 22. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: -41.5531005859375



buy possibilites: [-1] 
expected returns: [[-4.116377]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29. 29. 15. 15. 15. 15.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 21. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0 -90   0   0  16   0] 
sum of rewards: 331 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -41.466087341308594






Player: 1 
cards in hand: [0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 21. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  2.] 
adversary cards in hand: [10. 11. 15. 11. 10.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29. 29. 15. 15. 15. 15.  3. 11.  0.  0.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3] -> size -> 44 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 30. 30. 21. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  2.] 
adversary cards in hand: [10. 11. 15. 11. 10.] 
adversary cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29. 29. 15. 15. 15. 15.  3. 11.  0.  0.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3] -> size -> 44 
adversary victory points: 12
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [10. 11. 15. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 11. 10.] 
expected returns: [[104.9664  ]
 [ 89.137505]
 [122.43018 ]
 [107.30516 ]
 [122.43018 ]
 [ 89.137505]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15. 11. 10.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29. 29. 15. 15. 15. 15.  3. 11.  0.  0.
  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 21. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  2.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.116376876831055



action possibilites: [-1] 
expected returns: [[73.32212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 11. 10.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29. 29. 15. 15. 15. 15.  3. 11.  0.  0.
  3. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 21. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -100    0    0
   64    0] 
sum of rewards: 369 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 125.37662506103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[42.633926]
 [26.892372]
 [73.3221  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 11. 10.] 
cards in discard: [ 3.  3. 29.  3.  3.  0.  3. 10. 10.  3.  3.  3.  3. 29. 29. 15. 10. 10.
 25. 11. 15. 15. 11. 10.  0.  3. 29. 29. 15. 15. 15. 15.  3. 11.  0.  0.
  3. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 30. 30. 21. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.3221206665039






Player: 1 
cards in hand: [8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 21. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 15.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15] -> size -> 45 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 30. 30. 21. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 15.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15] -> size -> 45 
adversary victory points: 12
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [11. 15.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 15.] 
expected returns: [[156.19072]
 [185.99644]
 [176.1104 ]
 [176.1104 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 21. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 73.3221206665039



action possibilites: [-1] 
expected returns: [[191.92288]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.  0.] 
cards in discard: [15.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 21. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -110    0    0
   64    0] 
sum of rewards: 359 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 184.918701171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[189.6128 ]
 [203.49016]
 [176.89276]
 [201.92885]
 [194.9156 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  0.] 
cards in discard: [15.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 30. 30. 21. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 191.92288208007812



buy possibilites: [-1] 
expected returns: [[192.60367]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  0.] 
cards in discard: [15.  3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 20. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[  -5    0    0  420    0    0   20    0    0    0    0 -120    0    0
   16    0] 
sum of rewards: 331 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 203.4901580810547






Player: 1 
cards in hand: [8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 20. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 0. 15. 10.  3.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3] -> size -> 47 
adversary victory points: 13
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 20. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 0. 15. 10.  3.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3] -> size -> 47 
adversary victory points: 13
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 30. 30. 20. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 0. 15. 10.  3.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3] -> size -> 47 
adversary victory points: 13
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 0. 15. 10.  3.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3] -> size -> 47 
adversary victory points: 13
player victory points: -1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[86.253654]
 [95.350746]
 [84.24502 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.  3.  3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11
 10 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 192.60366821289062



action possibilites: [-1] 
expected returns: [[93.01963]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 95.3228759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[ 80.00647 ]
 [102.92587 ]
 [ 98.13343 ]
 [ 68.19709 ]
 [113.9691  ]
 [ 95.037796]
 [ 94.04268 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  5.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.0196304321289



buy possibilites: [-1] 
expected returns: [[72.40845]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[  -5    0    0  420    0    0   20    0    0    0    0 -120    0    0
   54    0] 
sum of rewards: 369 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 113.9691162109375






Player: 1 
cards in hand: [0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [10. 11.  3. 29. 10.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
adversary victory points: 13
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [10. 11.  3. 29. 10.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
adversary victory points: 13
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [10. 11.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 10.] 
expected returns: [[104.97394]
 [100.91457]
 [115.35023]
 [121.05685]
 [100.91457]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3. 29. 10.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.408447265625



action possibilites: [-1. 10. 29.] 
expected returns: [[98.859566]
 [85.36489 ]
 [91.67893 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 107.83903503417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 75.620224]
 [ 65.454056]
 [101.04214 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 29.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 1 
buys: 1 
player value: 1 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 98.85957336425781






Player: 1 
cards in hand: [6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 29.  3. 10. 11.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
adversary victory points: 13
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 29.  3. 10. 11.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
adversary victory points: 13
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 29.  3. 10. 11.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
adversary victory points: 13
player victory points: 0 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[ 97.81693]
 [133.47304]
 [ 97.83158]
 [124.9598 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3. 10. 11.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.04216766357422



action possibilites: [-1. 15.] 
expected returns: [[12.118716]
 [42.14598 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 113.46515655517578



action possibilites: [-1] 
expected returns: [[-1.9863964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 42.145957946777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-29.525866 ]
 [-47.549294 ]
 [ -2.3626518]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.9863964319229126






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  3. 25.  0.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
adversary victory points: 13
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  3. 25.  0.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
adversary victory points: 13
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  3. 25.  0.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
adversary victory points: 13
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  3. 25.  0.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
adversary victory points: 13
player victory points: 0 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-47.222275]
 [-18.447607]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.  0.  3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 20. 30.  8.  3. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -2.3626461029052734



action possibilites: [-1] 
expected returns: [[-25.844957]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 29. 10.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -18.44765853881836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-34.690994]
 [-38.170486]
 [-25.84497 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  3. 29. 10.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 30. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: -25.84495735168457






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [10. 15. 10. 15.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
adversary victory points: 13
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 30. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [10. 15. 10. 15.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
adversary victory points: 13
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [10. 15. 10. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10. 15.] 
expected returns: [[40.89341 ]
 [29.071115]
 [45.893158]
 [29.071115]
 [45.893158]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10. 15.  3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -25.84495735168457



action possibilites: [-1] 
expected returns: [[-27.67413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15.  3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 45.893157958984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-31.56384 ]
 [-36.395752]
 [-27.674139]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15.  3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 30. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: -27.674129486083984






Player: 1 
cards in hand: [0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [10. 11.  3. 11.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10. 15. 10. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
adversary victory points: 13
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 30. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [10. 11.  3. 11.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10. 15. 10. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
adversary victory points: 13
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [10. 11.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[-30.511803]
 [-35.471287]
 [-20.802595]
 [-20.802595]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3. 11.  3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10. 15. 10. 10. 15.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -27.674129486083984



action possibilites: [-1] 
expected returns: [[-52.885895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10. 15. 10. 10. 15.  3.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[  -5    0    0  420    0    0   20    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: 332 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -29.735219955444336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-54.644295]
 [-56.523193]
 [-52.88588 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11.  3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10. 15. 10. 10. 15.  3.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: -52.885894775390625






Player: 1 
cards in hand: [6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [15. 15.  0. 29.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10. 15. 10. 10. 15.  3.
  1. 11. 10.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
adversary victory points: 13
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [15. 15.  0. 29.  3.] 
adversary cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10. 15. 10. 10. 15.  3.
  1. 11. 10.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
adversary victory points: 13
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [15. 15.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 29.] 
expected returns: [[56.885803]
 [57.676826]
 [57.676826]
 [70.600105]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0. 29.  3.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10. 15. 10. 10. 15.  3.
  1. 11. 10.  3. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -52.885894775390625



action possibilites: [-1. 15. 15.] 
expected returns: [[58.704155]
 [71.43116 ]
 [71.43116 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10. 15. 10. 10. 15.  3.
  1. 11. 10.  3. 11.  3. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 54.04381561279297



action possibilites: [-1] 
expected returns: [[101.88105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10. 15. 10. 10. 15.  3.
  1. 11. 10.  3. 11.  3. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 455 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 71.4311752319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 65.356026]
 [ 46.062645]
 [101.88101 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [15.  3. 11. 15.  0. 15.  0. 11. 15. 10.  3.  3. 11. 10. 29.  3. 10. 29.
 10. 11. 29. 15.  3.  3. 25.  3.  3.  0.  3. 29. 10. 15. 10. 10. 15.  3.
  1. 11. 10.  3. 11.  3. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 455 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.88105010986328






Player: 1 
cards in hand: [8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 11. 15.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
adversary victory points: 13
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 11. 15.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
adversary victory points: 13
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 15.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 25.] 
expected returns: [[176.63081]
 [187.79146]
 [182.43816]
 [198.65283]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15.  0. 25.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  2. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.88105010986328



action possibilites: [-1] 
expected returns: [[105.12566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15.  0. 15. 10.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6 6] -> size -> 4 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 197.3885955810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 97.02559]
 [ 83.10576]
 [104.92348]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 15.  0. 15. 10.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 20. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6 6] -> size -> 4 
adversary victory points: -1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.12566375732422






Player: 1 
cards in hand: [6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 6] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  3. 15. 29. 15.] 
adversary cards in discard: [25.  3. 11. 15.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
adversary victory points: 13
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 6] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 20. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  3. 15. 29. 15.] 
adversary cards in discard: [25.  3. 11. 15.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
adversary victory points: 13
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8.] 
cards in discard: [6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 6 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 29. 30. 20. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  3. 15. 29. 15.] 
adversary cards in discard: [25.  3. 11. 15.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
adversary victory points: 13
player victory points: -2 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 15. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 15.] 
expected returns: [[153.08153]
 [158.25935]
 [172.57896]
 [158.25935]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 29. 15.] 
cards in discard: [25.  3. 11. 15.  0. 15. 10.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 20. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 6 0] -> size -> 5 
adversary victory points: -2
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 104.92347717285156



action possibilites: [-1. 15. 15.] 
expected returns: [[211.75417]
 [212.65248]
 [212.65248]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15.] 
cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 29. 30. 20. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 6 0] -> size -> 5 
adversary victory points: -2
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 155.9525909423828



action possibilites: [-1] 
expected returns: [[101.565834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 29. 30. 20. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 6 0] -> size -> 5 
adversary victory points: -2
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 450   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 485 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 212.6525115966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 82.80775]
 [ 76.17762]
 [101.72578]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 29. 30. 20. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 6 0] -> size -> 5 
adversary victory points: -2
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 450   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 485 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.56583404541016






Player: 1 
cards in hand: [6. 0. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 6 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 20. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [15. 11.  3. 10.  3.] 
adversary cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
adversary victory points: 13
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 6 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 20. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [15. 11.  3. 10.  3.] 
adversary cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
adversary victory points: 13
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 6 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 29. 30. 20. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [15. 11.  3. 10.  3.] 
adversary cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
adversary victory points: 13
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 6 0 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 19. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [15. 11.  3. 10.  3.] 
adversary cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
adversary victory points: 13
player victory points: 0 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [15. 11.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10.] 
expected returns: [[95.16178 ]
 [92.2757  ]
 [98.89741 ]
 [86.680016]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3. 10.  3.] 
cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 19. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.72579193115234



action possibilites: [-1] 
expected returns: [[91.64223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 10.  3.] 
cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 19. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: 292 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 90.18909454345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[83.24122]
 [74.97652]
 [89.75654]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 10.  3.] 
cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 28. 30. 19. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.64222717285156






Player: 1 
cards in hand: [8. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 19. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 10. 29. 15.  3.] 
adversary cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.  1. 11. 15.  3. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1
  1] -> size -> 49 
adversary victory points: 13
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 19. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 10. 29. 15.  3.] 
adversary cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.  1. 11. 15.  3. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1
  1] -> size -> 49 
adversary victory points: 13
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 29. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 15.] 
expected returns: [[19.553976]
 [10.696445]
 [31.07387 ]
 [21.327429]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29. 15.  3.] 
cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.  1. 11. 15.  3. 10.
  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 19. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.75653839111328



action possibilites: [-1. 15.] 
expected returns: [[21.113894]
 [24.397354]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.] 
cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.  1. 11. 15.  3. 10.
  3.  3. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 19. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.603975296020508



action possibilites: [-1] 
expected returns: [[-21.353987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.  1. 11. 15.  3. 10.
  3.  3. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 19. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 24.397340774536133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-28.807913]
 [-40.624268]
 [-21.354017]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.  1. 11. 15.  3. 10.
  3.  3. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 19. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.353986740112305






Player: 1 
cards in hand: [0. 6. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 19. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [11. 10. 10. 10. 15.] 
adversary cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.  1. 11. 15.  3. 10.
  3.  3. 10. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1
  1] -> size -> 49 
adversary victory points: 13
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 19. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [11. 10. 10. 10. 15.] 
adversary cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.  1. 11. 15.  3. 10.
  3.  3. 10. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1
  1] -> size -> 49 
adversary victory points: 13
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [11. 10. 10. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 10. 15.] 
expected returns: [[-35.00328 ]
 [-34.91683 ]
 [-40.23648 ]
 [-40.23648 ]
 [-40.23648 ]
 [-37.658897]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 10. 15.] 
cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.  1. 11. 15.  3. 10.
  3.  3. 10. 29. 15.  3.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 19. 30.  8.  1. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -21.353986740112305



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 10 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 0 
Witch: 1 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10. 10. 10. 15.] 
cards in discard: [25.  3. 11. 15.  0. 15. 10.  0. 15. 29. 15.  3. 15.  1. 11. 15.  3. 10.
  3.  3. 10. 29. 15.  3.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  3 25 11 11  3 10 11  3  3 10  3 10 11 10
 10 10 10 29 15  3 15 15 15  3 29 15 15 15  3 29 29 15  3 15 15  3 11  1
  1  6] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 19. 30.  8.  0. 10.  4.  6.  9.  5.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[     -5 3000000       0     360       0       0      20       0       0
       0       0    -150       0    -300       0       0] 
sum of rewards: 2999925 

action type: gain_card_n - action 3
Learning step: 299996.40625
desired expected reward: 299957.40625



