 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[111.09906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -180        0        0       20        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000165 

action type: buy - action 0.0
Learning step: -120006.4609375
desired expected reward: -120009.9140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[106.11586 ]
 [110.90427 ]
 [107.92322 ]
 [ 97.78631 ]
 [112.82391 ]
 [111.01657 ]
 [108.03552 ]
 [109.074936]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 111.28524017333984



buy possibilites: [-1] 
expected returns: [[110.652756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 112.82391357421875






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[114.37424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.65275573730469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[111.423874]
 [115.85615 ]
 [113.08702 ]
 [103.6971  ]
 [115.065735]
 [117.62147 ]
 [115.958305]
 [119.07478 ]
 [108.23154 ]
 [113.18919 ]
 [112.6638  ]
 [114.05512 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.64608764648438



buy possibilites: [-1] 
expected returns: [[109.6141]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 119.07478332519531






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[112.2781 ]
 [115.11325]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.61409759521484



action possibilites: [-1] 
expected returns: [[116.38681]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 122.72809600830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[111.05889 ]
 [116.363235]
 [113.1118  ]
 [101.99167 ]
 [118.59966 ]
 [116.4982  ]
 [113.24226 ]
 [114.98569 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 116.38681030273438



buy possibilites: [-1] 
expected returns: [[120.218346]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 118.59968566894531






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[125.128784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 120.21834564208984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[122.14335 ]
 [127.09706 ]
 [124.00558 ]
 [113.694984]
 [129.07237 ]
 [127.210144]
 [124.11866 ]
 [125.13492 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 126.21202087402344



buy possibilites: [-1] 
expected returns: [[137.69345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 129.07237243652344






Player: 1 
cards in hand: [ 3.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29.  0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  3.  0.  0.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[121.61416]
 [125.35368]
 [126.80794]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 137.69345092773438



action possibilites: [-1. 11.] 
expected returns: [[105.6682 ]
 [108.54503]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 128.26747131347656



action possibilites: [-1] 
expected returns: [[115.77223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 111.17758178710938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[111.643936]
 [116.95266 ]
 [113.68201 ]
 [103.822174]
 [116.028984]
 [119.12523 ]
 [117.08713 ]
 [120.86641 ]
 [108.236374]
 [113.816505]
 [113.2107  ]
 [115.27538 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.77223205566406



buy possibilites: [-1] 
expected returns: [[142.03928]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 120.86640930175781






Player: 1 
cards in hand: [ 0. 15.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  3.  0. 11.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  3.  0. 11.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  3.  0. 11.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[124.99659]
 [127.07379]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 11.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 142.03927612304688



action possibilites: [-1] 
expected returns: [[138.82109]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 130.81190490722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[135.9495 ]
 [138.25815]
 [126.63423]
 [141.74097]
 [140.1444 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 138.8210906982422



buy possibilites: [-1] 
expected returns: [[165.94046]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 141.740966796875






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.  3.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [29. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[140.54454]
 [145.03383]
 [139.62848]
 [143.68394]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 165.94046020507812



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[143.30833]
 [141.5657 ]
 [146.746  ]
 [146.746  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 145.83285522460938



action possibilites: [-1] 
expected returns: [[147.5097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 149.90892028808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[144.67857]
 [149.3638 ]
 [146.54562]
 [136.68146]
 [151.3648 ]
 [149.49774]
 [146.6796 ]
 [148.61996]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 147.50970458984375



buy possibilites: [-1] 
expected returns: [[169.9392]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 151.3647918701172






Player: 1 
cards in hand: [ 0.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10.  8.  0. 29.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10.  8.  0. 29.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 10.  8.  0. 29.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
expected returns: [[134.59033]
 [132.88445]
 [135.97723]
 [139.48828]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  0. 29.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 169.93919372558594



action possibilites: [-1. 10.  8. 11.] 
expected returns: [[138.96042]
 [137.33305]
 [140.05177]
 [141.8136 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  0. 11.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 139.41192626953125



action possibilites: [-1] 
expected returns: [[134.95197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 144.54624938964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[133.03064 ]
 [134.78935 ]
 [125.389915]
 [137.60599 ]
 [136.6725  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.95196533203125



buy possibilites: [-1] 
expected returns: [[175.55888]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 21 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 137.6060028076172






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  0. 29.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0. 11. 10.  8. 29. 11.  3. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  0. 29.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0. 11. 10.  8. 29. 11.  3. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  0. 29.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  5.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0. 11. 10.  8. 29. 11.  3. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8] -> size -> 23 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[137.96747]
 [133.75224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11. 10.  8. 29. 11.  3. 10.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  5.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 175.5588836669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[130.13574]
 [135.12909]
 [132.31499]
 [122.32301]
 [137.53622]
 [135.2819 ]
 [132.4678 ]
 [136.7834 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11. 10.  8. 29. 11.  3. 10.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  5.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 137.92868041992188



buy possibilites: [-1] 
expected returns: [[141.4709]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11. 10.  8. 29. 11.  3. 10.  8.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  4.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: -11 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 137.53623962402344






Player: 1 
cards in hand: [ 0.  3. 11. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 15.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  4.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 15.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  4.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11] -> size -> 24 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[134.7287 ]
 [137.39926]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  4.  8. 10.  7. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 141.4709014892578



action possibilites: [-1] 
expected returns: [[149.20154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  4.  8. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 138.98406982421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[147.03362]
 [148.79062]
 [139.72577]
 [151.47926]
 [151.04968]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  4.  8. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 149.2015380859375



buy possibilites: [-1] 
expected returns: [[155.13298]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  4.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 151.47927856445312






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3. 11. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  4.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3. 11. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  4.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3. 11. 15.  0.  4.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 29.  8. 10. 10.  4.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [11. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[147.59256]
 [150.70065]
 [150.70065]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  0.] 
cards in discard: [10.  8. 11.  0.  3.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 29.  8. 10. 10.  4.  7. 10.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  3. 10.] 
adversary cards in discard: [ 0.  3. 11. 15.  0.  4.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 155.1329803466797



action possibilites: [-1] 
expected returns: [[145.32834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [10.  8. 11.  0.  3.  3.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 29.  8. 10. 10.  4.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  3. 10.] 
adversary cards in discard: [ 0.  3. 11. 15.  0.  4.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -108 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 152.9647979736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[143.07938]
 [147.97206]
 [145.10834]
 [134.8598 ]
 [150.12846]
 [148.09949]
 [145.23578]
 [148.01274]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [10.  8. 11.  0.  3.  3.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 29.  8. 10. 10.  4.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  3. 10.] 
adversary cards in discard: [ 0.  3. 11. 15.  0.  4.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 145.32833862304688



buy possibilites: [-1] 
expected returns: [[180.2891]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [10.  8. 11.  0.  3.  3.  0. 10. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  3. 10.] 
adversary cards in discard: [ 0.  3. 11. 15.  0.  4.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -81 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 150.12844848632812






Player: 1 
cards in hand: [ 3.  3. 29.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  3. 10.] 
cards in discard: [ 0.  3. 11. 15.  0.  4.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10.  8.  3. 10.  0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  3.  0. 10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  3. 10.] 
cards in discard: [ 0.  3. 11. 15.  0.  4.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 28. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10.  8.  3. 10.  0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  3.  0. 10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10.  8.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
expected returns: [[203.46268]
 [199.25258]
 [202.46835]
 [199.25258]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3. 10.  0.] 
cards in discard: [10.  8. 11.  0.  3.  3.  0. 10. 11. 11. 11.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 4. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 180.28909301757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[197.08966]
 [188.02208]
 [203.94292]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3. 10.  0.] 
cards in discard: [10.  8. 11.  0.  3.  3.  0. 10. 11. 11. 11.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 4. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 203.46266174316406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 4. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 4. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0.  8. 10. 10.] 
adversary cards in discard: [10.  8. 11.  0.  3.  3.  0. 10. 11. 11. 11.  0.  0.  0. 10.  8.  3. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 4. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0.  8. 10. 10.] 
adversary cards in discard: [10.  8. 11.  0.  3.  3.  0. 10. 11. 11. 11.  0.  0.  0. 10.  8.  3. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 4. 3.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0.  8. 10. 10.] 
adversary cards in discard: [10.  8. 11.  0.  3.  3.  0. 10. 11. 11. 11.  0.  0.  0. 10.  8.  3. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29.  0.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10. 10.] 
expected returns: [[192.86122]
 [195.3025 ]
 [190.4751 ]
 [187.18462]
 [187.18462]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8. 10. 10.] 
cards in discard: [10.  8. 11.  0.  3.  3.  0. 10. 11. 11. 11.  0.  0.  0. 10.  8.  3. 10.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 29.] 
adversary cards in discard: [3. 0. 0. 0. 4. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3] -> size -> 18 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 203.94293212890625



action possibilites: [-1.  8. 10. 10. 11.] 
expected returns: [[170.2696 ]
 [167.59393]
 [164.89206]
 [164.89206]
 [169.86855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10. 11.] 
cards in discard: [10.  8. 11.  0.  3.  3.  0. 10. 11. 11. 11.  0.  0.  0. 10.  8.  3. 10.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 29.] 
adversary cards in discard: [3. 0. 0. 0. 4. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3] -> size -> 18 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 195.30252075195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[163.71843]
 [165.87158]
 [156.26088]
 [168.65512]
 [171.0465 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 10. 11.] 
cards in discard: [10.  8. 11.  0.  3.  3.  0. 10. 11. 11. 11.  0.  0.  0. 10.  8.  3. 10.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 29.] 
adversary cards in discard: [3. 0. 0. 0. 4. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3] -> size -> 18 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 170.26959228515625






Player: 1 
cards in hand: [ 0.  0.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 29.] 
cards in discard: [3. 0. 0. 0. 4. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [29. 10. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 29.] 
cards in discard: [3. 0. 0. 0. 4. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [29. 10. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 29.] 
cards in discard: [3. 0. 0. 0. 4. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [29. 10. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29. 10. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 10. 29.] 
expected returns: [[158.64665]
 [162.34528]
 [155.72426]
 [160.69516]
 [155.72426]
 [162.34528]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11. 10. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  4.  3.  0.  0.  0.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 19 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 171.04647827148438



action possibilites: [-1. 10. 11. 10. 29.  8.] 
expected returns: [[176.25934]
 [172.92398]
 [178.29738]
 [172.92398]
 [180.0796 ]
 [176.03238]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 29.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  4.  3.  0.  0.  0.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 19 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 160.8422393798828



action possibilites: [-1. 10. 11. 10.  8. 10.] 
expected returns: [[160.32596]
 [157.81949]
 [162.58946]
 [157.81949]
 [160.62915]
 [157.81949]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  8. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  4.  3.  0.  0.  0.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 19 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 180.07962036132812



action possibilites: [-1] 
expected returns: [[141.265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8. 10.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  4.  3.  0.  0.  0.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 19 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   60    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -98 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 165.51995849609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[136.45815]
 [138.46402]
 [128.8374 ]
 [141.2785 ]
 [142.15918]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8. 10.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  4.  3.  0.  0.  0.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 19 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.26499938964844






Player: 1 
cards in hand: [ 3. 15.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 10.  3.] 
cards in discard: [ 3.  0.  0.  0.  4.  3.  0.  0.  0.  0. 11. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 10.  8.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10] -> size -> 29 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  3.  3.] 
cards in discard: [ 3.  0.  0.  0.  4.  3.  0.  0.  0.  0. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 10.  8.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10] -> size -> 29 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [ 3.  0.  0.  0.  4.  3.  0.  0.  0.  0. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 10.  8.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10] -> size -> 29 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 3.  0.  0.  0.  4.  3.  0.  0.  0.  0. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 18 
action values: 1 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 10.  8.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10] -> size -> 29 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.  8.] 
expected returns: [[157.81027]
 [154.62993]
 [159.35204]
 [154.62993]
 [157.34076]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10.  8.] 
cards in discard: [10. 29. 29. 11. 10. 10.  8. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 4. 10.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 18 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 142.1591796875



action possibilites: [-1] 
expected returns: [[155.02417]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  8.] 
cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 4. 10.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 18 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -138 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 162.0203094482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[149.35938]
 [139.61284]
 [155.18373]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  8.] 
cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 4. 10.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 18 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 155.024169921875






Player: 1 
cards in hand: [ 4. 10.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 10.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 3.] 
cards in discard: [3. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[159.64284]
 [156.2164 ]
 [161.1471 ]
 [161.1471 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11.  0.] 
cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [ 3.  1. 10. 29.  4.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1] -> size -> 19 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 155.18374633789062



action possibilites: [-1] 
expected returns: [[158.41266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [ 3.  1. 10. 29.  4.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1] -> size -> 19 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -101 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 163.96731567382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[152.59027]
 [154.40433]
 [146.38103]
 [157.0608 ]
 [158.07489]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [ 3.  1. 10. 29.  4.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1] -> size -> 19 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 158.41265869140625






Player: 1 
cards in hand: [ 0.  0. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [ 3.  1. 10. 29.  4.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15. 11.  0. 10.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15] -> size -> 31 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [ 3.  1. 10. 29.  4.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15. 11.  0. 10.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15] -> size -> 31 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [ 3.  1. 10. 29.  4.  0.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 26. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15. 11.  0. 10.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15] -> size -> 31 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[135.20255]
 [132.2624 ]
 [136.51675]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 11.] 
cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15. 11.  0. 10.
 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 3.  1. 10. 29.  4.  0.  0.  3.  3.  0.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3] -> size -> 20 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 158.07489013671875



action possibilites: [-1] 
expected returns: [[192.96594]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15. 11.  0. 10.
 11.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 3.  1. 10. 29.  4.  0.  0.  3.  3.  0.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3] -> size -> 20 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -131 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 139.12869262695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[187.13757]
 [191.33844]
 [188.93253]
 [180.9249 ]
 [193.26956]
 [191.47464]
 [191.85916]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15. 11.  0. 10.
 11.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 26. 29.  8. 10. 10.  3.  7. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 3.  1. 10. 29.  4.  0.  0.  3.  3.  0.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3] -> size -> 20 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 192.9659423828125



buy possibilites: [-1] 
expected returns: [[210.69467]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15. 11.  0. 10.
 11.  0. 15. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 3.  1. 10. 29.  4.  0.  0.  3.  3.  0.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3] -> size -> 20 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -141 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 193.26956176757812






Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 3.  1. 10. 29.  4.  0.  0.  3.  3.  0.  0. 15.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 11.  8.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15. 11.  0. 10.
 11.  0. 15. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 3.  1. 10. 29.  4.  0.  0.  3.  3.  0.  0. 15.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 11.  8.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15. 11.  0. 10.
 11.  0. 15. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 3.  1. 10. 29.  4.  0.  0.  3.  3.  0.  0. 15.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 11.  8.] 
adversary cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15. 11.  0. 10.
 11.  0. 15. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[155.58684]
 [155.8384 ]
 [153.95981]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.  8.] 
cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15. 11.  0. 10.
 11.  0. 15. 11. 11.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0] -> size -> 21 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1
Learning step: 0
desired expected reward: 210.69467163085938



action possibilites: [-1] 
expected returns: [[201.52191]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15. 11.  0. 10.
 11.  0. 15. 11. 11.  0.  0.  0. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0] -> size -> 21 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -131 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 158.14053344726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[193.64578]
 [185.10297]
 [201.41658]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [10. 29. 29. 11. 10. 10.  8. 10. 10. 11.  0. 10. 10.  8. 15. 11.  0. 10.
 11.  0. 15. 11. 11.  0.  0.  0. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0] -> size -> 21 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 201.52191162109375






Player: 1 
cards in hand: [29.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11. 10. 11. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11. 10. 11. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11. 10. 11. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11. 10. 11. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 15.] 
expected returns: [[181.68301]
 [183.35248]
 [177.52066]
 [183.35248]
 [177.02075]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 15.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 3. 29.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0] -> size -> 21 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 201.41659545898438



action possibilites: [-1] 
expected returns: [[148.34917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15.  3.] 
cards in discard: [15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 3. 29.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0] -> size -> 21 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -131 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 186.4761962890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[142.3637 ]
 [133.53181]
 [148.71428]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 15.  3.] 
cards in discard: [15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 3. 29.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0] -> size -> 21 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 148.3491668701172






Player: 1 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 3. 29.  0.  0.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10.  0. 29. 10.  0.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 3. 29.  0.  0.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  7. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10.  0. 29. 10.  0.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 3. 29.  0.  0.  0. 11.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10.  0. 29. 10.  0.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10.  0. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[211.23691]
 [207.29419]
 [214.45352]
 [207.29419]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 10.  0.] 
cards in discard: [15. 11. 10. 11. 15.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [1. 3. 0. 4. 3.] 
adversary cards in discard: [ 3. 29.  0.  0.  0. 11.  8.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8] -> size -> 22 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 148.7142791748047



action possibilites: [-1. 10. 10.] 
expected returns: [[206.8307 ]
 [202.75949]
 [202.75949]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [1. 3. 0. 4. 3.] 
adversary cards in discard: [ 3. 29.  0.  0.  0. 11.  8.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8] -> size -> 22 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 210.16744995117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[200.99533]
 [206.44695]
 [203.28488]
 [191.84978]
 [208.86584]
 [206.60101]
 [207.23347]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  2.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [1. 3. 0. 4. 3.] 
adversary cards in discard: [ 3. 29.  0.  0.  0. 11.  8.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8] -> size -> 22 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 206.83070373535156



buy possibilites: [-1] 
expected returns: [[195.50644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  1.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [1. 3. 0. 4. 3.] 
adversary cards in discard: [ 3. 29.  0.  0.  0. 11.  8.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8] -> size -> 22 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0  -10    0    0
   54    0] 
sum of rewards: -151 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 208.8658447265625






Player: 1 
cards in hand: [1. 3. 0. 4. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 4. 3.] 
cards in discard: [ 3. 29.  0.  0.  0. 11.  8.  0.  3.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  1.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 0. 10. 10. 15. 10.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 4. 3.] 
cards in discard: [ 3. 29.  0.  0.  0. 11.  8.  0.  3.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 26. 29.  8. 10. 10.  1.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 0. 10. 10. 15. 10.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 4. 3.] 
cards in discard: [ 3. 29.  0.  0.  0. 11.  8.  0.  3.  0.  0. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 29.  8. 10. 10.  1.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 0. 10. 10. 15. 10.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15. 10.] 
expected returns: [[180.66188]
 [176.086  ]
 [176.086  ]
 [175.6369 ]
 [176.086  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 15. 10.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8. 10. 10.  1.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [ 3. 29.  0.  0.  0. 11.  8.  0.  3.  0.  0. 10.  3.  1.  3.  0.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3] -> size -> 23 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: 195.50643920898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[174.03465]
 [164.34018]
 [181.36371]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 15. 10.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 25. 29.  8. 10. 10.  1.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [ 3. 29.  0.  0.  0. 11.  8.  0.  3.  0.  0. 10.  3.  1.  3.  0.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3] -> size -> 23 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 180.66189575195312



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 15.] 
cards in discard: [ 3. 29.  0.  0.  0. 11.  8.  0.  3.  0.  0. 10.  3.  1.  3.  0.  4.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8. 10. 10.  1.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10. 11.  8.  0. 11.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 15.] 
cards in discard: [ 3. 29.  0.  0.  0. 11.  8.  0.  3.  0.  0. 10.  3.  1.  3.  0.  4.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 25. 29.  8. 10. 10.  1.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10. 11.  8.  0. 11.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 15.] 
cards in discard: [ 3. 29.  0.  0.  0. 11.  8.  0.  3.  0.  0. 10.  3.  1.  3.  0.  4.  3.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  1.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10. 11.  8.  0. 11.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10. 11.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8. 11.] 
expected returns: [[190.03983]
 [183.9879 ]
 [189.18088]
 [186.6674 ]
 [189.18088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  0. 11.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  1.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0] -> size -> 24 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 181.3636932373047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[181.8449 ]
 [173.87274]
 [190.53966]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  8.  0. 11.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  1.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0] -> size -> 24 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 190.039794921875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  1.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [11. 29. 10. 15.  8.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.
 10. 11.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  1.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [11. 29. 10. 15.  8.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.
 10. 11.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [11. 29. 10. 15.  8.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.
 10. 11.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11. 29. 10. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 15.  8.] 
expected returns: [[208.62288]
 [208.35574]
 [210.41965]
 [202.47237]
 [202.15627]
 [205.62375]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10. 15.  8.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.
 10. 11.  8.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11] -> size -> 25 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 190.53965759277344



action possibilites: [-1. 10. 15.] 
expected returns: [[207.81853]
 [202.6942 ]
 [202.37993]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.
 10. 11.  8.  0. 11. 11.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11] -> size -> 25 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 211.5069580078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[200.47516]
 [202.96619]
 [192.09344]
 [205.95178]
 [208.25105]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.
 10. 11.  8.  0. 11. 11.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11] -> size -> 25 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 207.81854248046875






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  0. 11.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [11.  8.  0.  3.  0.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.
 10. 11.  8.  0. 11. 11.  8. 29. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  0. 11.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  6. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [11.  8.  0.  3.  0.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.
 10. 11.  8.  0. 11. 11.  8. 29. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  0. 11.  0.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  5. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [11.  8.  0.  3.  0.] 
adversary cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.
 10. 11.  8.  0. 11. 11.  8. 29. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11.  8.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[165.48628]
 [165.96063]
 [163.11237]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  3.  0.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.
 10. 11.  8.  0. 11. 11.  8. 29. 10. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  5. 10.  7. 10. 10.  0. 10.  5.] 
adversary cards in hand: [29.  0.  8. 15.  0.] 
adversary cards in discard: [11.  3.  0. 11.  0.  0.  8.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 208.25106811523438



action possibilites: [-1] 
expected returns: [[177.67276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.
 10. 11.  8.  0. 11. 11.  8. 29. 10. 15.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  5. 10.  7. 10. 10.  0. 10.  4.] 
adversary cards in hand: [29.  0.  8. 15.  0.] 
adversary cards in discard: [11.  3.  0. 11.  0.  0.  8.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0  -20    0    0
   64    0] 
sum of rewards: -181 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 163.1123809814453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[173.71643]
 [175.60892]
 [166.06676]
 [178.60574]
 [177.67274]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.
 10. 11.  8.  0. 11. 11.  8. 29. 10. 15.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  5. 10.  7. 10. 10.  0. 10.  4.] 
adversary cards in hand: [29.  0.  8. 15.  0.] 
adversary cards in discard: [11.  3.  0. 11.  0.  0.  8.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 177.67276000976562



buy possibilites: [-1] 
expected returns: [[219.74487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [15. 11. 10. 11. 15.  3.  3. 11. 29. 10.  0. 10.  0.  0. 10. 10. 15. 10.
 10. 11.  8.  0. 11. 11.  8. 29. 10. 15.  0. 15.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  4.] 
adversary cards in hand: [29.  0.  8. 15.  0.] 
adversary cards in discard: [11.  3.  0. 11.  0.  0.  8.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0  -30    0    0
   16    0] 
sum of rewards: -239 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 178.60577392578125






Player: 1 
cards in hand: [29.  0.  8. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8. 15.  0.] 
cards in discard: [11.  3.  0. 11.  0.  0.  8.  3.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  4.] 
adversary cards in hand: [15. 10. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8] -> size -> 38 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  8. 15.  0.] 
cards in discard: [11.  3.  0. 11.  0.  0.  8.  3.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  4.] 
adversary cards in hand: [15. 10. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8] -> size -> 38 
adversary victory points: 3
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [15. 10. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 11. 10.] 
expected returns: [[180.53688]
 [175.02019]
 [175.3884 ]
 [175.3884 ]
 [180.85446]
 [175.3884 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10. 11. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  4.] 
adversary cards in hand: [10.  4.  3.  3.  1.] 
adversary cards in discard: [11.  3.  0. 11.  0.  0.  8.  3.  0.  0.  0.  0. 29.  0.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: 219.744873046875



action possibilites: [-1] 
expected returns: [[189.75372]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10. 10.] 
cards in discard: [15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  3.] 
adversary cards in hand: [10.  4.  3.  3.  1.] 
adversary cards in discard: [11.  3.  0. 11.  0.  0.  8.  3.  0.  0.  0.  0. 29.  0.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0  -40    0    0
   64    0] 
sum of rewards: -201 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 178.38009643554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[183.95155]
 [176.2144 ]
 [190.3551 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 10. 10.] 
cards in discard: [15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  3.] 
adversary cards in hand: [10.  4.  3.  3.  1.] 
adversary cards in discard: [11.  3.  0. 11.  0.  0.  8.  3.  0.  0.  0.  0. 29.  0.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 189.75372314453125






Player: 1 
cards in hand: [10.  4.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  4.  3.  3.  1.] 
cards in discard: [11.  3.  0. 11.  0.  0.  8.  3.  0.  0.  0.  0. 29.  0.  8. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  3.] 
adversary cards in hand: [15. 10. 11.  0. 15.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15] -> size -> 39 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  4.  3.  3.  1.] 
cards in discard: [11.  3.  0. 11.  0.  0.  8.  3.  0.  0.  0.  0. 29.  0.  8. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  3.] 
adversary cards in hand: [15. 10. 11.  0. 15.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15] -> size -> 39 
adversary victory points: 3
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [15. 10. 11.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11. 15.] 
expected returns: [[213.95602]
 [208.13602]
 [208.5075 ]
 [214.30435]
 [208.13602]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11.  0. 15.] 
cards in discard: [15. 11. 15. 10. 10. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  3.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 190.3551025390625



action possibilites: [-1] 
expected returns: [[172.59074]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0. 15.] 
cards in discard: [15. 11. 15. 10. 10. 10. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0  -50    0    0
   64    0] 
sum of rewards: -211 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 211.66998291015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[166.15868]
 [156.7021 ]
 [173.33168]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0. 15.] 
cards in discard: [15. 11. 15. 10. 10. 10. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 172.5907440185547






Player: 1 
cards in hand: [0. 3. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0.  0. 10.  0.  8.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0.  0. 10.  0.  8.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 3.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0.  0. 10.  0.  8.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[199.78764]
 [195.03902]
 [198.41765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 3. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0] -> size -> 27 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 173.33169555664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[191.48093]
 [197.58774]
 [194.0887 ]
 [181.54138]
 [197.76562]
 [198.9608 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 3. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0] -> size -> 27 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 199.7877197265625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 3. 3. 3. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 11. 11. 15. 29.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 3. 3. 3. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 11. 11. 15. 29.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 3. 3. 3. 3. 1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 11. 11. 15. 29.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11. 11. 11. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 15. 29.] 
expected returns: [[194.82515]
 [194.54076]
 [194.54076]
 [194.54076]
 [189.07025]
 [196.35797]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 15. 29.] 
cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 1. 10.  3.  8.  4.] 
adversary cards in discard: [0. 0. 3. 3. 3. 3. 1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0  1] -> size -> 28 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 198.9608154296875



action possibilites: [-1. 11. 11. 15.] 
expected returns: [[222.02277]
 [222.01381]
 [222.01381]
 [215.5285 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15.] 
cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 1. 10.  3.  8.  4.] 
adversary cards in discard: [0. 0. 3. 3. 3. 3. 1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0  1] -> size -> 28 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 191.9620819091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[213.47462]
 [204.56491]
 [222.55145]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 15.] 
cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 1. 10.  3.  8.  4.] 
adversary cards in discard: [0. 0. 3. 3. 3. 3. 1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0  1] -> size -> 28 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 222.0227813720703






Player: 1 
cards in hand: [ 1. 10.  3.  8.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  8.  4.] 
cards in discard: [0. 0. 3. 3. 3. 3. 1. 0. 0. 3. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [29.  8. 10.  0. 10.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3. 29. 11. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 8. 4. 0.] 
cards in discard: [0. 0. 3. 3. 3. 3. 1. 0. 0. 3. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0  1] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [29.  8. 10.  0. 10.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3. 29. 11. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 4. 0.] 
cards in discard: [0. 0. 3. 3. 3. 3. 1. 0. 0. 3. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [29.  8. 10.  0. 10.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3. 29. 11. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 4. 0.] 
cards in discard: [0. 0. 3. 3. 3. 3. 1. 0. 0. 3. 3. 0. 1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0  1  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [29.  8. 10.  0. 10.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3. 29. 11. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [29.  8. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10. 10.] 
expected returns: [[221.82434]
 [223.23283]
 [219.12521]
 [216.38657]
 [216.38657]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 10.  0. 10.] 
cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3. 29. 11. 11. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11.  8. 15.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  3.  3.  1.  0.  0.  3.  3.  0.  1. 10.  1.  3.  8.  4.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0  1  1] -> size -> 29 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 222.55145263671875



action possibilites: [-1.  8. 10. 15.] 
expected returns: [[199.26611]
 [195.35115]
 [192.52406]
 [192.2818 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 15.] 
cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3. 29. 11. 11. 15.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11.  8. 15.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  3.  3.  1.  0.  0.  3.  3.  0.  1. 10.  1.  3.  8.  4.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0  1  1] -> size -> 29 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 218.96868896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[190.10287]
 [181.76576]
 [199.60129]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 15.] 
cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3. 29. 11. 11. 15.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11.  8. 15.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  3.  3.  1.  0.  0.  3.  3.  0.  1. 10.  1.  3.  8.  4.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0  1  1] -> size -> 29 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 199.26611328125






Player: 1 
cards in hand: [11.  8. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 15.  0.  0.] 
cards in discard: [ 0.  0.  3.  3.  3.  3.  1.  0.  0.  3.  3.  0.  1. 10.  1.  3.  8.  4.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0
 11  8  0  1  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 11. 10.  0.  8.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3. 29. 11. 11. 15.  0. 10. 29.  8. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.] 
cards in discard: [ 0.  0.  3.  3.  3.  3.  1.  0.  0.  3.  3.  0.  1. 10.  1.  3.  8.  4.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0 11
  8  0  1  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 11. 10.  0.  8.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3. 29. 11. 11. 15.  0. 10. 29.  8. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.] 
cards in discard: [ 0.  0.  3.  3.  3.  3.  1.  0.  0.  3.  3.  0.  1. 10.  1.  3.  8.  4.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0 11
  8  0  1  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 11. 10.  0.  8.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3. 29. 11. 11. 15.  0. 10. 29.  8. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.] 
cards in discard: [ 0.  0.  3.  3.  3.  3.  1.  0.  0.  3.  3.  0.  1. 10.  1.  3.  8.  4.
  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0 11
  8  0  1  1 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 11. 10.  0.  8.] 
adversary cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3. 29. 11. 11. 15.  0. 10. 29.  8. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[116.25115 ]
 [116.26311 ]
 [110.56289 ]
 [113.658585]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0.  8.] 
cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3. 29. 11. 11. 15.  0. 10. 29.  8. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  1.] 
adversary cards in hand: [29. 11.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  3.  3.  1.  0.  0.  3.  3.  0.  1. 10.  1.  3.  8.  4.
  0. 15. 15. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0 11
  8  0  1  1 15] -> size -> 29 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 199.601318359375



Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 4 
Witch: 0 
Poacher: 2 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 10.  0.  8.] 
cards in discard: [15. 11. 15. 10. 10. 10. 15. 11. 15. 10.  0. 15.  0.  0. 10.  0.  8. 11.
  3. 29. 11. 11. 15.  0. 10. 29.  8. 10. 15. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10  8 10 11 10  8 11
 10  8 10 11 10 10 15 15 11 15 15 11 15  8 15 15 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  0.  4. 10.  7. 10. 10.  0. 10.  0.] 
adversary cards in hand: [29. 11.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  3.  3.  1.  0.  0.  3.  3.  0.  1. 10.  1.  3.  8.  4.
  0. 15. 15. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 29  0 15 11 10  3  4  3  0  1  3  0  8  3  0 11
  8  0  1  1 15] -> size -> 29 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -240        0        0       20        0
        0        0        0      -60        0        0       64        0] 
sum of rewards: -3000221 

action type: gain_card_n - action 8
Learning step: -120013.390625
desired expected reward: -119899.734375



