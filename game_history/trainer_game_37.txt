 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[320.55017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0  -90    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -605 

action type: buy - action 0.0
Learning step: -30.115427017211914
desired expected reward: -32.80690383911133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[295.3968 ]
 [304.05386]
 [303.4387 ]
 [284.7412 ]
 [300.99817]
 [314.56018]
 [305.3946 ]
 [312.2421 ]
 [295.69116]
 [304.9194 ]
 [305.1604 ]
 [323.78748]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.372614860534668
desired expected reward: 315.0056457519531



buy possibilites: [-1] 
expected returns: [[309.21402]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -7.664619445800781
desired expected reward: 295.7740783691406






Player: 1 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[330.55862]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [3. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.5313639640808105
desired expected reward: 301.6826477050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[311.33813]
 [319.50037]
 [318.79645]
 [301.42548]
 [329.27545]
 [320.78876]
 [320.20038]
 [337.91876]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [3. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.879240036010742
desired expected reward: 323.5357666015625



buy possibilites: [-1] 
expected returns: [[322.96716]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [3. 0. 0. 0. 0. 3. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -302.0 

action type: buy - action 6.0
Learning step: -22.90451431274414
desired expected reward: 278.5209655761719






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[303.31808]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.373821258544922
desired expected reward: 313.5933532714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[271.92935]
 [280.6042 ]
 [279.92715]
 [261.7192 ]
 [290.87393]
 [281.95358]
 [281.41196]
 [300.15958]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.953398704528809
desired expected reward: 296.5815734863281



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[306.70267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [8. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.145627975463867
desired expected reward: 292.013916015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[285.0326 ]
 [291.37848]
 [276.2692 ]
 [293.44217]
 [309.00815]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [8. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.930325508117676
desired expected reward: 300.5074462890625



buy possibilites: [-1] 
expected returns: [[350.44858]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [0. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [8. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -7.966538429260254
desired expected reward: 277.0660705566406






Player: 1 
cards in hand: [ 3.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [8. 8. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 8. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 8. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 8. 0. 0. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[337.81335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -10.46065616607666
desired expected reward: 339.9879150390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[301.18646]
 [309.48163]
 [308.85684]
 [290.96927]
 [319.31982]
 [310.7734 ]
 [310.27737]
 [328.85956]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.553719520568848
desired expected reward: 329.9695129394531



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  3.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 3. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8  3] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 3. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[337.42722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 3. 6. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [29.  3.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.44262409210205
desired expected reward: 319.4169616699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[310.5745 ]
 [319.67194]
 [319.31223]
 [299.51498]
 [330.8904 ]
 [321.03595]
 [320.84042]
 [341.1067 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 3. 6. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [29.  3.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.17358684539795
desired expected reward: 327.6199951171875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [29.  3.  8.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 29  8  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.  3.  8.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8 29  8  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  3.  8.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8 29  8  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[363.95236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 29  8  3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.964396476745605
desired expected reward: 332.142333984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[340.6241 ]
 [348.36087]
 [347.7683 ]
 [331.07852]
 [357.54413]
 [349.5711 ]
 [349.10046]
 [365.72217]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 29  8  3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.367485046386719
desired expected reward: 353.67425537109375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 29  8  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 29  8  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 29  8  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[377.98367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  8.  3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 29  8  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.446919441223145
desired expected reward: 348.0689697265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[354.33484]
 [362.7059 ]
 [361.7654 ]
 [343.88965]
 [372.45596]
 [364.04095]
 [363.20416]
 [381.15588]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  8.  3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 29  8  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.792144775390625
desired expected reward: 368.26898193359375



buy possibilites: [-1] 
expected returns: [[309.15085]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  3.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  8.  3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 29  8  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -10.86690616607666
desired expected reward: 361.5890808105469






Player: 1 
cards in hand: [ 8.  3. 29.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  8.  3.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 29  8  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  8 29  8  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3 29  8  3 10] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3 29  8  3 10] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[345.04456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [29.  8.  3.] 
adversary owned cards: [ 0  0  0  3 29  8  3 10] -> size -> 8 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -7.2392473220825195
desired expected reward: 301.9115905761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[326.9321 ]
 [334.33817]
 [333.68286]
 [317.74265]
 [342.56888]
 [335.502  ]
 [334.95667]
 [348.8538 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [29.  8.  3.] 
adversary owned cards: [ 0  0  0  3 29  8  3 10] -> size -> 8 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -9.376200675964355
desired expected reward: 338.10357666015625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [29.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  8  3 10] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [29.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  8  3 10] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [29.  8.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  8  3 10 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[321.83817]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29  8  3 10 10] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -9.72911548614502
desired expected reward: 339.1247253417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[299.87735]
 [307.5838 ]
 [307.00046]
 [290.3729 ]
 [304.86673]
 [316.95648]
 [308.78064]
 [314.79898]
 [300.07248]
 [308.31464]
 [308.458  ]
 [325.52646]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29  8  3 10 10] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.836174964904785
desired expected reward: 316.2117004394531



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  8  3 10 10] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 29  8  3 10 10] -> size -> 9 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3 29  8  3 10 10] -> size -> 9 
action values: 3 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3 29  8  3 10 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[335.22617]
 [326.88098]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29  8  3 10 10] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -8.41656494140625
desired expected reward: 317.10986328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[310.32248]
 [317.76953]
 [300.3367 ]
 [319.8067 ]
 [337.1549 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29  8  3 10 10] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -9.099041938781738
desired expected reward: 325.65423583984375



buy possibilites: [-1] 
expected returns: [[313.2913]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29  8  3 10 10] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -22.0 

action type: buy - action 0.0
Learning step: -9.567071914672852
desired expected reward: 300.75543212890625






Player: 1 
cards in hand: [0. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  8  3 10 10] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 29  8  3 10 10] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 29  8  3 10 10] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[308.2272]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 11.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29  8  3 10 10] -> size -> 8 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -8.284682273864746
desired expected reward: 305.0066223144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[281.13727]
 [289.38013]
 [288.6196 ]
 [270.9187 ]
 [298.9387 ]
 [290.67172]
 [290.0268 ]
 [307.33014]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 11.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29  8  3 10 10] -> size -> 8 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.502202033996582
desired expected reward: 301.7148132324219



buy possibilites: [-1] 
expected returns: [[281.30008]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 11.  0.  6.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29  8  3 10 10] -> size -> 8 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 26 

action type: buy - action 11.0
Learning step: -7.317685127258301
desired expected reward: 291.62103271484375






Player: 1 
cards in hand: [ 8. 10. 10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.  3. 29.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  8  3 10 10] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 29  8  3 10 10] -> size -> 8 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  3 29  8  3 10 10] -> size -> 8 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0 29  8 10 10] -> size -> 6 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0 29  8 10 10] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0 29  8 10 10  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[342.60516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  8 10 10  0] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -4.953712463378906
desired expected reward: 276.34637451171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[320.85522]
 [328.56653]
 [328.01114]
 [311.37363]
 [337.8886 ]
 [329.77316]
 [329.34283]
 [346.2163 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  8 10 10  0] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -8.244150161743164
desired expected reward: 334.4799499511719



buy possibilites: [-1] 
expected returns: [[272.39218]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  8 10 10  0] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -2.0 

action type: buy - action 0.0
Learning step: -9.852339744567871
desired expected reward: 311.0028991699219






Player: 1 
cards in hand: [29. 10.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  8 10 10  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8 10  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8 10  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8 10  0  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[321.15854]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 6. 0. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 10  0  0] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -4.96523380279541
desired expected reward: 267.42694091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[296.90585]
 [304.8931 ]
 [304.1188 ]
 [287.28183]
 [314.59515]
 [306.20868]
 [305.552  ]
 [323.08014]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 6. 0. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 10  0  0] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -7.758647441864014
desired expected reward: 314.65802001953125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 10  0  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [0. 6. 0. 0. 3. 0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [0. 6. 0. 0. 3. 0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [0. 6. 0. 0. 3. 0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [0. 6. 0. 0. 3. 0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[295.37503]
 [287.10385]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [0. 6. 0. 0. 3. 0. 0. 3. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -8.14755916595459
desired expected reward: 314.9326171875



action possibilites: [-1] 
expected returns: [[324.41306]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  6.  0.  0.  3.  0.  0.  3.  0.  3.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 64 

action type: gain_card_n - action 4
Learning step: -2.7880876064300537
desired expected reward: 262.95953369140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[301.202  ]
 [309.49747]
 [308.88086]
 [291.61633]
 [319.93985]
 [310.85565]
 [310.3896 ]
 [329.3466 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  6.  0.  0.  3.  0.  0.  3.  0.  3.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 28. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1
Learning step: -6.741345405578613
desired expected reward: 317.6717224121094



buy possibilites: [-1] 
expected returns: [[326.085]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  6.  0.  0.  3.  0.  0.  3.  0.  3.  0. 16.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 66 

action type: buy - action 1.0
Learning step: -4.837961673736572
desired expected reward: 304.6595153808594






Player: 1 
cards in hand: [ 8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  0] -> size -> 3 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 10] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 10] -> size -> 2 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 16.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[266.56165]
 [248.14267]
 [258.8751 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -9.021817207336426
desired expected reward: 317.06317138671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[247.16612]
 [253.09909]
 [238.93228]
 [254.80151]
 [269.6776 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -6.237880229949951
desired expected reward: 262.01202392578125



buy possibilites: [-1] 
expected returns: [[253.624]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0. 11.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -283.0 

action type: buy - action 6.0
Learning step: -20.39007568359375
desired expected reward: 218.54222106933594






Player: 1 
cards in hand: [ 8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  3. 16.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10] -> size -> 2 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  3. 16.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  3. 16.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[252.31111]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 6.  0.  3. 16.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -6.127572536468506
desired expected reward: 247.4964141845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[234.58972]
 [240.9259 ]
 [240.38078]
 [227.28972]
 [238.68825]
 [248.31953]
 [241.92871]
 [246.64629]
 [234.67725]
 [241.47205]
 [241.52472]
 [254.74506]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 6.  0.  3. 16.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -6.331947326660156
desired expected reward: 247.16259765625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  0.  3. 16.  0. 11.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  0] -> size -> 3 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  0.  3. 16.  0. 11.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 10] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  0.  3. 16.  0. 11.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 10] -> size -> 2 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  0.  3. 16.  0. 11.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[287.35468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 6.  0.  3. 16.  0. 11.  6.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -5.386718273162842
desired expected reward: 249.35830688476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[260.3675 ]
 [267.81213]
 [267.11786]
 [251.11595]
 [276.43533]
 [268.98715]
 [268.39584]
 [283.95425]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 6.  0.  3. 16.  0. 11.  6.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -7.482292175292969
desired expected reward: 281.4302978515625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  1.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  1.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  1.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  1.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [16.  1.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[272.3949 ]
 [253.84166]
 [264.85495]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -7.371856689453125
desired expected reward: 276.5823974609375



action possibilites: [-1] 
expected returns: [[277.94897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0.  3.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 52 

action type: gain_card_n - action 2
Learning step: -3.2637856006622314
desired expected reward: 239.08895874023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[259.3547 ]
 [265.6308 ]
 [264.97693]
 [251.99696]
 [273.2263 ]
 [266.6816 ]
 [266.11792]
 [279.8294 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.  3.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 27. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1
Learning step: -5.440959453582764
desired expected reward: 272.5080261230469



buy possibilites: [-1] 
expected returns: [[247.87074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.  3.] 
cards in discard: [3. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 29. 30. 27. 30.  8.  7.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -263.0 

action type: buy - action 6.0
Learning step: -20.17275619506836
desired expected reward: 231.82418823242188






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  7.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 3.  6. 11. 16.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6] -> size -> 22 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 27. 30.  8.  7.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 3.  6. 11. 16.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6] -> size -> 22 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[214.9792 ]
 [209.42921]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [ 3.  6. 11. 16.  1.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  7.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -6.7284440994262695
desired expected reward: 241.14230346679688



action possibilites: [-1] 
expected returns: [[236.04163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3.  6. 11. 16.  1.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[  -5    0    1   10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -274 

action type: gain_card_n - action 3
Learning step: -18.56977653503418
desired expected reward: 185.04443359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[216.47993]
 [222.80022]
 [222.2262 ]
 [208.60834]
 [230.16336]
 [223.79782]
 [223.31517]
 [236.59727]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3.  6. 11. 16.  1.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -5.413924217224121
desired expected reward: 230.62770080566406






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [ 3.  6. 11. 16.  1.  0.  3.  6. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6] -> size -> 23 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [ 3.  6. 11. 16.  1.  0.  3.  6. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6] -> size -> 23 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[190.2809]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [ 3.  6. 11. 16.  1.  0.  3.  6. 11.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -7.2313432693481445
desired expected reward: 229.36590576171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[170.53459]
 [176.11227]
 [163.0105 ]
 [177.67194]
 [189.89073]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [ 3.  6. 11. 16.  1.  0.  3.  6. 11.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -5.229676723480225
desired expected reward: 185.8156280517578



buy possibilites: [-1] 
expected returns: [[177.96428]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [ 3.  6. 11. 16.  1.  0.  3.  6. 11.  3.  0.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 14 

action type: buy - action 8.0
Learning step: -4.1793999671936035
desired expected reward: 173.49252319335938






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 3.  6. 11. 16.  1.  0.  3.  6. 11.  3.  0.  0.  0.  8.  3.  0.  6.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8] -> size -> 24 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 3.  6. 11. 16.  1.  0.  3.  6. 11.  3.  0.  0.  0.  8.  3.  0.  6.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8] -> size -> 24 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[194.88353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 3.  6. 11. 16.  1.  0.  3.  6. 11.  3.  0.  0.  0.  8.  3.  0.  6.  0.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -4.195373058319092
desired expected reward: 173.76890563964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[179.12007]
 [184.70651]
 [184.19147]
 [172.25296]
 [182.72702]
 [191.23222]
 [185.5769 ]
 [189.79568]
 [179.16574]
 [185.14127]
 [185.21065]
 [197.11914]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 3.  6. 11. 16.  1.  0.  3.  6. 11.  3.  0.  0.  0.  8.  3.  0.  6.  0.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -5.264013290405273
desired expected reward: 190.4178009033203



buy possibilites: [-1] 
expected returns: [[230.2163]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 3.  6. 11. 16.  1.  0.  3.  6. 11.  3.  0.  0.  0.  8.  3.  0.  6.  0.
  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  7. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 38 

action type: buy - action 15.0
Learning step: -2.1806678771972656
desired expected reward: 183.03001403808594






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  7. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  1.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15] -> size -> 25 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  7. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  1.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15] -> size -> 25 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 6.  1.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[231.00464]
 [224.612  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  7. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -6.082493782043457
desired expected reward: 224.13380432128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[213.77228]
 [220.18852]
 [219.43353]
 [205.79681]
 [227.46616]
 [221.21182]
 [220.53642]
 [234.08118]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  7. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -6.1912970542907715
desired expected reward: 224.2061767578125



buy possibilites: [-1] 
expected returns: [[215.64899]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  3.  0. 11.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5.  0.  1. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 8.0 

action type: buy - action 8.0
Learning step: -5.674489974975586
desired expected reward: 215.53732299804688






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  6.] 
adversary cards in discard: [ 8.  6.  1.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8] -> size -> 26 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  6.] 
adversary cards in discard: [ 8.  6.  1.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8] -> size -> 26 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  6.] 
adversary cards in discard: [ 8.  6.  1.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8] -> size -> 26 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  6.] 
adversary cards in discard: [ 8.  6.  1.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8] -> size -> 26 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[196.82704]
 [191.47165]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  6.] 
cards in discard: [ 8.  6.  1.  3.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -6.0820231437683105
desired expected reward: 209.5669708251953



action possibilites: [-1] 
expected returns: [[206.36789]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [ 8.  6.  1.  3.  0. 11. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  7.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 35 

action type: gain_card_n - action 5
Learning step: -2.5165774822235107
desired expected reward: 175.68052673339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[187.45746]
 [192.85175]
 [180.14174]
 [194.25949]
 [208.76852]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [ 8.  6.  1.  3.  0. 11. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  7.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -4.599188327789307
desired expected reward: 201.76870727539062






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  7.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 6. 3. 6.] 
adversary cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11] -> size -> 27 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  7.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 6. 3. 6.] 
adversary cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11] -> size -> 27 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  6.  9.  7.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 6. 3. 6.] 
adversary cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11] -> size -> 27 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [8. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[149.47052]
 [138.88593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 3. 6.] 
cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  6.  9.  7.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -6.8563103675842285
desired expected reward: 201.9121856689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[132.73944 ]
 [126.058495]
 [149.49979 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 3. 6.] 
cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  6.  9.  7.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -4.065174579620361
desired expected reward: 145.8761749267578



buy possibilites: [-1] 
expected returns: [[145.28511]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 3. 6.] 
cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  5.  9.  7.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -18.28400993347168
desired expected reward: 107.77449798583984






Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  9.  7.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.  6.  8.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6] -> size -> 28 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 27. 30.  8.  5.  9.  7.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.  6.  8.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6] -> size -> 28 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  9.  7.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.  6.  8.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6] -> size -> 28 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [16.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[176.8179 ]
 [158.91418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.  6.  8.  0.  6.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  9.  7.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -3.7451329231262207
desired expected reward: 141.53997802734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[151.84857]
 [158.70282]
 [158.17354]
 [143.41283]
 [156.27747]
 [166.85481]
 [159.7694 ]
 [165.05824]
 [151.99484]
 [159.35274]
 [159.49693]
 [173.73201]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.  6.  8.  0.  6.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 27. 30.  8.  5.  9.  7.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -5.320725440979004
desired expected reward: 169.0795135498047



buy possibilites: [-1] 
expected returns: [[159.7562]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.  6.  8.  0.  6.  3.  6.
 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  5.  9.  6.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -4.773227214813232
desired expected reward: 162.08160400390625






Player: 1 
cards in hand: [8. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  9.  6.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.  6.  8.  0.  6.  3.  6.
 11. 16.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11] -> size -> 29 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 27. 30.  8.  5.  9.  6.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.  6.  8.  0.  6.  3.  6.
 11. 16.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11] -> size -> 29 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  6.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.  6.  8.  0.  6.  3.  6.
 11. 16.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11] -> size -> 29 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[121.191765]
 [107.17004 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15.  3.] 
cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.  6.  8.  0.  6.  3.  6.
 11. 16.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  6.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 0] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -5.669120788574219
desired expected reward: 154.08706665039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 95.11564 ]
 [100.83036 ]
 [ 87.39709 ]
 [102.287415]
 [115.82853 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 15.  3.] 
cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.  6.  8.  0.  6.  3.  6.
 11. 16.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  6.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 0] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -3.890422821044922
desired expected reward: 115.66464233398438



buy possibilites: [-1] 
expected returns: [[82.22961]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 15.  3.] 
cards in discard: [ 8.  6.  1.  3.  0. 11. 11. 11.  0.  3.  0.  6.  6.  8.  0.  6.  3.  6.
 11. 16.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  6.  4. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 0] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -3.1142046451568604
desired expected reward: 99.17321014404297






Player: 1 
cards in hand: [0. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  6.  4. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  6. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8] -> size -> 30 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  6.  4. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  6. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8] -> size -> 30 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  6.  4. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  6. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8] -> size -> 30 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  5.  4. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  6. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8] -> size -> 30 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  6. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[202.08922]
 [189.41869]
 [186.22386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 16.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  5.  4. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0.017601395025849342
desired expected reward: 82.24720764160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[186.17513]
 [191.51913]
 [179.5793 ]
 [193.06595]
 [206.781  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 16.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  5.  4. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -5.974639415740967
desired expected reward: 196.25558471679688



buy possibilites: [-1] 
expected returns: [[167.4873]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 16.  0.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 11] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -5.571012496948242
desired expected reward: 187.49493408203125






Player: 1 
cards in hand: [ 8. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8] -> size -> 31 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8] -> size -> 31 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8] -> size -> 31 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[150.52965]
 [144.07901]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -5.254519462585449
desired expected reward: 162.2327880859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[135.74495]
 [140.81555]
 [129.02972]
 [142.00526]
 [153.83167]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -4.631190776824951
desired expected reward: 147.5294189453125



buy possibilites: [-1] 
expected returns: [[147.76564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: -5.212520122528076
desired expected reward: 130.53240966796875






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  1.  6.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  1.  6.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  1.  6.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 15.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[173.01851]
 [161.69719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  1.  6.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -3.843229293823242
desired expected reward: 143.9224090576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[146.36021]
 [151.82494]
 [151.23581]
 [139.5109 ]
 [149.88184]
 [158.04051]
 [152.6853 ]
 [156.66785]
 [146.30519]
 [152.16751]
 [152.17824]
 [164.55127]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  1.  6.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -5.417935848236084
desired expected reward: 167.57098388671875



buy possibilites: [-1] 
expected returns: [[141.31029]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  1.  6.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: -3.3039116859436035
desired expected reward: 153.36395263671875






Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  6.  0. 11. 11.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29] -> size -> 33 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  6.  0. 11. 11.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29] -> size -> 33 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  6.  0. 11. 11.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29] -> size -> 33 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[128.9453 ]
 [121.88697]
 [121.88697]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 11. 11.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -4.57129430770874
desired expected reward: 136.73899841308594



action possibilites: [-1] 
expected returns: [[140.66563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 11.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.
 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: -1.5657932758331299
desired expected reward: 117.04961395263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[121.595894]
 [114.80473 ]
 [139.02782 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 11.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.
 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -3.3953895568847656
desired expected reward: 137.27024841308594






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.
 10. 11.  3.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10] -> size -> 34 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.
 10. 11.  3.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.
 10. 11.  3.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10] -> size -> 34 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.
 10. 11.  3.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10] -> size -> 34 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [8. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[82.25666 ]
 [67.642105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.
 10. 11.  3.  6.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -5.477044582366943
desired expected reward: 133.55076599121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[58.71107 ]
 [63.27187 ]
 [53.584263]
 [64.29288 ]
 [77.863686]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.
 10. 11.  3.  6.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 27. 30.  8.  5.  9.  5.  3. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -2.858642578125
desired expected reward: 79.39803314208984



buy possibilites: [-1] 
expected returns: [[46.766773]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.
 10. 11.  3.  6.  0. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -2.012392282485962
desired expected reward: 62.28049850463867






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  3.  6.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.
 10. 11.  3.  6.  0. 11.  8.  8.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8] -> size -> 35 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  3.  6.] 
adversary cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.
 10. 11.  3.  6.  0. 11.  8.  8.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8] -> size -> 35 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[78.59916]
 [68.95681]
 [73.71235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  3.  6.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.
 10. 11.  3.  6.  0. 11.  8.  8.  0.  6.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.90365070104599
desired expected reward: 45.863121032714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[61.169567]
 [56.87097 ]
 [75.43487 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  3.  6.] 
cards in discard: [ 8.  8.  0.  6. 16.  0.  0.  3.  3.  0.  0. 11. 29.  0.  0. 15.  1.  6.
 10. 11.  3.  6.  0. 11.  8.  8.  0.  6.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -2.6720073223114014
desired expected reward: 75.92716217041016



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [1. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8] -> size -> 35 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [1. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8] -> size -> 35 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [1. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8] -> size -> 35 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [1. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8] -> size -> 35 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [1. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[256.9404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 1.807206392288208
desired expected reward: 77.24209594726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[229.22562]
 [234.7815 ]
 [234.10016]
 [222.3037 ]
 [232.7326 ]
 [241.24814]
 [235.7096 ]
 [239.86627]
 [229.10997]
 [235.10274]
 [235.12112]
 [246.82777]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -7.762417793273926
desired expected reward: 249.35400390625



buy possibilites: [-1] 
expected returns: [[204.00864]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3. 0.] 
cards in discard: [0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 4 
card supply: [14. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: -36.0 

action type: buy - action 0.0
Learning step: -8.6710844039917
desired expected reward: 220.55450439453125






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [0. 1. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8  0] -> size -> 36 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [0. 1. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8  0] -> size -> 36 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [0. 1. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8  0] -> size -> 36 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [0. 1. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8  0] -> size -> 36 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [11.  6.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[195.35876]
 [187.0237 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  3.] 
cards in discard: [0. 1. 0. 6. 3. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -6.1315016746521
desired expected reward: 197.87713623046875



action possibilites: [-1] 
expected returns: [[210.74051]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8  0 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -2  0  0  9  0] 
sum of rewards: 22 

action type: gain_card_n - action 9
Learning step: -3.510847806930542
desired expected reward: 183.53933715820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[183.86198]
 [189.6717 ]
 [175.62683]
 [191.4638 ]
 [204.37859]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8  0 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -5.454573154449463
desired expected reward: 205.2859344482422






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [6. 8. 0. 6. 3.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8  0 10] -> size -> 37 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [6. 8. 0. 6. 3.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8  0 10] -> size -> 37 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [6. 8. 0. 6. 3.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8  0 10] -> size -> 37 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [6. 8. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[140.55142]
 [127.66078]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 6. 3.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 11  0 11  0 16  1  6  3  6  6  8
 15  8 11  6 11  8  8  0 29 10  8  0 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -7.463913917541504
desired expected reward: 196.91468811035156



action possibilites: [-1] 
expected returns: [[179.2991]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  0 11  0 16  1  6  3  6  6  8 15  8 11
  6 11  8  8  0 29 10  8  0 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.8086376190185547
desired expected reward: 130.0487060546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[154.76295]
 [145.20596]
 [180.84323]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  0 11  0 16  1  6  3  6  6  8 15  8 11
  6 11  8  8  0 29 10  8  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 29. 30. 27. 30.  8.  5.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -4.501922130584717
desired expected reward: 174.79718017578125



buy possibilites: [-1] 
expected returns: [[187.8981]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  0 11  0 16  1  6  3  6  6  8 15  8 11
  6 11  8  8  0 29 10  8  0 10  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -296 

action type: buy - action 6.0
Learning step: -17.83259391784668
desired expected reward: 127.37338256835938






Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 29. 11.  8.  0.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  0 11  0 16  1  6  3  6  6  8 15  8 11
  6 11  8  8  0 29 10  8  0 10  6] -> size -> 35 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 29. 11.  8.  0.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  0 11  0 16  1  6  3  6  6  8 15  8 11
  6 11  8  8  0 29 10  8  0 10  6] -> size -> 35 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.  8.] 
expected returns: [[144.62167]
 [134.55788]
 [138.81784]
 [140.0802 ]
 [134.55788]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 11.  8.  0.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  0 11  0 16  1  6  3  6  6  8 15  8 11
  6 11  8  8  0 29 10  8  0 10  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -7.049003601074219
desired expected reward: 180.84909057617188



action possibilites: [-1] 
expected returns: [[90.568535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11
  8  8  0 10  8  0 10  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: trash_cards_n_from_hand - action 12
Learning step: -4.172829627990723
desired expected reward: 124.03960418701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[74.39656]
 [68.55235]
 [91.29822]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11
  8  8  0 10  8  0 10  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -2.502873182296753
desired expected reward: 88.06565856933594






Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  0.  8.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11
  8  8  0 10  8  0 10  6] -> size -> 32 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  0.  8.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11
  8  8  0 10  8  0 10  6] -> size -> 32 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  0.  8.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11
  8  8  0 10  8  0 10  6] -> size -> 32 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  0.  8.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11
  8  8  0 10  8  0 10  6] -> size -> 32 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
expected returns: [[128.86282]
 [118.91925]
 [118.90439]
 [118.91925]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  0.  8.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11
  8  8  0 10  8  0 10  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -2.614372491836548
desired expected reward: 88.68385314941406



action possibilites: [-1] 
expected returns: [[95.113914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action 15.0
Learning step: -3.4360928535461426
desired expected reward: 112.08702087402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[77.8042 ]
 [83.55428]
 [83.08496]
 [70.7021 ]
 [81.54294]
 [90.29486]
 [84.44348]
 [88.75951]
 [77.86586]
 [84.05929]
 [84.10144]
 [96.69676]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -2.6070334911346436
desired expected reward: 92.50688171386719






Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3.  3. 10.  0.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8. 15.
  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6] -> size -> 31 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 29. 30. 27. 30.  8.  4.  9.  5.  2. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3.  3. 10.  0.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8. 15.
  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6] -> size -> 31 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 27. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3.  3. 10.  0.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8. 15.
  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6] -> size -> 31 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [11.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[131.70148]
 [125.83873]
 [120.11527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3. 10.  0.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8. 15.
  8.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 27. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -2.8175930976867676
desired expected reward: 93.87915802001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[110.60032]
 [104.87821]
 [127.43134]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3. 10.  0.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8. 15.
  8.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 29. 30. 27. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -4.643608093261719
desired expected reward: 125.02989959716797



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 27. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  0. 16.  0. 11.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8. 15.
  8.  0.  8. 11.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6] -> size -> 31 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 29. 30. 27. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  0. 16.  0. 11.] 
adversary cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8. 15.
  8.  0.  8. 11.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6] -> size -> 31 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 16.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[126.953316]
 [111.342445]
 [120.48026 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  0. 11.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8. 15.
  8.  0.  8. 11.  3.  3. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 27. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -4.442480564117432
desired expected reward: 122.98886108398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[102.12686 ]
 [107.472046]
 [ 95.16669 ]
 [108.625336]
 [121.47994 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  0. 11.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8. 15.
  8.  0.  8. 11.  3.  3. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 29. 30. 27. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -4.665342807769775
desired expected reward: 122.2879867553711



buy possibilites: [-1] 
expected returns: [[115.48342]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  0. 11.] 
cards in discard: [ 0.  1.  0.  6.  3.  0. 10. 11.  6.  0.  0.  3.  6.  8.  6.  8.  8. 15.
  8.  0.  8. 11.  3.  3. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 29. 30. 27. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -46.0 

action type: buy - action 0.0
Learning step: -4.8079657554626465
desired expected reward: 97.31888580322266






Player: 1 
cards in hand: [0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 27. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 29. 30. 27. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[115.37579]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 3] -> size -> 5 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -4.491467475891113
desired expected reward: 110.99195098876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 99.13544 ]
 [103.92967 ]
 [103.29919 ]
 [ 92.91916 ]
 [109.30812 ]
 [104.70177 ]
 [104.125015]
 [113.95179 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 3] -> size -> 5 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -4.6489715576171875
desired expected reward: 110.13787078857422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0. 10.] 
adversary cards in discard: [6. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0. 10.] 
adversary cards in discard: [6. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0. 10.] 
adversary cards in discard: [6. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
expected returns: [[122.357216]
 [109.171074]
 [108.99651 ]
 [108.869606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  0. 10.] 
cards in discard: [6. 3. 0. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -3.926645040512085
desired expected reward: 110.02516174316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[106.16504]
 [111.24799]
 [ 99.35162]
 [112.52436]
 [125.71047]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  0. 10.] 
cards in discard: [6. 3. 0. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -4.32403039932251
desired expected reward: 117.63592529296875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  8.  3.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  8.  3.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  8.  3.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  8.  3.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
expected returns: [[149.16142]
 [136.5269 ]
 [142.75824]
 [136.5269 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  8.  3.] 
cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -3.9128379821777344
desired expected reward: 121.79763793945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[129.1067 ]
 [121.78347]
 [148.576  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  8.  3.] 
cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -5.0786895751953125
desired expected reward: 142.01824951171875



buy possibilites: [-1] 
expected returns: [[138.71129]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  8.  3.] 
cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action 0.0
Learning step: -5.634331703186035
desired expected reward: 123.47237396240234






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 6. 0. 8.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0  0] -> size -> 33 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 6. 0. 8.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0  0] -> size -> 33 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [6. 1. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[118.437386]
 [106.96036 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 6. 0. 8.] 
cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11  0 16  1  6  3  6  6  8 15  8 11  6 11  8
  8  0 10  8  0 10  6  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -5.276988983154297
desired expected reward: 133.43429565429688



action possibilites: [-1] 
expected returns: [[67.5977]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: -2.801232099533081
desired expected reward: 98.64237213134766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.3324 ]
 [46.46786]
 [68.96283]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -1.3038667440414429
desired expected reward: 66.29383850097656



buy possibilites: [-1] 
expected returns: [[65.54094]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action 0.0
Learning step: -1.8919495344161987
desired expected reward: 50.440460205078125






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 10.  0. 11.  6.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.  0.  8.
  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 10.  0. 11.  6.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.  0.  8.
  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 10.  0. 11.  6.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.  0.  8.
  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[101.44124]
 [ 90.29527]
 [ 89.83554]
 [ 95.83727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 11.  6.] 
cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.  0.  8.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.4190834760665894
desired expected reward: 64.12185668945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 84.087746]
 [ 77.89668 ]
 [101.39087 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0. 11.  6.] 
cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.  0.  8.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -3.157276153564453
desired expected reward: 95.90838623046875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [16.  3. 11.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.  0.  8.
  6.  8. 10.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [16.  3. 11.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.  0.  8.
  6.  8. 10.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [16.  3. 11.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.  0.  8.
  6.  8. 10.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [16.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[145.56746]
 [133.03812]
 [140.66432]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 11.  0.  0.] 
cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.  0.  8.
  6.  8. 10.  0. 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -2.1673405170440674
desired expected reward: 99.22351837158203



action possibilites: [-1] 
expected returns: [[102.34953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  0.] 
cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.  0.  8.
  6.  8. 10.  0. 11.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: -3.5115725994110107
desired expected reward: 136.7771759033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[85.01585 ]
 [89.10723 ]
 [79.822845]
 [90.31603 ]
 [99.868385]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.] 
cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.  0.  8.
  6.  8. 10.  0. 11.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -2.3114888668060303
desired expected reward: 100.03804779052734



buy possibilites: [-1] 
expected returns: [[108.51686]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.] 
cards in discard: [ 6.  3.  0.  0.  0.  8.  0. 15.  0. 10.  0.  3.  8. 11.  8.  3.  0.  8.
  6.  8. 10.  0. 11.  6. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -15.0 

action type: buy - action 0.0
Learning step: -2.5591630935668945
desired expected reward: 82.45668029785156






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[154.0701 ]
 [147.89856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -2.3177096843719482
desired expected reward: 106.19915008544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[133.84825 ]
 [139.23816 ]
 [127.004166]
 [140.54492 ]
 [152.74507 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 29. 30. 26. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -4.63781213760376
desired expected reward: 146.98536682128906



buy possibilites: [-1] 
expected returns: [[113.23622]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  6.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 25. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 14 

action type: buy - action 3.0
Learning step: -3.7140939235687256
desired expected reward: 135.52407836914062






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 25. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  8.  8.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3] -> size -> 34 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 29. 30. 25. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  8.  8.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3] -> size -> 34 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
expected returns: [[89.03995]
 [79.78971]
 [80.24364]
 [80.24364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  8.  8.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 25. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -3.484889268875122
desired expected reward: 109.75133514404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[77.16455 ]
 [72.225945]
 [90.7652  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.  8.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 29. 30. 25. 30.  8.  4.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -2.2684686183929443
desired expected reward: 86.23807525634766



buy possibilites: [-1] 
expected returns: [[104.96573]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.  8.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 29. 30. 25. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -16.41774559020996
desired expected reward: 55.808204650878906






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 25. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6] -> size -> 35 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 25. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6] -> size -> 35 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 29. 30. 25. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6] -> size -> 35 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[72.40596 ]
 [63.382633]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  0.  0.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 25. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -3.9450719356536865
desired expected reward: 101.02066040039062



action possibilites: [-1.] 
expected returns: [[66.746284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 25. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 16 

action type: take_action - action 10.0
Learning step: -0.8698553442955017
desired expected reward: 62.563079833984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[57.04098 ]
 [61.169895]
 [60.68618 ]
 [51.869343]
 [59.6976  ]
 [65.82324 ]
 [61.831078]
 [64.79344 ]
 [56.965897]
 [61.398426]
 [61.384968]
 [69.86445 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 29. 30. 25. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -1.1679766178131104
desired expected reward: 65.57830810546875






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 25. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 16.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6] -> size -> 35 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 25. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 16.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6] -> size -> 35 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 29. 30. 25. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 16.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6] -> size -> 35 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 25. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 16.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6] -> size -> 35 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[103.455246]
 [ 90.206696]
 [ 87.50816 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 16.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 25. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -1.5791658163070679
desired expected reward: 68.2852783203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 84.00075 ]
 [ 90.115234]
 [ 89.62561 ]
 [ 76.648346]
 [ 97.35024 ]
 [ 91.053986]
 [ 90.664856]
 [103.841606]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 16.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 29. 30. 25. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -3.327465772628784
desired expected reward: 100.30368041992188



buy possibilites: [-1] 
expected returns: [[100.09717]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 16.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.
  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 29. 30. 24. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5.  0.  1. 10.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  2.  0.] 
sum of rewards: 7.0 

action type: buy - action 3.0
Learning step: -1.8790947198867798
desired expected reward: 87.74652099609375






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 24. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 11. 15.  3.  8.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.
  3. 10.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6  3] -> size -> 36 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 29. 30. 24. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 11. 15.  3.  8.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.
  3. 10.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6  3] -> size -> 36 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 29. 30. 24. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 11. 15.  3.  8.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.
  3. 10.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6  3] -> size -> 36 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 15.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 15.  8.] 
expected returns: [[75.28009]
 [67.42958]
 [71.28574]
 [67.0418 ]
 [67.42958]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 15.  3.  8.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.
  3. 10.  0.  0.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 11  0 16  3  6  6  8 15  8 11  6 11  8  8  0 10
  8  0 10  6  0  0  0 10  0  3  6  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 24. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -3.1077163219451904
desired expected reward: 96.98944854736328



action possibilites: [-1] 
expected returns: [[79.52717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.
  3. 10.  0.  0.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 24. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.5008403658866882
desired expected reward: 71.30319213867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[67.003815]
 [62.455746]
 [79.54266 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.
  3. 10.  0.  0.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 29. 30. 24. 30.  8.  3.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -1.0575071573257446
desired expected reward: 78.46965789794922



buy possibilites: [-1] 
expected returns: [[63.806507]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.
  3. 10.  0.  0.  0. 16.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 24. 30.  8.  2.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -15.937141418457031
desired expected reward: 46.518611907958984






Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 24. 30.  8.  2.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [6. 8. 0. 3. 6.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.
  3. 10.  0.  0.  0. 16.  6.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6] -> size -> 35 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 29. 30. 24. 30.  8.  2.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [6. 8. 0. 3. 6.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.
  3. 10.  0.  0.  0. 16.  6.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6] -> size -> 35 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [6. 8. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[57.974823]
 [45.162186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 3. 6.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.
  3. 10.  0.  0.  0. 16.  6.  8. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 24. 30.  8.  2.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -2.246731996536255
desired expected reward: 61.559776306152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.768375]
 [34.274246]
 [61.242035]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 3. 6.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.
  3. 10.  0.  0.  0. 16.  6.  8. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 29. 30. 24. 30.  8.  2.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -2.0444016456604004
desired expected reward: 55.930423736572266



buy possibilites: [-1] 
expected returns: [[56.40281]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 3. 6.] 
cards in discard: [ 3.  0.  3. 11.  0.  6.  6.  0. 10.  3.  8.  8. 10.  0.  6.  0.  0.  0.
  3. 10.  0.  0.  0. 16.  6.  8. 15.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 29. 30. 24. 30.  8.  1.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -10.    0.    0.    0.    0.    0.    0.    0.   -1.
    0. -300.    0.    0.] 
sum of rewards: -317.0 

action type: buy - action 6.0
Learning step: -16.294649124145508
desired expected reward: 17.979589462280273






Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 24. 30.  8.  1.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6] -> size -> 36 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 29. 30. 24. 30.  8.  1.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6] -> size -> 36 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[109.967896]
 [105.51163 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 24. 30.  8.  1.  9.  5.  1. 10.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -1.2136452198028564
desired expected reward: 55.18916320800781



action possibilites: [-1] 
expected returns: [[99.48199]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 24. 30.  8.  1.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0  -2   0   0   9   0] 
sum of rewards: 11 

action type: gain_card_n - action 9
Learning step: -2.3104653358459473
desired expected reward: 99.66573333740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 89.711754]
 [ 94.126595]
 [ 93.48951 ]
 [ 84.17599 ]
 [ 98.66441 ]
 [ 94.85009 ]
 [ 94.26    ]
 [102.135735]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 29. 30. 24. 30.  8.  1.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -2.618074417114258
desired expected reward: 96.8639144897461






Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 24. 30.  8.  1.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  6.  6.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10] -> size -> 37 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 24. 30.  8.  1.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  6.  6.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10] -> size -> 37 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 29. 30. 24. 30.  8.  1.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  6.  6.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10] -> size -> 37 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 29. 30. 24. 30.  8.  1.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  6.  6.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10] -> size -> 37 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[98.34162]
 [91.15084]
 [90.61697]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  6.  6.] 
cards in discard: [10. 11.  0.  6.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 29. 30. 24. 30.  8.  1.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -3.8047730922698975
desired expected reward: 98.33096313476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[85.893456]
 [81.20477 ]
 [97.71273 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  6.  6.] 
cards in discard: [10. 11.  0.  6.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 29. 30. 24. 30.  8.  1.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -3.6271324157714844
desired expected reward: 93.61885070800781



buy possibilites: [-1] 
expected returns: [[127.058266]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  6.  6.] 
cards in discard: [10. 11.  0.  6.  0.  0.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 29. 30. 24. 30.  8.  0.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -20.    0.    0.    0.    0.    0.    0.    0.   -3.
    0. -300.    0.    0.] 
sum of rewards: -330.0 

action type: buy - action 6.0
Learning step: -17.70142936706543
desired expected reward: 63.50334167480469






Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 29. 30. 24. 30.  8.  0.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10  6] -> size -> 38 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 29. 30. 24. 30.  8.  0.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10  6] -> size -> 38 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 29. 30. 24. 30.  8.  0.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10  6] -> size -> 38 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[91.561806]
 [80.93839 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 16.] 
cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 29. 30. 24. 30.  8.  0.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -5.791795253753662
desired expected reward: 121.26647186279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[78.30557 ]
 [82.1031  ]
 [81.89415 ]
 [80.77919 ]
 [86.74611 ]
 [82.69342 ]
 [85.68297 ]
 [78.443306]
 [82.55396 ]
 [82.635414]
 [91.01033 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 16.] 
cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 29. 30. 24. 30.  8.  0.  9.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -3.892253875732422
desired expected reward: 85.13082885742188



buy possibilites: [-1] 
expected returns: [[75.52881]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 16.] 
cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0  -4   0   0  32   0] 
sum of rewards: 1 

action type: buy - action 16.0
Learning step: -2.2895610332489014
desired expected reward: 78.4896240234375






Player: 1 
cards in hand: [0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3.  8. 15.  3.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 39 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3.  8. 15.  3.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 39 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3.  8. 15.  3.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 39 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[80.15202]
 [71.58483]
 [71.3835 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 15.  3.] 
cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0
 10  6  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -3.4229989051818848
desired expected reward: 72.1058120727539



action possibilites: [-1] 
expected returns: [[86.459145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3.] 
cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0 10
  6  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action 15.0
Learning step: -1.9738438129425049
desired expected reward: 69.4096450805664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[69.95295 ]
 [75.37126 ]
 [74.98934 ]
 [81.87072 ]
 [76.20255 ]
 [75.90963 ]
 [87.696365]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3.] 
cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0 10
  6  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1
Learning step: -2.8774571418762207
desired expected reward: 83.5816879272461






Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 0.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.
 15.  3.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0 10
  6  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 38 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 0.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.
 15.  3.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0 10
  6  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 38 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 0.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.
 15.  3.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0 10
  6  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 38 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 0.] 
adversary cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.
 15.  3.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0 10
  6  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 38 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [8. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[66.64648]
 [60.49831]
 [60.49831]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 8. 0.] 
cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.
 15.  3.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 16  3  6  6 15  8 11  6 11  8  8  0 10  8  0 10
  6  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -4.306188106536865
desired expected reward: 83.39016723632812



action possibilites: [-1] 
expected returns: [[99.34132]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.
 15.  3.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0 16  3  6 15  8 11  6 11  8  8  0 10  8  0 10  6
  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: trash_cards_n_from_hand - action 0
Learning step: -0.41855889558792114
desired expected reward: 56.656211853027344





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[85.258446]
 [86.44843 ]
 [98.07845 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.
 15.  3.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0 16  3  6 15  8 11  6 11  8  8  0 10  8  0 10  6
  0  0  0 10  0  3  6  3  6  6 10  6 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 29. 30. 24. 30.  8.  0.  8.  5.  1. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -2.7013096809387207
desired expected reward: 96.64000701904297



Player 1 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 1 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 1 
Workshop: 3 
Chapel: 6 
Witch: 0 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 8. 0.] 
cards in discard: [10. 11.  0.  6.  0.  0.  6.  8.  0. 10.  6.  6. 16.  0.  0.  0.  0. 16.
 15.  3.  8.  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0 16  3  6 15  8 11  6 11  8  8  0 10  8  0 10  6
  0  0  0 10  0  3  6  3  6  6 10  6 16  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 30. 24. 30.  8.  0.  8.  5.  0. 10.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[  -5 -500   -1  -10    0    0   20    0    0    0    0   -3    0    0
    4    0] 
sum of rewards: -495 

action type: buy - action 8.0
Learning step: -29.07242202758789
desired expected reward: 57.375980377197266



