 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.489376]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5 500   0   0   0   0  20   0   0   0   0  -4   0   0   4   0] 
sum of rewards: 515 

action type: buy - action 8.0
Learning step: 14.60766887664795
desired expected reward: 42.685359954833984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.933273]
 [20.355503]
 [18.849913]
 [14.424901]
 [18.5859  ]
 [21.7933  ]
 [20.858618]
 [21.888216]
 [17.301828]
 [19.34745 ]
 [19.71162 ]
 [19.77385 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5390496850013733
desired expected reward: 19.34735107421875



buy possibilites: [-1] 
expected returns: [[20.852879]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.43654218316078186
desired expected reward: 18.413372039794922






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.331785]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5491852164268494
desired expected reward: 20.303693771362305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.078642]
 [22.538658]
 [21.013325]
 [16.527617]
 [24.001396]
 [23.050495]
 [21.516438]
 [21.946878]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5672502517700195
desired expected reward: 20.994762420654297



buy possibilites: [-1] 
expected returns: [[20.927048]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.426094055175781
desired expected reward: 7.101522445678711






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.640987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 8. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5582810640335083
desired expected reward: 20.36876678466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.114475]
 [20.026367]
 [15.624274]
 [22.015835]
 [20.93658 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 8. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5668308734893799
desired expected reward: 20.340822219848633



buy possibilites: [-1] 
expected returns: [[19.34434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 8. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5203186273574829
desired expected reward: 18.594154357910156






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 8. 10.  0.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 8. 10.  0.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 8. 10.  0.  3.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.984962]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [0. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5300508141517639
desired expected reward: 18.814289093017578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.526937]
 [19.916895]
 [18.438828]
 [14.036736]
 [18.176208]
 [21.32696 ]
 [20.410318]
 [21.420065]
 [16.898766]
 [18.929712]
 [19.285448]
 [19.346514]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [0. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5192451477050781
desired expected reward: 18.554977416992188



buy possibilites: [-1] 
expected returns: [[19.356842]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 0.  3.  3.  0.  3.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 15.0
Learning step: 0.43468332290649414
desired expected reward: 19.72013282775879






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 15] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 15] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 15] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.035702]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [8. 8. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4968954622745514
desired expected reward: 18.859947204589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.515118]
 [22.948532]
 [21.44505 ]
 [16.955862]
 [21.177185]
 [24.37904 ]
 [23.449104]
 [24.473476]
 [19.874508]
 [21.945623]
 [22.307926]
 [22.369852]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [8. 8. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5833448171615601
desired expected reward: 21.684255599975586



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [8. 8. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  0.  3.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 15] -> size -> 14 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 8. 0. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8  8] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  0.  3.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 15] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 8. 0. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  0.  3.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 15] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [15.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[20.36624 ]
 [20.304314]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3.  3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6063700914382935
desired expected reward: 21.763479232788086



action possibilites: [-1] 
expected returns: [[24.076878]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.09042073786258698
desired expected reward: 20.50330352783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.451246]
 [24.897097]
 [23.38593 ]
 [18.87531 ]
 [23.116673]
 [26.34615 ]
 [25.400211]
 [26.442688]
 [21.807364]
 [23.889042]
 [24.253216]
 [24.315441]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.017150459811091423
desired expected reward: 24.05972671508789



buy possibilites: [-1] 
expected returns: [[22.631277]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.031114080920815468
desired expected reward: 21.914926528930664






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  8  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  8  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  8  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  8  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[17.931921]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  8  8  0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6381720900535583
desired expected reward: 21.993104934692383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[16.391   ]
 [18.748863]
 [17.292093]
 [13.031964]
 [20.133966]
 [19.232878]
 [17.776106]
 [18.173939]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  8  8  0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5049450397491455
desired expected reward: 17.66326141357422



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  8.] 
cards in discard: [0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  8  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  8.] 
cards in discard: [0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  8  8  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  8.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  8  8  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [15.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[15.8431015]
 [15.796299 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0.  0.] 
cards in discard: [0. 0. 0. 6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0.  8.  0.  0.  0. 10.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  8  8  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5281369686126709
desired expected reward: 17.645801544189453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[14.332992]
 [16.692656]
 [15.22542 ]
 [10.9954  ]
 [18.105219]
 [17.18625 ]
 [15.708496]
 [16.107344]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  0.  0.] 
cards in discard: [0. 0. 0. 6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 28. 30.  8.  9. 10. 10.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0.  8.  0.  0.  0. 10.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  8  8  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4593440294265747
desired expected reward: 15.471871376037598



buy possibilites: [-1] 
expected returns: [[18.798656]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  0.  0.] 
cards in discard: [ 0.  0.  0.  6.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0.  8.  0.  0.  0. 10.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  8  8  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0.044229354709386826
desired expected reward: 18.149446487426758






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 0.  8.  0.  0.  0. 10.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  8  8  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  8.  0.  0.  0. 10.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  8  8  8  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  0.  0.  0. 10.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  8  8  8  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  0.  0.  0. 10.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  8  8  8  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[16.646013]
 [18.603552]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  8  8  8  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5243716239929199
desired expected reward: 18.27428436279297



action possibilites: [-1] 
expected returns: [[18.702162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  8  8  8  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 5
Learning step: 0.4523996412754059
desired expected reward: 15.918168067932129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.230104]
 [18.116343]
 [13.921614]
 [20.050827]
 [18.989748]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  8  8  8  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.07940042018890381
desired expected reward: 18.78156280517578



buy possibilites: [-1] 
expected returns: [[21.376509]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [11.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  8  8  8  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.31292855739593506
desired expected reward: 20.36375617980957






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  8  8  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [11.  8. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  8  8  8  0  0  0] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [11.  8. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  8  8  8  0  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [11.  8. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  8  8  8  0  0  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [11.  8. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[20.142393]
 [20.0955  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [11.  8. 11.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 10  8  8  8  0  0  0  8] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5793121457099915
desired expected reward: 20.797197341918945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.495667]
 [20.83629 ]
 [19.388124]
 [15.09153 ]
 [22.221397]
 [21.320307]
 [19.867498]
 [20.261549]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [11.  8. 11.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 10  8  8  8  0  0  0  8] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5442070960998535
desired expected reward: 19.66341209411621



buy possibilites: [-1] 
expected returns: [[18.96088]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [11.  8. 11.  0.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 30. 30. 28. 30.  8.  9. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 10  8  8  8  0  0  0  8] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5057806372642517
desired expected reward: 17.989883422851562






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  8  8  0  0  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  9. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [11.  8. 11.  0.  0.  3.  3.  0.  3.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  9. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [11.  8. 11.  0.  0.  3.  3.  0.  3.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  9. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [11.  8. 11.  0.  0.  3.  3.  0.  3.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 28. 30.  8.  9. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [11.  8. 11.  0.  0.  3.  3.  0.  3.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[17.328838]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [11.  8. 11.  0.  0.  3.  3.  0.  3.  0.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  9. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  8. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5358386635780334
desired expected reward: 18.42504119873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[15.8705015]
 [18.138132 ]
 [16.729176 ]
 [12.587984 ]
 [19.502684 ]
 [18.608322 ]
 [17.193253 ]
 [17.579622 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [11.  8. 11.  0.  0.  3.  3.  0.  3.  0.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 28. 30.  8.  9. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  8. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.48884615302085876
desired expected reward: 16.938552856445312



buy possibilites: [-1] 
expected returns: [[18.244923]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [11.  8. 11.  0.  0.  3.  3.  0.  3.  0.  0.  0. 15. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8  0 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  9. 10.  7.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  8. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0.016277674585580826
desired expected reward: 18.859411239624023






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 8.  8. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  9. 10.  7.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 28. 30.  8.  9. 10.  7.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[17.798328]
 [19.730206]
 [18.85044 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11 11  8  0 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  9. 10.  7.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  8. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.49714815616607666
desired expected reward: 17.747774124145508



action possibilites: [-1] 
expected returns: [[15.6384735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  9. 10.  7.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  8. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.0641452744603157
desired expected reward: 18.39943504333496





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[14.575475]
 [16.821604]
 [15.431623]
 [11.291536]
 [18.138153]
 [17.28177 ]
 [15.89179 ]
 [16.245216]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 28. 30.  8.  9. 10.  7.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  8. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.15089692175388336
desired expected reward: 15.7893705368042



buy possibilites: [-1] 
expected returns: [[17.344175]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9. 10.  7.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  8. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 1.0
Learning step: 0.6674656867980957
desired expected reward: 17.48906898498535






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 8.  8. 10.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9. 10.  7.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  6.  0.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 8.  8. 10.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 28. 30.  8.  9. 10.  7.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  6.  0.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1] -> size -> 19 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  3. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[15.273143]
 [17.189426]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  6.  0.] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9. 10.  7.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.49728938937187195
desired expected reward: 16.846885681152344



action possibilites: [-1] 
expected returns: [[15.587221]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 1.  8.  0.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9. 10.  7.  5. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.3233061730861664
desired expected reward: 19.001962661743164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.098986]
 [10.85202 ]
 [15.75235 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 1.  8.  0.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  9. 10.  7.  5. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.12943267822265625
desired expected reward: 15.716653823852539



buy possibilites: [-1] 
expected returns: [[15.229692]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 1.  8.  0.  0.  0. 10.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  8. 10.  7.  5. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.715648651123047
desired expected reward: 2.136371612548828






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [10.  8.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  8. 10.  7.  5. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 1.  8.  0.  0.  0. 10.  6. 11.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6] -> size -> 21 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 28. 30.  8.  8. 10.  7.  5. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 1.  8.  0.  0.  0. 10.  6. 11.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6] -> size -> 21 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[16.33019 ]
 [18.244558]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [ 1.  8.  0.  0.  0. 10.  6. 11.  3.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  8. 10.  7.  5. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [10.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4224557876586914
desired expected reward: 14.807236671447754



action possibilites: [-1] 
expected returns: [[17.460913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 1.  8.  0.  0.  0. 10.  6. 11.  3.  3.  6.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  8. 10.  7.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [10.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 7
Learning step: 0.7014914751052856
desired expected reward: 14.429762840270996





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[16.100721]
 [18.230495]
 [16.907892]
 [13.112972]
 [19.498499]
 [18.67275 ]
 [17.34165 ]
 [17.676607]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 1.  8.  0.  0.  0. 10.  6. 11.  3.  3.  6.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 28. 30.  8.  8. 10.  7.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [10.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.11153817921876907
desired expected reward: 17.572450637817383



buy possibilites: [-1] 
expected returns: [[15.926185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 1.  8.  0.  0.  0. 10.  6. 11.  3.  3.  6.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 29. 30. 28. 30.  8.  8. 10.  7.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [10.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.13548974692821503
desired expected reward: 16.23621368408203






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 8.] 
cards in discard: [10.  8.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8  8  8  0  0  0  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  8. 10.  7.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0] -> size -> 23 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10.  8.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  8  8  0  0  0  8  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  8. 10.  7.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0] -> size -> 23 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10.  8.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  8  8  0  0  0  8  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 28. 30.  8.  8. 10.  7.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0] -> size -> 23 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10.  8.  0.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  8  8  0  0  0  8  0  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  8. 10.  7.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0] -> size -> 23 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 8.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[13.764701]
 [14.671889]
 [13.767983]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  8. 10.  7.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  8  8  0  0  0  8  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4783618152141571
desired expected reward: 15.447822570800781



action possibilites: [-1] 
expected returns: [[16.10695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 29. 30. 27. 30.  8.  8. 10.  7.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  8  8  0  0  0  8  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.20504501461982727
desired expected reward: 14.00764274597168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.720384]
 [16.858677]
 [15.516472]
 [11.666207]
 [15.274671]
 [18.142336]
 [17.30506 ]
 [18.21561 ]
 [14.160688]
 [15.948722]
 [16.27024 ]
 [16.266525]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 27. 30.  8.  8. 10.  7.  5. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  8  8  0  0  0  8  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.13828617334365845
desired expected reward: 16.245237350463867



buy possibilites: [-1] 
expected returns: [[18.244755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3.] 
cards in discard: [29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  8. 10.  7.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  8  8  0  0  0  8  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 1.0551015138626099
desired expected reward: 19.270713806152344






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  8  8  0  0  0  8  0  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  8. 10.  7.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [29. 15.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29] -> size -> 23 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  8  8  0  0  0  8  0  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 27. 30.  8.  8. 10.  7.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [29. 15.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29] -> size -> 23 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  8  8  0  0  0  8  0  3  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 26. 30.  8.  8. 10.  7.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [29. 15.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29] -> size -> 23 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[18.548555]
 [20.497929]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [29. 15.  8.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 30.  8.  8. 10.  7.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  3 10  8  8  0  0  0  8  0  3  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4897520840167999
desired expected reward: 17.755002975463867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.230732]
 [19.470934]
 [18.077518]
 [14.075968]
 [20.817413]
 [19.939178]
 [18.529015]
 [18.857681]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [29. 15.  8.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 26. 30.  8.  8. 10.  7.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  3 10  8  8  0  0  0  8  0  3  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5098518133163452
desired expected reward: 18.087373733520508



buy possibilites: [-1] 
expected returns: [[15.013084]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [29. 15.  8.  0.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  7.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  3 10  8  8  0  0  0  8  0  3  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.03649074584245682
desired expected reward: 19.434446334838867






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 8.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  8  8  0  0  0  8  0  3  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  7.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  6.  0. 11.] 
adversary cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  8  0  0  0  8  0  3  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  7.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  6.  0. 11.] 
adversary cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  8  0  0  0  8  0  3  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  7.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  6.  0. 11.] 
adversary cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [29.  0.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[16.907274]
 [18.828894]
 [18.75618 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  0. 11.] 
cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  7.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  0  0  0  8  0  3  3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4074770510196686
desired expected reward: 14.605607032775879



action possibilites: [-1. 11. 10.] 
expected returns: [[18.936962]
 [20.902443]
 [18.601059]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11. 10.] 
cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  7.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  0  0  0  8  0  3  3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.09028695523738861
desired expected reward: 18.998334884643555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.419008]
 [19.6224  ]
 [18.230793]
 [14.337407]
 [20.960236]
 [20.085407]
 [18.68175 ]
 [19.00886 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11. 10.] 
cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  7.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  0  0  0  8  0  3  3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.08167076110839844
desired expected reward: 19.018632888793945



buy possibilites: [-1] 
expected returns: [[18.116194]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11. 10.] 
cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  0  0  0  8  0  3  3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.5514129400253296
desired expected reward: 21.511648178100586






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  0  0  0  8  0  3  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0. 11. 29.  0.  6.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1
 11] -> size -> 25 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 10  8  0  0  0  8  0  3  3] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0. 11. 29.  0.  6.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1
 11] -> size -> 25 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  0  0  8  0  3  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0. 11. 29.  0.  6.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1
 11] -> size -> 25 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  0  0  8  0  3  3] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0. 11. 29.  0.  6.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1
 11] -> size -> 25 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[16.745815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0. 11. 29.  0.  6.  0. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  8  0  3  3] -> size -> 8 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5175702571868896
desired expected reward: 17.598623275756836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[15.36853 ]
 [17.356586]
 [16.10363 ]
 [12.685735]
 [18.548014]
 [17.770878]
 [16.51091 ]
 [16.806614]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0. 11. 29.  0.  6.  0. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  8  0  3  3] -> size -> 8 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4759564995765686
desired expected reward: 16.277904510498047



buy possibilites: [-1] 
expected returns: [[16.833593]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [29. 15.  8.  0.  3.  1.  0.  0. 11.  3.  0. 11. 29.  0.  6.  0. 11. 10.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1
 11  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  8  0  3  3] -> size -> 8 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.353818893432617
desired expected reward: 3.331915855407715






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  8  0  3  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  8. 10.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1
 11  6] -> size -> 26 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  8. 10.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1
 11  6] -> size -> 26 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  8. 10.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1
 11  6] -> size -> 26 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  8. 10.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1
 11  6] -> size -> 26 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [ 6.  8. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[15.051925]
 [16.077747]
 [14.743842]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10.  1.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  6  0 15  0 11  8  0 11  1 10  6 29  0 29  1
 11  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  0  0] -> size -> 6 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.49194955825805664
desired expected reward: 16.341644287109375



action possibilites: [-1] 
expected returns: [[13.993834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  0  0] -> size -> 6 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 13
Learning step: 0.11532589048147202
desired expected reward: 16.16897201538086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.491028]
 [ 9.56802 ]
 [14.041859]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  0  0] -> size -> 6 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1607554405927658
desired expected reward: 14.15458869934082



buy possibilites: [-1] 
expected returns: [[12.537444]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  0  0] -> size -> 6 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.2069123238325119
desired expected reward: 12.6979398727417






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  0  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 15.  0.  6.  3.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0] -> size -> 24 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 15.  0.  6.  3.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0] -> size -> 24 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  8. 10.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  0  0  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 15.  0.  6.  3.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0] -> size -> 24 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 6. 15.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[13.769742]
 [13.801252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  6.  3.] 
cards in discard: [0. 8. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  0  0  0] -> size -> 7 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.38070452213287354
desired expected reward: 12.156739234924316





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.4265  ]
 [ 9.597609]
 [13.881793]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  6.  3.] 
cards in discard: [0. 8. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 26. 30.  8.  7. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  0  0  0] -> size -> 7 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4352239966392517
desired expected reward: 13.395186424255371



buy possibilites: [-1] 
expected returns: [[12.136646]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  6.  3.] 
cards in discard: [0. 8. 3. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 26. 30.  8.  6. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  0  0  0] -> size -> 7 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.310492515563965
desired expected reward: 0.28711605072021484






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  0  0  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  6. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  1. 29.] 
adversary cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6] -> size -> 25 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  6. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  1. 29.] 
adversary cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6] -> size -> 25 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 26. 30.  8.  6. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  1. 29.] 
adversary cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6] -> size -> 25 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0  0  0  3] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  1. 29.] 
adversary cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6] -> size -> 25 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 3.  3. 29.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[11.3542595]
 [13.196516 ]
 [13.196516 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  1. 29.] 
cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0  0  0  3] -> size -> 7 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3798919916152954
desired expected reward: 11.756753921508789



action possibilites: [-1. 29.] 
expected returns: [[11.939004]
 [13.761461]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 29.  0.] 
cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0  0  0  3] -> size -> 7 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.18864892423152924
desired expected reward: 13.461718559265137



action possibilites: [-1.] 
expected returns: [[16.92779]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0  0  0  3] -> size -> 7 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0.8148980140686035
desired expected reward: 14.576358795166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[15.6073  ]
 [17.801476]
 [14.250463]
 [16.44136 ]
 [13.748643]
 [12.417071]
 [16.182648]
 [19.096914]
 [18.245358]
 [21.082428]
 [19.168736]
 [15.015745]
 [15.151612]
 [16.880844]
 [12.968779]
 [17.209917]
 [17.176117]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  6.  5. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0  0  0  3] -> size -> 7 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.7240241169929504
desired expected reward: 17.651813507080078



buy possibilites: [-1] 
expected returns: [[19.540289]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3. 23.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  6.  5. 10.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0  0  0  3] -> size -> 7 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 47.5 

action type: buy - action 23.0
Learning step: 1.1756244897842407
desired expected reward: 16.327238082885742






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  0  3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  6.  5. 10.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0. 11.  0.] 
adversary cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3. 23. 29. 29.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23] -> size -> 26 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0  3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  6.  5. 10.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0. 11.  0.] 
adversary cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3. 23. 29. 29.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23] -> size -> 26 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0  3] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  6.  5. 10.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0. 11.  0.] 
adversary cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3. 23. 29. 29.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23] -> size -> 26 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [11.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[16.204748]
 [17.960491]
 [17.960491]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11.  0.] 
cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3. 23. 29. 29.  3.  3.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  6.  5. 10.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  3] -> size -> 6 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5519623756408691
desired expected reward: 18.988327026367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[14.803395]
 [16.823578]
 [15.571275]
 [11.974516]
 [18.004148]
 [17.228184]
 [15.975866]
 [16.247843]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 11.  0.] 
cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3. 23. 29. 29.  3.  3.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  6.  5. 10.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  3] -> size -> 6 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.46701833605766296
desired expected reward: 15.792558670043945



buy possibilites: [-1] 
expected returns: [[20.537943]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 11.  0.] 
cards in discard: [ 0.  8.  3.  6.  6. 15.  0.  6.  3. 23. 29. 29.  3.  3.  1.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  5.  5. 10.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  3] -> size -> 6 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0.06552400439977646
desired expected reward: 18.069669723510742






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  5.  5. 10.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11] -> size -> 27 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  3] -> size -> 6 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 25. 30.  8.  6. 10.  5.  5. 10.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11] -> size -> 27 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  3  3] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 24. 30.  8.  6. 10.  5.  5. 10.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11] -> size -> 27 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[14.189297]
 [15.996171]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  6. 10.  5.  5. 10.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  3  3] -> size -> 7 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6049020886421204
desired expected reward: 19.933040618896484



action possibilites: [-1] 
expected returns: [[15.357793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  3  3] -> size -> 7 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -8.79134750366211
desired expected reward: 4.628775596618652





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.585463 ]
 [16.653835 ]
 [15.367425 ]
 [11.719721 ]
 [15.121688 ]
 [17.890293 ]
 [17.073408 ]
 [17.961987 ]
 [14.0299835]
 [15.775705 ]
 [16.090693 ]
 [16.02997  ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 24. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  3  3] -> size -> 7 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1587965190410614
desired expected reward: 15.516589164733887



buy possibilites: [-1] 
expected returns: [[17.597988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  3  3] -> size -> 7 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 15.0
Learning step: 1.1120579242706299
desired expected reward: 17.2027530670166






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  3  3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  6. 11. 29.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6 15] -> size -> 29 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  6. 11. 29.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6 15] -> size -> 29 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  6. 11. 29.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6 15] -> size -> 29 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 24. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  6. 11. 29.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6 15] -> size -> 29 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 3.  3.  6. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[13.213516 ]
 [15.0497265]
 [15.122358 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 11. 29.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 24. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5242023468017578
desired expected reward: 17.07378578186035



action possibilites: [-1] 
expected returns: [[13.233898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 29.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6 15  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 23. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0] -> size -> 5 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 2
Learning step: 0.3908112645149231
desired expected reward: 10.995633125305176





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.753489]
 [ 8.972315]
 [13.172863]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6. 29.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6 15  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 23. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0] -> size -> 5 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.17556232213974
desired expected reward: 13.409460067749023






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [10.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 23. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [1. 8. 0. 3. 3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6 15  3] -> size -> 30 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 23. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [1. 8. 0. 3. 3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6 15  3] -> size -> 30 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 23. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [1. 8. 0. 3. 3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6 15  3] -> size -> 30 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 28. 30. 23. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [1. 8. 0. 3. 3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6 15  3] -> size -> 30 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [1. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[14.597027]
 [15.637793]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 3. 3.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0
  6 23 11  6 15  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0] -> size -> 5 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.38509318232536316
desired expected reward: 12.787771224975586



action possibilites: [-1] 
expected returns: [[12.618839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11
  6 15  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.05035623535513878
desired expected reward: 17.788408279418945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[11.228943 ]
 [12.022621 ]
 [ 8.2645645]
 [13.772384 ]
 [12.70085  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11
  6 15  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 30. 23. 30.  8.  5. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.19777897000312805
desired expected reward: 12.816617965698242



buy possibilites: [-1] 
expected returns: [[9.576599]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11
  6 15  3  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 28. 30. 23. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0] -> size -> 5 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.697381973266602
desired expected reward: -0.4328174591064453






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  6. 15.  0.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11
  6 15  3  6] -> size -> 28 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0] -> size -> 5 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  6. 15.  0.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11
  6 15  3  6] -> size -> 28 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 28. 30. 23. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  6. 15.  0.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11
  6 15  3  6] -> size -> 28 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 28. 30. 23. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  6. 15.  0.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11
  6 15  3  6] -> size -> 28 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  6. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[13.09538 ]
 [13.153624]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 15.  0.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11
  6 15  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 23. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0] -> size -> 6 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.29883426427841187
desired expected reward: 9.277765274047852



action possibilites: [-1] 
expected returns: [[16.434687]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 28. 30. 23. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0] -> size -> 6 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.22625473141670227
desired expected reward: 13.436570167541504





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[15.071222]
 [17.197334]
 [15.868216]
 [13.297115]
 [12.020376]
 [15.617392]
 [18.434917]
 [17.620737]
 [20.323116]
 [18.506184]
 [14.505274]
 [14.637794]
 [16.291615]
 [12.546754]
 [16.617989]
 [16.555319]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 28. 30. 23. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0] -> size -> 6 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.13357143104076385
desired expected reward: 16.56825828552246



buy possibilites: [-1] 
expected returns: [[19.269258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 28. 30. 23. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0] -> size -> 6 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 10.0
Learning step: 0.30083683133125305
desired expected reward: 16.592453002929688






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 23. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [11.  0.  0. 23.  6.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1. 10. 15.
  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10] -> size -> 28 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 28. 30. 23. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [11.  0.  0. 23.  6.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1. 10. 15.
  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10] -> size -> 28 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0  3] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 22. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [11.  0.  0. 23.  6.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1. 10. 15.
  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10] -> size -> 28 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [11.  0.  0. 23.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.] 
expected returns: [[11.900818]
 [13.468277]
 [10.406755]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 23.  6.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1. 10. 15.
  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 22. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3] -> size -> 7 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.599733293056488
desired expected reward: 18.669525146484375



action possibilites: [-1] 
expected returns: [[13.141429]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 23.  6.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1. 10. 15.
  0.  6.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3] -> size -> 7 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.48496198654174805
desired expected reward: 12.919063568115234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[11.912062]
 [12.63563 ]
 [ 9.337272]
 [14.245651]
 [13.23419 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 23.  6.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1. 10. 15.
  0.  6.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 22. 30.  8.  4. 10.  5.  5. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3] -> size -> 7 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.18876585364341736
desired expected reward: 13.330194473266602



buy possibilites: [-1] 
expected returns: [[16.046415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 23.  6.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  3. 11.  3.  3.  6. 29.  6.  8.  1. 10. 15.
  0.  6.  0.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 22. 30.  8.  3. 10.  5.  5. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3] -> size -> 7 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.661630630493164
desired expected reward: 0.6756420135498047






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0  3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  3. 10.  5.  5. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 15. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6] -> size -> 30 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0  0  3] -> size -> 7 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  3. 10.  5.  5. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 15. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6] -> size -> 30 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0  0  3] -> size -> 7 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 27. 30. 22. 30.  8.  3. 10.  5.  5. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 15. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6] -> size -> 30 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0  0  3  8] -> size -> 8 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 22. 30.  8.  3. 10.  5.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 15. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6] -> size -> 30 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [ 6.  0. 15. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29.] 
expected returns: [[10.728905]
 [10.7958  ]
 [12.20854 ]
 [12.267883]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15. 11. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  3. 10.  5.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3  8] -> size -> 8 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.508867621421814
desired expected reward: 15.537548065185547



action possibilites: [-1. 15. 11.] 
expected returns: [[13.715842]
 [13.789207]
 [15.352436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15. 11.  6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 22. 30.  8.  3. 10.  5.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3  8] -> size -> 8 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.23367799818515778
desired expected reward: 12.51911449432373





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.435952]
 [13.11301 ]
 [ 9.878468]
 [14.595089]
 [13.668886]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15. 11.  6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 22. 30.  8.  3. 10.  5.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3  8] -> size -> 8 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.1761760115623474
desired expected reward: 13.892017364501953



buy possibilites: [-1] 
expected returns: [[11.965981]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15. 11.  6.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 22. 30.  8.  2. 10.  5.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3  8] -> size -> 8 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.720711708068848
desired expected reward: 1.1577568054199219






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0  3  8] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  2. 10.  5.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [11.  0.  6. 11.  1.] 
adversary cards in discard: [ 6. 29.  6.  0. 15. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6] -> size -> 31 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0  3  8] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 22. 30.  8.  2. 10.  5.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [11.  0.  6. 11.  1.] 
adversary cards in discard: [ 6. 29.  6.  0. 15. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6] -> size -> 31 
adversary victory points: -4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  8.] 
cards in discard: [3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0  3  8  3] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  2. 10.  5.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [11.  0.  6. 11.  1.] 
adversary cards in discard: [ 6. 29.  6.  0. 15. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6] -> size -> 31 
adversary victory points: -4
player victory points: 2 





Player: 0 
cards in hand: [11.  0.  6. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[11.297395]
 [12.836055]
 [12.836055]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6. 11.  1.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  2. 10.  5.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3  8  3] -> size -> 9 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.37760260701179504
desired expected reward: 11.588377952575684



action possibilites: [-1] 
expected returns: [[12.977838]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  1.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  5.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3  8  3] -> size -> 9 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -8.73929214477539
desired expected reward: 2.11269474029541





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[11.617387]
 [13.439964]
 [12.302404]
 [ 9.008402]
 [14.551304]
 [13.81289 ]
 [12.655532]
 [12.868092]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  1.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  5.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3  8  3] -> size -> 9 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.19649136066436768
desired expected reward: 13.174328804016113



buy possibilites: [-1] 
expected returns: [[9.578764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  1.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  4.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3  8  3] -> size -> 9 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.6540377736091614
desired expected reward: 15.205343246459961






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0  3  8  3] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  4.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 6. 10.  0.  6.  3.] 
adversary cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11] -> size -> 33 
adversary victory points: -5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0  3  8  3] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  4.  4. 10.  8. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 6. 10.  0.  6.  3.] 
adversary cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11] -> size -> 33 
adversary victory points: -5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0  3  8  3 10] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  4.  4. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 10.  0.  6.  3.] 
adversary cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11] -> size -> 33 
adversary victory points: -5
player victory points: 2 





Player: 0 
cards in hand: [ 6. 10.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[7.6765137]
 [7.531671 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  6.  3.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  4.  4. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3  8  3 10] -> size -> 10 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3571324944496155
desired expected reward: 9.221631050109863



action possibilites: [-1.] 
expected returns: [[7.499998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  4.  4. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3  8  3 10] -> size -> 10 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.30516156554222107
desired expected reward: 7.859248161315918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[6.3898444]
 [6.9221234]
 [4.5407467]
 [8.134806 ]
 [7.36878  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  4.  4. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3  8  3 10] -> size -> 10 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.29812172055244446
desired expected reward: 7.798120021820068



buy possibilites: [-1] 
expected returns: [[8.460956]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  4.  3. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3  8  3 10] -> size -> 10 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.5347958207130432
desired expected reward: 8.669601440429688






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0  3  8  3 10] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  4.  3. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 23.  1.  0.  0.] 
adversary cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11  8] -> size -> 34 
adversary victory points: -5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0  3  8  3 10] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  4.  3. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 23.  1.  0.  0.] 
adversary cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11  8] -> size -> 34 
adversary victory points: -5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.  0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0  3  8  3 10  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 23.  1.  0.  0.] 
adversary cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11  8] -> size -> 34 
adversary victory points: -5
player victory points: 2 





Player: 0 
cards in hand: [ 3. 23.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[6.2392144]
 [5.1747627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  1.  0.  0.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.  0.  8.] 
adversary cards in discard: [ 8.  0. 10.  3.  8.  0.] 
adversary owned cards: [10  8  0  0  0  0  3  8  3 10  8] -> size -> 11 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.34278762340545654
desired expected reward: 8.118167877197266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[5.384735 ]
 [6.5974207]
 [5.835808 ]
 [3.734106 ]
 [5.691608 ]
 [7.3416862]
 [6.845979 ]
 [7.3906817]
 [5.0730743]
 [6.069309 ]
 [6.2617993]
 [6.2029757]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  1.  0.  0.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 27. 30. 21. 30.  8.  1. 10.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.  0.  8.] 
adversary cards in discard: [ 8.  0. 10.  3.  8.  0.] 
adversary owned cards: [10  8  0  0  0  0  3  8  3 10  8] -> size -> 11 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.27095556259155273
desired expected reward: 5.968258857727051



buy possibilites: [-1] 
expected returns: [[9.141785]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  1.  0.  0.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11  8 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.  0.  8.] 
adversary cards in discard: [ 8.  0. 10.  3.  8.  0.] 
adversary owned cards: [10  8  0  0  0  0  3  8  3 10  8] -> size -> 11 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 16.0
Learning step: 0.7352404594421387
desired expected reward: 6.426848411560059






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  8.] 
cards in discard: [ 8.  0. 10.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0  3  8  3 10  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [29.  8.  3. 11.  0.] 
adversary cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0. 16.  3. 23.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11  8 16] -> size -> 35 
adversary victory points: -5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  0. 10.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0  8  3 10  8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [29.  8.  3. 11.  0.] 
adversary cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0. 16.  3. 23.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11  8 16] -> size -> 35 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0. 10.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0  8  3 10  8] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 21. 30.  8.  1.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [29.  8.  3. 11.  0.] 
adversary cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0. 16.  3. 23.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11  8 16] -> size -> 35 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0. 10.  3.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0  8  3 10  8  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 21. 30.  8.  1.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [29.  8.  3. 11.  0.] 
adversary cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0. 16.  3. 23.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11  8 16] -> size -> 35 
adversary victory points: -5
player victory points: 1 





Player: 0 
cards in hand: [29.  8.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
expected returns: [[8.064702]
 [9.274329]
 [8.72594 ]
 [9.224893]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3. 11.  0.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0. 16.  3. 23.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11  8 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 30.  8.  1.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  8  3 10  8  0] -> size -> 9 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.33066871762275696
desired expected reward: 8.811116218566895



action possibilites: [-1.  8. 11.] 
expected returns: [[ 9.695991]
 [10.380658]
 [10.898213]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  0.  0.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0. 16.  3. 23.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  0 15  0 11  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6
 15  3  6 10  1  6  6  6 11  8 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 21. 30.  8.  1.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  8  3 10  8  0] -> size -> 9 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.2813859283924103
desired expected reward: 9.555717468261719



action possibilites: [-1] 
expected returns: [[10.519987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0. 16.  3. 23.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  0 15  0  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6 15
  3  6 10  1  6  6  6 11  8 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 21. 30.  8.  1.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  8  3 10  8  0] -> size -> 9 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.8967498540878296
desired expected reward: 9.687081336975098





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 9.432583 ]
 [11.05113  ]
 [10.036563 ]
 [ 7.3020434]
 [12.043598 ]
 [11.379691 ]
 [10.348709 ]
 [10.530356 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0. 16.  3. 23.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  0 15  0  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6 15
  3  6 10  1  6  6  6 11  8 16] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 27. 30. 21. 30.  8.  1.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  8  3 10  8  0] -> size -> 9 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.8459228277206421
desired expected reward: 11.365909576416016



buy possibilites: [-1] 
expected returns: [[10.878631]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6. 29.  6.  0. 15. 11.  6.  6. 11. 11.  0.  6. 11.  1.  8. 10.  6.  0.
  6.  3.  0. 16.  3. 23.  1.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  0 15  0  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6 15
  3  6 10  1  6  6  6 11  8 16  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 27. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  8  3 10  8  0] -> size -> 9 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -265.0 

action type: buy - action 6.0
Learning step: -8.054835319519043
desired expected reward: -0.7527914047241211






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  8.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  8  3 10  8  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [23.  8.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 15  0  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6 15
  3  6 10  1  6  6  6 11  8 16  6] -> size -> 35 
adversary victory points: -6
player victory points: 1 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  0  0  0  8  3 10  8  0] -> size -> 9 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [23.  8.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 15  0  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6 15
  3  6 10  1  6  6  6 11  8 16  6] -> size -> 35 
adversary victory points: -6
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  8  3 10  8  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [23.  8.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 15  0  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6 15
  3  6 10  1  6  6  6 11  8 16  6] -> size -> 35 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  8  3 10  8  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 27. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [23.  8.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 15  0  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6 15
  3  6 10  1  6  6  6 11  8 16  6] -> size -> 35 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  8  3 10  8  0  1] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [23.  8.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 15  0  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6 15
  3  6 10  1  6  6  6 11  8 16  6] -> size -> 35 
adversary victory points: -6
player victory points: 1 





Player: 0 
cards in hand: [23.  8.  0.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 15.] 
expected returns: [[6.5921144]
 [5.312388 ]
 [7.34461  ]
 [6.660535 ]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  0.  6. 15.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 15  0  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6 15
  3  6 10  1  6  6  6 11  8 16  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3 10  8  0  1] -> size -> 9 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4058153033256531
desired expected reward: 10.47281551361084



action possibilites: [-1.  8. 15.] 
expected returns: [[7.700097 ]
 [8.494212 ]
 [7.7731476]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 15.  1.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3  0 15  0  8  0 11  6 29  0 29  1 11  6  0  6 23 11  6 15
  3  6 10  1  6  6  6 11  8 16  6] -> size -> 35 
action values: 1 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3 10  8  0  1] -> size -> 9 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 23.0
Learning step: 0.37363511323928833
desired expected reward: 5.750689506530762



action possibilites: [-1] 
expected returns: [[5.3534803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3 10  8  0  1] -> size -> 9 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 11
Learning step: 0.8334136605262756
desired expected reward: 9.926676750183105





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[4.5517454]
 [5.464937 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6] -> size -> 32 
action values: 0 
buys: 2 
player value: 1 
card supply: [15. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3 10  8  0  1] -> size -> 9 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.9429419636726379
desired expected reward: 6.296422481536865






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3 10  8  0  1] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  6. 11.  6.  0.] 
adversary cards in discard: [23.  8. 15.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6] -> size -> 32 
adversary victory points: -5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  0  1] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  6. 11.  6.  0.] 
adversary cards in discard: [23.  8. 15.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6] -> size -> 32 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  0  1] -> size -> 5 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  6. 11.  6.  0.] 
adversary cards in discard: [23.  8. 15.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6] -> size -> 32 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  0  1  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  6. 11.  6.  0.] 
adversary cards in discard: [23.  8. 15.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6] -> size -> 32 
adversary victory points: -5
player victory points: 0 





Player: 0 
cards in hand: [ 3.  6. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[10.255935]
 [11.850639]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11.  6.  0.] 
cards in discard: [23.  8. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  1.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  0  1  0] -> size -> 6 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.20813320577144623
desired expected reward: 5.666140079498291





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.039216]
 [10.255083]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.  6.  0.] 
cards in discard: [23.  8. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  1.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  0  1  0] -> size -> 6 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3561377227306366
desired expected reward: 9.934178352355957



buy possibilites: [-1] 
expected returns: [[9.259914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.  6.  0.] 
cards in discard: [23.  8. 15.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  1.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  0  1  0] -> size -> 6 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.32394739985466003
desired expected reward: 8.715270042419434






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  8. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  0  1  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6.  6.  0. 16.  0.] 
adversary cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6  0] -> size -> 33 
adversary victory points: -5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6.  6.  0. 16.  0.] 
adversary cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6  0] -> size -> 33 
adversary victory points: -5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6.  6.  0. 16.  0.] 
adversary cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6  0] -> size -> 33 
adversary victory points: -5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6.  6.  0. 16.  0.] 
adversary cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6  0] -> size -> 33 
adversary victory points: -5
player victory points: 0 





Player: 0 
cards in hand: [ 6.  6.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[6.6113634]
 [6.0530643]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 16.  0.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  6  0  6 23 11  6 15  3  6 10
  1  6  6  6 11  8 16  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3599419891834259
desired expected reward: 8.899971961975098



action possibilites: [-1] 
expected returns: [[8.381979]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 20. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 1
Learning step: 0.42584744095802307
desired expected reward: 8.16462516784668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[7.350451 ]
 [7.9633117]
 [9.294676 ]
 [8.465743 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 26. 30. 20. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.28751522302627563
desired expected reward: 8.66949462890625






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 20. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [15. 29.  1.  6.  8.] 
adversary cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3] -> size -> 33 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 26. 30. 20. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [15. 29.  1.  6.  8.] 
adversary cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3] -> size -> 33 
adversary victory points: -3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 26. 30. 20. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [15. 29.  1.  6.  8.] 
adversary cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3] -> size -> 33 
adversary victory points: -3
player victory points: 0 





Player: 0 
cards in hand: [15. 29.  1.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.  8.] 
expected returns: [[ 9.317335]
 [ 9.393558]
 [10.847683]
 [10.141532]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  1.  6.  8.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 20. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2968984544277191
desired expected reward: 8.168844223022461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 8.332896]
 [ 8.915859]
 [10.238535]
 [ 9.409163]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29.  1.  6.  8.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 20. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.33303287625312805
desired expected reward: 9.067512512207031



buy possibilites: [-1] 
expected returns: [[9.286894]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29.  1.  6.  8.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.07996338605880737
desired expected reward: 8.835895538330078






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 29.  0. 11.  3.] 
adversary cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3] -> size -> 34 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 26. 30. 19. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 29.  0. 11.  3.] 
adversary cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3] -> size -> 34 
adversary victory points: -2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6. 29.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 9.53423 ]
 [10.978518]
 [10.913584]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0. 11.  3.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3175581991672516
desired expected reward: 8.969335556030273



action possibilites: [-1. 11. 11.] 
expected returns: [[10.764938]
 [12.291168]
 [12.291168]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 11.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 19. 30.  8.  0.  9.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0.3189584016799927
desired expected reward: 8.846473693847656



action possibilites: [-1] 
expected returns: [[12.146452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.  6. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 3
Learning step: 1.3531873226165771
desired expected reward: 11.434976577758789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[11.110656]
 [11.739741]
 [13.098378]
 [12.242795]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.  6. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  4.  2. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.8143153786659241
desired expected reward: 12.96076774597168



buy possibilites: [-1] 
expected returns: [[12.649401]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.  6. 16.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  4.  1. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -1  0  0  8  0] 
sum of rewards: 42 

action type: buy - action 8.0
Learning step: 0.9998674392700195
desired expected reward: 14.098245620727539






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [8. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  4.  1. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 10. 11.  0.  6.] 
adversary cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.  6. 16.  8. 29. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8] -> size -> 36 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  4.  1. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 10. 11.  0.  6.] 
adversary cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.  6. 16.  8. 29. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8] -> size -> 36 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  4.  1. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 10. 11.  0.  6.] 
adversary cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.  6. 16.  8. 29. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8] -> size -> 36 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  4.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 10. 11.  0.  6.] 
adversary cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.  6. 16.  8. 29. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8] -> size -> 36 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 6. 10. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[15.661304]
 [15.475306]
 [17.257532]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 11.  0.  6.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.  6. 16.  8. 29. 11.  0.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  4.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.35773760080337524
desired expected reward: 12.29166316986084



action possibilites: [-1] 
expected returns: [[13.703797]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  6.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.  6. 16.  8. 29. 11.  0.  3. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  0.  8.  4.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -2  0  0  9  0] 
sum of rewards: 22 

action type: gain_card_n - action 1
Learning step: 0.3175385892391205
desired expected reward: 16.52924919128418





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.535138]
 [13.718055]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  6.] 
cards in discard: [23.  8. 15.  0.  3.  6. 11.  6.  0.  3. 16.  6.  0.  0.  3. 15. 29.  1.
  6.  8.  6. 16.  8. 29. 11.  0.  3. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 25. 30. 19. 30.  8.  0.  8.  4.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1779574304819107
desired expected reward: 13.881754875183105






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  0.  8.  4.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1] -> size -> 37 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 25. 30. 19. 30.  8.  0.  8.  4.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1] -> size -> 37 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 25. 30. 19. 30.  8.  0.  8.  4.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1] -> size -> 37 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[10.151088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 30.  8.  0.  8.  4.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 0] -> size -> 5 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.45424190163612366
desired expected reward: 13.263813018798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 9.159811]
 [10.757382]
 [ 9.771188]
 [11.691929]
 [10.081898]
 [10.25353 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 25. 30. 19. 30.  8.  0.  8.  4.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 0] -> size -> 5 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.34561556577682495
desired expected reward: 9.873406410217285



buy possibilites: [-1] 
expected returns: [[7.7426]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 0] -> size -> 5 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -3  0  0 18  0] 
sum of rewards: 10 

action type: buy - action 11.0
Learning step: 0.030539387837052345
desired expected reward: 11.722469329833984






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [8. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 8. 16.  3.  0. 11.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11] -> size -> 38 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 8. 16.  3.  0. 11.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11] -> size -> 38 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 25. 30. 19. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 8. 16.  3.  0. 11.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11] -> size -> 38 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 0 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 8. 16.  3.  0. 11.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11] -> size -> 38 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [ 8. 16.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 11.] 
expected returns: [[10.605123]
 [11.515527]
 [ 9.873994]
 [12.23606 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3.  0. 11.] 
cards in discard: [11.  6.  0.  3.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 0 3] -> size -> 5 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.26291170716285706
desired expected reward: 7.4796881675720215





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.505254]
 [10.674215]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  3.  0. 11.] 
cards in discard: [11.  6.  0.  3.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 0 3] -> size -> 5 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3631550967693329
desired expected reward: 10.314335823059082



buy possibilites: [-1] 
expected returns: [[7.197479]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  3.  0. 11.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 0 3] -> size -> 5 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -4.  0.  0.  0.  0.] 
sum of rewards: -9.0 

action type: buy - action 0.0
Learning step: -0.47958406805992126
desired expected reward: 9.02566909790039






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 0 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 29.  6.  6.  0.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 39 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 29.  6.  6.  0.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 39 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 29.  6.  6.  0.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 39 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 29.  6.  6.  0.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 39 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [ 6. 29.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[6.312485]
 [7.449367]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  6.  6.  0.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.292291522026062
desired expected reward: 6.905187129974365



action possibilites: [-1.] 
expected returns: [[8.178216]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.33453676104545593
desired expected reward: 7.0456862449646





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[7.1567106]
 [7.7436337]
 [8.213691 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.2866216003894806
desired expected reward: 8.464838027954102






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [23. 10.  6.  3.  8.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 39 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [23. 10.  6.  3.  8.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 39 
adversary victory points: -2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [23. 10.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.  8.] 
expected returns: [[10.992844]
 [ 9.57665 ]
 [10.833897]
 [11.876704]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 10.  6.  3.  8.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.28008174896240234
desired expected reward: 7.916953086853027



action possibilites: [-1. 10.  8.] 
expected returns: [[11.023841]
 [10.866362]
 [11.904214]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3.  8.  0.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1
  6  6  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 39 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 8. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 23.0
Learning step: 0.2823237478733063
desired expected reward: 9.858972549438477



action possibilites: [-1] 
expected returns: [[11.948271]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.9171916842460632
desired expected reward: 9.526030540466309





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.883245]
 [12.009696]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 37 
action values: 0 
buys: 2 
player value: 1 
card supply: [ 8. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.8129226565361023
desired expected reward: 12.76119327545166






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [15. 11.  0.  1. 11.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6.] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 37 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [15. 11.  0.  1. 11.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6.] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 37 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [15. 11.  0.  1. 11.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6.] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 37 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [15. 11.  0.  1. 11.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6.] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 37 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [15. 11.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11.] 
expected returns: [[10.444518]
 [10.547119]
 [11.956479]
 [11.956479]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0.  1. 11.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.39088261127471924
desired expected reward: 11.618813514709473



action possibilites: [-1] 
expected returns: [[13.364595]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1. 11.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0 16  0] 
sum of rewards: 28 

action type: gain_card_n - action 8
Learning step: 0.6411610841751099
desired expected reward: 11.946734428405762





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[12.243621]
 [13.987178]
 [12.891563]
 [15.025069]
 [13.229822]
 [13.402363]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1. 11.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 25. 30. 18. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.19370624423027039
desired expected reward: 13.55830192565918



buy possibilites: [-1] 
expected returns: [[14.936708]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1. 11.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 25. 30. 17. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -4.  0.  0.  2.  0.] 
sum of rewards: 13.0 

action type: buy - action 3.0
Learning step: 0.16008850932121277
desired expected reward: 13.051652908325195






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 17. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  6. 16.  1.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11.] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3] -> size -> 39 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 17. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  6. 16.  1.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11.] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3] -> size -> 39 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 25. 30. 17. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  6. 16.  1.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11.] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3] -> size -> 39 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  6. 16.  1.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11.] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3] -> size -> 39 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [ 6.  0.  6. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[12.214184]
 [11.481127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 16.  1.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4729311466217041
desired expected reward: 14.463777542114258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[11.027063 ]
 [12.794251 ]
 [11.700531 ]
 [13.8305855]
 [12.042934 ]
 [12.214185 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 16.  1.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 25. 30. 17. 30.  8.  0.  8.  3.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3843279480934143
desired expected reward: 11.829856872558594



buy possibilites: [-1] 
expected returns: [[11.861023]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 16.  1.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -5  0  0 18  0] 
sum of rewards: 8 

action type: buy - action 11.0
Learning step: -0.05037689208984375
desired expected reward: 13.780210494995117






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  3. 29.  3. 15.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11. 11.  6.  0.  6. 16.  1.] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11] -> size -> 40 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  3. 29.  3. 15.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11. 11.  6.  0.  6. 16.  1.] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11] -> size -> 40 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  3. 29.  3. 15.] 
adversary cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11. 11.  6.  0.  6. 16.  1.] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11] -> size -> 40 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 8.  3. 29.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 15.] 
expected returns: [[13.122564]
 [14.064193]
 [14.827125]
 [13.235831]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  3. 15.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11. 11.  6.  0.  6. 16.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.35866934061050415
desired expected reward: 11.50235366821289



action possibilites: [-1] 
expected returns: [[15.084045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  3.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11. 11.  6.  0.  6. 16.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.21130748093128204
desired expected reward: 13.447139739990234





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.969023]
 [15.084044]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29.  3.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11. 11.  6.  0.  6. 16.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.15117798745632172
desired expected reward: 15.235223770141602



buy possibilites: [-1] 
expected returns: [[14.54975]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29.  3.] 
cards in discard: [11.  6.  0.  3.  0.  0.  0.  8. 16.  3.  0. 11.  6. 11. 29.  6.  6.  0.
 23.  8. 10.  6. 15.  3. 11. 15.  0.  1. 11. 11.  6.  0.  6. 16.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -6  0  0  0  0] 
sum of rewards: 9 

action type: buy - action 0.0
Learning step: 0.002101364079862833
desired expected reward: 14.024468421936035






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 15.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0] -> size -> 41 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 15.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0] -> size -> 41 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 15.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0] -> size -> 41 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[3.641253 ]
 [3.7353148]
 [4.3237314]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  8.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6
  6 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5446619391441345
desired expected reward: 14.005088806152344



action possibilites: [-1] 
expected returns: [[3.0653987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6
 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.3702273368835449
desired expected reward: 4.1022047996521





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[2.383377 ]
 [3.411844 ]
 [2.7685714]
 [2.641051 ]
 [4.030193 ]
 [4.0695543]
 [2.1208632]
 [2.9683218]
 [3.1337595]
 [3.0559142]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6
 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.3922741711139679
desired expected reward: 3.4576728343963623



buy possibilites: [-1] 
expected returns: [[3.4781213]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6
 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 4. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -6.  0.  0.  0.  0.] 
sum of rewards: 9.0 

action type: buy - action 0.0
Learning step: 0.23501895368099213
desired expected reward: 2.618396043777466






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [16.  0. 11.  0.  0.] 
adversary cards in discard: [ 0. 15.  3.  8.  0.] 
adversary owned cards: [ 3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6
 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [16.  0. 11.  0.  0.] 
adversary cards in discard: [ 0. 15.  3.  8.  0.] 
adversary owned cards: [ 3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6
 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [16.  0. 11.  0.  0.] 
adversary cards in discard: [ 0. 15.  3.  8.  0.] 
adversary owned cards: [ 3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6
 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [16.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[ 8.723419]
 [ 8.139133]
 [10.100027]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11.  0.  0.] 
cards in discard: [ 0. 15.  3.  8.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6
 11  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 17. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.15750771760940552
desired expected reward: 3.3206136226654053



action possibilites: [-1] 
expected returns: [[8.289648]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [ 0. 15.  3.  8.  0.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6 11
  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 16. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -6  0  0  4  0] 
sum of rewards: 13 

action type: gain_card_n - action 1
Learning step: 0.3003065586090088
desired expected reward: 6.191464424133301





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[7.388402]
 [7.954157]
 [8.369686]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [ 0. 15.  3.  8.  0.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6 11
  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 25. 30. 16. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2852811813354492
desired expected reward: 8.574929237365723



buy possibilites: [-1] 
expected returns: [[5.8934345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [ 0. 15.  3.  8.  0.  3.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6 11
  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 25. 30. 16. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -7.  0.  0.  0.  0.] 
sum of rewards: 8.0 

action type: buy - action 0.0
Learning step: 0.0802290067076683
desired expected reward: 7.468630790710449






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 16. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [3. 6. 0. 0. 1.] 
adversary cards in discard: [ 0. 15.  3.  8.  0.  3.  0. 16. 11.  0.  0.] 
adversary owned cards: [ 3 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6 11
  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0  3  0] -> size -> 42 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 16. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [3. 6. 0. 0. 1.] 
adversary cards in discard: [ 0. 15.  3.  8.  0.  3.  0. 16. 11.  0.  0.] 
adversary owned cards: [ 3 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6 11
  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0  3  0] -> size -> 42 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [3. 6. 0. 0. 1.] 
adversary cards in discard: [ 0. 15.  3.  8.  0.  3.  0. 16. 11.  0.  0.] 
adversary owned cards: [ 3 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6 11
  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0  3  0] -> size -> 42 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [3. 6. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[5.3955054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 1.] 
cards in discard: [ 0. 15.  3.  8.  0.  3.  0. 16. 11.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6 11
  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0  3  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.2697717547416687
desired expected reward: 5.623662948608398





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[4.7879996]
 [6.037313 ]
 [5.2503815]
 [5.095598 ]
 [6.794661 ]
 [6.8412504]
 [4.469812 ]
 [5.4949718]
 [5.6954   ]
 [5.6014023]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 1.] 
cards in discard: [ 0. 15.  3.  8.  0.  3.  0. 16. 11.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6 11
  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0  3  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.25148212909698486
desired expected reward: 5.180069923400879



Player 1 won the game! 



Player 0 bought cards:
Copper: 11 
Silver: 2 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 8 

Remodel: 1 
Workshop: 7 
Chapel: 3 
Witch: 0 
Poacher: 1 
Militia: 0 
Market: 1 
Village: 1 
Library: 0 
Moneylender: 2 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [3. 6. 0. 0. 1.] 
cards in discard: [ 0. 15.  3.  8.  0.  3.  0. 16. 11.  0.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  0  8  0 11 29  0 29 11  0  6 23 11  6 15  3  6 10  1  6  6  6 11
  8 16  6  0  3  3 16  8  1 11  0 15  3 11  0  0  3  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0. 25. 30. 16. 30.  8.  0.  8.  2.  0. 10.  8. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0   -8    0    0
    0    0] 
sum of rewards: -513 

action type: buy - action 0.0
Learning step: -15.53364086151123
desired expected reward: -10.745641708374023



