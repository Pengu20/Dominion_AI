 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[94.51726]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -300        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000305 

action type: buy - action -1.0
Learning step: -120007.0
desired expected reward: -120136.8828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 85.07552 ]
 [102.163536]
 [ 95.75082 ]
 [ 64.19409 ]
 [100.27475 ]
 [110.79783 ]
 [102.408455]
 [114.31248 ]
 [ 78.465706]
 [ 95.99575 ]
 [ 93.51445 ]
 [ 94.12735 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 95.7211685180664



buy possibilites: [-1] 
expected returns: [[78.56205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 114.3124771118164






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[91.23334]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.56204986572266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 89.839874]
 [ 99.70688 ]
 [ 93.83412 ]
 [ 72.668236]
 [107.51762 ]
 [ 99.61452 ]
 [ 93.73884 ]
 [ 92.09849 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 92.42291259765625



buy possibilites: [-1] 
expected returns: [[105.70519]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 107.51766204833984






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  3.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[113.90501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.70519256591797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[103.74819 ]
 [119.09105 ]
 [112.674644]
 [ 81.82836 ]
 [117.082375]
 [130.73915 ]
 [120.112434]
 [134.04996 ]
 [ 96.83811 ]
 [113.66913 ]
 [112.712074]
 [114.99715 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 114.76813507080078



buy possibilites: [-1] 
expected returns: [[111.52101]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 134.04995727539062






Player: 1 
cards in hand: [ 3.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 96.421715]
 [114.154015]
 [110.541084]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3. 11.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [11.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 111.52101135253906



action possibilites: [-1. 11.] 
expected returns: [[116.23675]
 [131.43033]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [11.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 114.78925323486328



action possibilites: [-1] 
expected returns: [[119.5191]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [11.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 142.9682159423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[107.14084]
 [122.4358 ]
 [115.77487]
 [ 85.28436]
 [135.10847]
 [123.55241]
 [116.82918]
 [119.46308]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [11.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 119.51909637451172



buy possibilites: [-1] 
expected returns: [[131.89565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [11.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 135.1084747314453






Player: 1 
cards in hand: [ 3.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [11.  3.  0.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  0. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  0. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  0. 10.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[126.980064]
 [124.76197 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 131.89564514160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[117.95075 ]
 [131.63713 ]
 [125.888145]
 [ 90.9988  ]
 [130.27869 ]
 [141.19453 ]
 [132.05272 ]
 [144.26706 ]
 [111.5262  ]
 [126.33433 ]
 [125.31974 ]
 [128.52637 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 127.30284881591797



buy possibilites: [-1] 
expected returns: [[113.335594]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 144.2670440673828






Player: 1 
cards in hand: [ 0. 10. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 11.] 
adversary cards in discard: [29.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 11.] 
adversary cards in discard: [29.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 11.] 
adversary cards in discard: [29.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 11.] 
adversary cards in discard: [29.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[110.24349]
 [126.12643]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 11.] 
cards in discard: [29.  0.  0.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [10. 10.  0. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.3355941772461



action possibilites: [-1] 
expected returns: [[127.72585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0. 10.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [10. 10.  0. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 134.0764923095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[117.37578 ]
 [126.419136]
 [ 96.56176 ]
 [133.85419 ]
 [128.3509  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0. 10.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [10. 10.  0. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.7258529663086



buy possibilites: [-1] 
expected returns: [[161.64494]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0. 10.  0. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [10. 10.  0. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 133.85415649414062






Player: 1 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [10. 10.  0. 29.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  3. 29. 29.] 
adversary cards in discard: [29.  0.  0.  0. 10.  0. 10.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [10. 10.  0. 29.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  3. 29. 29.] 
adversary cards in discard: [29.  0.  0.  0. 10.  0. 10.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [10. 10.  0. 29.  3.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  3. 29. 29.] 
adversary cards in discard: [29.  0.  0.  0. 10.  0. 10.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11.  0.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[160.98381]
 [174.0518 ]
 [175.38809]
 [175.38809]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 29. 29.] 
cards in discard: [29.  0.  0.  0. 10.  0. 10.  8. 11.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 161.6449432373047



action possibilites: [-1. 11. 29. 10.] 
expected returns: [[122.72111]
 [137.63155]
 [139.98418]
 [125.04902]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 29. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 174.75038146972656



action possibilites: [-1. 11. 10.] 
expected returns: [[136.37424]
 [151.40988]
 [136.03105]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 139.98419189453125



action possibilites: [-1] 
expected returns: [[125.86083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 157.70387268066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 96.92335 ]
 [128.463   ]
 [122.557686]
 [ 58.51692 ]
 [141.81374 ]
 [129.48778 ]
 [123.455025]
 [128.38255 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.86083221435547



buy possibilites: [-1] 
expected returns: [[139.19028]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 109 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 141.813720703125






Player: 1 
cards in hand: [ 0.  3. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[138.57933]
 [150.59604]
 [146.13847]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  8.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 139.19027709960938



action possibilites: [-1] 
expected returns: [[155.37889]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  8.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 154.4864044189453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[161.40114]
 [175.0772 ]
 [167.8619 ]
 [134.91826]
 [174.53412]
 [173.093  ]
 [167.50652]
 [159.50243]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  8.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 155.37889099121094



buy possibilites: [-1] 
expected returns: [[158.82127]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3. 10.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11 10  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  8.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 175.0771942138672






Player: 1 
cards in hand: [ 0. 10. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  8.  0.] 
cards in discard: [ 0.  0.  3. 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3. 10.  1. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11 10  1] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  0.  0.] 
cards in discard: [ 0.  0.  3. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 11 10 10  8  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3. 10.  1. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11 10  1] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 0.  0.  3. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3. 10.  1. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11 10  1] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [ 0.  0.  3. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3. 10.  1. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11 10  1] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [ 0.  0.  3. 10.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3. 10.  1. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11 10  1] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[100.364586]
 [103.03625 ]
 [116.07219 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 29.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3. 10.  1. 11.  0.  0. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11 10  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0.  3.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  0.  0. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 158.82127380371094



action possibilites: [-1.  8.] 
expected returns: [[121.12438]
 [124.32014]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3. 10.  1. 11.  0.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10  8 10 11 10  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0.  3.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  0.  0. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 114.8729476928711



action possibilites: [-1] 
expected returns: [[186.53644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3. 10.  1. 11.  0.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0.  3.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  0.  0. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 8
Learning step: 0
desired expected reward: 123.24353790283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[195.68033]
 [174.8344 ]
 [191.29764]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3. 10.  1. 11.  0.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0.  3.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  0.  0. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 186.53643798828125



buy possibilites: [-1] 
expected returns: [[153.21558]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 10.  3. 10.  1. 11.  0.  0. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0.  3.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  0.  0. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 195.68035888671875






Player: 1 
cards in hand: [ 0. 11. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0.  3.] 
cards in discard: [ 0.  0.  3. 10.  3.  0.  0. 10.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  1.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0.  3.] 
cards in discard: [ 0.  0.  3. 10.  3.  0.  0. 10.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  1.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0.  3.] 
cards in discard: [ 0.  0.  3. 10.  3.  0.  0. 10.  8. 29.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  1.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11.  1.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[ 98.857994]
 [112.427315]
 [112.427315]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 153.215576171875



action possibilites: [-1] 
expected returns: [[90.909935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 119.77948760986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 72.9507  ]
 [ 91.512695]
 [ 84.63184 ]
 [ 32.680363]
 [ 88.67103 ]
 [104.21639 ]
 [ 92.652214]
 [107.69087 ]
 [ 67.65493 ]
 [ 86.0825  ]
 [ 85.495316]
 [ 90.73466 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.9099349975586



buy possibilites: [-1] 
expected returns: [[116.07902]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.] 
cards in discard: [10. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0 10 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 107.69088745117188






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10. 29.  3. 10.  0.] 
adversary cards in discard: [10. 29. 11.  1.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10. 29.  3. 10.  0.] 
adversary cards in discard: [10. 29. 11.  1.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 29.  3. 10.  0.] 
adversary cards in discard: [10. 29. 11.  1.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [10. 29.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[120.01835]
 [125.10554]
 [133.02617]
 [125.10554]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3. 10.  0.] 
cards in discard: [10. 29. 11.  1.  0. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 10.  8.  3. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8 15] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 116.07901763916016



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[ 92.83659]
 [ 94.22643]
 [ 94.22643]
 [110.54545]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  0. 29.] 
cards in discard: [10. 29. 11.  1.  0. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 10.  8.  3. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8 15] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 133.19729614257812



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[116.62258 ]
 [119.976425]
 [119.976425]
 [119.976425]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  0. 10.] 
cards in discard: [10. 29. 11.  1.  0. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 10.  8.  3. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8 15] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 110.54547119140625



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[128.14214]
 [133.2197 ]
 [133.2197 ]
 [138.80322]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 10.  8.] 
cards in discard: [10. 29. 11.  1.  0. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  3  3 29 11 29 10 11 29 10  8 10 11 10  1  0 10 29] -> size -> 21 
action values: 2 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 10.  8.  3. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8 15] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 119.9764404296875



action possibilites: [-1.] 
expected returns: [[136.01147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10. 29. 11.  1.  0. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 10.  8.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 10.  8.  3. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8 15] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 146.49168395996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[113.4586 ]
 [131.43188]
 [125.36259]
 [ 73.79848]
 [148.18596]
 [134.54195]
 [128.47266]
 [137.97975]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 29. 11.  1.  0. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 10.  8.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 10.  8.  3. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8 15] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 136.011474609375



buy possibilites: [-1] 
expected returns: [[172.99242]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 29. 11.  1.  0. 11.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 10.  8.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 10.  8.  3. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8 15] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0  54   0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 148.1859588623047






Player: 1 
cards in hand: [ 8. 10.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  3. 10.] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 11.  0. 29.  0.] 
adversary cards in discard: [10. 29. 11.  1.  0. 11.  0. 11. 29. 29. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11] -> size -> 19 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3. 10.  0.] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 11 10 10  8  0  0  8 15] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 11.  0. 29.  0.] 
adversary cards in discard: [10. 29. 11.  1.  0. 11.  0. 11. 29. 29. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11] -> size -> 19 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 11.  0. 29.  0.] 
adversary cards in discard: [10. 29. 11.  1.  0. 11.  0. 11. 29. 29. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 11.  0. 29.  0.] 
adversary cards in discard: [10. 29. 11.  1.  0. 11.  0. 11. 29. 29. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11] -> size -> 19 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  0.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 11.  0. 29.  0.] 
adversary cards in discard: [10. 29. 11.  1.  0. 11.  0. 11. 29. 29. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11] -> size -> 19 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10. 11.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[120.60105]
 [114.19931]
 [129.51219]
 [132.93672]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 29.  0.] 
cards in discard: [10. 29. 11.  1.  0. 11.  0. 11. 29. 29. 10.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 29. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 172.99241638183594



action possibilites: [-1. 10. 11.] 
expected returns: [[155.99403]
 [156.24568]
 [168.32297]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.  3.] 
cards in discard: [10. 29. 11.  1.  0. 11.  0. 11. 29. 29. 10.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 29. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 134.3726348876953



action possibilites: [-1] 
expected returns: [[159.89072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [10. 29. 11.  1.  0. 11.  0. 11. 29. 29. 10.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 29. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 173.2023162841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[166.75002]
 [167.81477]
 [164.14037]
 [161.62456]
 [171.63152]
 [165.57494]
 [162.21214]
 [163.22713]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [10. 29. 11.  1.  0. 11.  0. 11. 29. 29. 10.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 29. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 159.89071655273438



buy possibilites: [-1] 
expected returns: [[182.72324]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [10. 29. 11.  1.  0. 11.  0. 11. 29. 29. 10.  8.  0. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  4.  7. 10.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 29. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 171.6315460205078






Player: 1 
cards in hand: [ 3. 11.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 29. 10.] 
cards in discard: [15.  0.  0.  3.  0.  0.  0. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  4.  7. 10.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11] -> size -> 21 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1. 11. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  4.  7. 10.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  4.  7. 10.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11] -> size -> 21 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11. 10.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[135.35133]
 [146.13979]
 [131.37413]
 [148.6123 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  4.  7. 10.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [15.  0. 10.  0.  0.] 
adversary cards in discard: [29.  3. 11.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 182.72323608398438



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[117.12697]
 [128.77483]
 [110.13085]
 [128.77483]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  4.  7. 10.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [15.  0. 10.  0.  0.] 
adversary cards in discard: [29.  3. 11.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 148.5282745361328



action possibilites: [-1] 
expected returns: [[141.65436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  4.  7. 10.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [15.  0. 10.  0.  0.] 
adversary cards in discard: [29.  3. 11.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 134.6246795654297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[122.37742 ]
 [138.76839 ]
 [133.39378 ]
 [102.388405]
 [155.10129 ]
 [140.79507 ]
 [144.75053 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  4.  7. 10.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [15.  0. 10.  0.  0.] 
adversary cards in discard: [29.  3. 11.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.65435791015625



buy possibilites: [-1] 
expected returns: [[127.4909]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  3.  7. 10.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [15.  0. 10.  0.  0.] 
adversary cards in discard: [29.  3. 11.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 155.1012725830078






Player: 1 
cards in hand: [15.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10.  0.  0.] 
cards in discard: [29.  3. 11.  0. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  3.  7. 10.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11] -> size -> 23 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10.  0.  0.] 
cards in discard: [29.  3. 11.  0. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  3.  7. 10.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11] -> size -> 23 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10.  0.  0.] 
cards in discard: [29.  3. 11.  0. 10.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  2.  7. 10.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11] -> size -> 23 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[125.71276]
 [142.39319]
 [139.90118]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11.  3.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  2.  7. 10.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0 11] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 127.49089813232422



action possibilites: [-1. 11.] 
expected returns: [[145.82526]
 [156.27844]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  2.  7. 10.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0 11] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 130.94363403320312



action possibilites: [-1] 
expected returns: [[197.36925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.  8. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  2.  7. 10.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0 11] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 160.84585571289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[185.73607]
 [208.47581]
 [200.91304]
 [158.69975]
 [216.65302]
 [208.72746]
 [200.206  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.  8. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  2.  7. 10.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0 11] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 197.36924743652344



buy possibilites: [-1] 
expected returns: [[184.43977]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.  8. 15. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0 11] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 216.65298461914062






Player: 1 
cards in hand: [ 8. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11 10 10  0  0  8 15  0 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29. 10. 29. 11. 10.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.  8. 15. 11. 29. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11] -> size -> 25 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11 10 10  0  0  8 15  0 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29. 10. 29. 11. 10.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.  8. 15. 11. 29. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11] -> size -> 25 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11 10 10  0  0  8 15  0 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29. 10. 29. 11. 10.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.  8. 15. 11. 29. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11] -> size -> 25 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29. 10. 29. 11. 10.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.  8. 15. 11. 29. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11] -> size -> 25 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [29. 10. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 11. 10.] 
expected returns: [[166.40216]
 [179.10295]
 [165.32222]
 [179.10295]
 [176.8163 ]
 [165.32222]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29. 11. 10.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.  8. 15. 11. 29. 11.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 11.  0.  0.  3.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0] -> size -> 12 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 184.4397735595703



action possibilites: [-1. 10. 11. 10. 11.] 
expected returns: [[169.28459]
 [164.81464]
 [178.48491]
 [164.81464]
 [178.48491]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 11.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.  8. 15. 11. 29. 11.  0.  0.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 11.  0.  0.  3.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0] -> size -> 12 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 168.72634887695312



action possibilites: [-1] 
expected returns: [[220.75465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.  8. 15. 11. 29. 11.  0.  0.  3. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10. 11.  0.  0.  3.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0] -> size -> 12 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 182.86305236816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[203.88957]
 [180.88536]
 [220.63583]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0. 11.  8. 15. 11. 29. 11.  0.  0.  3. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10. 11.  0.  0.  3.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0] -> size -> 12 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 220.75465393066406






Player: 1 
cards in hand: [10. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.  3.] 
cards in discard: [0. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29. 10. 10.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15] -> size -> 26 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29. 10. 10.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15] -> size -> 26 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29. 10. 10.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15] -> size -> 26 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29. 10. 10.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15] -> size -> 26 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29. 10. 10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[162.24883]
 [179.39247]
 [155.86742]
 [155.86742]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10.  0.  1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0. 11. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0  3] -> size -> 13 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 220.6358184814453



action possibilites: [-1. 10. 10.] 
expected returns: [[151.28035]
 [145.96098]
 [145.96098]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0. 11. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0  3] -> size -> 13 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 159.69754028320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[126.31637]
 [151.51677]
 [145.05247]
 [ 86.80979]
 [164.51796]
 [153.04279]
 [152.07175]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  1.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0. 11. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0  3] -> size -> 13 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 151.28038024902344



buy possibilites: [-1] 
expected returns: [[135.69397]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [ 1. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0. 11. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0  3] -> size -> 13 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 164.51795959472656






Player: 1 
cards in hand: [11.  0. 11. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 15. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11. 10. 11. 11.  0.] 
adversary cards in discard: [ 1. 11. 29. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11] -> size -> 27 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11. 15. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11. 10. 11. 11.  0.] 
adversary cards in discard: [ 1. 11. 29. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11] -> size -> 27 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11. 15. 10.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11. 10. 11. 11.  0.] 
adversary cards in discard: [ 1. 11. 29. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11] -> size -> 27 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11. 10. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 11.] 
expected returns: [[152.69133]
 [168.08803]
 [153.64122]
 [168.08803]
 [168.08803]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 11.  0.] 
cards in discard: [ 1. 11. 29. 10. 10.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  7.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 0. 11.  0. 11. 15. 10.] 
adversary owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0  3  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 135.6939697265625



action possibilites: [-1] 
expected returns: [[167.12593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0.] 
cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 0. 11.  0. 11. 15. 10.] 
adversary owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0  3  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 49 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 158.0338897705078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[163.41026]
 [148.28398]
 [167.82365]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11.  0.] 
cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 0. 11.  0. 11. 15. 10.] 
adversary owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0  3  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 167.1259307861328






Player: 1 
cards in hand: [8. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3. 0.] 
cards in discard: [ 0. 11.  0. 11. 15. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10 10  0  0  8 15  0 11  0  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11. 15. 10. 29.  3.] 
adversary cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15] -> size -> 28 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 0. 11.  0. 11. 15. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10 10  0  0  8 15  0 11  0  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11. 15. 10. 29.  3.] 
adversary cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15] -> size -> 28 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0. 11.  0. 11. 15. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10 10  0  0  8 15  0 11  0  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11. 15. 10. 29.  3.] 
adversary cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15] -> size -> 28 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0. 11.  0. 11. 15. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11. 15. 10. 29.  3.] 
adversary cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15] -> size -> 28 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 15. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10. 29.] 
expected returns: [[191.18477]
 [204.53549]
 [193.14906]
 [197.06285]
 [206.40286]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10. 29.  3.] 
cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 167.82366943359375



action possibilites: [-1. 15. 10. 11.] 
expected returns: [[235.9824 ]
 [233.033  ]
 [236.99945]
 [246.71785]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11.] 
cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 209.48191833496094



action possibilites: [-1] 
expected returns: [[216.9321]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.] 
cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.  3. 11.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 243.4058380126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[204.66605]
 [178.95253]
 [216.9088 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.] 
cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.  3. 11.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 216.93209838867188






Player: 1 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0. 10. 11. 15.] 
adversary cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.  3. 11.  1. 29. 11.
 15. 10.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1] -> size -> 29 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0. 10. 11. 15.] 
adversary cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.  3. 11.  1. 29. 11.
 15. 10.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1] -> size -> 29 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0. 10. 11. 15.] 
adversary cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.  3. 11.  1. 29. 11.
 15. 10.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1] -> size -> 29 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0. 10. 11. 15.] 
adversary cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.  3. 11.  1. 29. 11.
 15. 10.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1] -> size -> 29 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11. 15.] 
expected returns: [[171.28621]
 [176.41957]
 [172.23996]
 [183.07735]
 [167.74617]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 11. 15.] 
cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.  3. 11.  1. 29. 11.
 15. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 15.  3. 11.  0.] 
adversary cards in discard: [ 1. 10.  0.  0.  0.  0. 11.] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1] -> size -> 14 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 216.90882873535156



action possibilites: [-1] 
expected returns: [[190.98114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 15.] 
cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.  3. 11.  1. 29. 11.
 15. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 15.  3. 11.  0.] 
adversary cards in discard: [ 1. 10.  0.  0.  0.  0. 11.] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1] -> size -> 14 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 178.11720275878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[194.15704]
 [170.65005]
 [191.21666]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 15.] 
cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.  3. 11.  1. 29. 11.
 15. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 15.  3. 11.  0.] 
adversary cards in discard: [ 1. 10.  0.  0.  0.  0. 11.] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1] -> size -> 14 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 190.98114013671875



buy possibilites: [-1] 
expected returns: [[156.32494]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 15.] 
cards in discard: [ 1. 11. 29. 10. 10.  0.  0. 15. 11. 10. 11. 11.  0.  3. 11.  1. 29. 11.
 15. 10.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 15.  3. 11.  0.] 
adversary cards in discard: [ 1. 10.  0.  0.  0.  0. 11.] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1] -> size -> 14 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 194.15701293945312






Player: 1 
cards in hand: [10. 15.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3. 11.  0.] 
cards in discard: [ 1. 10.  0.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11.  0. 11. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0] -> size -> 31 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  3. 11.  0.] 
cards in discard: [ 1. 10.  0.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11.  0. 11. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0] -> size -> 31 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  3. 11.  0.] 
cards in discard: [ 1. 10.  0.  0.  0.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11.  0. 11. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0] -> size -> 31 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11.  0. 11. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29. 29.] 
expected returns: [[162.10127]
 [174.6744 ]
 [174.6744 ]
 [177.26979]
 [177.26979]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 29. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 15.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1  0] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 156.32493591308594



action possibilites: [-1. 11. 11. 29.] 
expected returns: [[149.77715]
 [161.51599]
 [161.51599]
 [164.91685]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29.] 
cards in discard: [ 0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 15.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1  0] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 166.05117797851562



action possibilites: [-1. 11.] 
expected returns: [[189.26485]
 [202.37965]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 0. 10. 11. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 15.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1  0] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 118.8580551147461



action possibilites: [-1] 
expected returns: [[191.7148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 10. 11. 11. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 0. 15.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1  0] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 64  0] 
sum of rewards: 119 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 192.24143981933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[180.71127]
 [190.24348]
 [149.04468]
 [198.63618]
 [193.74702]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 10. 11. 11. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  7. 10.  5. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 0. 15.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1  0] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 191.7147979736328



buy possibilites: [-1] 
expected returns: [[168.63464]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 10. 11. 11. 15.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 0. 15.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1  0] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 16  0] 
sum of rewards: 71 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 198.63621520996094






Player: 1 
cards in hand: [ 0. 15.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  0  8 15  0 11  0  3  0  0  1  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10.  0. 15. 15. 11.] 
adversary cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8] -> size -> 33 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10.  0. 15. 15. 11.] 
adversary cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8] -> size -> 33 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10.  0. 15. 15. 11.] 
adversary cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8] -> size -> 33 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [22.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0. 15. 15. 11.] 
adversary cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8] -> size -> 33 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10.  0. 15. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15. 11.] 
expected returns: [[119.235634]
 [119.14565 ]
 [117.94899 ]
 [117.94899 ]
 [128.30342 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15. 15. 11.] 
cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0. 10. 11.  0.] 
adversary cards in discard: [22. 15.  0.  0.  8.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 168.6346435546875



action possibilites: [-1] 
expected returns: [[155.31087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15. 15.] 
cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0.  9.  4.] 
adversary cards in hand: [10.  0. 10. 11.  0.] 
adversary cards in discard: [22. 15.  0.  0.  8.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 122.8508071899414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[148.44707]
 [125.58929]
 [155.58638]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 15. 15.] 
cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0.  9.  4.] 
adversary cards in hand: [10.  0. 10. 11.  0.] 
adversary cards in discard: [22. 15.  0.  0.  8.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 155.3108673095703






Player: 1 
cards in hand: [10.  0. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 11.  0.] 
cards in discard: [22. 15.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0.  9.  4.] 
adversary cards in hand: [11. 11.  1.  1. 11.] 
adversary cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15] -> size -> 34 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 11.  0.] 
cards in discard: [22. 15.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0.  9.  4.] 
adversary cards in hand: [11. 11.  1.  1. 11.] 
adversary cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15] -> size -> 34 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 11.  0.] 
cards in discard: [22. 15.  0.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0.  9.  4.] 
adversary cards in hand: [11. 11.  1.  1. 11.] 
adversary cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15] -> size -> 34 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11. 11.  1.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[154.26591]
 [168.38426]
 [168.38426]
 [168.38426]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  1.  1. 11.] 
cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0.  9.  4.] 
adversary cards in hand: [ 3.  1. 11.  0.  0.] 
adversary cards in discard: [22. 15.  0.  0.  8.  0. 10.  0. 10. 11.  0.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 155.58641052246094



action possibilites: [-1] 
expected returns: [[205.7881]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  1. 11.] 
cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0.  9.  3.] 
adversary cards in hand: [ 3.  1. 11.  0.  0.] 
adversary cards in discard: [22. 15.  0.  0.  8.  0. 10.  0. 10. 11.  0.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 158.31239318847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[192.69919]
 [207.79573]
 [201.81523]
 [175.62166]
 [204.76797]
 [209.65561]
 [226.59514]
 [188.41135]
 [204.33315]
 [209.63219]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1. 11.] 
cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  5. 10. 10.  0.  9.  3.] 
adversary cards in hand: [ 3.  1. 11.  0.  0.] 
adversary cards in discard: [22. 15.  0.  0.  8.  0. 10.  0. 10. 11.  0.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 205.78810119628906



buy possibilites: [-1] 
expected returns: [[218.60963]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1. 11.] 
cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4. 10. 10.  0.  9.  3.] 
adversary cards in hand: [ 3.  1. 11.  0.  0.] 
adversary cards in discard: [22. 15.  0.  0.  8.  0. 10.  0. 10. 11.  0.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -10   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 226.5951690673828






Player: 1 
cards in hand: [ 3.  1. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11.  0.  0.] 
cards in discard: [22. 15.  0.  0.  8.  0. 10.  0. 10. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4. 10. 10.  0.  9.  3.] 
adversary cards in hand: [10. 15.  0. 29.  0.] 
adversary cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15. 29. 11.
 11.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29] -> size -> 36 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11.  0.  0.] 
cards in discard: [22. 15.  0.  0.  8.  0. 10.  0. 10. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4. 10. 10.  0.  9.  3.] 
adversary cards in hand: [10. 15.  0. 29.  0.] 
adversary cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15. 29. 11.
 11.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29] -> size -> 36 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11.  0.  0.] 
cards in discard: [22. 15.  0.  0.  8.  0. 10.  0. 10. 11.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10. 15.  0. 29.  0.] 
adversary cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15. 29. 11.
 11.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29] -> size -> 36 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10. 15.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 29.] 
expected returns: [[190.4583 ]
 [189.3177 ]
 [188.15938]
 [205.92073]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0. 29.  0.] 
cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15. 29. 11.
 11.  1.  1. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  0.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 218.60963439941406



action possibilites: [-1. 10.] 
expected returns: [[202.16316]
 [193.2407 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15. 29. 11.
 11.  1.  1. 11. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  0.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 194.26112365722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[176.73607]
 [197.0868 ]
 [190.61185]
 [143.2427 ]
 [199.93205]
 [202.2032 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15. 29. 11.
 11.  1.  1. 11. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  0.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 202.16317749023438






Player: 1 
cards in hand: [10.  0.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 14.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 8. 10.  1.  0. 11.] 
adversary cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15. 29. 11.
 11.  1.  1. 11. 15.  0. 29. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29] -> size -> 36 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 8. 10.  1.  0. 11.] 
adversary cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15. 29. 11.
 11.  1.  1. 11. 15.  0. 29. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29] -> size -> 36 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 8. 10.  1.  0. 11.] 
adversary cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15. 29. 11.
 11.  1.  1. 11. 15.  0. 29. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29] -> size -> 36 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[174.22102]
 [170.91508]
 [164.88731]
 [184.53122]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  1.  0. 11.] 
cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15. 29. 11.
 11.  1.  1. 11. 15.  0. 29. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0.  0. 10. 22.  0.] 
adversary cards in discard: [10.  0.  0. 14.  8.  0.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 202.2032470703125



action possibilites: [-1] 
expected returns: [[217.73698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  1.  0.] 
cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15. 29. 11.
 11.  1.  1. 11. 15.  0. 29. 10.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  0. 10. 22.  0.] 
adversary cards in discard: [10.  0.  0. 14.  8.  0.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 59 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 170.9151153564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[197.95432]
 [212.67593]
 [207.7913 ]
 [179.17897]
 [214.43968]
 [218.21141]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  1.  0.] 
cards in discard: [ 0. 10. 11. 11. 15.  8. 29. 29. 11. 15. 11. 10.  0. 15. 15. 15. 29. 11.
 11.  1.  1. 11. 15.  0. 29. 10.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  0. 10. 22.  0.] 
adversary cards in discard: [10.  0.  0. 14.  8.  0.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 217.7369842529297






Player: 1 
cards in hand: [ 0.  0. 10. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 22.  0.] 
cards in discard: [10.  0.  0. 14.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [15. 15. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1. 22. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22.  0. 11.] 
cards in discard: [10.  0.  0. 14.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [15. 15. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.  0. 11.] 
cards in discard: [10.  0.  0. 14.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [15. 15. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.  0. 11.] 
cards in discard: [10.  0.  0. 14.  8.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [15. 15. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [15. 15. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 29. 10.] 
expected returns: [[188.74043]
 [185.77927]
 [185.77927]
 [201.58879]
 [184.43242]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 29. 10.  3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [15.  3. 11.  1.  0.] 
adversary cards in discard: [10.  0.  0. 14.  8.  0.  1. 10.  0.  0. 22.  0. 11.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 218.21141052246094



action possibilites: [-1. 15. 15.] 
expected returns: [[190.55998]
 [188.31879]
 [188.31879]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.] 
cards in discard: [15. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [15.  3. 11.  1.  0.] 
adversary cards in discard: [10.  0.  0. 14.  8.  0.  1. 10.  0.  0. 22.  0. 11.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 187.64761352539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[182.86049]
 [157.99165]
 [191.00833]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 15.] 
cards in discard: [15. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [15.  3. 11.  1.  0.] 
adversary cards in discard: [10.  0.  0. 14.  8.  0.  1. 10.  0.  0. 22.  0. 11.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 190.5599822998047






Player: 1 
cards in hand: [15.  3. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 11.  1.  0.] 
cards in discard: [10.  0.  0. 14.  8.  0.  1. 10.  0.  0. 22.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10. 29. 11. 11. 11.] 
adversary cards in discard: [15. 10. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 11.  1.  0.] 
cards in discard: [10.  0.  0. 14.  8.  0.  1. 10.  0.  0. 22.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10. 29. 11. 11. 11.] 
adversary cards in discard: [15. 10. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 11.  1.  0.] 
cards in discard: [10.  0.  0. 14.  8.  0.  1. 10.  0.  0. 22.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 25. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10. 29. 11. 11. 11.] 
adversary cards in discard: [15. 10. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10. 29. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 11. 11.] 
expected returns: [[134.08522]
 [136.97774]
 [147.41098]
 [145.47876]
 [145.47876]
 [145.47876]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11. 11. 11.] 
cards in discard: [15. 10. 29. 15.  3. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [14. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 191.00833129882812



action possibilites: [-1. 11. 11. 29.] 
expected returns: [[202.77193]
 [216.4626 ]
 [216.4626 ]
 [219.213  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29.] 
cards in discard: [15. 10. 29. 15.  3. 15. 10. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [14. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 141.9873809814453



action possibilites: [-1. 11.] 
expected returns: [[194.61284]
 [206.68352]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [15. 10. 29. 15.  3. 15. 10. 11. 11. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  2.] 
adversary cards in hand: [14. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 184.02261352539062



action possibilites: [-1] 
expected returns: [[187.07677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15. 10. 29. 15.  3. 15. 10. 11. 11. 11. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  1.] 
adversary cards in hand: [14. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 89 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 186.2358856201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[146.31384]
 [173.89479]
 [100.45351]
 [187.77118]
 [187.37753]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15. 10. 29. 15.  3. 15. 10. 11. 11. 11. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 30. 29. 30.  8. 10. 10.  0.  6. 10.  4.  9. 10.  0.  9.  1.] 
adversary cards in hand: [14. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 187.07676696777344



buy possibilites: [-1] 
expected returns: [[229.3401]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15. 10. 29. 15.  3. 15. 10. 11. 11. 11. 15.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15 15  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 29. 30.  8. 10. 10.  0.  5. 10.  4.  9. 10.  0.  9.  1.] 
adversary cards in hand: [14. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 187.77122497558594






Player: 1 
cards in hand: [14. 10.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 29. 30.  8. 10. 10.  0.  5. 10.  4.  9. 10.  0.  9.  1.] 
adversary cards in hand: [ 8.  8.  0. 11. 10.] 
adversary cards in discard: [15. 10. 29. 15.  3. 15. 10. 11. 11. 11. 15.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15 15  8] -> size -> 39 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 30. 29. 30.  8. 10. 10.  0.  5. 10.  4.  9. 10.  0.  9.  1.] 
adversary cards in hand: [ 8.  8.  0. 11. 10.] 
adversary cards in discard: [15. 10. 29. 15.  3. 15. 10. 11. 11. 11. 15.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15 15  8] -> size -> 39 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  0.  8.  0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 28. 30.  8. 10. 10.  0.  5. 10.  4.  9. 10.  0.  9.  1.] 
adversary cards in hand: [ 8.  8.  0. 11. 10.] 
adversary cards in discard: [15. 10. 29. 15.  3. 15. 10. 11. 11. 11. 15.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15 15  8] -> size -> 39 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 10.] 
expected returns: [[247.4369 ]
 [250.31999]
 [250.31999]
 [257.00668]
 [245.26668]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 11. 10.] 
cards in discard: [15. 10. 29. 15.  3. 15. 10. 11. 11. 11. 15.  8. 29. 29. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15 15  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 28. 30.  8. 10. 10.  0.  5. 10.  4.  9. 10.  0.  9.  1.] 
adversary cards in hand: [ 0.  0. 15.  0.  3.] 
adversary cards in discard: [ 3. 14. 10.  0.  8.  0.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 229.34010314941406



Player 1 won the game! 



Player 0 bought cards:
Copper: 2 
Silver: 1 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 3 
Witch: 0 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 8.  8.  0. 10.] 
cards in discard: [15. 10. 29. 15.  3. 15. 10. 11. 11. 11. 15.  8. 29. 29. 11. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 29 11 29  8 10 11 10  1  0 10 29 11 10 11 10 11 15
 11 15 11 15  1  1  0 15  8 15 15 29 15 15  8 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 28. 30.  8. 10. 10.  0.  5. 10.  4.  9. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  0. 15.  0.  3.] 
adversary cards in discard: [ 3. 14. 10.  0.  8.  0.] 
adversary owned cards: [11 10 10  0  8 15  0 11  0  3  0  0  1  0 22  0 14  1  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0       20        0
        0        0        0      -50        0        0       64        0] 
sum of rewards: -3000001 

action type: gain_card_n - action 8
Learning step: -120010.046875
desired expected reward: -119759.7265625



