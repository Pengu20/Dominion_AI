 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[295.49356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0  -90    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -566 

action type: gain_card_n - action 4
Learning step: -27.70352554321289
desired expected reward: -39.63300323486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[269.95355]
 [285.7232 ]
 [279.63992]
 [239.48286]
 [294.59183]
 [280.57864]
 [276.95804]
 [299.5584 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.643773078918457
desired expected reward: 289.2420654296875



buy possibilites: [-1] 
expected returns: [[258.97955]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -21.797103881835938
desired expected reward: 217.68576049804688






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[298.93103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [6. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -6.901351451873779
desired expected reward: 252.0782012939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[274.48233]
 [290.5885 ]
 [283.509  ]
 [243.68315]
 [281.2205 ]
 [298.69763]
 [285.55362]
 [287.1704 ]
 [258.01392]
 [280.59   ]
 [274.70706]
 [302.6792 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [6. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.13775634765625
desired expected reward: 288.5345153808594



buy possibilites: [-1] 
expected returns: [[292.08292]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [6. 3. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 3.0
Learning step: -7.603583812713623
desired expected reward: 275.9053955078125






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[260.4108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.90648078918457
desired expected reward: 283.1764221191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[233.62497]
 [248.59044]
 [241.72882]
 [203.7017 ]
 [254.76254]
 [244.15048]
 [239.32509]
 [257.2712 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.504513740539551
desired expected reward: 250.16952514648438



buy possibilites: [-1] 
expected returns: [[270.74017]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -5.537868022918701
desired expected reward: 243.05255126953125






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 3. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 3. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1.  0.  3.  0.  3.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[293.9985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.020796298980713
desired expected reward: 263.7193908691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[265.1384 ]
 [285.057  ]
 [277.8174 ]
 [231.20943]
 [295.32626]
 [277.88547]
 [273.0714 ]
 [300.5172 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.495079040527344
desired expected reward: 285.5588073730469



buy possibilites: [-1] 
expected returns: [[266.08536]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 3. 0. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -21.22355079650879
desired expected reward: 209.98587036132812






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[256.15027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.272615432739258
desired expected reward: 257.812744140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[222.87115]
 [189.6141 ]
 [252.46625]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.160368919372559
desired expected reward: 244.35752868652344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 6. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 6. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  3.  0.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 6. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[250.1985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 6. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -7.699892520904541
desired expected reward: 244.76632690429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[233.88263]
 [248.39925]
 [242.03345]
 [216.55757]
 [206.45679]
 [239.83485]
 [256.41855]
 [243.81483]
 [267.90457]
 [245.28331]
 [219.34538]
 [228.54567]
 [239.35602]
 [213.60034]
 [234.03146]
 [260.0331 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 6. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.570106506347656
desired expected reward: 240.13739013671875



buy possibilites: [-1] 
expected returns: [[226.52995]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 6. 3. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6] -> size -> 15 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -324.0 

action type: buy - action 6.0
Learning step: -21.002344131469727
desired expected reward: 185.45443725585938






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  1.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  1.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  1.  0.] 
cards in discard: [16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [3. 6. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[235.24243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [16.  3.  0. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10 16] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -7.2814531326293945
desired expected reward: 219.24850463867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[210.494  ]
 [226.51305]
 [219.08133]
 [179.26427]
 [233.43211]
 [221.50261]
 [215.64839]
 [235.22282]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [16.  3.  0. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10 16] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.885409832000732
desired expected reward: 225.22767639160156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [16.  3.  0. 11.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [3. 6. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [16.  3.  0. 11.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [3. 6. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [16.  3.  0. 11.  1.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10 16  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [3. 6. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[197.32832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [3. 6. 1. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [16.  3.  0. 11.  1.  0.  1.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10 16  1] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -8.614206314086914
desired expected reward: 226.6085968017578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[172.29617]
 [180.32088]
 [145.80585]
 [181.59297]
 [195.62254]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [3. 6. 1. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [16.  3.  0. 11.  1.  0.  1.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10 16  1] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -6.834092617034912
desired expected reward: 186.36300659179688



buy possibilites: [-1] 
expected returns: [[190.02519]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [3. 6. 1. 3. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6 3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [16.  3.  0. 11.  1.  0.  1.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10 16  1] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -5 

action type: buy - action 3.0
Learning step: -4.990476131439209
desired expected reward: 175.33038330078125






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  8.] 
cards in discard: [16.  3.  0. 11.  1.  0.  1.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 11  8 10 16  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [3. 6. 1. 3. 0. 3. 0. 3. 0. 6. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6 3] -> size -> 16 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [16.  3.  0. 11.  1.  0.  1.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 11  8 10 16  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [3. 6. 1. 3. 0. 3. 0. 3. 0. 6. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6 3] -> size -> 16 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [16.  3.  0. 11.  1.  0.  1.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 11  8 10 16  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [3. 6. 1. 3. 0. 3. 0. 3. 0. 6. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6 3] -> size -> 16 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [16.  3.  0. 11.  1.  0.  1.  0.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 11  8 10 16  1  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [3. 6. 1. 3. 0. 3. 0. 3. 0. 6. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6 3] -> size -> 16 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[210.42932]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [3. 6. 1. 3. 0. 3. 0. 3. 0. 6. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6 3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  0. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 11  8 10 16  1  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -5.380836486816406
desired expected reward: 184.64434814453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[186.63216]
 [199.24504]
 [194.14838]
 [162.76167]
 [191.81395]
 [206.50629]
 [194.93863]
 [196.40172]
 [175.39964]
 [192.18634]
 [187.99347]
 [211.31485]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [3. 6. 1. 3. 0. 3. 0. 3. 0. 6. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6 3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  0. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 11  8 10 16  1  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -6.857583522796631
desired expected reward: 205.16122436523438



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [16.  0. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 11  8 10 16  1  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6 3] -> size -> 16 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6 3] -> size -> 16 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6 3] -> size -> 16 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[257.5526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6 3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 1.] 
adversary cards in discard: [ 8. 16.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -5.428222179412842
desired expected reward: 205.88665771484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[229.13171]
 [245.48595]
 [237.46388]
 [199.10873]
 [252.00493]
 [240.17464]
 [233.58511]
 [253.41325]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 1 6 6 3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 1.] 
adversary cards in discard: [ 8. 16.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.123183250427246
desired expected reward: 249.1000213623047



buy possibilites: [-1] 
expected returns: [[232.59578]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 1.] 
adversary cards in discard: [ 8. 16.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 10.0
Learning step: -6.195849895477295
desired expected reward: 227.38925170898438






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [3. 0. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 1.] 
cards in discard: [ 8. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 6. 1. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10] -> size -> 17 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 1.] 
cards in discard: [ 8. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 6. 1. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10] -> size -> 17 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 1.] 
cards in discard: [ 8. 16.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 6. 6. 1. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10] -> size -> 17 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 6. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[244.03357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 1. 0.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [ 8. 16.  0. 10.  3.  0.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -6.812510967254639
desired expected reward: 225.78326416015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[223.20108]
 [237.6555 ]
 [231.31456]
 [194.6727 ]
 [244.46802]
 [233.12474]
 [228.67534]
 [246.90895]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 1. 0.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [ 8. 16.  0. 10.  3.  0.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.554011821746826
desired expected reward: 235.43614196777344



buy possibilites: [-1] 
expected returns: [[195.69353]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 1. 0.] 
cards in discard: [10.  3.  3.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  8. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [ 8. 16.  0. 10.  3.  0.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -11.0 

action type: buy - action 8.0
Learning step: -7.803134918212891
desired expected reward: 225.3216552734375






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 10.] 
cards in discard: [ 8. 16.  0. 10.  3.  0.  1.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  8. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.  8.  3.  6.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8] -> size -> 18 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0 10] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  8. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.  8.  3.  6.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8] -> size -> 18 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  8. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.  8.  3.  6.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8] -> size -> 18 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0 10  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.  8.  3.  6.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8] -> size -> 18 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[173.05785]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [10.  3.  3.  0.  0.  0.  8.  3.  6.  6.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  1. 16.  0.] 
adversary cards in discard: [ 8. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -6.50579309463501
desired expected reward: 189.18772888183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[154.28801]
 [166.86162]
 [161.59819]
 [130.0522 ]
 [172.57175]
 [162.5222 ]
 [158.52097]
 [173.49405]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [10.  3.  3.  0.  0.  0.  8.  3.  6.  6.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 28. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  1. 16.  0.] 
adversary cards in discard: [ 8. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -5.72484016418457
desired expected reward: 168.8922119140625



buy possibilites: [-1] 
expected returns: [[202.43593]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [10.  3.  3.  0.  0.  0.  8.  3.  6.  6.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 27. 30. 28. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  1. 16.  0.] 
adversary cards in discard: [ 8. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -43.0 

action type: buy - action 0.0
Learning step: -5.079726696014404
desired expected reward: 149.20826721191406






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  1. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  1. 16.  0.] 
cards in discard: [ 8. 10.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10 16  1  0 10  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0.] 
cards in discard: [ 8. 10.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 8. 10.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 28. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 8. 10.  3.  3.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0] -> size -> 19 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [1. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[196.12227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -6.853236675262451
desired expected reward: 195.5826873779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[173.8622 ]
 [188.47162]
 [183.12418]
 [146.22296]
 [196.03104]
 [183.23636]
 [179.89986]
 [199.9142 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -6.8113884925842285
desired expected reward: 189.56906127929688



buy possibilites: [-1] 
expected returns: [[203.68562]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -53.0 

action type: buy - action 0.0
Learning step: -6.760183811187744
desired expected reward: 167.10202026367188






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [0. 1. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  1. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8  3] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [0. 1. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8  3] -> size -> 15 
action values: 3 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [0. 1. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  9.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [0. 1. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [23.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8  3 23] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [0. 1. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[175.59116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [0. 1. 3. 3. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [23. 10. 10.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8  3 23] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -7.279626369476318
desired expected reward: 196.40599060058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[153.58525]
 [166.43456]
 [160.45436]
 [129.2048 ]
 [172.93616]
 [162.81728]
 [158.72697]
 [175.34624]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [0. 1. 3. 3. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [23. 10. 10.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8  3 23] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -6.497538089752197
desired expected reward: 173.70932006835938



buy possibilites: [-1] 
expected returns: [[203.84601]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [0. 1. 3. 3. 0. 3. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [23. 10. 10.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8  3 23] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -334.0 

action type: buy - action 6.0
Learning step: -18.573705673217773
desired expected reward: 110.63109588623047






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 8.] 
cards in discard: [23. 10. 10.  0.  3.  0.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1  8 10  1  0 10  8  3 23] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10.  0.] 
adversary cards in discard: [0. 1. 3. 3. 0. 3. 6. 0. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6] -> size -> 21 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [23. 10. 10.  0.  3.  0.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10.  0.] 
adversary cards in discard: [0. 1. 3. 3. 0. 3. 6. 0. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [23. 10. 10.  0.  3.  0.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10.  0.] 
adversary cards in discard: [0. 1. 3. 3. 0. 3. 6. 0. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 6.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[208.35396]
 [191.08656]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 10.  0.] 
cards in discard: [0. 1. 3. 3. 0. 3. 6. 0. 3. 0. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -6.867964267730713
desired expected reward: 196.97804260253906



action possibilites: [-1.] 
expected returns: [[206.67438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [0. 1. 3. 3. 0. 3. 6. 0. 3. 0. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -3 

action type: take_action - action 10.0
Learning step: -5.037939548492432
desired expected reward: 185.7243194580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[182.88046]
 [197.58783]
 [191.58215]
 [156.35974]
 [189.0114 ]
 [204.12813]
 [192.28726]
 [193.48358]
 [169.03682]
 [187.86385]
 [182.6615 ]
 [206.67464]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [0. 1. 3. 3. 0. 3. 6. 0. 3. 0. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -6.229645729064941
desired expected reward: 200.44473266601562



buy possibilites: [-1] 
expected returns: [[200.16052]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 0.  1.  3.  3.  0.  3.  6.  0.  3.  0.  6.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  8.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 28 

action type: buy - action 16.0
Learning step: -3.546957492828369
desired expected reward: 185.4644317626953






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  1.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  8.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6 16] -> size -> 22 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  8.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6 16] -> size -> 22 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 27. 30.  8.  6.  8.  9.  7. 10. 10. 10.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6 16] -> size -> 22 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 1.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  6.  8.  9.  7. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6 16] -> size -> 22 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[161.3234 ]
 [148.55367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  8.  9.  7. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [23.  8.  0.  0.  3.] 
adversary cards in discard: [14. 10.  0.  3.  1.  3.  1.] 
adversary owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -7.746370792388916
desired expected reward: 192.41415405273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[141.38875]
 [125.59439]
 [161.16476]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  6.  8.  9.  7. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [23.  8.  0.  0.  3.] 
adversary cards in discard: [14. 10.  0.  3.  1.  3.  1.] 
adversary owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -5.8650665283203125
desired expected reward: 153.19573974609375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [23.  8.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  0.  0.  3.] 
cards in discard: [14. 10.  0.  3.  1.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  8.  9.  7. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [10.  1. 16.  6.  3.] 
adversary cards in discard: [3. 0. 6. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6 16] -> size -> 22 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  8.  0.  0.  3.] 
cards in discard: [14. 10.  0.  3.  1.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8.  6.  8.  9.  7. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [10.  1. 16.  6.  3.] 
adversary cards in discard: [3. 0. 6. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6 16] -> size -> 22 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  1. 16.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[112.59461 ]
 [ 97.33928 ]
 [ 97.734955]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 16.  6.  3.] 
cards in discard: [3. 0. 6. 8. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  1  6  6  3 10  8  0  0  6 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  8.  9.  7. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -6.9009881019592285
desired expected reward: 154.26382446289062



action possibilites: [-1] 
expected returns: [[96.385544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.] 
cards in discard: [3. 0. 6. 8. 3. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 11 

action type: gain_card_n - action 3
Learning step: -5.149788856506348
desired expected reward: 155.65435791015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[78.2808  ]
 [84.25008 ]
 [58.090244]
 [85.3099  ]
 [96.80288 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.] 
cards in discard: [3. 0. 6. 8. 3. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -2.5892457962036133
desired expected reward: 93.79629516601562



buy possibilites: [-1] 
expected returns: [[149.91895]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.] 
cards in discard: [3. 0. 6. 8. 3. 8. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 26 

action type: buy - action 3.0
Learning step: 0.4606727659702301
desired expected reward: 84.71073913574219






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 12 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [6. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[135.19998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [14.  0. 10.  0.  3.] 
adversary cards in discard: [10.  8.  3.  3.] 
adversary owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -4.606507301330566
desired expected reward: 145.31243896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[116.60998]
 [125.73231]
 [ 83.82182]
 [127.16744]
 [136.60995]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 26. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [14.  0. 10.  0.  3.] 
adversary cards in discard: [10.  8.  3.  3.] 
adversary owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -4.010879039764404
desired expected reward: 128.85311889648438



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [14.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10.  0.  3.] 
cards in discard: [10.  8.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 14. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3. 23.] 
cards in discard: [10.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.  1.] 
cards in discard: [10.  8.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 12 
action values: 2 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 26. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [10.  8.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 23. 14.] 
owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 12 
action values: 1 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 26. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.  6.  0.  0.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [10.  8.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 23. 14.] 
owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14] -> size -> 12 
action values: 0 
buys: 2 
player value: 7 
card supply: [26. 27. 30. 26. 30.  8.  6.  8.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.  6.  0.  0.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [10.  8.  3.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 23. 14.] 
owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.  6.  0.  0.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [10.  8.  3.  3. 16.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 23. 14.] 
owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14 16  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.  6.  0.  0.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[99.18483]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.  6.  0.  0.  3.  6.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 16. 23.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14 16  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    3    0    0    0    0 -210    0    0    0    0    0 -900
   32    0] 
sum of rewards: -1080 

action type: discard_down_to_3_cards - action 1
Learning step: -56.205718994140625
desired expected reward: 32.04319763183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[76.35097 ]
 [89.583115]
 [85.20223 ]
 [53.670345]
 [95.6831  ]
 [84.027115]
 [81.04569 ]
 [97.7164  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  0.  6.  8.  3.  8.  3. 16. 10.  1.  3.  6.  0.  0.  3.  6.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 16. 23.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14 16  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -3.076678514480591
desired expected reward: 95.0001220703125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 16. 23.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16. 23.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14 16  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.  1.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3  0  1 10  1  0 10  8  3 23 14 16  0] -> size -> 14 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23. 16.] 
owned cards: [ 3  0  1 10  1  0 10  8  3 23 14 16  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23. 16.] 
owned cards: [ 3  0  1 10  1  0 10  8  3 23 14 16  0  8] -> size -> 14 
action values: 0 
buys: 2 
player value: 4 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 2 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23. 16.] 
owned cards: [ 3  0  1 10  1  0 10  8  3 23 14 16  0  8 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[171.26295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  8. 10.  3.] 
adversary cards in discard: [ 8. 10. 23. 16.  3.  1.  0.] 
adversary owned cards: [ 3  0  1 10  1  0 10  8  3 23 14 16  0  8 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -0.6797721982002258
desired expected reward: 97.03661346435547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[151.26259 ]
 [163.92574 ]
 [158.5185  ]
 [126.676094]
 [169.84354 ]
 [159.78798 ]
 [156.0093  ]
 [172.15367 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  8. 10.  3.] 
adversary cards in discard: [ 8. 10. 23. 16.  3.  1.  0.] 
adversary owned cards: [ 3  0  1 10  1  0 10  8  3 23 14 16  0  8 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -4.457257270812988
desired expected reward: 164.7003936767578



buy possibilites: [-1] 
expected returns: [[160.014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  8. 10.  3.] 
adversary cards in discard: [ 8. 10. 23. 16.  3.  1.  0.] 
adversary owned cards: [ 3  0  1 10  1  0 10  8  3 23 14 16  0  8 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 26 

action type: buy - action 10.0
Learning step: -2.900148868560791
desired expected reward: 153.109130859375






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 10.  3.] 
cards in discard: [ 8. 10. 23. 16.  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1 10  1  0 10  8  3 23 14 16  0  8 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10.  3.  3.  3.  3.] 
adversary cards in discard: [10.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10] -> size -> 24 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  3.  1.] 
cards in discard: [ 8. 10. 23. 16.  3.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  0  1 10  1  0 10  8  3 23 14 16  0  8 10] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10.  3.  3.  3.  3.] 
adversary cards in discard: [10.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10] -> size -> 24 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  3.  1.] 
cards in discard: [ 8. 10. 23. 16.  3.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  0  1 10  1  0 10  8  3 23 14 16  0  8 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10.  3.  3.  3.  3.] 
adversary cards in discard: [10.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10] -> size -> 24 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  3.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[142.2063 ]
 [126.21145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  3.  3.] 
cards in discard: [10.  3.  0.  6.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 8.  1.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1 10  1  0 10  8  3 23 14 16  0  8 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -4.559250831604004
desired expected reward: 155.4547576904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[121.5539 ]
 [101.0212 ]
 [142.22108]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  3.  3.] 
cards in discard: [10.  3.  0.  6.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 8.  1.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1 10  1  0 10  8  3 23 14 16  0  8 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -3.861563205718994
desired expected reward: 137.8075408935547



buy possibilites: [-1] 
expected returns: [[122.717354]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  3.  3.] 
cards in discard: [10.  3.  0.  6.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 8.  1.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1 10  1  0 10  8  3 23 14 16  0  8 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  10   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action 0.0
Learning step: -4.4165544509887695
desired expected reward: 117.13733673095703






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 8.  1.  8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  8.  0. 14.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1 10  1  0 10  8  3 23 14 16  0  8 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  6.  0.] 
adversary cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10
  0] -> size -> 25 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 10  1  0 10  8  3 23 16  0  8 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  6.  0.] 
adversary cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10
  0] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 10  1  0 10  8  3 23 16  0  8 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  6.  0.] 
adversary cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10
  0] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 10  1  0 10  8  3 23 16  0  8 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  6.  0.] 
adversary cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10
  0] -> size -> 25 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[168.52792]
 [154.96484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  6.  0.] 
cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0. 16.  1.] 
adversary cards in discard: [0. 8. 8. 0.] 
adversary owned cards: [ 3  0 10  1  0 10  8  3 23 16  0  8 10  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -2.159597873687744
desired expected reward: 120.55775451660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[151.47523 ]
 [162.99762 ]
 [158.6965  ]
 [126.941826]
 [167.94061 ]
 [158.53519 ]
 [155.45389 ]
 [169.98824 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  6.  0.] 
cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  9.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0. 16.  1.] 
adversary cards in discard: [0. 8. 8. 0.] 
adversary owned cards: [ 3  0 10  1  0 10  8  3 23 16  0  8 10  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -4.247900009155273
desired expected reward: 160.2603759765625



buy possibilites: [-1] 
expected returns: [[134.25383]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  6.  0.] 
cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0. 16.  1.] 
adversary cards in discard: [0. 8. 8. 0.] 
adversary owned cards: [ 3  0 10  1  0 10  8  3 23 16  0  8 10  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 26 

action type: buy - action 11.0
Learning step: -3.976031541824341
desired expected reward: 163.96458435058594






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [10. 10.  0. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 16.  1.] 
cards in discard: [0. 8. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 10  1  0 10  8  3 23 16  0  8 10  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [8. 8. 0. 3. 0.] 
adversary cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3. 11.  0.  0. 16.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10
  0 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [0. 8. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [8. 8. 0. 3. 0.] 
adversary cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3. 11.  0.  0. 16.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10
  0 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [0. 8. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [8. 8. 0. 3. 0.] 
adversary cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3. 11.  0.  0. 16.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10
  0 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [0. 8. 8. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [8. 8. 0. 3. 0.] 
adversary cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3. 11.  0.  0. 16.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10
  0 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [8. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[123.32604]
 [118.18176]
 [118.18176]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 3. 0.] 
cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3. 11.  0.  0. 16.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  8  0  0  6 16  8  3 10
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10.  3.  3. 23.  0.] 
adversary cards in discard: [ 0.  8.  8.  0.  0.  0. 16. 10. 10.  0.] 
adversary owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -3.600731372833252
desired expected reward: 130.65309143066406



action possibilites: [-1] 
expected returns: [[119.49009]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3. 11.  0.  0. 16.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10.  3.  3. 23.  0.] 
adversary cards in discard: [ 0.  8.  8.  0.  0.  0. 16. 10. 10.  0.] 
adversary owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.8701072931289673
desired expected reward: 117.30257415771484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 95.098595]
 [103.33726 ]
 [ 70.36711 ]
 [103.909134]
 [116.13591 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3. 11.  0.  0. 16.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10.  3.  3. 23.  0.] 
adversary cards in discard: [ 0.  8.  8.  0.  0.  0. 16. 10. 10.  0.] 
adversary owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -2.2981679439544678
desired expected reward: 117.19192504882812



buy possibilites: [-1] 
expected returns: [[97.80326]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10.  3.  0.  6.  0.  0.  0. 10.  3.  3.  3.  3. 11.  0.  0. 16.  6.  0.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10.  3.  3. 23.  0.] 
adversary cards in discard: [ 0.  8.  8.  0.  0.  0. 16. 10. 10.  0.] 
adversary owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -2.0 

action type: buy - action 0.0
Learning step: -2.6543564796447754
desired expected reward: 92.4442367553711






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [10.  3.  3. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 23.  0.] 
cards in discard: [ 0.  8.  8.  0.  0.  0. 16. 10. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0] -> size -> 26 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 23.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0] -> size -> 26 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0] -> size -> 15 
action values: 2 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0] -> size -> 15 
action values: 0 
buys: 2 
player value: 4 
card supply: [20. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0] -> size -> 26 
adversary victory points: 3
player victory points: 2 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0] -> size -> 26 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0] -> size -> 26 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [6. 0. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[135.80008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  8.] 
adversary cards in discard: [14.  0. 10. 23.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -1.4349826574325562
desired expected reward: 96.36827850341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[114.80313 ]
 [124.12855 ]
 [119.29972 ]
 [ 96.03596 ]
 [118.71278 ]
 [128.22592 ]
 [121.63899 ]
 [122.42813 ]
 [105.01444 ]
 [118.054924]
 [114.61553 ]
 [129.64714 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  8.] 
adversary cards in discard: [14.  0. 10. 23.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -3.6909492015838623
desired expected reward: 132.09483337402344



buy possibilites: [-1] 
expected returns: [[138.95557]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 1.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  8.] 
adversary cards in discard: [14.  0. 10. 23.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 12.5 

action type: buy - action 10.0
Learning step: -2.151245594024658
desired expected reward: 115.9036636352539






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  8.] 
cards in discard: [14.  0. 10. 23.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 16.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0 10] -> size -> 27 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  8.] 
cards in discard: [14.  0. 10. 23.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 26. 30.  8.  6.  7.  8.  5. 10. 10.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 16.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0 10] -> size -> 27 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  8.] 
cards in discard: [14.  0. 10. 23.  3.  3.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 16.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0 10] -> size -> 27 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[152.15575]
 [138.83453]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 16.] 
cards in discard: [10.  6.  0.  0.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0
 11  0 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  4. 10. 10.] 
adversary cards in hand: [23.  0. 10.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0 11] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -3.3588390350341797
desired expected reward: 135.5967254638672



action possibilites: [-1] 
expected returns: [[117.97577]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  6.  0.  0.  6.  1. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [23.  0. 10.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0 11] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 26 

action type: gain_card_n - action 9
Learning step: -5.291965484619141
desired expected reward: 179.63644409179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[100.67514 ]
 [110.31676 ]
 [106.13031 ]
 [ 82.068825]
 [114.47127 ]
 [106.94842 ]
 [103.72985 ]
 [115.67353 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  6.  0.  0.  6.  1. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [23.  0. 10.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0 11] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -2.6417863368988037
desired expected reward: 115.333984375






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [23.  0. 10.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0. 10.  8. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3. 10.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0. 10.  8. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3. 10.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0. 10.  8. 10.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0 11  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3. 10.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 3.  0. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[100.81906]
 [ 88.75415]
 [ 88.75415]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3. 10.] 
cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 16.  3.] 
adversary cards in discard: [ 0. 23.  0. 10.  8. 10.] 
adversary owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0 11  0] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -3.846989393234253
desired expected reward: 111.82655334472656



action possibilites: [-1. 10.] 
expected returns: [[61.369164]
 [46.416992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  3.] 
cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 16.  3.] 
adversary cards in discard: [ 0. 23.  0. 10.  8. 10.] 
adversary owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0 11  0] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action 10.0
Learning step: -2.267789602279663
desired expected reward: 84.96284484863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.083675]
 [25.873709]
 [63.595337]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  3.] 
cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 16.  3.] 
adversary cards in discard: [ 0. 23.  0. 10.  8. 10.] 
adversary owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0 11  0] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -1.1373275518417358
desired expected reward: 60.23182678222656






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 16.  3.] 
cards in discard: [ 0. 23.  0. 10.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 10  0 10  8  3 23 16  0  8 10  0  0  0 14  0 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 23.  0. 10.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 23.  0. 10.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 23.  0. 10.  8. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[105.45807]
 [104.55621]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 11.] 
adversary cards in discard: [ 0. 23.  0. 10.  8. 10.  0.  8.  3.] 
adversary owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -0.3373163342475891
desired expected reward: 60.69980239868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[82.74981 ]
 [93.3407  ]
 [89.47197 ]
 [65.48064 ]
 [97.45644 ]
 [89.13    ]
 [86.140884]
 [98.37993 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 26. 30.  8.  6.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 11.] 
adversary cards in discard: [ 0. 23.  0. 10.  8. 10.  0.  8.  3.] 
adversary owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -2.9038960933685303
desired expected reward: 102.55418395996094



buy possibilites: [-1] 
expected returns: [[32.72241]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 27. 30. 26. 30.  8.  5.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 11.] 
adversary cards in discard: [ 0. 23.  0. 10.  8. 10.  0.  8.  3.] 
adversary owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -17.737775802612305
desired expected reward: 47.742828369140625






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [14.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0. 11.] 
cards in discard: [ 0. 23.  0. 10.  8. 10.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  5.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 8. 6. 3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.  6.
  0.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6] -> size -> 28 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 0. 23.  0. 10.  8. 10.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 26. 30.  8.  5.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [8. 6. 3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.  6.
  0.  0. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6] -> size -> 28 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 0. 23.  0. 10.  8. 10.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 27. 30. 26. 30.  8.  5.  7.  7.  5. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [8. 6. 3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.  6.
  0.  0. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6] -> size -> 28 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 0. 23.  0. 10.  8. 10.  0.  8.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 27. 30. 26. 30.  8.  5.  7.  7.  4. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [8. 6. 3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.  6.
  0.  0. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6] -> size -> 28 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[49.03225 ]
 [41.155346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3.] 
cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.  6.
  0.  0. 11.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  5.  7.  7.  4. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[   -5     0     1     0     0     0     0   -90     0     0     0     0
     0 -1200    50     0] 
sum of rewards: -1244 

action type: discard_down_to_3_cards - action 0
Learning step: -60.948455810546875
desired expected reward: -65.35896301269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[36.286884]
 [24.59713 ]
 [48.564194]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3.] 
cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.  6.
  0.  0. 11.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  5.  7.  7.  4. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -1.7804149389266968
desired expected reward: 47.2518310546875



buy possibilites: [-1] 
expected returns: [[-11.665506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3.] 
cards in discard: [10.  6.  0.  0.  6.  1. 10. 16.  0.  0.  0. 10.  3.  0.  3. 10.  3.  6.
  0.  0. 11.  0.  3.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  4.  7.  7.  4. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -10    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -315 

action type: buy - action 6.0
Learning step: -17.24233055114746
desired expected reward: 7.354787826538086






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  4.  7.  7.  4. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [11.  6.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6] -> size -> 29 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  4.  7.  7.  4. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [11.  6.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6] -> size -> 29 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 26. 30.  8.  4.  7.  7.  4. 10. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [11.  6.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6] -> size -> 29 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  4.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [11.  6.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6] -> size -> 29 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [11.  6.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[100.77764]
 [ 98.75933]
 [ 91.26056]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  4.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0. 14.] 
adversary cards in discard: [15. 10.  0.  0.  0. 10.  0.] 
adversary owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: 2.007988691329956
desired expected reward: -9.657517433166504



action possibilites: [-1. 11.] 
expected returns: [[109.22378 ]
 [107.265434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  4.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0. 14.] 
adversary cards in discard: [15. 10.  0.  0.  0. 10.  0.] 
adversary owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 6 

action type: take_action - action 10.0
Learning step: -1.7772592306137085
desired expected reward: 88.55958557128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[101.872116]
 [113.44689 ]
 [107.336266]
 [ 79.27928 ]
 [117.9964  ]
 [110.22424 ]
 [105.36424 ]
 [118.90564 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 26. 30.  8.  4.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0. 14.] 
adversary cards in discard: [15. 10.  0.  0.  0. 10.  0.] 
adversary owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: -2.757694721221924
desired expected reward: 106.46607971191406



buy possibilites: [-1] 
expected returns: [[109.637314]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 27. 30. 26. 30.  8.  3.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0. 14.] 
adversary cards in discard: [15. 10.  0.  0.  0. 10.  0.] 
adversary owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15] -> size -> 19 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -306.0 

action type: buy - action 6.0
Learning step: -16.7971248626709
desired expected reward: 62.48216247558594






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [10.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0. 14.] 
cards in discard: [15. 10.  0.  0.  0. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  3.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 10.  6.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6  6] -> size -> 30 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.] 
cards in discard: [15. 10.  0.  0.  0. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 26. 30.  8.  3.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6  6] -> size -> 30 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.] 
cards in discard: [15. 10.  0.  0.  0. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 26. 30.  8.  3.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6  6] -> size -> 30 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.] 
cards in discard: [15. 10.  0.  0.  0. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 27. 30. 26. 30.  8.  3.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6  6] -> size -> 30 
adversary victory points: -1
player victory points: 1 





Player: 0 
cards in hand: [0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[94.33727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  3.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  8. 23.] 
adversary cards in discard: [15. 10.  0.  0.  0. 10.  0.  0. 14. 10.  8.  0.  0.] 
adversary owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0] -> size -> 20 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[   -5     0    -1   -20     0     0     0   -90     0     0     0     0
     0 -1800    50     0] 
sum of rewards: -1866 

action type: discard_down_to_3_cards - action 5
Learning step: -90.58210754394531
desired expected reward: -102.08676147460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.705696]
 [55.638103]
 [93.57369 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 26. 30.  8.  3.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  8. 23.] 
adversary cards in discard: [15. 10.  0.  0.  0. 10.  0.  0. 14. 10.  8.  0.  0.] 
adversary owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0] -> size -> 20 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -4.297095775604248
desired expected reward: 90.93243408203125



buy possibilites: [-1] 
expected returns: [[57.82499]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6  6  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 26. 30.  8.  2.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  8. 23.] 
adversary cards in discard: [15. 10.  0.  0.  0. 10.  0.  0. 14. 10.  8.  0.  0.] 
adversary owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0] -> size -> 20 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -337.0 

action type: buy - action 6.0
Learning step: -18.330842971801758
desired expected reward: 37.3072509765625






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  0.  8. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  8. 23.] 
cards in discard: [15. 10.  0.  0.  0. 10.  0.  0. 14. 10.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  0 10  8  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  2.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  3. 10.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6  6  6] -> size -> 31 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 23.] 
cards in discard: [15. 10.  0.  0.  0. 10.  0.  0. 14. 10.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  2.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  3. 10.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6  6  6] -> size -> 31 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 23.] 
cards in discard: [15. 10.  0.  0.  0. 10.  0.  0. 14. 10.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  2.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  3. 10.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6  6  6] -> size -> 31 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 23.] 
cards in discard: [15. 10.  0.  0.  0. 10.  0.  0. 14. 10.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 26. 30.  8.  2.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  3. 10.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6  6  6] -> size -> 31 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [ 0.  6.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[58.49619 ]
 [51.042343]
 [48.858967]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  3. 10.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  6  3 10  0  0  6 16  8  3 10  0 11
  0 10 10  6  6  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 26. 30.  8.  2.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0] -> size -> 19 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1
Learning step: -3.5295326709747314
desired expected reward: 54.29545593261719



action possibilites: [-1] 
expected returns: [[37.795265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10
 10  6  6  6  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 26. 30.  8.  2.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0] -> size -> 19 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: trash_cards_n_from_hand - action 9
Learning step: -2.9017367362976074
desired expected reward: 55.140865325927734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.715157]
 [12.390421]
 [36.836338]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10
 10  6  6  6  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 26. 30.  8.  2.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0] -> size -> 19 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1
Learning step: -2.122192621231079
desired expected reward: 35.673072814941406



buy possibilites: [-1] 
expected returns: [[43.735428]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10
 10  6  6  6  6  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 26. 30.  8.  1.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0] -> size -> 19 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -328.0 

action type: buy - action 6.0
Learning step: -16.03547477722168
desired expected reward: -3.645059585571289






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 26. 30.  8.  1.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 6.  3. 16.  6.  0.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10
 10  6  6  6  6  6] -> size -> 30 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 27. 30. 26. 30.  8.  1.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 6.  3. 16.  6.  0.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10
 10  6  6  6  6  6] -> size -> 30 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [14. 27. 30. 26. 30.  8.  1.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 6.  3. 16.  6.  0.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10
 10  6  6  6  6  6] -> size -> 30 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [ 6.  3. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-3.058071 ]
 [-5.4032717]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 16.  6.  0.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10
 10  6  6  6  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  1.  7.  7.  4. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 11. 10.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0] -> size -> 20 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -4.6770758628845215
desired expected reward: 39.058353424072266



action possibilites: [-1] 
expected returns: [[-0.58416605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  1.  7.  7.  3. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 11. 10.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0] -> size -> 20 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -24 

action type: gain_card_n - action 3
Learning step: -2.7604923248291016
desired expected reward: 28.186479568481445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-12.328632  ]
 [-11.826836  ]
 [ -0.49086237]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  1.  7.  7.  3. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 11. 10.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0] -> size -> 20 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action -1
Learning step: -1.5234558582305908
desired expected reward: -2.107621908187866



buy possibilites: [-1] 
expected returns: [[-3.2358212]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.  8.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  7.  3. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 11. 10.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0] -> size -> 20 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4  -50    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -339 

action type: buy - action 6.0
Learning step: -16.43146324157715
desired expected reward: -28.25830078125






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11. 10.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  7.  3. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.  1.  3.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.  8.
  6. 16.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6] -> size -> 31 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.  0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  7.  3. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.  1.  3.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.  8.
  6. 16.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6] -> size -> 31 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  8.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0] -> size -> 20 
action values: 3 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  7.  3. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.  1.  3.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.  8.
  6. 16.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6] -> size -> 31 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 0.  0.  0.  0.  0.  3. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  7.  3. 10. 10.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.  1.  3.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.  8.
  6. 16.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6] -> size -> 31 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 0.  0.  0.  0.  0.  3. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  7.  3. 10. 10.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.  1.  3.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.  8.
  6. 16.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6] -> size -> 31 
adversary victory points: -4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 0.  0.  0.  0.  0.  3. 14. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.  1.  3.] 
adversary cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.  8.
  6. 16.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6] -> size -> 31 
adversary victory points: -4
player victory points: 1 





Player: 0 
cards in hand: [10.  0.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[19.586634]
 [15.852566]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  1.  3.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.  8.
  6. 16.  6.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10. 14.  0.  8. 23.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  3. 14. 11. 10. 10. 11.  0.  0.  0.  8.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11] -> size -> 22 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1
Learning step: -2.381739377975464
desired expected reward: -5.617560386657715



action possibilites: [-1.] 
expected returns: [[25.874163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.  8.
  6. 16.  6.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10. 14.  0.  8. 23.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  3. 14. 11. 10. 10. 11.  0.  0.  0.  8.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11] -> size -> 22 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -38 

action type: take_action - action 10.0
Learning step: -2.110459327697754
desired expected reward: 13.742100715637207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[14.417431 ]
 [20.231089 ]
 [17.952219 ]
 [ 7.02241  ]
 [16.540262 ]
 [23.072752 ]
 [17.72198  ]
 [27.809912 ]
 [18.16155  ]
 [ 8.87372  ]
 [13.130194 ]
 [16.229654 ]
 [ 6.8515105]
 [14.362303 ]
 [24.32745  ]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.  8.
  6. 16.  6.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10. 14.  0.  8. 23.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  3. 14. 11. 10. 10. 11.  0.  0.  0.  8.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11] -> size -> 22 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1.0
Learning step: -2.8263092041015625
desired expected reward: 23.047853469848633



buy possibilites: [-1] 
expected returns: [[49.184036]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 6. 10. 11.  6.  0.  0.  0. 10.  6.  6.  0.  3.  3.  6.  8.  0. 10.  8.
  6. 16.  6.  3.  6. 22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3.  9.  9.] 
adversary cards in hand: [10. 14.  0.  8. 23.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  3. 14. 11. 10. 10. 11.  0.  0.  0.  8.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11] -> size -> 22 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: 11 

action type: buy - action 22.0
Learning step: 1.3140655755996704
desired expected reward: 8.16557502746582






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [10. 14.  0.  8. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0.  8. 23.] 
cards in discard: [ 0.  0.  0.  0.  0.  3. 14. 11. 10. 10. 11.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3.  9.  9.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22] -> size -> 32 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1. 10. 14.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0.  8. 15.] 
cards in discard: [ 0.  0.  0.  0.  0.  3. 14. 11. 10. 10. 11.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11] -> size -> 22 
action values: 1 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3.  9.  9.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22] -> size -> 32 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  8. 15.] 
cards in discard: [ 0.  0.  0.  0.  0.  3. 14. 11. 10. 10. 11.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11] -> size -> 22 
action values: 0 
buys: 2 
player value: 2 
card supply: [14. 27. 30. 26. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3.  9.  9.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22] -> size -> 32 
adversary victory points: -4
player victory points: 1 


buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  8. 15.] 
cards in discard: [ 0.  0.  0.  0.  0.  3. 14. 11. 10. 10. 11.  0.  0.  0.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 27. 30. 25. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3.  9.  9.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22] -> size -> 32 
adversary victory points: -4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  8. 15.] 
cards in discard: [ 0.  0.  0.  0.  0.  3. 14. 11. 10. 10. 11.  0.  0.  0.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3.  9.  9.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22] -> size -> 32 
adversary victory points: -4
player victory points: 2 





Player: 0 
cards in hand: [6. 8. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[16.899996]
 [11.099434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3.  9.  9.] 
adversary cards in hand: [23.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0] -> size -> 24 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1
Learning step: -5.597190856933594
desired expected reward: 43.58684539794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 9.899614]
 [12.535643]
 [12.638697]
 [18.05572 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 27. 30. 25. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3.  9.  9.] 
adversary cards in hand: [23.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0] -> size -> 24 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1.0
Learning step: -3.9319515228271484
desired expected reward: 12.081916809082031



buy possibilites: [-1] 
expected returns: [[87.467445]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 0. 0.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 24. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3.  9.  9.] 
adversary cards in hand: [23.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0] -> size -> 24 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -50 

action type: buy - action 3.0
Learning step: -0.8264583945274353
desired expected reward: 5.063056468963623






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [23.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 24. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 3.  0. 16.  0. 11.] 
adversary cards in discard: [3. 6. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3] -> size -> 33 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 27. 30. 24. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 3.  0. 16.  0. 11.] 
adversary cards in discard: [3. 6. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3] -> size -> 33 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  8.  0.  0.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 3.  0. 16.  0. 11.] 
adversary cards in discard: [3. 6. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3] -> size -> 33 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0. 16.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[40.741943]
 [31.92886 ]
 [38.70475 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  0. 11.] 
cards in discard: [3. 6. 8. 6. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  3. 10. 10.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 14.] 
adversary cards in discard: [ 3. 23.  0.  8.  0.  0.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -6.922987461090088
desired expected reward: 80.5444564819336



action possibilites: [-1] 
expected returns: [[27.939102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  0.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  3. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 14.] 
adversary cards in discard: [ 3. 23.  0.  8.  0.  0.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -32 

action type: gain_card_n - action 6
Learning step: -2.015852451324463
desired expected reward: 18.873794555664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[12.5057535]
 [19.185123 ]
 [17.944914 ]
 [27.286972 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  3. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 14.] 
adversary cards in discard: [ 3. 23.  0.  8.  0.  0.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1
Learning step: -3.3306992053985596
desired expected reward: 24.608402252197266






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 14.] 
cards in discard: [ 3. 23.  0.  8.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  3. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 6. 10.  0.  0. 10.] 
adversary cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29] -> size -> 34 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 14.] 
cards in discard: [ 3. 23.  0.  8.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  3. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 6. 10.  0.  0. 10.] 
adversary cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29] -> size -> 34 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 14.] 
cards in discard: [ 3. 23.  0.  8.  0.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  2. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 6. 10.  0.  0. 10.] 
adversary cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29] -> size -> 34 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [ 6. 10.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[9.711357]
 [5.006592]
 [5.006592]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0. 10.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  2. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 3. 14. 10. 10. 11.] 
adversary cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1.0
Learning step: -4.603346347808838
desired expected reward: 22.68361473083496



action possibilites: [-1. 10.  8.] 
expected returns: [[-11.892643]
 [-12.260169]
 [-13.25109 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 10.  8.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  2. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 3. 14. 10. 10. 11.] 
adversary cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action 10.0
Learning step: -2.9284615516662598
desired expected reward: 2.0781235694885254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-12.000527]
 [-11.191874]
 [-12.05498 ]
 [-10.528929]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 10.  8.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  2. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 3. 14. 10. 10. 11.] 
adversary cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.059046745300293
desired expected reward: -13.951688766479492



buy possibilites: [-1] 
expected returns: [[8.874964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 10.  8.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 3. 14. 10. 10. 11.] 
adversary cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -40 

action type: buy - action 8.0
Learning step: -1.1975644826889038
desired expected reward: -13.252542495727539






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 3. 14. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14. 10. 10. 11.] 
cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [6. 3. 6. 0. 3.] 
adversary cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8] -> size -> 35 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14. 10. 10. 11.] 
cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3  8] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [6. 3. 6. 0. 3.] 
adversary cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8] -> size -> 35 
adversary victory points: -3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[10.753516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0. 3.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  3. 15.  8. 10.] 
adversary cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.  3. 14. 10. 10. 11.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -3.6017940044403076
desired expected reward: 5.27316951751709





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.035865]
 [10.837958]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 3.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  3. 15.  8. 10.] 
adversary cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.  3. 14. 10. 10. 11.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1.0
Learning step: -3.710341215133667
desired expected reward: 7.043174743652344



buy possibilites: [-1] 
expected returns: [[17.662066]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 3.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  3. 15.  8. 10.] 
adversary cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.  3. 14. 10. 10. 11.] 
adversary owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -60.   0.   0.   0. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: -99.0 

action type: buy - action 0.0
Learning step: -5.004396915435791
desired expected reward: 4.031466007232666






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 15.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  8. 10.] 
cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.  3. 14. 10. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 10.] 
adversary cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.  6.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0] -> size -> 36 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  8.  0.] 
cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.  3. 14. 10. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10  3 23  0  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0
  3  8] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 10.] 
adversary cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.  6.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0] -> size -> 36 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.  3. 14. 10. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [10 10  3 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 3 
card supply: [12. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 10.] 
adversary cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.  6.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0] -> size -> 36 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.  3. 14. 10. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 10.] 
adversary cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.  6.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0] -> size -> 36 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.  3. 14. 10. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 10.] 
adversary cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.  6.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0] -> size -> 36 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 23.  0.  8.  0.  0.  8.  0.  0.  0. 11. 14.  3. 14. 10. 10. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [11. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 10.] 
adversary cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.  6.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0] -> size -> 36 
adversary victory points: -3
player victory points: 2 





Player: 0 
cards in hand: [ 1.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-12.469711]
 [-10.813268]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  3. 10.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.  6.  3.  6.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1
Learning step: -4.041585922241211
desired expected reward: 13.620479583740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.985891 ]
 [-11.624763 ]
 [-10.253056 ]
 [-11.356168 ]
 [-11.8079815]
 [-12.059297 ]
 [-12.298217 ]
 [ -9.248982 ]
 [-11.000843 ]
 [-10.738757 ]
 [-12.686274 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  3. 10.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.  6.  3.  6.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 27. 30. 23. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -2.5218193531036377
desired expected reward: -14.991535186767578



buy possibilites: [-1] 
expected returns: [[-27.633358]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  3. 10.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.  6.  3.  6.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -40.   0.   0.   0.   0.   0.   0.   0.  -2.   0.   0.
   2.   0.] 
sum of rewards: -47.0 

action type: buy - action 3.0
Learning step: -2.4590978622436523
desired expected reward: -12.712154388427734






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  6. 22. 10.  0.] 
adversary cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.  6.  3.  6.  0.  3.  3.  1.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  6. 22. 10.  0.] 
adversary cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.  6.  3.  6.  0.  3.  3.  1.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  6. 22. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
expected returns: [[36.270256]
 [23.712233]
 [31.329113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 22. 10.  0.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.  6.  3.  6.  0.  3.  3.  1.  0.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 8.  0.  3.  8. 10.] 
adversary cards in discard: [8. 0. 0. 0. 0.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -0.25919246673583984
desired expected reward: -27.89255142211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.364067]
 [32.475143]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 22. 10.  0.] 
cards in discard: [ 3.  6.  8.  6.  0.  0. 29. 11.  3.  0. 16.  0.  8. 10.  6.  0.  0. 10.
  8.  0.  6.  3.  6.  0.  3.  3.  1.  0.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 8.  0.  3.  8. 10.] 
adversary cards in discard: [8. 0. 0. 0. 0.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -3.2990853786468506
desired expected reward: 29.176050186157227



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  8. 10.] 
cards in discard: [8. 0. 0. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  8. 10.] 
cards in discard: [8. 0. 0. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  8. 10.] 
cards in discard: [8. 0. 0. 0. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 2 





Player: 0 
cards in hand: [8. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-4.3910065]
 [-6.10233  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10
  6  6  6  6  6  8  6 22  3 29  8  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 0. 11. 14. 14. 11.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  0.  8.  0.  3.  8. 10.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -4.0882415771484375
desired expected reward: 28.38689422607422



action possibilites: [-1] 
expected returns: [[20.754362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 0. 11. 14. 14. 11.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  0.  8.  0.  3.  8. 10.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: trash_cards_n_from_hand - action 4
Learning step: -0.14175967872142792
desired expected reward: -14.967103958129883





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.211727]
 [18.81505 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 0. 11. 14. 14. 11.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  0.  8.  0.  3.  8. 10.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1
Learning step: -2.0157439708709717
desired expected reward: 18.738618850708008






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 14. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 14. 14. 11.] 
cards in discard: [ 8.  0.  0.  0.  0.  0.  8.  0.  3.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 1. 10.  0.  3. 11.] 
adversary cards in discard: [8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 14. 14. 11.] 
cards in discard: [ 8.  0.  0.  0.  0.  0.  8.  0.  3.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [ 1. 10.  0.  3. 11.] 
adversary cards in discard: [8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
adversary victory points: -2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 10.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[5.6297555]
 [1.1572709]
 [3.2306771]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  3. 11.] 
cards in discard: [8. 6. 6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [15. 10. 10.  0. 23.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  0.  8.  0.  3.  8. 10.  0. 11. 14. 14. 11.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -3.2060768604278564
desired expected reward: 15.608977317810059



action possibilites: [-1. 11. 16.] 
expected returns: [[-5.670744 ]
 [-6.408408 ]
 [-7.1860175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 11. 16.] 
cards in discard: [8. 6. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [15. 10. 10.  0. 23.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  0.  8.  0.  3.  8. 10.  0. 11. 14. 14. 11.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action 10.0
Learning step: -1.549223780632019
desired expected reward: -0.3919466733932495





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-6.474562 ]
 [-6.700056 ]
 [-5.750075 ]
 [-5.8504024]
 [-7.0665827]
 [-5.9044566]
 [-4.8251085]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 11. 16.] 
cards in discard: [8. 6. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [15. 10. 10.  0. 23.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  0.  8.  0.  3.  8. 10.  0. 11. 14. 14. 11.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -1.1980642080307007
desired expected reward: -6.868804454803467






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [15. 10. 10.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 23.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10.  0. 23.] 
cards in discard: [ 8.  0.  0.  0.  0.  0.  8.  0.  3.  8. 10.  0. 11. 14. 14. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1. 15. 10. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0. 23.  0.] 
cards in discard: [ 8.  0.  0.  0.  0.  0.  8.  0.  3.  8. 10.  0. 11. 14. 14. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  0.  3.] 
cards in discard: [ 8.  0.  0.  0.  0.  0.  8.  0.  3.  8. 10.  0. 11. 14. 14. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0] -> size -> 26 
action values: 2 
buys: 1 
player value: 1 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  0.  3.] 
cards in discard: [ 8.  0.  0.  0.  0.  0.  8.  0.  3.  8. 10.  0. 11. 14. 14. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0] -> size -> 26 
action values: 0 
buys: 2 
player value: 3 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  1. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
adversary victory points: -2
player victory points: 2 


buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  0.  3.] 
cards in discard: [ 8.  0.  0.  0.  0.  0.  8.  0.  3.  8. 10.  0. 11. 14. 14. 11.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  0. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
adversary victory points: -2
player victory points: 2 





Player: 0 
cards in hand: [6. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[1.7224164]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  0. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8] -> size -> 27 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -2.069990634918213
desired expected reward: -6.895092487335205





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-3.4176414 ]
 [-0.12276363]
 [ 4.635856  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 27. 30. 22. 30.  8.  0.  7.  6.  0. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8] -> size -> 27 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -2.410111665725708
desired expected reward: -0.6876952648162842



buy possibilites: [-1] 
expected returns: [[27.57217]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8] -> size -> 27 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0  -1   0   0   8   0] 
sum of rewards: -29 

action type: buy - action 3.0
Learning step: -0.8234883546829224
desired expected reward: -0.9462436437606812






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [10.  0.  8. 10.  0.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3  3] -> size -> 36 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  9.  7.  9.  3.  9.  9.] 
adversary cards in hand: [10.  0.  8. 10.  0.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3  3] -> size -> 36 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  9.] 
adversary cards in hand: [10.  0.  8. 10.  0.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3  3] -> size -> 36 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [10.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
expected returns: [[16.559412]
 [13.951426]
 [14.936426]
 [13.951426]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 10.  0.] 
cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  9.] 
adversary cards in hand: [10. 11. 23.  0.  0.] 
adversary cards in discard: [29.  8.  0.  0.  0.  0.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8 29] -> size -> 28 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -2.837367534637451
desired expected reward: 24.73480224609375



action possibilites: [-1.  8. 10. 29.] 
expected returns: [[32.295994]
 [29.025198]
 [28.719557]
 [29.273314]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0. 29.] 
cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6
  6  6  6  8  6 22  3 29  8  0  3  3] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  9.] 
adversary cards in hand: [10. 11. 23.  0.  0.] 
adversary cards in discard: [29.  8.  0.  0.  0.  0.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8 29] -> size -> 28 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action 10.0
Learning step: -0.8161491751670837
desired expected reward: 13.135274887084961



action possibilites: [-1. 10.] 
expected returns: [[-10.784826]
 [-13.015211]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  9.] 
adversary cards in hand: [10. 11. 23.  0.  0.] 
adversary cards in discard: [29.  8.  0.  0.  0.  0.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8 29] -> size -> 28 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.7840439081192017
desired expected reward: 32.63475036621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-13.086899]
 [-10.611355]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  9.] 
adversary cards in hand: [10. 11. 23.  0.  0.] 
adversary cards in discard: [29.  8.  0.  0.  0.  0.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8 29] -> size -> 28 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: 0.4777931869029999
desired expected reward: -10.307037353515625






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [10. 11. 23.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 23.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 23.  0.  0.] 
cards in discard: [29.  8.  0.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3] -> size -> 33 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 23.  0.  0.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8 29 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  8.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3] -> size -> 33 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 23.  0.  0.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8 29 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  8.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3] -> size -> 33 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-11.581744]
 [-12.419809]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  8.] 
adversary cards in hand: [11.  8. 10.  8.  0.] 
adversary cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8 29 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -1.4924813508987427
desired expected reward: -13.00828742980957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-12.767828]
 [-12.220829]
 [-12.423775]
 [-11.927389]
 [-12.480853]
 [-11.337768]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  8.] 
adversary cards in hand: [11.  8. 10.  8.  0.] 
adversary cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8 29 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -1.491693377494812
desired expected reward: -13.07343864440918



buy possibilites: [-1] 
expected returns: [[-12.336161]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  8.] 
adversary cards in hand: [11.  8. 10.  8.  0.] 
adversary cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0.] 
adversary owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8 29 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -66.0 

action type: buy - action 0.0
Learning step: -2.9391722679138184
desired expected reward: -15.706998825073242






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [11.  8. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 10.  8.  0.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8 29 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.
  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.  0.  0.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10 23  8 10  0  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8
  0  0  8 29 15] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.
  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  7.  9.  3.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.
  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  6.  9.  3.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.
  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  6.  9.  3.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.
  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [3. 6. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-4.3692408]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 3.] 
cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.
  0.  0.  0.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  6.  9.  3.  9.  8.] 
adversary cards in hand: [ 3. 14.  0.  0. 14.] 
adversary cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0.] 
adversary owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15 14] -> size -> 28 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -1.281499981880188
desired expected reward: -13.617660522460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-4.2755327]
 [-4.656815 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 3.] 
cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.
  0.  0.  0.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  6.  9.  3.  9.  8.] 
adversary cards in hand: [ 3. 14.  0.  0. 14.] 
adversary cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0.] 
adversary owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15 14] -> size -> 28 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -1.6812326908111572
desired expected reward: -6.050473213195801



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0. 14.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  6.  9.  3.  9.  8.] 
adversary cards in hand: [10.  3.  6.  6. 22.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.
  0.  0.  0.  8.  3.  0.  3.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  6.  9.  3.  9.  8.] 
adversary cards in hand: [10.  3. 22.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.
  0.  0.  0.  8.  3.  0.  3.  6.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  8.  6.  9.  3.  9.  8.] 
adversary cards in hand: [10.  3. 22.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.
  0.  0.  0.  8.  3.  0.  3.  6.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15 14 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  3.  9.  8.] 
adversary cards in hand: [10.  3. 22.] 
adversary cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.
  0.  0.  0.  8.  3.  0.  3.  6.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [10.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
expected returns: [[-12.309583]
 [-13.155074]
 [-12.308936]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 22.] 
cards in discard: [ 8.  6.  6. 10.  1.  0.  3. 11. 16.  3.  6.  0.  0.  6.  6. 10.  8. 10.
  0.  0.  0.  8.  3.  0.  3.  6.  3.  0.  3.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  3.  9.  8.] 
adversary cards in hand: [10.  0. 15.  3.  8.] 
adversary cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0. 29.
 14.  3.  0.  0. 14.] 
adversary owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15 14 29] -> size -> 29 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[   -5     0    -1   -30     0     0     0     0     0     0     0     0
     0 -2400    79     0] 
sum of rewards: -2357 

action type: discard_down_to_3_cards - action 3
Learning step: -117.8955078125
desired expected reward: -122.62786102294922



action possibilites: [-1. 22.] 
expected returns: [[ -6.875306]
 [-12.200414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22.  6.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  3.  9.  8.] 
adversary cards in hand: [10.  0. 15.  3.  8.] 
adversary cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0. 29.
 14.  3.  0.  0. 14.] 
adversary owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15 14 29] -> size -> 29 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action 10.0
Learning step: -0.3457549512386322
desired expected reward: -13.500828742980957





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-12.099759 ]
 [ -6.9706206]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.  6.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0] -> size -> 34 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  3.  9.  8.] 
adversary cards in hand: [10.  0. 15.  3.  8.] 
adversary cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0. 29.
 14.  3.  0.  0. 14.] 
adversary owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15 14 29] -> size -> 29 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -0.6600912809371948
desired expected reward: -7.535403251647949



buy possibilites: [-1] 
expected returns: [[2.6500099]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.  6.] 
cards in discard: [0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0  0] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  3.  9.  8.] 
adversary cards in hand: [10.  0. 15.  3.  8.] 
adversary cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0. 29.
 14.  3.  0.  0. 14.] 
adversary owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15 14 29] -> size -> 29 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action 0.0
Learning step: -1.6353870630264282
desired expected reward: -13.735142707824707






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [10.  0. 15.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.  3.  8.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0. 29.
 14.  3.  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0
  8 29 15 14 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  3.  9.  8.] 
adversary cards in hand: [6. 3. 6. 8. 0.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0. 29.
 14.  3.  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  3.  9.  8.] 
adversary cards in hand: [6. 3. 6. 8. 0.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0. 29.
 14.  3.  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  3.  9.  8.] 
adversary cards in hand: [6. 3. 6. 8. 0.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.] 
cards in discard: [29.  8.  0.  0.  0.  0. 15. 11. 10. 23.  0.  0. 14. 10.  8. 11.  0. 29.
 14.  3.  0.  0. 14. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [6. 3. 6. 8. 0.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.] 
adversary owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [6. 3. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-4.2644362]
 [-4.9499125]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 8. 0.] 
cards in discard: [ 0. 10.  3. 22.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  6  3 10  0  0  6 16  8  3 10  0 11  0 10 10  6  6  6  6
  6  8  6 22  3  8  0  3  3  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10] -> size -> 29 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -2.034734010696411
desired expected reward: 0.6152758598327637



action possibilites: [-1] 
expected returns: [[-1.8611178]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 0. 10.  3. 22.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: trash_cards_n_from_hand - action 6
Learning step: 1.2336541414260864
desired expected reward: -18.276931762695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.6566744]
 [-1.8798971]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0. 10.  3. 22.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: 0.30697035789489746
desired expected reward: -1.554147481918335






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  6.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  5.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 0.  6.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-19.625067]
 [-17.479473]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 10.  0.] 
cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  5.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [11.  0. 14.  0.  8.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11] -> size -> 30 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -1.0189621448516846
desired expected reward: -2.8988490104675293



action possibilites: [-1.  8.] 
expected returns: [[ -9.440466]
 [-10.56418 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 8.] 
cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  5.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [11.  0. 14.  0.  8.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11] -> size -> 30 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action 10.0
Learning step: 0.9468079805374146
desired expected reward: -16.532665252685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-9.472386]
 [-8.409887]
 [-9.465459]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 8.] 
cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  5.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [11.  0. 14.  0.  8.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11] -> size -> 30 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: 0.5698568224906921
desired expected reward: -8.870609283447266






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [11.  0. 14.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 14.  0.  8.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  5.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [8. 1. 6. 3. 0.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  5.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [1. 3. 0.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  8.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  5.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [1. 3. 0.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[3.027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0.] 
cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  5.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 15.  8. 29.  0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11] -> size -> 30 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[   -5     0     1   -10     0     0     0     0     0     0     0     0
     0 -1800    70     0] 
sum of rewards: -1744 

action type: discard_down_to_3_cards - action 4
Learning step: -87.32398223876953
desired expected reward: -83.48220825195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-1.142014  ]
 [-1.5627582 ]
 [-0.63340163]
 [-1.0390143 ]
 [-0.7280896 ]
 [-0.12863827]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  7.  5.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 15.  8. 29.  0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11] -> size -> 30 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -0.8678787350654602
desired expected reward: 2.15912127494812



buy possibilites: [-1] 
expected returns: [[-3.0083032]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 27. 30. 20. 30.  8.  0.  7.  5.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 15.  8. 29.  0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -1.0 

action type: buy - action 3.0
Learning step: -0.0860166922211647
desired expected reward: -0.7194193005561829






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8. 29.  0.] 
cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 30.  8.  0.  7.  5.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10.  3.  0.  0.  3.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3] -> size -> 34 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 27. 30. 20. 30.  8.  0.  7.  5.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10.  3.  0.  0.  3.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3] -> size -> 34 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 27. 30. 20. 30.  8.  0.  7.  5.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10.  3.  0.  0.  3.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3] -> size -> 34 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10.  3.  0.  0.  3.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3] -> size -> 34 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [10.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[7.3140697]
 [2.521027 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  3.] 
cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10. 14. 11.  3. 14.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.12104477733373642
desired expected reward: -2.887258291244507





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[0.93191814]
 [3.7299519 ]
 [7.2267485 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  3.] 
cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10. 14. 11.  3. 14.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -0.4129398763179779
desired expected reward: 6.901120185852051



buy possibilites: [-1] 
expected returns: [[-3.470963]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  3.] 
cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10. 14. 11.  3. 14.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -33.0 

action type: buy - action 0.0
Learning step: -1.7746919393539429
desired expected reward: -0.8427857160568237






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [10. 14. 11.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14. 11.  3. 14.] 
cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 6.  6.  0. 11. 10.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.  0. 10.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0] -> size -> 35 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14. 11.  3. 14.] 
cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 6.  6.  0. 11. 10.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.  0. 10.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0] -> size -> 35 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14. 11.  3. 14.] 
cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 6.  6.  0. 11. 10.] 
adversary cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.  0. 10.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0] -> size -> 35 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 6.  6.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[19.80381 ]
 [20.155941]
 [15.851722]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 11. 10.] 
cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.  0. 10.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10. 29. 10.  8. 15.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.
  0. 10. 14. 11.  3. 14.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0] -> size -> 32 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.4486008584499359
desired expected reward: -3.022362232208252



action possibilites: [-1. 11.] 
expected returns: [[23.498055]
 [24.338669]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 11.  0.] 
cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.  0. 10.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10. 29. 10.  8. 15.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.
  0. 10. 14. 11.  3. 14.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0] -> size -> 32 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 18 

action type: take_action - action 10.0
Learning step: 0.6473287343978882
desired expected reward: 16.499040603637695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[18.226944]
 [19.814804]
 [22.603477]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 11.  0.] 
cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.  0. 10.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10. 29. 10.  8. 15.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.
  0. 10. 14. 11.  3. 14.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0] -> size -> 32 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: 0.13988761603832245
desired expected reward: 23.637937545776367



buy possibilites: [-1] 
expected returns: [[-13.014978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 11.  0.] 
cards in discard: [ 0. 10.  3. 22.  6.  8.  3.  0. 10.  0.  6.  6.  0.  8.  8.  6.  3.  1.
  3.  0.  0. 10.  3.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10. 29. 10.  8. 15.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.
  0. 10. 14. 11.  3. 14.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0] -> size -> 32 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.   0.   0.   0.  20. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: -14.0 

action type: buy - action 0.0
Learning step: -1.9041839838027954
desired expected reward: 16.322755813598633






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [10. 29. 10.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  8. 15.] 
cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.
  0. 10. 14. 11.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 22.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  8.] 
cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.
  0. 10. 14. 11.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 22.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 10.  8.] 
cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.
  0. 10. 14. 11.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 22.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 10.  8.] 
cards in discard: [11.  0.  3.  0.  0.  0. 14. 11.  0.  0.  8. 15. 10. 11. 29.  0.  8.  0.
  0. 10. 14. 11.  3. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 22.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0. 22.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 16.] 
expected returns: [[-7.1638136]
 [-7.199792 ]
 [-7.340469 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  3.  3. 16.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [11. 14.  0.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0] -> size -> 33 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.3382636606693268
desired expected reward: -12.676714897155762





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-7.605006 ]
 [-7.6194706]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  3.  3. 16.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [11. 14.  0.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0] -> size -> 33 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: 0.036945413798093796
desired expected reward: -7.126867294311523



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [11. 14.  0.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 23.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  0.  0. 23.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 20. 30.  8.  0.  7.  4.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 23.] 
cards in discard: [11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 20. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0. 23.] 
cards in discard: [11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 20. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0. 23.] 
cards in discard: [11.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 27. 30. 20. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0. 10.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-1.2814082]
 [-2.9930942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  0.  0.] 
cards in discard: [ 0. 22.  3.  3. 16.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 20. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 29. 11. 14.  0.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11  0] -> size -> 35 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: 0.18645106256008148
desired expected reward: -7.433018207550049





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-1.8944689]
 [-1.1209903]
 [-0.9932692]
 [-0.2899251]
 [-1.289227 ]
 [ 0.4435284]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  0.  0.] 
cards in discard: [ 0. 22.  3.  3. 16.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 27. 30. 20. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 29. 11. 14.  0.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11  0] -> size -> 35 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -0.09980108588933945
desired expected reward: -1.3812037706375122



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 0. 29. 11. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 14.  0.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 20. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 3.  3. 10.  8.  0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 27. 30. 20. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 3.  3. 10.  8.  0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 27. 30. 20. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 3.  3. 10.  8.  0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 3.  3. 10.  8.  0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 3.  3. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[ 4.4602737]
 [-0.2927034]
 [ 1.6252286]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  8.  0.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 10  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8
  6 22  3  8  0  3  3  0  0  3  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [15. 10.  0. 11. 29.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11  0  3] -> size -> 36 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -0.6223012804985046
desired expected reward: -0.09659284353256226



action possibilites: [-1] 
expected returns: [[-16.462381]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [15. 10.  0. 11. 29.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11  0  3] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 8
Learning step: -0.37923476099967957
desired expected reward: -4.202610969543457





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-12.075744]
 [-17.023676]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [15. 10.  0. 11. 29.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11  0  3] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: 0.30605801939964294
desired expected reward: -16.156322479248047



buy possibilites: [-1] 
expected returns: [[-11.438737]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 19. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [15. 10.  0. 11. 29.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8.] 
adversary owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11  0  3] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action 0.0
Learning step: -1.3535842895507812
desired expected reward: -13.429329872131348






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [15. 10.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0. 11. 29.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 19. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 10 23 10  0 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8
 29 15 14 29 10 11 11  0  0 11  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 27. 30. 19. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [10 10 23 10 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8 29
 15 14 29 10 11 11  0  0 11  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 2. 27. 30. 19. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [10 10 23 10 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8 29
 15 14 29 10 11 11  0  0 11  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 27. 30. 19. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [10 10 23 10 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8 29
 15 14 29 10 11 11  0  0 11  0  3  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 19. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [3. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-7.5490103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 19. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10.  0.  8.  0.  3.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.] 
adversary owned cards: [10 10 23 10 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8 29
 15 14 29 10 11 11  0  0 11  0  3  1] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -0.7979158759117126
desired expected reward: -12.236652374267578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-6.430005 ]
 [-4.417388 ]
 [-7.5680656]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 26. 30. 19. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10.  0.  8.  0.  3.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.] 
adversary owned cards: [10 10 23 10 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8 29
 15 14 29 10 11 11  0  0 11  0  3  1] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -0.953494668006897
desired expected reward: -8.5025053024292



buy possibilites: [-1] 
expected returns: [[-14.609076]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [10.  0.  8.  0.  3.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.] 
adversary owned cards: [10 10 23 10 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8 29
 15 14 29 10 11 11  0  0 11  0  3  1] -> size -> 36 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -5 

action type: buy - action 3.0
Learning step: -0.3578348159790039
desired expected reward: -4.775221824645996






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [10.  0.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  0.  3.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10 14  0 11  0  0  8 15  0  0  0 14 11  3  0  3  8  0  0  8 29
 15 14 29 10 11 11  0  0 11  0  3  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 3. 10.  6.  3.  0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3] -> size -> 35 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 3. 10.  6.  3.  0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3] -> size -> 35 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 3. 10.  6.  3.  0.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3] -> size -> 35 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 3. 10.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-8.53129 ]
 [-8.647782]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  3.  0.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [14.  3. 11.  0. 10.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0.] 
adversary owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1] -> size -> 34 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.38743191957473755
desired expected reward: -14.221643447875977





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-9.199544]
 [-8.56395 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  3.  0.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [14.  3. 11.  0. 10.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0.] 
adversary owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1] -> size -> 34 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: 0.07804927974939346
desired expected reward: -8.453240394592285



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [14.  3. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 11.  0. 10.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 3.  0. 11.  1. 10.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.  3. 10.  6.  3.  0.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3] -> size -> 35 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 10.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [11.  1. 10.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.  3. 10.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3] -> size -> 35 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 10.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  2.  9.  8.] 
adversary cards in hand: [11.  1. 10.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.  3. 10.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3] -> size -> 35 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 10.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  1.  9.  8.] 
adversary cards in hand: [11.  1. 10.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.  3. 10.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3] -> size -> 35 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [11.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[-6.2358236]
 [-6.4280214]
 [-5.4530764]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 10.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.  3. 10.  6.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 8.  0.  0. 15. 10.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0. 10. 14.  3. 11.  0. 10.] 
adversary owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1 10] -> size -> 35 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[   -5     0     2     0     0     0     0     0     0     0     0     0
     0 -1800    65     0] 
sum of rewards: -1738 

action type: discard_down_to_3_cards - action 6
Learning step: -86.99055480957031
desired expected reward: -87.84819030761719



action possibilites: [-1. 11.] 
expected returns: [[-20.764406]
 [-21.126228]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.  3. 10.  6.  3.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 8.  0.  0. 15. 10.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0. 10. 14.  3. 11.  0. 10.] 
adversary owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1 10] -> size -> 35 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 18 

action type: take_action - action 10.0
Learning step: 0.70213782787323
desired expected reward: -4.750936508178711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-17.97566 ]
 [-19.762568]
 [-17.782112]
 [-20.040205]
 [-17.662733]
 [-19.830349]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.  3. 10.  6.  3.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 8.  0.  0. 15. 10.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0. 10. 14.  3. 11.  0. 10.] 
adversary owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1 10] -> size -> 35 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: 1.4691836833953857
desired expected reward: -19.295223236083984



buy possibilites: [-1] 
expected returns: [[-9.982321]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.  3. 10.  6.  3.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 8.  0.  0. 15. 10.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0. 10. 14.  3. 11.  0. 10.] 
adversary owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1 10] -> size -> 35 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.   0.   0.   0.  20. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: -14.0 

action type: buy - action 0.0
Learning step: -0.025819016620516777
desired expected reward: -18.001483917236328






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 15. 10.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0. 10. 14.  3. 11.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  1.  9.  8.] 
adversary cards in hand: [8. 6. 0. 6. 8.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.  3. 10.  6.  3.  0.  3.  0.  0. 10. 11.  1.  0.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 15.  0.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0. 10. 14.  3. 11.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10 23 10 14 11  0  0  8 15  0  0  0 14 11  0  3  8  0  0  8 29 15 14
 29 10 11 11  0  0 11  0  3  1 10] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  1.  9.  8.] 
adversary cards in hand: [8. 6. 0. 6. 8.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.  3. 10.  6.  3.  0.  3.  0.  0. 10. 11.  1.  0.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0. 10. 14.  3. 11.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10 10 23 10 14 11  8  0  0  0 14 11  0  3  8  0  0  8 29 15 14 29 10 11
 11  0  0 11  0  3  1 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  1.  9.  8.] 
adversary cards in hand: [8. 6. 0. 6. 8.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.  3. 10.  6.  3.  0.  3.  0.  0. 10. 11.  1.  0.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0. 10. 14.  3. 11.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10 10 23 10 14 11  8  0  0  0 14 11  0  3  8  0  0  8 29 15 14 29 10 11
 11  0  0 11  0  3  1 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  1.  9.  8.] 
adversary cards in hand: [8. 6. 0. 6. 8.] 
adversary cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.  3. 10.  6.  3.  0.  3.  0.  0. 10. 11.  1.  0.] 
adversary owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3  0] -> size -> 36 
adversary victory points: 2
player victory points: 2 


Game is draw!



Player 0 bought cards:
Copper: 11 
Silver: 1 
Gold: 0 
Estate: 8 
Duchy: 0 
Province: 0 
Curse: 10 

Remodel: 1 
Workshop: 1 
Chapel: 2 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 3 
Library: 1 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [8. 6. 0. 6. 8.] 
cards in discard: [ 0. 22.  3.  3. 16.  0. 10.  6.  0.  0.  0.  8.  3.  3.  3.  6.  6.  0.
  0.  3. 10.  6.  3.  0.  3.  0.  0. 10. 11.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  0  0 16  8  3 10  0 11  0 10 10  6  6  6  6  6  8  6 22  3
  8  0  3  3  0  0  3  0  0  0  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 18. 30.  8.  0.  7.  3.  0. 10.  7.  6.  9.  1.  9.  8.] 
adversary cards in hand: [0.] 
adversary cards in discard: [11.  0. 11. 14.  0.  0. 23. 14.  0.  3. 29. 11.  0.  8. 11.  0.  1. 29.
 15. 10.  8. 10.  0. 10. 14.  3. 11.  0. 10.  0.] 
adversary owned cards: [10 10 23 10 14 11  8  0  0  0 14 11  0  3  8  0  0  8 29 15 14 29 10 11
 11  0  0 11  0  3  1 10  0] -> size -> 33 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.3491160571575165
desired expected reward: -9.633204460144043



