 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[61.051563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      90       0       0      40       0       0
       0       0    -110       0       0      27       0] 
sum of rewards: 3000042 

action type: buy - action 11.0
Learning step: 299992.875
desired expected reward: 300106.125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[57.93637 ]
 [86.4466  ]
 [77.306076]
 [41.13682 ]
 [95.98334 ]
 [74.73587 ]
 [66.478775]
 [59.67614 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 60.96102523803711



buy possibilites: [-1] 
expected returns: [[40.984272]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 95.98333740234375






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.  0.  0.  3.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[51.99956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.98427200317383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 49.27754 ]
 [ 77.2112  ]
 [ 68.36257 ]
 [ 32.631916]
 [ 64.41822 ]
 [ 86.84968 ]
 [ 65.7054  ]
 [102.10538 ]
 [ 47.59955 ]
 [ 57.18935 ]
 [ 74.93969 ]
 [ 50.92141 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 50.22868728637695



buy possibilites: [-1] 
expected returns: [[21.167515]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 102.1053695678711






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [2.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[33.068134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [2. 0. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.16751480102539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[32.15562 ]
 [52.467747]
 [46.047073]
 [20.915577]
 [43.180775]
 [59.69098 ]
 [44.132324]
 [72.018486]
 [31.087711]
 [37.932877]
 [50.729763]
 [33.72214 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [2. 0. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.11354446411133



buy possibilites: [-1] 
expected returns: [[15.054391]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [2. 0. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 72.01847839355469






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [2. 0. 0. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0. 29.  3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [2. 0. 0. 0. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0. 29.  3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [2. 0. 0. 0. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0. 29.  3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 2.  0.  0.  0.  0.  1. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0. 29.  3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  3.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[18.793964]
 [39.706635]
 [48.460575]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 29.  3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.054390907287598



action possibilites: [-1. 11.] 
expected returns: [[41.917313]
 [63.248005]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 46.15513229370117



action possibilites: [-1] 
expected returns: [[38.48043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 74.01026916503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[41.341377]
 [60.140057]
 [54.23911 ]
 [30.102806]
 [66.54226 ]
 [52.570133]
 [47.04765 ]
 [41.902836]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.480430603027344



buy possibilites: [-1] 
expected returns: [[33.966434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 66.5422592163086






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[11.653614]
 [37.204807]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  1. 11. 10.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.966434478759766



action possibilites: [-1.] 
expected returns: [[23.062683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  1. 11. 10.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.07640075683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.824726]
 [38.682106]
 [33.398617]
 [16.128468]
 [11.392475]
 [30.862846]
 [45.56403 ]
 [31.770466]
 [66.71747 ]
 [56.682472]
 [20.82024 ]
 [36.44183 ]
 [26.866783]
 [19.966713]
 [37.42422 ]
 [23.195389]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  1. 11. 10.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.06268310546875



buy possibilites: [-1] 
expected returns: [[26.888756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  1. 11. 10.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 66.71747589111328






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  1. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 11. 10.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0. 29.  3.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 11.  0.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0. 29.  3.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0.] 
cards in discard: [10.  0.  0.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0. 29.  3.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0.] 
cards in discard: [10.  0.  0.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 29. 30. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0. 29.  3.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[33.94166 ]
 [37.075317]
 [60.68968 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 29.  3.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 2. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.888755798339844



action possibilites: [-1. 10. 11.] 
expected returns: [[17.78452 ]
 [22.037758]
 [38.72865 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3. 11.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 30. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 2. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 54.20381546020508



action possibilites: [-1] 
expected returns: [[24.600403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 30. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 2. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 45.2314338684082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.00079 ]
 [37.34874 ]
 [33.62446 ]
 [16.701992]
 [41.997005]
 [32.15943 ]
 [28.435143]
 [26.300758]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 29. 30. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 2. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.60040283203125



buy possibilites: [-1] 
expected returns: [[26.159176]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8.  9. 10.  6. 10.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 2. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 41.99701690673828






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 3. 2. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 2. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8.  9. 10.  6. 10.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 2. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 29. 30. 30.  8.  9. 10.  6. 10.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 2. 0. 0.] 
cards in discard: [15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 29. 30. 30.  8.  9. 10.  6. 10.  9.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[17.72168 ]
 [20.491268]
 [36.90549 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8.  9. 10.  6. 10.  9.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [15.  0.  3.  2.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.159175872802734



action possibilites: [-1] 
expected returns: [[25.311306]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 30. 30.  8.  9. 10.  6. 10.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [15.  0.  3.  2.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.481929779052734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.503773]
 [39.810413]
 [14.751107]
 [37.87349 ]
 [28.140781]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 29. 30. 30.  8.  9. 10.  6. 10.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [15.  0.  3.  2.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.31130599975586



buy possibilites: [-1] 
expected returns: [[19.32174]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6. 10.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [15.  0.  3.  2.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 39.81041717529297






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 1. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 6. 0.] 
cards in discard: [15.  0.  3.  2.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6. 10.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3] -> size -> 20 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 6. 0.] 
cards in discard: [15.  0.  3.  2.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6. 10.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3] -> size -> 20 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 6. 0.] 
cards in discard: [15.  0.  3.  2.  0.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9.  9.  6. 10.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3] -> size -> 20 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [11.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[44.66665]
 [67.28809]
 [76.64399]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 29.  0.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9.  9.  6. 10.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  3.  0.] 
adversary cards in discard: [15.  0.  3.  2.  0.  0. 16.  3.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.321739196777344



action possibilites: [-1. 11. 10.] 
expected returns: [[60.716457]
 [81.972115]
 [64.18769 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 10.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 29. 30.  8.  9.  9.  6. 10.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  3.  0.] 
adversary cards in discard: [15.  0.  3.  2.  0.  0. 16.  3.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 69.57203674316406



action possibilites: [-1] 
expected returns: [[28.655354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 29. 30.  8.  9.  9.  6. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  3.  0.] 
adversary cards in discard: [15.  0.  3.  2.  0.  0. 16.  3.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 87.4511489868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.112259]
 [41.674183]
 [37.81668 ]
 [18.273247]
 [47.36156 ]
 [35.96921 ]
 [32.375195]
 [31.42381 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 29. 29. 30.  8.  9.  9.  6. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  3.  0.] 
adversary cards in discard: [15.  0.  3.  2.  0.  0. 16.  3.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.655353546142578



buy possibilites: [-1] 
expected returns: [[8.291117]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9.  9.  5. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  3.  0.] 
adversary cards in discard: [15.  0.  3.  2.  0.  0. 16.  3.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 47.361568450927734






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0. 10. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  3.  0.] 
cards in discard: [15.  0.  3.  2.  0.  0. 16.  3.  1.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9.  9.  5. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 25.] 
adversary cards in discard: [10.  3. 11. 10.  0.  3.  0. 10. 11. 29. 11.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11] -> size -> 22 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  3.  0.] 
cards in discard: [15.  0.  3.  2.  0.  0. 16.  3.  1.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 29. 29. 30.  8.  9.  9.  5. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 25.] 
adversary cards in discard: [10.  3. 11. 10.  0.  3.  0. 10. 11. 29. 11.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11] -> size -> 22 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 11. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[31.538723]
 [44.75523 ]
 [48.8887  ]
 [55.642296]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29. 25.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10. 11. 29. 11.  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9.  9.  5. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  6.  1.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.291116714477539



action possibilites: [-1] 
expected returns: [[16.42558]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29.  0.  3.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10. 11. 29. 11.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  8.  9.  5. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  6.  1.  3. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 53.81184768676758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.177953]
 [18.77855 ]
 [18.271404]
 [ 3.636437]
 [24.184067]
 [16.24696 ]
 [15.932956]
 [21.266857]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29.  0.  3.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10. 11. 29. 11.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 29. 29. 30.  8.  8.  9.  5. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  6.  1.  3. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.425579071044922



buy possibilites: [-1] 
expected returns: [[21.631527]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29.  0.  3.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10. 11. 29. 11.  0.  3.  0. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  8.  9.  4. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  6.  1.  3. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 24.184070587158203






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [10.  6.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  1.  3. 11.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  8.  9.  4. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25. 11.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  1.  3. 11.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 29. 29. 30.  8.  8.  9.  4. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25. 11.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  1.  3. 11.] 
cards in discard: [6. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 29. 29. 30.  8.  8.  9.  4. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25. 11.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 0. 25. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[31.700607]
 [68.10894 ]
 [51.465767]
 [60.403492]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  3. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  8.  9.  4. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  2. 10.] 
adversary cards in discard: [ 6.  0. 10.  6.  1.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0] -> size -> 20 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.631526947021484



action possibilites: [-1] 
expected returns: [[12.515561]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 29. 11. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  4. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  2. 10.] 
adversary cards in discard: [ 6.  0. 10.  6.  1.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.372676849365234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.640277]
 [ 5.296274]
 [14.857266]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 29. 11. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  4. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  2. 10.] 
adversary cards in discard: [ 6.  0. 10.  6.  1.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.5155611038208






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  2. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  2. 10.] 
cards in discard: [ 6.  0. 10.  6.  1.  3. 11.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  4. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10. 10.] 
adversary cards in discard: [25.  0. 11.  3. 29. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  2. 10.] 
cards in discard: [ 6.  0. 10.  6.  1.  3. 11.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  4. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10. 10.] 
adversary cards in discard: [25.  0. 11.  3. 29. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  2. 10.] 
cards in discard: [ 6.  0. 10.  6.  1.  3. 11.  6. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  3. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10. 10.] 
adversary cards in discard: [25.  0. 11.  3. 29. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[7.3032923]
 [4.2234325]
 [4.2234325]
 [4.2234325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10. 10.] 
cards in discard: [25.  0. 11.  3. 29. 11. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  3. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  0. 10.  6.  1.  3. 11.  6. 11.  0. 16.  0.  2. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11] -> size -> 22 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 14.857266426086426





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-0.2884884]
 [ 7.3824615]
 [-5.7930136]
 [ 5.574088 ]
 [ 7.392146 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10. 10.] 
cards in discard: [25.  0. 11.  3. 29. 11. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  3. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  0. 10.  6.  1.  3. 11.  6. 11.  0. 16.  0.  2. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11] -> size -> 22 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.944182395935059



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6.  0. 10.  6.  1.  3. 11.  6. 11.  0. 16.  0.  2. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  3. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11. 29.  3.  3.] 
adversary cards in discard: [25.  0. 11.  3. 29. 11. 11.  0.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6.  0. 10.  6.  1.  3. 11.  6. 11.  0. 16.  0.  2. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  3. 10.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11. 29.  3.  3.] 
adversary cards in discard: [25.  0. 11.  3. 29. 11. 11.  0.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6.  0. 10.  6.  1.  3. 11.  6. 11.  0. 16.  0.  2. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  3.  9.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11. 29.  3.  3.] 
adversary cards in discard: [25.  0. 11.  3. 29. 11. 11.  0.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [11. 11. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[15.975165]
 [15.76843 ]
 [15.76843 ]
 [13.731702]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29.  3.  3.] 
cards in discard: [25.  0. 11.  3. 29. 11. 11.  0.  0. 10. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  3.  9.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  6.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 7.392153739929199





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.7078905]
 [ 5.4224653]
 [15.395356 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 29.  3.  3.] 
cards in discard: [25.  0. 11.  3. 29. 11. 11.  0.  0. 10. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  3.  9.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  6.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.183799743652344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  3.  9.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [25.  0. 11.  3. 29. 11. 11.  0.  0. 10. 10. 10. 11. 11. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  3.  9.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [25.  0. 11.  3. 29. 11. 11.  0.  0. 10. 10. 10. 11. 11. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 15.  0.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  3.  8.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [25.  0. 11.  3. 29. 11. 11.  0.  0. 10. 10. 10. 11. 11. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[46.120533]
 [44.72642 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [25.  0. 11.  3. 29. 11. 11.  0.  0. 10. 10. 10. 11. 11. 29.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  3.  8.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [ 8.  3.  6.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 15.395352363586426





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[39.33392 ]
 [53.12895 ]
 [50.164597]
 [30.99282 ]
 [59.575535]
 [47.90593 ]
 [45.410385]
 [46.744923]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [25.  0. 11.  3. 29. 11. 11.  0.  0. 10. 10. 10. 11. 11. 29.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  3.  8.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [ 8.  3.  6.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 46.120540618896484



buy possibilites: [-1] 
expected returns: [[60.37646]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [25.  0. 11.  3. 29. 11. 11.  0.  0. 10. 10. 10. 11. 11. 29.  3.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  2.  8.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [ 8.  3.  6.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 59.5755500793457






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [ 8.  3.  6.  0. 15.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  2.  8.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11] -> size -> 24 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [ 8.  3.  6.  0. 15.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  2.  8.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11] -> size -> 24 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [ 8.  3.  6.  0. 15.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  2.  8.  9.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11] -> size -> 24 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [11.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[38.6428 ]
 [65.18112]
 [65.18112]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  2.  8.  9.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 11. 10.] 
adversary cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.376461029052734



action possibilites: [-1] 
expected returns: [[56.263348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  2.  8.  9.  8.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 11. 10.] 
adversary cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 60.177005767822266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[50.19345]
 [66.41084]
 [63.29571]
 [40.16638]
 [73.79176]
 [60.68758]
 [57.57243]
 [59.6854 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  2.  8.  9.  8.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 11. 10.] 
adversary cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.26334762573242



buy possibilites: [-1] 
expected returns: [[39.904156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  1.  8.  9.  8.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 11. 10.] 
adversary cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 73.7917709350586






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11. 10.] 
cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  1.  8.  9.  8.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10. 10.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11. 10.] 
cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 29. 29. 30.  8.  7.  9.  1.  8.  9.  8.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10. 10.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11. 10.] 
cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 28. 30.  8.  7.  9.  1.  8.  9.  8.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10. 10.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11] -> size -> 26 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[134.40363]
 [131.47734]
 [131.47734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10. 10.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 28. 30.  8.  7.  9.  1.  8.  9.  8.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  2. 16.] 
adversary cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.  3.  0.  0. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14  3] -> size -> 26 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.90415573120117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[121.46395]
 [145.02237]
 [103.18036]
 [140.371  ]
 [137.37552]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10. 10.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 29. 28. 30.  8.  7.  9.  1.  8.  9.  8.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  2. 16.] 
adversary cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.  3.  0.  0. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14  3] -> size -> 26 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 134.4036102294922



buy possibilites: [-1] 
expected returns: [[96.02181]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10. 10.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 27. 30.  8.  7.  9.  1.  8.  9.  8.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  2. 16.] 
adversary cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.  3.  0.  0. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14  3] -> size -> 26 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: 131 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 145.02236938476562






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 11.  2. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  2. 16.] 
cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.  3.  0.  0. 10. 11. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 27. 30.  8.  7.  9.  1.  8.  9.  8.  9. 10.  3. 10.  9.] 
adversary cards in hand: [25. 29.  3. 10. 10.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3] -> size -> 27 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  2. 16.] 
cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.  3.  0.  0. 10. 11. 10.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 26. 30.  8.  7.  9.  1.  8.  9.  8.  9. 10.  3. 10.  9.] 
adversary cards in hand: [25. 29.  3. 10. 10.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3] -> size -> 27 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  2. 16.] 
cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.  3.  0.  0. 10. 11. 10.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14  3  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 29. 26. 30.  8.  7.  9.  1.  8.  9.  8.  9. 10.  3. 10.  9.] 
adversary cards in hand: [25. 29.  3. 10. 10.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3] -> size -> 27 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  2. 16.] 
cards in discard: [ 8.  3.  6.  0. 15.  0. 14.  3.  0.  3.  1.  0.  3.  0.  0. 10. 11. 10.
  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14  3  3 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 29. 26. 30.  8.  7.  9.  1.  8.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25. 29.  3. 10. 10.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3] -> size -> 27 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [25. 29.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10. 10.] 
expected returns: [[107.31141 ]
 [126.93156 ]
 [121.433464]
 [ 99.86055 ]
 [ 99.86055 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  3. 10. 10.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 26. 30.  8.  7.  9.  1.  8.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [15. 10.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14  3  3 10] -> size -> 28 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.02181243896484



action possibilites: [-1] 
expected returns: [[122.84071]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10. 10.  0.  0.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 26. 30.  8.  6.  9.  1.  8.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [15. 10.  8.  6.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14  3  3 10  6] -> size -> 29 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 126.9315414428711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[112.18972]
 [131.4435 ]
 [ 95.44984]
 [128.09357]
 [123.42528]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 10. 10.  0.  0.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 29. 26. 30.  8.  6.  9.  1.  8.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [15. 10.  8.  6.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14  3  3 10  6] -> size -> 29 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.84071350097656



buy possibilites: [-1] 
expected returns: [[83.54037]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 10. 10.  0.  0.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  1.  8.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [15. 10.  8.  6.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14  3  3 10  6] -> size -> 29 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 131.44349670410156






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [15. 10.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  8.  6.  0.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8
 14  3  3 10  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  1.  8.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  3. 29. 11. 11.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.  3. 25. 29.  3. 10.
 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3] -> size -> 28 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  6.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  1.  8.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  3. 29. 11. 11.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.  3. 25. 29.  3. 10.
 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3] -> size -> 28 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  6.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  1.  8.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  3. 29. 11. 11.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.  3. 25. 29.  3. 10.
 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3] -> size -> 28 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  6.] 
cards in discard: [ 6. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  3. 29. 11. 11.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.  3. 25. 29.  3. 10.
 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3] -> size -> 28 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [11.  3. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11. 11.] 
expected returns: [[ 80.8722  ]
 [ 99.01006 ]
 [104.405716]
 [ 99.01006 ]
 [ 99.01006 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29. 11. 11.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.  3. 25. 29.  3. 10.
 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [14.  6. 16. 10.  3.] 
adversary cards in discard: [ 6. 11. 15. 10.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6 11] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.54036712646484



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[116.324005]
 [129.49304 ]
 [129.49304 ]
 [129.49304 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  3.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.  3. 25. 29.  3. 10.
 10.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [14.  6. 16. 10.  3.] 
adversary cards in discard: [ 6. 11. 15. 10.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6 11] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 91.20237731933594



action possibilites: [-1] 
expected returns: [[71.86974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.  3. 25. 29.  3. 10.
 10.  0.  0.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [14.  6. 16. 10.  3.] 
adversary cards in discard: [ 6. 11. 15. 10.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6 11] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 249 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 131.40040588378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[64.00938]
 [53.04044]
 [71.33514]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  3.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.  3.  3.  0.  0. 10. 10.  3. 25. 29.  3. 10.
 10.  0.  0.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [14.  6. 16. 10.  3.] 
adversary cards in discard: [ 6. 11. 15. 10.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6 11] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.86974334716797






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [14.  6. 16. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 16. 10.  3.] 
cards in discard: [ 6. 11. 15. 10.  8.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [11.  0. 11.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15] -> size -> 29 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 16.  3.  3.] 
cards in discard: [ 6. 11. 15. 10.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6 11] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [11.  0. 11.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15] -> size -> 29 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6. 16.  3.  3.] 
cards in discard: [ 6. 11. 15. 10.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6 11] -> size -> 29 
action values: 2 
buys: 1 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [11.  0. 11.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15] -> size -> 29 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [11.  0. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[ 95.55987]
 [120.69546]
 [120.69546]
 [120.69546]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  3. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6 11] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 71.33514404296875



action possibilites: [-1] 
expected returns: [[146.72757]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 11.] 
cards in discard: [15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6 11] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 130.93411254882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[116.4582 ]
 [ 96.48189]
 [143.11073]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 11.] 
cards in discard: [15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6 11] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 146.72756958007812






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 8.] 
cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10  6 15 16  6  0  6 11  8  8 14
  3  3 10  6 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  3. 10.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  3. 10.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  8.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  3. 10.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  7.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  3. 10.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [ 0. 10.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[138.24406]
 [130.67155]
 [130.67155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3. 10.] 
cards in discard: [15. 11.  0. 11.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  7.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [0. 3. 0. 2. 0.] 
adversary cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.  8.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8] -> size -> 29 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 143.1106719970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[121.89024]
 [133.60173]
 [114.91663]
 [130.59915]
 [137.3031 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3. 10.] 
cards in discard: [15. 11.  0. 11.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  7.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [0. 3. 0. 2. 0.] 
adversary cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.  8.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8] -> size -> 29 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 138.24404907226562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 2. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 2. 0.] 
cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.  8.  8.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  7.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 25. 10.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 2. 0.] 
cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.  8.  8.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  7.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 25. 10.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
adversary victory points: 6
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29.  0. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10.] 
expected returns: [[ 87.566216]
 [ 95.18464 ]
 [104.41274 ]
 [ 76.43468 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 25. 10.] 
cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  6.  9.  0.  7.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [11.  0.  0.  1. 11.] 
adversary cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.  8.  8.  0.  0.  3.  0.
  3.  0.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8] -> size -> 29 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 137.30311584472656



action possibilites: [-1] 
expected returns: [[88.50109]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 10.  0.  3.] 
cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  5.  9.  0.  7.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [11.  0.  0.  1. 11.] 
adversary cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.  8.  8.  0.  0.  3.  0.
  3.  0.  2.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6] -> size -> 30 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 104.41275787353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[62.73731 ]
 [78.11044 ]
 [77.08213 ]
 [55.788902]
 [73.15098 ]
 [72.122665]
 [81.90084 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 10.  0.  3.] 
cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 29. 25. 30.  8.  5.  9.  0.  7.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [11.  0.  0.  1. 11.] 
adversary cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.  8.  8.  0.  0.  3.  0.
  3.  0.  2.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6] -> size -> 30 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.50109100341797






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  1. 11.] 
cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.  8.  8.  0.  0.  3.  0.
  3.  0.  2.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 25. 30.  8.  5.  9.  0.  7.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  3. 11.  3. 11.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 11.] 
cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.  8.  8.  0.  0.  3.  0.
  3.  0.  2.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  7.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  3. 11.  3. 11.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 11.] 
cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.  8.  8.  0.  0.  3.  0.
  3.  0.  2.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  7.  9.  8.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  3. 11.  3. 11.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 11.] 
cards in discard: [ 6. 11. 15. 10.  8.  6. 10. 14.  6. 16.  3.  3.  8.  8.  0.  0.  3.  0.
  3.  0.  2.  0.  6.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  7.  9.  8.  9. 10.  2. 10.  6.] 
adversary cards in hand: [ 3.  3. 11.  3. 11.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 3.  3. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[70.22189]
 [81.99266]
 [81.99266]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  3. 11.] 
cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  7.  9.  8.  9. 10.  2. 10.  6.] 
adversary cards in hand: [ 1. 15. 16. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15] -> size -> 32 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 81.90082550048828



action possibilites: [-1] 
expected returns: [[70.869255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 11.] 
cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.
 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  7.  9.  8.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 1. 15. 16. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15] -> size -> 32 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 85.23331451416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[60.118706]
 [54.060207]
 [70.32957 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 11.] 
cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.
 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  7.  9.  8.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 1. 15. 16. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15] -> size -> 32 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.86925506591797






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 1. 15. 16. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 16. 10.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  7.  9.  8.  9. 10.  2. 10.  5.] 
adversary cards in hand: [15. 11.  0. 11. 10.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.
 15. 11.  3.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15] -> size -> 31 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1. 15. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 16.  3.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  7.  9.  8.  9. 10.  2. 10.  5.] 
adversary cards in hand: [15. 11.  0. 11. 10.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.
 15. 11.  3.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15] -> size -> 31 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 16.  3.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  7.  9.  8.  9. 10.  2. 10.  5.] 
adversary cards in hand: [15. 11.  0. 11. 10.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.
 15. 11.  3.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15] -> size -> 31 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 16.  3.  0.] 
cards in discard: [8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  5.] 
adversary cards in hand: [15. 11.  0. 11. 10.] 
adversary cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.
 15. 11.  3.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15] -> size -> 31 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [15. 11.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11. 10.] 
expected returns: [[115.045456]
 [128.6373  ]
 [138.40828 ]
 [138.40828 ]
 [115.12368 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0. 11. 10.] 
cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.
 15. 11.  3.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 3.  6.  0. 11.  8.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15  8] -> size -> 33 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 70.32953643798828



action possibilites: [-1] 
expected returns: [[38.243374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11. 10.] 
cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.
 15. 11.  3.  3.  3. 11. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  6.  0. 11.  8.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15  8] -> size -> 33 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 142.18748474121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.705643]
 [22.173843]
 [38.117794]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 11. 10.] 
cards in discard: [15. 11.  0. 11.  3. 11.  0. 10.  0.  3. 10. 25.  0. 29.  0. 10.  0.  3.
 15. 11.  3.  3.  3. 11. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  6.  0. 11.  8.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15  8] -> size -> 33 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.24337387084961






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 11.  8.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 15. 29. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15] -> size -> 32 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 11.  8.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 15. 29. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15] -> size -> 32 
adversary victory points: 6
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 15. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 10. 29.] 
expected returns: [[168.98396]
 [176.83214]
 [193.72661]
 [158.72548]
 [193.72661]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29. 10. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  4.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15  8] -> size -> 33 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 38.11778259277344



action possibilites: [-1. 15. 10. 29.] 
expected returns: [[114.93014]
 [130.40453]
 [111.5536 ]
 [150.78429]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10. 29.] 
cards in discard: [11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  4.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15  8] -> size -> 33 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 174.3184051513672



action possibilites: [-1. 10. 10.] 
expected returns: [[88.869156]
 [75.12216 ]
 [75.12216 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [11. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  4.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15  8] -> size -> 33 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 129.8755340576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[69.154686]
 [69.143364]
 [73.344635]
 [57.84084 ]
 [71.501114]
 [76.11787 ]
 [89.7381  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [11. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  4.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15  8] -> size -> 33 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 88.86915588378906






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3
  3 10  6 11  8  6  0 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  0. 15. 11. 10.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15] -> size -> 32 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3  3 10  6
 11  8  6  0 15  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  0. 15. 11. 10.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15] -> size -> 32 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3  3 10  6
 11  8  6  0 15  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  0. 15. 11. 10.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15] -> size -> 32 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3  3 10  6
 11  8  6  0 15  8  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 3.  0. 15. 11. 10.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15] -> size -> 32 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [ 3.  0. 15. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10.] 
expected returns: [[107.0537  ]
 [119.350395]
 [128.66028 ]
 [105.39121 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 11. 10.] 
cards in discard: [11. 15. 29. 29.  0. 10. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 2.  0. 11.  8. 14.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3  3 10  6
 11  8  6  0 15  8  0] -> size -> 31 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.7381362915039



action possibilites: [-1] 
expected returns: [[111.31197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 10.] 
cards in discard: [11. 15. 29. 29.  0. 10. 10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 2.  0. 11.  8. 14.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3  3 10  6
 11  8  6  0 15  8  0] -> size -> 31 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 259 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 133.9120635986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 96.48832]
 [ 83.4458 ]
 [110.80065]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15. 10.] 
cards in discard: [11. 15. 29. 29.  0. 10. 10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 2.  0. 11.  8. 14.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3  3 10  6
 11  8  6  0 15  8  0] -> size -> 31 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 111.31197357177734






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 2.  0. 11.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  0. 11.  8. 14.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  2 11 10 15 16  6  0  6 11  8  8 14  3  3 10  6
 11  8  6  0 15  8  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [11.  3.  0. 25.  0.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15] -> size -> 33 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [11.  3.  0. 25.  0.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15] -> size -> 33 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [11.  3.  0. 25.  0.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15] -> size -> 33 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  8. 10.  2. 10.  3.] 
adversary cards in hand: [11.  3.  0. 25.  0.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15] -> size -> 33 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [11.  3.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[141.15068]
 [150.04123]
 [158.06294]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 25.  0.] 
cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  5.  9.  0.  6.  9.  8.  8. 10.  2. 10.  3.] 
adversary cards in hand: [ 6.  6.  0. 10. 15.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3. 14.  8.  2.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14] -> size -> 30 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 110.80066680908203



action possibilites: [-1] 
expected returns: [[60.305943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0. 11.  0.] 
cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  3.] 
adversary cards in hand: [ 6.  6.  0. 10. 15.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3. 14.  8.  2.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6] -> size -> 31 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 158.06297302246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[47.278385]
 [68.863556]
 [65.24213 ]
 [41.358425]
 [60.24641 ]
 [59.435936]
 [72.760704]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0. 11.  0.] 
cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 29. 25. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  3.] 
adversary cards in hand: [ 6.  6.  0. 10. 15.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3. 14.  8.  2.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6] -> size -> 31 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.30594253540039






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 6.  6.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 10. 15.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3. 14.  8.  2.
  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  3.] 
adversary cards in hand: [15. 11.  3.  3. 11.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10. 25. 11.  3.  0.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15] -> size -> 33 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 15. 10.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3. 14.  8.  2.
  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  3.] 
adversary cards in hand: [15. 11.  3.  3. 11.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10. 25. 11.  3.  0.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15] -> size -> 33 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 15. 10.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3. 14.  8.  2.
  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 29. 25. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  3.] 
adversary cards in hand: [15. 11.  3.  3. 11.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10. 25. 11.  3.  0.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15] -> size -> 33 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [15. 11.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11.] 
expected returns: [[75.88292]
 [74.4946 ]
 [82.09113]
 [82.09113]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3.  3. 11.] 
cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10. 25. 11.  3.  0.  0.
 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  3.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3. 14.  8.  2.
  0.  6. 10.  6.  6.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6] -> size -> 31 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 72.76066589355469



action possibilites: [-1] 
expected returns: [[139.94884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3. 11.] 
cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10. 25. 11.  3.  0.  0.
 11.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3. 14.  8.  2.
  0.  6. 10.  6.  6.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6] -> size -> 31 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 289 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 84.29341888427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[122.422066]
 [114.533264]
 [140.37566 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3. 11.] 
cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10. 25. 11.  3.  0.  0.
 11.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3. 14.  8.  2.
  0.  6. 10.  6.  6.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6] -> size -> 31 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.94883728027344






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3. 14.  8.  2.
  0.  6. 10.  6.  6.  0. 15. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 25. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  2.] 
adversary cards in hand: [15.  3. 10.  0. 11.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10. 25. 11.  3.  0.  0.
 11.  0. 15. 11. 15.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3. 14.  8.  2.
  0.  6. 10.  6.  6.  0. 15. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 29. 25. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  2.] 
adversary cards in hand: [15.  3. 10.  0. 11.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10. 25. 11.  3.  0.  0.
 11.  0. 15. 11. 15.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [ 8. 10.  1. 15. 16.  3.  0.  3.  6.  0. 11.  8.  0.  8.  3. 14.  8.  2.
  0.  6. 10.  6.  6.  0. 15. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  2.] 
adversary cards in hand: [15.  3. 10.  0. 11.] 
adversary cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10. 25. 11.  3.  0.  0.
 11.  0. 15. 11. 15.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [15.  3. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11.] 
expected returns: [[40.377804]
 [44.61401 ]
 [38.100437]
 [49.38113 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 10.  0. 11.] 
cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10. 25. 11.  3.  0.  0.
 11.  0. 15. 11. 15.  3.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 8. 10.  1.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6  3] -> size -> 32 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 140.3756561279297



action possibilites: [-1] 
expected returns: [[67.89936]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 10.  0.] 
cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10. 25. 11.  3.  0.  0.
 11.  0. 15. 11. 15.  3.  3. 11. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [ 8. 10.  1.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6  3] -> size -> 32 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 259 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 51.814414978027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[55.625484]
 [48.925663]
 [65.54385 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 10.  0.] 
cards in discard: [11. 15. 29. 29.  0. 10. 10. 15. 11.  3.  0. 15. 10. 25. 11.  3.  0.  0.
 11.  0. 15. 11. 15.  3.  3. 11. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [ 8. 10.  1.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6  3] -> size -> 32 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.89936065673828






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  1.  0. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [15.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1.  8. 10. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  1  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8
  6  0 15  8  0 14  6  3] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [15.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8  6  0
 15  8  0 14  6  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [15.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8  6  0
 15  8  0 14  6  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [15.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [15.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[163.62679]
 [171.55397]
 [152.73268]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11
 10 11  3  3 15 15 15 15 15 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [3. 8. 0. 6. 6.] 
adversary cards in discard: [10.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8  6  0
 15  8  0 14  6  3] -> size -> 30 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 65.54385375976562



action possibilites: [-1] 
expected returns: [[152.0601]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [3. 8. 0. 6. 6.] 
adversary cards in discard: [10.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8  6  0
 15  8  0 14  6  3] -> size -> 30 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 171.5540313720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[138.06563]
 [156.70958]
 [154.18192]
 [125.98174]
 [150.86   ]
 [147.85658]
 [152.37837]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [3. 8. 0. 6. 6.] 
adversary cards in discard: [10.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8  6  0
 15  8  0 14  6  3] -> size -> 30 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 152.0601043701172



buy possibilites: [-1] 
expected returns: [[164.66844]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [3. 8. 0. 6. 6.] 
adversary cards in discard: [10.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8  6  0
 15  8  0 14  6  3] -> size -> 30 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 156.70960998535156






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 6. 6.] 
cards in discard: [10.  8.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  2 10 15 16  6  0  6 11  8  8  3  3 10  6 11  8  6  0
 15  8  0 14  6  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [11.  0.  3. 10. 15.] 
adversary cards in discard: [ 1. 15.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1] -> size -> 35 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10.  8.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  2 10 15 16  0 11  8  8  3  3 10  6 11  8  6  0 15  8  0 14
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [11.  0.  3. 10. 15.] 
adversary cards in discard: [ 1. 15.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1] -> size -> 35 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  8.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  2 10 15 16  0 11  8  8  3  3 10  6 11  8  6  0 15  8  0 14
  6  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [11.  0.  3. 10. 15.] 
adversary cards in discard: [ 1. 15.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1] -> size -> 35 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [11.  0.  3. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15.] 
expected returns: [[173.9959 ]
 [189.36072]
 [169.82793]
 [179.94603]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 10. 15.] 
cards in discard: [ 1. 15.  3.  3. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  1.] 
adversary cards in hand: [ 8.  8. 15.  3.  0.] 
adversary cards in discard: [10.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  2 10 15 16  0 11  8  8  3  3 10  6 11  8  6  0 15  8  0 14
  6  3] -> size -> 26 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 164.66844177246094



action possibilites: [-1] 
expected returns: [[91.98822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 15.] 
cards in discard: [ 1. 15.  3.  3. 10. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 8.  8. 15.  3.  0.] 
adversary cards in discard: [10.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  2 10 15 16  0 11  8  8  3  3 10  6 11  8  6  0 15  8  0 14
  6  3] -> size -> 26 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 192.58547973632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.99613 ]
 [68.440056]
 [92.29171 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 15.] 
cards in discard: [ 1. 15.  3.  3. 10. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 8.  8. 15.  3.  0.] 
adversary cards in discard: [10.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  2 10 15 16  0 11  8  8  3  3 10  6 11  8  6  0 15  8  0 14
  6  3] -> size -> 26 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.98822021484375






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 8.  8. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 15.  3.  0.] 
cards in discard: [10.  8.  0. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  2 10 15 16  0 11  8  8  3  3 10  6 11  8  6  0 15  8  0 14
  6  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15. 11. 15. 10.  0.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15] -> size -> 36 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  8.  0. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15. 11. 15. 10.  0.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15] -> size -> 36 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  8.  0. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15. 11. 15. 10.  0.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15] -> size -> 36 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  8.  0. 10.  8.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15. 11. 15. 10.  0.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15] -> size -> 36 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [15. 11. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 15. 10.] 
expected returns: [[131.43011]
 [134.2893 ]
 [145.33894]
 [134.2893 ]
 [121.08707]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15. 10.  0.] 
cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 6.  0.  6. 15.  2.] 
adversary cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0] -> size -> 24 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.2917251586914



action possibilites: [-1] 
expected returns: [[123.98179]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10.  0.] 
cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 6.  0.  6. 15.  2.] 
adversary cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0] -> size -> 24 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: 202 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 131.65621948242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[105.110146]
 [ 93.63471 ]
 [128.0755  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 10.  0.] 
cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 6.  0.  6. 15.  2.] 
adversary cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0] -> size -> 24 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 123.9817886352539






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  6. 15.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 15.  2.] 
cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 3. 11. 11. 29. 15.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1] -> size -> 37 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 2.] 
cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 27. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 3. 11. 11. 29. 15.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1] -> size -> 37 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 10. 22. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 2.] 
cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 27. 29. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 3. 11. 11. 29. 15.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1] -> size -> 37 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 2.] 
cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.  2.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 28. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 3. 11. 11. 29. 15.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1] -> size -> 37 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11. 11. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29. 15.] 
expected returns: [[129.01982]
 [130.95413]
 [130.95413]
 [125.34724]
 [125.10003]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11. 29. 15.] 
cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 28. 24. 30.  8.  4.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  0. 16.  3. 14.] 
adversary cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.  2. 15.  6.  6.  2.] 
adversary owned cards: [ 0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2] -> size -> 24 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.07553100585938



action possibilites: [-1] 
expected returns: [[134.22337]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29. 15.] 
cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  0. 16.  3. 14.] 
adversary cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.  2. 15.  6.  6.  2.] 
adversary owned cards: [ 0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2] -> size -> 24 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5    0    0  150    0    0   20    0    0    0    0  -30    0 -300
    0    0] 
sum of rewards: -165 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 122.49845123291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[116.9075 ]
 [104.77869]
 [136.01765]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 29. 15.] 
cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  0. 16.  3. 14.] 
adversary cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.  2. 15.  6.  6.  2.] 
adversary owned cards: [ 0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2] -> size -> 24 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.22337341308594






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3. 14.] 
cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.  2. 15.  6.  6.  2.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15.  0.  0.  0. 10.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.
 11.  3. 11. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6] -> size -> 38 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.] 
cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.  2. 15.  6.  6.  2.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15.  0.  0.  0. 10.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.
 11.  3. 11. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6] -> size -> 38 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.] 
cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.  2. 15.  6.  6.  2.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15.  0.  0.  0. 10.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.
 11.  3. 11. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6] -> size -> 38 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.] 
cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.  2. 15.  6.  6.  2.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15.  0.  0.  0. 10.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.
 11.  3. 11. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6] -> size -> 38 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [15.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[114.127556]
 [ 95.89617 ]
 [ 95.49205 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0. 10.] 
cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.
 11.  3. 11. 29. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 3.  0. 11.  3. 11.] 
adversary cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.  2. 15.  6.  6.  2.  0.  0. 16.  0.  3.
 14.] 
adversary owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0] -> size -> 25 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 136.0176239013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[ 90.993416]
 [101.57653 ]
 [103.41356 ]
 [ 88.46102 ]
 [ 99.09466 ]
 [100.788795]
 [114.74267 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0. 10.] 
cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.
 11.  3. 11. 29. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 3.  0. 11.  3. 11.] 
adversary cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.  2. 15.  6.  6.  2.  0.  0. 16.  0.  3.
 14.] 
adversary owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0] -> size -> 25 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 114.12755584716797



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3. 11.] 
cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.  2. 15.  6.  6.  2.  0.  0. 16.  0.  3.
 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [11. 10. 11.  0. 29.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.
 11.  3. 11. 29. 15. 15.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6] -> size -> 38 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.] 
cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.  2. 15.  6.  6.  2.  0.  0. 16.  0.  3.
 14.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [11. 10. 11.  0. 29.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.
 11.  3. 11. 29. 15. 15.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6] -> size -> 38 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.] 
cards in discard: [10.  8.  0. 10.  8.  0.  8.  0.  2. 15.  6.  6.  2.  0.  0. 16.  0.  3.
 14.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [11. 10. 11.  0. 29.] 
adversary cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.
 11.  3. 11. 29. 15. 15.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6] -> size -> 38 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [11. 10. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 29.] 
expected returns: [[73.702675]
 [87.46072 ]
 [68.838104]
 [87.46072 ]
 [88.27526 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0. 29.] 
cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.
 11.  3. 11. 29. 15. 15.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 1.  0.  3. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0  1] -> size -> 26 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 114.74272918701172



action possibilites: [-1. 11.] 
expected returns: [[111.19287 ]
 [127.401665]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.] 
cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.
 11.  3. 11. 29. 15. 15.  0.  0.  0. 10. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 1.  0.  3. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0  1] -> size -> 26 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 77.28690338134766



action possibilites: [-1] 
expected returns: [[123.225105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.
 11.  3. 11. 29. 15. 15.  0.  0.  0. 10. 11. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 1.  0.  3. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0  1] -> size -> 26 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 172 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 115.7358169555664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[101.8248 ]
 [121.87499]
 [ 87.5348 ]
 [117.31965]
 [123.22515]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 1. 15.  3.  3. 10. 15. 11.  0.  3. 10. 15.  1. 11. 15. 15. 10.  0.  6.
 11.  3. 11. 29. 15. 15.  0.  0.  0. 10. 11. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 1.  0.  3. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0  1] -> size -> 26 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 123.22510528564453






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  3. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 15.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15. 15.  3. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1] -> size -> 39 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 15.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 28. 24. 30.  8.  3.  9.  0.  6.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15. 15.  3. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1] -> size -> 39 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 15.  6.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0  1  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 28. 24. 30.  8.  3.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15. 15.  3. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1] -> size -> 39 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [15. 15.  3. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 11. 25.] 
expected returns: [[145.21054]
 [138.30804]
 [138.30804]
 [146.74434]
 [143.64229]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3. 11. 25.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 24. 30.  8.  3.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 8.  1.  0.  3. 15.  6.] 
adversary owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0  1  8] -> size -> 27 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 123.22510528564453



action possibilites: [-1] 
expected returns: [[206.4158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3. 25.] 
cards in discard: [6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 24. 30.  8.  2.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 8.  1.  0.  3. 15.  6.] 
adversary owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0  1  8] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  120    0    0   20    0    0    0    0  -50    0 -300
    0    0] 
sum of rewards: -215 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 134.79273986816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[173.61185]
 [147.20976]
 [204.14316]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  3. 25.] 
cards in discard: [6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 25. 28. 24. 30.  8.  2.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 8.  1.  0.  3. 15.  6.] 
adversary owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0  1  8] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 206.41580200195312






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 0.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  2 10 16  0 11  8  3  3 10  6 11  8  6  0 15  8  0 14  6  3  0  2  0
  0  1  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 24. 30.  8.  2.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [10. 10.  3.  0. 11.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6] -> size -> 40 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 24. 30.  8.  2.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [10. 10.  3.  0. 11.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6] -> size -> 40 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 28. 24. 30.  8.  2.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [10. 10.  3.  0. 11.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6] -> size -> 40 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [10. 10.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[86.35915]
 [80.90739]
 [80.90739]
 [98.47339]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0. 11.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 24. 30.  8.  2.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 3. 11. 10.  2.  2.] 
adversary cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 204.14315795898438



action possibilites: [-1] 
expected returns: [[137.53946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 28. 24. 30.  8.  2.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 3. 11. 10.  2.  2.] 
adversary cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 72 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 88.50196838378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[127.25994]
 [115.68766]
 [137.62271]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 28. 24. 30.  8.  2.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 3. 11. 10.  2.  2.] 
adversary cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 137.53945922851562






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3. 11. 10.  2.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  2.  2.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 28. 24. 30.  8.  2.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  3. 29. 15.  3.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  2.  2.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  3. 29. 15.  3.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 10. 22. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  2.  2.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 24. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  3. 29. 15.  3.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  2.  2.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 6 
card supply: [23. 24. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  3. 29. 15.  3.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3. 29. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[133.45168]
 [143.19652]
 [133.19896]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 15.  3.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 8. 14. 16. 10.  8.] 
adversary cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 137.6227264404297



action possibilites: [-1. 15.] 
expected returns: [[185.76308]
 [186.58334]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 24. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 8. 14. 16. 10.  8.] 
adversary cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 130.19296264648438



action possibilites: [-1] 
expected returns: [[248.7961]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 8. 14. 16. 10.  8.] 
adversary cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 186.58334350585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[221.20364]
 [201.38766]
 [248.71   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 8. 14. 16. 10.  8.] 
adversary cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 248.7960968017578






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 8. 14. 16. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 16. 10.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 16. 10.  8.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0 14  6  3  0  2  0  0  1  8
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [10.  3. 11.  0.  0.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0  6  3  0  2  0  0  1  8  6
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [10.  3. 11.  0.  0.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0  6  3  0  2  0  0  1  8  6
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 24. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [10.  3. 11.  0.  0.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0  6  3  0  2  0  0  1  8  6
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [10.  3. 11.  0.  0.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [10.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[150.91823]
 [146.41656]
 [173.43036]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  0.  0.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  0.  0.  6. 11.] 
adversary cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.  0.  0. 16.
  8. 10.  8.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0  6  3  0  2  0  0  1  8  6
  0  0  0] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 248.7100372314453



action possibilites: [-1] 
expected returns: [[171.8846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  0.  0.  6. 11.] 
adversary cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.  0.  0. 16.
  8. 10.  8.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0  6  3  0  2  0  0  1  8  6
  0  0  0] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: 92 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 158.27378845214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[159.28464]
 [176.23506]
 [147.17024]
 [172.0596 ]
 [180.34079]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 23. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  0.  0.  6. 11.] 
adversary cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.  0.  0. 16.
  8. 10.  8.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0  6  3  0  2  0  0  1  8  6
  0  0  0] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 171.8845977783203






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 11.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.  0.  0. 16.
  8. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0  6  3  0  2  0  0  1  8  6
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 3. 15. 10. 11. 15.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1] -> size -> 42 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6. 11.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.  0.  0. 16.
  8. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0  6  3  0  2  0  0  1  8  6
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 23. 28. 24. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 3. 15. 10. 11. 15.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1] -> size -> 42 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6. 11.] 
cards in discard: [ 8.  1.  0.  3. 15.  6.  8.  0.  6.  0. 11.  3. 10.  2.  2.  0.  0. 16.
  8. 10.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0  6  3  0  2  0  0  1  8  6
  0  0  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 28. 23. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 3. 15. 10. 11. 15.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1] -> size -> 42 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 3. 15. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11. 15.] 
expected returns: [[38.88011 ]
 [43.10322 ]
 [33.766647]
 [50.981556]
 [43.10322 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10. 11. 15.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 23. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0  6  3  0  2  0  0  1  8  6
  0  0  0  3] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 180.3407745361328



action possibilites: [-1] 
expected returns: [[114.84197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10. 15.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 28. 23. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0  6  3  0  2  0  0  1  8  6
  0  0  0  3] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -80   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 42.429447174072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 93.1056  ]
 [ 88.37204 ]
 [114.841965]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 10. 15.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 22. 28. 23. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0  6  3  0  2  0  0  1  8  6
  0  0  0  3] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.84197235107422






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [15.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6  0 15  8  0  6  3  0  2  0  0  1  8  6
  0  0  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 28. 23. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [29.  0.  0.  1. 11.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1] -> size -> 43 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0
  0  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 22. 28. 23. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [29.  0.  0.  1. 11.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1] -> size -> 43 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0
  0  0  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 22. 28. 23. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [29.  0.  0.  1. 11.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1] -> size -> 43 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0
  0  0  3  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 21. 28. 23. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [29.  0.  0.  1. 11.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1] -> size -> 43 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [29.  0.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 99.20486]
 [101.96116]
 [103.48675]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  1. 11.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 28. 23. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 2. 11.  8.  8.  6.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0
  0  0  3  1] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 114.84197235107422



action possibilites: [-1] 
expected returns: [[100.17194]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  1.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 28. 23. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 2. 11.  8.  8.  6.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0
  0  0  3  1] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -90   0   0  27   0] 
sum of rewards: 42 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 93.27003479003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. -1.] 
expected returns: [[ 76.527504]
 [116.75379 ]
 [106.41023 ]
 [ 60.19112 ]
 [ 91.99934 ]
 [ 99.143906]
 [139.88527 ]
 [ 78.54055 ]
 [ 93.06586 ]
 [100.17191 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  1.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 20. 28. 23. 30.  8.  1.  9.  0.  5.  9.  8.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 2. 11.  8.  8.  6.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0
  0  0  3  1] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.17194366455078



buy possibilites: [-1] 
expected returns: [[28.407948]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  1.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 28. 23. 30.  8.  1.  9.  0.  5.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 2. 11.  8.  8.  6.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.] 
adversary owned cards: [ 2 10 16 11  8  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0
  0  0  3  1] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[  -5    0    0   90    0    0   20    0    0    0    0 -100    0    0
  128    0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 139.88526916503906






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 2. 11.  8.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2. 11.  8.  8.  6.] 
cards in discard: [ 1. 15.  3.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 2 10 16 11  8  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0
  0  0  3  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 28. 23. 30.  8.  1.  9.  0.  5.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [11. 15. 15. 15. 10.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.  1. 29. 11. 29.  0.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29] -> size -> 45 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2. 11.  6.] 
cards in discard: [ 1. 15.  3.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0  0
  0  3  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 28. 23. 30.  8.  1.  9.  0.  5.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [11. 15. 15. 15. 10.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.  1. 29. 11. 29.  0.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29] -> size -> 45 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2. 11.  6.] 
cards in discard: [ 1. 15.  3.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0  0
  0  3  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 20. 28. 23. 30.  8.  1.  9.  0.  5.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [11. 15. 15. 15. 10.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.  1. 29. 11. 29.  0.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29] -> size -> 45 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2. 11.  6.] 
cards in discard: [ 1. 15.  3.  0.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0  0
  0  3  1  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 20. 28. 23. 30.  8.  1.  9.  0.  4.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [11. 15. 15. 15. 10.] 
adversary cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.  1. 29. 11. 29.  0.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29] -> size -> 45 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [11. 15. 15. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 15. 15. 10.] 
expected returns: [[138.21309]
 [157.43991]
 [140.81165]
 [140.81165]
 [140.81165]
 [129.22926]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 15. 15. 10.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.  1. 29. 11. 29.  0.  0.
  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 28. 23. 30.  8.  1.  9.  0.  4.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [10.  0.  8.  3.  1.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.] 
adversary owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0  0
  0  3  1  8] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.407947540283203



action possibilites: [-1] 
expected returns: [[140.16962]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 10.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.  1. 29. 11. 29.  0.  0.
  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 28. 23. 30.  8.  1.  9.  0.  4.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [10.  0.  8.  3.  1.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.] 
adversary owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0  0
  0  3  1  8] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[  -5    0    0   90    0    0   20    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: 22 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 138.64173889160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[117.79392]
 [102.34832]
 [140.16963]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 15. 10.] 
cards in discard: [ 6. 11. 15. 15.  3. 25.  1. 11. 10. 10.  3.  0.  0.  6. 29. 15.  3.  3.
  1. 11. 10.  3.  0.  0.  1. 11.  3. 15. 10. 15.  1. 29. 11. 29.  0.  0.
  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 19. 28. 23. 30.  8.  1.  9.  0.  4.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [10.  0.  8.  3.  1.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.] 
adversary owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0  0
  0  3  1  8] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 140.16961669921875






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [10.  0.  8.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  3.  1.] 
cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  0  6  3  0  2  0  0  1  8  6  0  0
  0  3  1  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 19. 28. 23. 30.  8.  1.  9.  0.  4.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15.  0.  1.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1] -> size -> 46 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.] 
cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  6  3  0  2  0  0  1  8  6  0  0  0
  3  1  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 28. 23. 30.  8.  1.  9.  0.  4.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15.  0.  1.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1] -> size -> 46 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.] 
cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  6  3  0  2  0  0  1  8  6  0  0  0
  3  1  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 19. 28. 23. 30.  8.  1.  9.  0.  4.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15.  0.  1.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1] -> size -> 46 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.] 
cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  6  3  0  2  0  0  1  8  6  0  0  0
  3  1  8  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 28. 22. 30.  8.  1.  9.  0.  4.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [15.  0.  1.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1] -> size -> 46 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [15.  0.  1.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[196.132  ]
 [208.6454 ]
 [224.66777]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  1. 11.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 19. 28. 22. 30.  8.  1.  9.  0.  4.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 6. 10.  0.  2.  6.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.  3.  8. 10.  3.  1.] 
adversary owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  6  3  0  2  0  0  1  8  6  0  0  0
  3  1  8  3] -> size -> 28 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 140.16961669921875



action possibilites: [-1] 
expected returns: [[237.81013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  1.] 
cards in discard: [1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 28. 22. 30.  8.  1.  9.  0.  4.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 6. 10.  0.  2.  6.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.  3.  8. 10.  3.  1.] 
adversary owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  6  3  0  2  0  0  1  8  6  0  0  0
  3  1  8  3] -> size -> 28 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[  -5    0    0   60    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: -18 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 206.21458435058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 10. 22. -1.] 
expected returns: [[210.76129]
 [239.66335]
 [235.84634]
 [198.88113]
 [194.69485]
 [222.62509]
 [230.01756]
 [271.06067]
 [258.05722]
 [213.34866]
 [234.80946]
 [226.2295 ]
 [205.96513]
 [236.78557]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.  1.] 
cards in discard: [1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 18. 28. 22. 30.  8.  1.  9.  0.  4.  9.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 6. 10.  0.  2.  6.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.  3.  8. 10.  3.  1.] 
adversary owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  6  3  0  2  0  0  1  8  6  0  0  0
  3  1  8  3] -> size -> 28 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 237.8101348876953



buy possibilites: [-1] 
expected returns: [[185.42973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.  1.] 
cards in discard: [ 1. 25.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1  1 25] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 28. 22. 30.  8.  1.  9.  0.  4.  8.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 6. 10.  0.  2.  6.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.  3.  8. 10.  3.  1.] 
adversary owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  6  3  0  2  0  0  1  8  6  0  0  0
  3  1  8  3] -> size -> 28 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[  -5    0    0   60    0    0   20    0    0    0    0 -130    0    0
  250    0] 
sum of rewards: 195 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 271.0606689453125






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 6. 10.  0.  2.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  2.  6.] 
cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.  3.  8. 10.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  6  3  0  2  0  0  1  8  6  0  0  0
  3  1  8  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 28. 22. 30.  8.  1.  9.  0.  4.  8.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  3.  1. 25. 15.] 
adversary cards in discard: [ 1. 25. 11. 15.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1  1 25] -> size -> 48 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  2.  6.] 
cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.  3.  8. 10.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  6  3  0  2  0  0  1  8  6  0  0  0
  3  1  8  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 18. 28. 22. 30.  8.  1.  9.  0.  4.  8.  7.  8. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  3.  1. 25. 15.] 
adversary cards in discard: [ 1. 25. 11. 15.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1  1 25] -> size -> 48 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  2.  6.] 
cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.  3.  8. 10.  3.  1. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  6  3  0  2  0  0  1  8  6  0  0  0
  3  1  8  3 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 18. 28. 22. 30.  8.  1.  9.  0.  4.  8.  7.  8. 10.  1. 10.  0.] 
adversary cards in hand: [ 0.  3.  1. 25. 15.] 
adversary cards in discard: [ 1. 25. 11. 15.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1  1 25] -> size -> 48 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3.  1. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
expected returns: [[273.02643]
 [296.5897 ]
 [282.32916]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 25. 15.] 
cards in discard: [ 1. 25. 11. 15.  0.  1.  1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1  1 25] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 28. 22. 30.  8.  1.  9.  0.  4.  8.  7.  8. 10.  1. 10.  0.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.  3.  8. 10.  3.  1. 10.  6. 10.
  0.  2.  6.] 
adversary owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  6  3  0  2  0  0  1  8  6  0  0  0
  3  1  8  3 10] -> size -> 29 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 185.4297332763672



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 1 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 0 
Witch: 2 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  3.  1. 15.  3. 11.] 
cards in discard: [ 1. 25. 11. 15.  0.  1.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10 11 10  3 10 11 11 11 10
 11  3  3 15 15 15 15 15 15 15  1 15  1  6  1  6  1  1  1  1 29  1  1 25] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 28. 22. 30.  8.  0.  9.  0.  4.  8.  7.  8. 10.  1. 10.  0.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.  8.  8.  2. 11.  6.  3.  8. 10.  3.  1. 10.  6. 10.
  0.  2.  6.  6.] 
adversary owned cards: [ 2 10 16 11  3  3 10 11  8  6 15  8  6  3  0  2  0  0  1  8  6  0  0  0
  3  1  8  3 10  6] -> size -> 30 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[     -5 3000000       0      60       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000075 

action type: take_action - action 25.0
Learning step: 299977.84375
desired expected reward: 300274.4375



