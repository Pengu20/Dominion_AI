 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[302.8407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -1 -150    0    0    0    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -647 

action type: buy - action 11.0
Learning step: -34.07801818847656
desired expected reward: 0.4823646545410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[282.2803 ]
 [290.20578]
 [288.66446]
 [273.73264]
 [287.88574]
 [298.3822 ]
 [291.61038]
 [299.2931 ]
 [283.4245 ]
 [290.05853]
 [291.74817]
 [305.94998]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.834917068481445
desired expected reward: 297.2179870605469



buy possibilites: [-1] 
expected returns: [[268.52673]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 16.0
Learning step: -6.852433681488037
desired expected reward: 281.03326416015625






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[300.59872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.706636905670166
desired expected reward: 261.8200988769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[286.29156]
 [293.33572]
 [292.0522 ]
 [279.14325]
 [300.90402]
 [294.60626]
 [293.31232]
 [307.9153 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.61854076385498
desired expected reward: 294.479248046875



buy possibilites: [-1] 
expected returns: [[316.59393]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -7.6069464683532715
desired expected reward: 286.999267578125






Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [16.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[267.37573]
 [254.72816]
 [257.30414]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.025818824768066
desired expected reward: 306.568115234375



action possibilites: [-1] 
expected returns: [[373.1341]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: trash_cards_n_from_hand - action 1
Learning step: -5.5618133544921875
desired expected reward: 291.58477783203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[348.06476]
 [355.71066]
 [354.4212 ]
 [340.20624]
 [363.8666 ]
 [357.05273]
 [355.75082]
 [371.50388]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -9.714041709899902
desired expected reward: 363.4200439453125



buy possibilites: [-1] 
expected returns: [[349.6694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 36 

action type: buy - action 1.0
Learning step: -8.11797046661377
desired expected reward: 347.5926513671875






Player: 1 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[338.6034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.961030006408691
desired expected reward: 339.7083740234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[326.37433]
 [332.73892]
 [331.41327]
 [319.47855]
 [339.19446]
 [333.88516]
 [332.55267]
 [345.3143 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.525147438049316
desired expected reward: 329.25



buy possibilites: [-1] 
expected returns: [[342.56018]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1. 8. 0. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -8.129339218139648
desired expected reward: 324.6095275878906






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[336.7229 ]
 [323.73627]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.77060604095459
desired expected reward: 332.7895812988281



action possibilites: [-1] 
expected returns: [[292.78128]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 1 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 2
Learning step: -8.18034839630127
desired expected reward: 305.4473876953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[268.41428]
 [273.46957]
 [261.63986]
 [275.82596]
 [287.58173]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 1 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -8.104681968688965
desired expected reward: 284.6766052246094






Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 1] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 1] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 1] -> size -> 11 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[321.16397]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 8. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -7.759710788726807
desired expected reward: 279.822021484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[294.89017]
 [301.63403]
 [293.12494]
 [300.0758 ]
 [289.96436]
 [287.82977]
 [299.53696]
 [308.78644]
 [302.91415]
 [315.88278]
 [309.57166]
 [295.57553]
 [299.3492 ]
 [301.344  ]
 [292.41275]
 [302.71463]
 [315.73776]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 27. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 8. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -10.003578186035156
desired expected reward: 313.0798034667969



buy possibilites: [-1] 
expected returns: [[336.84424]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 1 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 27. 30. 29. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 8. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 3.0
Learning step: -7.424794673919678
desired expected reward: 292.6510009765625






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1. 8. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 1 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1. 8. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 29. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 1 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 1.  8.  0.  0.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 1 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [8. 0. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[290.374  ]
 [275.94733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 1. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 1 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.50208568572998
desired expected reward: 326.3421630859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[265.73785]
 [271.8815 ]
 [270.81915]
 [259.1748 ]
 [279.6648 ]
 [272.9925 ]
 [271.89227]
 [287.3215 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 1. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 1 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 29. 30.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.580704689025879
desired expected reward: 284.3254699707031



buy possibilites: [-1] 
expected returns: [[280.97684]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 1. 3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 1 3 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8. 10.  9.  9.  7. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -7.327649116516113
desired expected reward: 265.6649169921875






Player: 1 
cards in hand: [ 0.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10.  9.  9.  7. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [8. 8. 0. 3. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 1 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8. 10.  9.  9.  7. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [8. 8. 0. 3. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 1 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 29. 30.  8. 10.  9.  9.  7. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [8. 8. 0. 3. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 1 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [8. 8. 0. 3. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 1 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[289.7044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [8. 8. 0. 3. 1. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 1 3 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  1.  3.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.647431373596191
desired expected reward: 273.32940673828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[275.08954]
 [281.55594]
 [273.52237]
 [280.36768]
 [270.19266]
 [268.13742]
 [279.6724 ]
 [288.34827]
 [282.70673]
 [294.4983 ]
 [288.99902]
 [276.00366]
 [279.83023]
 [281.50287]
 [272.98486]
 [282.84906]
 [294.55826]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [8. 8. 0. 3. 1. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 1 3 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 27. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  1.  3.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.200709342956543
desired expected reward: 280.7508850097656



buy possibilites: [-1] 
expected returns: [[287.4906]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [8. 8. 0. 3. 1. 3. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 1 3 8 1] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  1.  3.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 1.0
Learning step: -7.484260082244873
desired expected reward: 274.07171630859375






Player: 1 
cards in hand: [11.  1.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  0.  3.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 1. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 1 3 8 1] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  0.  3.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 1. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 1 3 8 1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [8. 1. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[262.6098]
 [248.2774]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 1 3 8 1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.681925773620605
desired expected reward: 278.8086853027344



action possibilites: [-1] 
expected returns: [[279.7519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 3 8 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: trash_cards_n_from_hand - action 9
Learning step: -5.588353633880615
desired expected reward: 250.06707763671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[253.08017]
 [244.85553]
 [277.30542]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 3 8 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -7.229114532470703
desired expected reward: 272.52276611328125






Player: 1 
cards in hand: [0. 1. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1 11 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 8 3 8 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 8 3 8 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 8 3 8 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[303.71448]
 [292.49188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 3 8 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  0.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.241903781890869
desired expected reward: 270.0635070800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[277.78946]
 [284.1303 ]
 [282.92856]
 [270.9729 ]
 [290.73727]
 [285.25107]
 [284.0345 ]
 [296.80194]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 3 8 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  0.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.874836921691895
desired expected reward: 295.0531005859375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.  0.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 3 8 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 11.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 3 8 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 11.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 3 8 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 11.] 
cards in discard: [ 8.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 3 8 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[291.81107]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 3 8 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.962533473968506
desired expected reward: 281.41961669921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[277.76532]
 [283.8933 ]
 [282.5841 ]
 [273.0548 ]
 [271.13516]
 [282.10806]
 [289.97476]
 [284.992  ]
 [296.07785]
 [290.65063]
 [278.5143 ]
 [281.9507 ]
 [283.66858]
 [275.62534]
 [284.8205 ]
 [295.8708 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 3 8 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.377291679382324
desired expected reward: 285.2481994628906



buy possibilites: [-1] 
expected returns: [[234.3161]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  3  8  1 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 48 

action type: buy - action 25.0
Learning step: -7.131782531738281
desired expected reward: 288.94610595703125






Player: 1 
cards in hand: [ 0. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [25.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  3  8  1 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  9.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [25.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  3  8  1 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3.  0.  0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  8.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [25.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  3  8  1 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[274.15164]
 [258.02615]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [25.  0.  1.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  3  8  1 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  8.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10. 29. 11.  0.] 
adversary cards in discard: [11.  0. 25.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -5.830827236175537
desired expected reward: 228.4852752685547



action possibilites: [-1] 
expected returns: [[215.94624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [25.  0.  1.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  3  8  1 25] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  8.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10. 29. 11.  0.] 
adversary cards in discard: [11.  0. 25.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: trash_cards_n_from_hand - action 4
Learning step: -6.391415119171143
desired expected reward: 236.61268615722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[208.91362]
 [204.1767 ]
 [220.49661]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [25.  0.  1.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  3  8  1 25] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10.  9.  8.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10. 29. 11.  0.] 
adversary cards in discard: [11.  0. 25.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -5.123663425445557
desired expected reward: 210.8225860595703



buy possibilites: [-1] 
expected returns: [[295.55722]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [25.  0.  1.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  3  8  1 25  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  9.  8.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10. 29. 11.  0.] 
adversary cards in discard: [11.  0. 25.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   3   0   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action 0.0
Learning step: -4.395644664764404
desired expected reward: 204.5179901123047






Player: 1 
cards in hand: [ 3. 10. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29. 11.  0.] 
cards in discard: [11.  0. 25.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  9.  8.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  1.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  3  8  1 25  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  0.  3.] 
cards in discard: [11.  0. 25.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 29. 30.  8. 10.  9.  8.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  1.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  3  8  1 25  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.] 
cards in discard: [11.  0. 25.  3.  0.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  1.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  3  8  1 25  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.] 
cards in discard: [11.  0. 25.  3.  0.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  1.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  3  8  1 25  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.] 
cards in discard: [11.  0. 25.  3.  0.  0. 16.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  6.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  1.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  3  8  1 25  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  1.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[253.41983]
 [253.18967]
 [239.87659]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  1.  0.  8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  3  8  1 25  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  6.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.254251480102539
desired expected reward: 286.302978515625



action possibilites: [-1] 
expected returns: [[277.42023]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 8 3 8 1 0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  6.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 10
Learning step: -5.5325212478637695
desired expected reward: 236.95700073242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[250.41925]
 [255.86371]
 [243.5183 ]
 [258.05737]
 [270.86682]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 8 3 8 1 0] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  6.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -7.731390476226807
desired expected reward: 269.6888427734375



buy possibilites: [-1] 
expected returns: [[289.3836]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 8 3 8 1 0 8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 15 

action type: buy - action 8.0
Learning step: -5.641737461090088
desired expected reward: 252.41563415527344






Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [8. 8. 1.] 
adversary owned cards: [0 0 3 8 3 8 1 0 8] -> size -> 9 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [8. 8. 1.] 
adversary owned cards: [0 0 3 8 3 8 1 0 8] -> size -> 9 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16  8 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [8. 8. 1.] 
adversary owned cards: [0 0 3 8 3 8 1 0 8] -> size -> 9 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[307.3078 ]
 [291.98776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [8. 8. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 8 3 8 1 0 8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10. 11. 16.  3.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16  8 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.369670867919922
desired expected reward: 281.0139465332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[285.08762]
 [292.74118]
 [291.5356 ]
 [277.32968]
 [301.52304]
 [294.07706]
 [292.8412 ]
 [309.799  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [8. 8. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 8 3 8 1 0 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10. 11. 16.  3.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16  8 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.365229606628418
desired expected reward: 297.62200927734375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 10. 11. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 16.  3.] 
cards in discard: [29.  0.  8.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16  8 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 8 3 8 1 0 8] -> size -> 9 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 11. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 16.  3.  8.] 
cards in discard: [29.  0.  8.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 11 25 10 11 16  8 29] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 8 3 8 1 0 8] -> size -> 9 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.] 
cards in discard: [29.  0.  8.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 25 10 11 16  8 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 8 3 8 1 0 8] -> size -> 9 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29.  0.  8.  0.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 8 3 8 1 0 8] -> size -> 9 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  0.  8.  0.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 8 3 8 1 0 8] -> size -> 9 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [8. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[278.19592]
 [261.6374 ]
 [261.6374 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 8 3 8 1 0 8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0. 29.  3.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0. 10. 10.  8. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -9.629829406738281
desired expected reward: 300.169189453125



action possibilites: [-1] 
expected returns: [[282.7183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 8 1 0 8] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0. 29.  3.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0. 10. 10.  8. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: trash_cards_n_from_hand - action 6
Learning step: -4.629708290100098
desired expected reward: 232.18768310546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[256.22134]
 [249.03194]
 [277.42453]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 8 1 0 8] -> size -> 7 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0. 29.  3.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0. 10. 10.  8. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -7.377177715301514
desired expected reward: 275.34112548828125






Player: 1 
cards in hand: [25.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29.  3.] 
cards in discard: [29.  0.  8.  0.  0.  0. 10. 10.  8. 16.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 1 0 8] -> size -> 7 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3. 11.  0.] 
cards in discard: [29.  0.  8.  0.  0.  0. 10. 10.  8. 16.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  9.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 3 3 8 1 0 8 6] -> size -> 8 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3. 11.  0.] 
cards in discard: [29.  0.  8.  0.  0.  0. 10. 10.  8. 16.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 29. 30.  8.  9.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 3 3 8 1 0 8 6] -> size -> 8 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[312.1749 ]
 [294.61783]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 1. 0.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 1 0 8 6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  9.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -10    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -314 

action type: buy - action -1.0
Learning step: -22.722326278686523
desired expected reward: 254.70220947265625



action possibilites: [-1] 
expected returns: [[279.97415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 8 0 8 6] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  9.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 5
Learning step: -9.913866996765137
desired expected reward: 279.3518371582031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[256.54263]
 [260.9646 ]
 [250.76064]
 [263.08456]
 [273.5772 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 8 0 8 6] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 29. 30.  8.  9.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -9.847084045410156
desired expected reward: 270.1270751953125



buy possibilites: [-1] 
expected returns: [[254.34244]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 8 0 8 6 3] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  9.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0 -30   0   0   0   8   0] 
sum of rewards: -16 

action type: buy - action 3.0
Learning step: -8.125526428222656
desired expected reward: 252.839111328125






Player: 1 
cards in hand: [16.  0.  0. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 25.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  9.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 25.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 28. 30.  8.  9.  8.  8.  5.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 25.  8.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  9.  8.  8.  4.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[272.51935]
 [262.26355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 8 0 8 6 3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  9.  8.  8.  4.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [ 8. 16.  0.  0. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -8.914156913757324
desired expected reward: 245.42828369140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[249.4903 ]
 [243.14008]
 [266.8154 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 8 0 8 6 3] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 26. 30. 28. 30.  8.  9.  8.  8.  4.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [ 8. 16.  0.  0. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -10.052774429321289
desired expected reward: 261.5586853027344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [ 8. 16.  0.  0. 25.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  9.  8.  8.  4.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8. 16.  0.  0. 25.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  9.  8.  8.  4.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8. 16.  0.  0. 25.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 27. 30.  8.  9.  8.  8.  4.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8. 16.  0.  0. 25.  8.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[251.2561 ]
 [240.21283]
 [240.21283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 8 0 8 6 3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10. 29. 10.  0.] 
adversary cards in discard: [ 8. 16.  0.  0. 25.  8.  3.  8. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -10.580645561218262
desired expected reward: 256.2347412109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[224.77782]
 [229.53964]
 [218.59412]
 [231.71326]
 [242.53697]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 8 0 8 6 3] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10. 29. 10.  0.] 
adversary cards in discard: [ 8. 16.  0.  0. 25.  8.  3.  8. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -9.97083568572998
desired expected reward: 239.30323791503906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 10. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 29. 10.  0.] 
cards in discard: [ 8. 16.  0.  0. 25.  8.  3.  8. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 29. 10.  0.] 
cards in discard: [ 8. 16.  0.  0. 25.  8.  3.  8. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 29. 10.  0.] 
cards in discard: [ 8. 16.  0.  0. 25.  8.  3.  8. 11.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[261.30515]
 [249.9881 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 8 0 8 6 3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -9.109453201293945
desired expected reward: 233.42750549316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[236.05544]
 [240.43065]
 [230.23674]
 [242.62492]
 [254.71289]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 8 0 8 6 3] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -10.221453666687012
desired expected reward: 249.22312927246094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [23.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3] -> size -> 7 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[286.41547]
 [276.11688]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 8 0 8 6 3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10.  9.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  3.] 
adversary cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23] -> size -> 23 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -9.200573921203613
desired expected reward: 245.51234436035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[258.40338]
 [262.42108]
 [252.76906]
 [264.52817]
 [273.55698]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 8 0 8 6 3] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  9.  8.  8.  3.  8.  8. 10.  9.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  3.] 
adversary cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23] -> size -> 23 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -10.85819149017334
desired expected reward: 270.8814697265625



buy possibilites: [-1] 
expected returns: [[244.3022]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 8.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 8 0 8 6 3 6] -> size -> 8 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  8.  8.  8.  3.  8.  8. 10.  9.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  3.] 
adversary cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.  -30.    0.
    0. -300.    0.    0.] 
sum of rewards: -365.0 

action type: buy - action 6.0
Learning step: -24.604368209838867
desired expected reward: 212.41897583007812






Player: 1 
cards in hand: [16.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  3.] 
cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  8.  8.  8.  3.  8.  8. 10.  9.  8. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3 6] -> size -> 8 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  3.] 
cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 27. 30.  8.  8.  8.  8.  3.  8.  8. 10.  9.  8. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3 6] -> size -> 8 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  3.] 
cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8.  8.  8.  8.  2.  8.  8. 10.  9.  8. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 8 0 8 6 3 6] -> size -> 8 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [0. 8. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[256.92014]
 [243.76465]
 [243.76465]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 8 0 8 6 3 6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  8.  8.  8.  2.  8.  8. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 10. 11.  8.  0.] 
adversary cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23  8] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -9.870152473449707
desired expected reward: 234.4320526123047



action possibilites: [-1] 
expected returns: [[257.22018]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 3 6] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  8.  8.  8.  2.  8.  8. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 10. 11.  8.  0.] 
adversary cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23  8] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -125 

action type: trash_cards_n_from_hand - action 14
Learning step: -12.258859634399414
desired expected reward: 223.66738891601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[234.60172]
 [228.7385 ]
 [251.96031]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 3 6] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  8.  8.  8.  2.  8.  8. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 10. 11.  8.  0.] 
adversary cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23  8] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -125 

action type: take_action - action -1
Learning step: -13.714627265930176
desired expected reward: 243.50555419921875



buy possibilites: [-1] 
expected returns: [[231.61375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 3 6 6] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7.  8.  8.  2.  8.  8. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 10. 11.  8.  0.] 
adversary cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23  8] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -40    0    0   20    0    0    0  -60    0    0 -300
    0    0] 
sum of rewards: -386 

action type: buy - action 6.0
Learning step: -25.525615692138672
desired expected reward: 203.21287536621094






Player: 1 
cards in hand: [ 8. 10. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11.  8.  0.] 
cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7.  8.  8.  2.  8.  8. 10.  9.  8. 10. 10.] 
adversary cards in hand: [6. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 3 6 6] -> size -> 5 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  0.] 
cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23  8
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 3 6 6] -> size -> 5 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.  0.] 
cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23  8
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8.  7.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 3 6 6] -> size -> 5 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [6. 8. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[242.14117]
 [230.91245]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 3 6 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  8. 25.] 
adversary cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3. 14. 11.  8. 10.
  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23  8
 14] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -11.600973129272461
desired expected reward: 220.01278686523438



action possibilites: [-1] 
expected returns: [[223.2303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  8. 25.] 
adversary cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3. 14. 11.  8. 10.
  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23  8
 14] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -116 

action type: trash_cards_n_from_hand - action 10
Learning step: -12.514561653137207
desired expected reward: 222.23031616210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[196.97296]
 [192.55798]
 [210.44946]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  8. 25.] 
adversary cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3. 14. 11.  8. 10.
  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23  8
 14] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -116 

action type: take_action - action -1
Learning step: -12.437214851379395
desired expected reward: 210.7930908203125



buy possibilites: [-1] 
expected returns: [[257.1751]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  8. 25.] 
adversary cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3. 14. 11.  8. 10.
  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23  8
 14] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -40    0    0   20   50    0    0  -90    0  -50 -300
    0    0] 
sum of rewards: -416 

action type: buy - action 6.0
Learning step: -24.641460418701172
desired expected reward: 167.91651916503906






Player: 1 
cards in hand: [ 8. 10.  0.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  8. 25.] 
cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3. 14. 11.  8. 10.
  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  8 25 10 11 16  8 29 10  8  3  8  0 23  8
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25.] 
cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3. 14. 11.  8. 10.
  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25.] 
cards in discard: [23. 29. 29.  0.  0.  3.  3.  0.  8. 16.  0.  0.  0.  3. 14. 11.  8. 10.
  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[269.89136]
 [260.31915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -136 

action type: buy - action -1
Learning step: -13.643216133117676
desired expected reward: 243.53189086914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[252.5026 ]
 [246.82098]
 [268.32098]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -136 

action type: take_action - action -1.0
Learning step: -14.589320182800293
desired expected reward: 256.92547607421875



buy possibilites: [-1] 
expected returns: [[223.54083]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0 -30   0   0 -60   0 -50   0   0   0] 
sum of rewards: -186 

action type: buy - action 0.0
Learning step: -16.89546012878418
desired expected reward: 235.60711669921875






Player: 1 
cards in hand: [ 3.  0.  8. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 14.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[222.0716 ]
 [213.84181]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 29. 16. 23.  8.] 
adversary cards in discard: [ 8.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 23 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -156 

action type: buy - action -1
Learning step: -14.083877563476562
desired expected reward: 209.4569549560547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[201.47528]
 [196.52585]
 [214.84793]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 29. 16. 23.  8.] 
adversary cards in discard: [ 8.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 23 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -156 

action type: take_action - action -1.0
Learning step: -14.237025260925293
desired expected reward: 206.92489624023438



buy possibilites: [-1] 
expected returns: [[202.01427]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 29. 16. 23.  8.] 
adversary cards in discard: [ 8.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 23 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -40.   0.   0.   0. -30.   0.   0. -30.   0. -50.   0.
   0.   0.] 
sum of rewards: -156.0 

action type: buy - action 0.0
Learning step: -11.987749099731445
desired expected reward: 162.67364501953125






Player: 1 
cards in hand: [ 8. 29. 16. 23.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 16. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 16. 23.  8.] 
cards in discard: [ 8.  3. 14.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0] -> size -> 4 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1.  8. 29. 16.  8. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 16.  8. 11.] 
cards in discard: [ 8.  3. 14.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 23 
action values: 1 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0] -> size -> 4 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1.  8. 16.  8. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  8. 11.  3.] 
cards in discard: [ 8.  3. 14.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14] -> size -> 23 
action values: 1 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 27. 30.  8.  6.  8.  8.  2.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0] -> size -> 4 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11.] 
cards in discard: [ 8.  3. 14.  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23. 29. 16.] 
owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 27. 30.  8.  6.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0] -> size -> 4 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 11.] 
cards in discard: [ 8.  3. 14.  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23. 29. 16.] 
owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8] -> size -> 23 
action values: 0 
buys: 2 
player value: 2 
card supply: [26. 26. 30. 27. 30.  8.  6.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0] -> size -> 4 
adversary victory points: -1
player victory points: 2 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 11.] 
cards in discard: [ 8.  3. 14.  8.  8.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23. 29. 16.] 
owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  6.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0] -> size -> 4 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 11.] 
cards in discard: [ 8.  3. 14.  8.  8.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23. 29. 16.] 
owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  6.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0] -> size -> 4 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[173.44872]
 [165.86954]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  6.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0. 10.] 
adversary cards in discard: [ 8.  3. 14.  8.  8.  3.  0. 23. 29. 16.  8.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -126 

action type: buy - action -1
Learning step: -12.58541488647461
desired expected reward: 189.42884826660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[149.34943]
 [152.766  ]
 [144.48341]
 [154.71416]
 [162.33235]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 26. 30.  8.  6.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0. 10.] 
adversary cards in discard: [ 8.  3. 14.  8.  8.  3.  0. 23. 29. 16.  8.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -126 

action type: take_action - action -1.0
Learning step: -11.490187644958496
desired expected reward: 161.49072265625



buy possibilites: [-1] 
expected returns: [[184.97218]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 0 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  6.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0. 10.] 
adversary cards in discard: [ 8.  3. 14.  8.  8.  3.  0. 23. 29. 16.  8.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0 -30   0   0   0   8   0] 
sum of rewards: -57 

action type: buy - action 3.0
Learning step: -6.326426982879639
desired expected reward: 146.43959045410156






Player: 1 
cards in hand: [ 0. 29. 25.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  0. 10.] 
cards in discard: [ 8.  3. 14.  8.  8.  3.  0. 23. 29. 16.  8.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  6.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 10.  0.  3.] 
cards in discard: [ 8.  3. 14.  8.  8.  3.  0. 23. 29. 16.  8.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 6. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 0 3 6] -> size -> 6 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 10.  0.  3.] 
cards in discard: [ 8.  3. 14.  8.  8.  3.  0. 23. 29. 16.  8.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 6. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 0 3 6] -> size -> 6 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[194.5511 ]
 [185.24641]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 3.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 0 3 6] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [ 8.  3. 14.  8.  8.  3.  0. 23. 29. 16.  8.  8. 11. 25.  0. 29.  0. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -40    0    0    0    0    0    0  -30    0    0 -300
    0    0] 
sum of rewards: -376 

action type: buy - action -1
Learning step: -23.792373657226562
desired expected reward: 161.1798095703125



action possibilites: [-1] 
expected returns: [[132.75937]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 3 6] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [ 8.  3. 14.  8.  8.  3.  0. 23. 29. 16.  8.  8. 11. 25.  0. 29.  0. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -116 

action type: trash_cards_n_from_hand - action 6
Learning step: -11.445474624633789
desired expected reward: 161.20571899414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[113.50353]
 [108.28514]
 [127.53673]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 3 6] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [ 8.  3. 14.  8.  8.  3.  0. 23. 29. 16.  8.  8. 11. 25.  0. 29.  0. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -116 

action type: take_action - action -1
Learning step: -9.792086601257324
desired expected reward: 122.96728515625



buy possibilites: [-1] 
expected returns: [[174.98964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 3 6 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [ 8.  3. 14.  8.  8.  3.  0. 23. 29. 16.  8.  8. 11. 25.  0. 29.  0. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20 -30   0   0 -60   0   0   0   0   0] 
sum of rewards: -116 

action type: buy - action 0.0
Learning step: -7.537909030914307
desired expected reward: 105.96561431884766






Player: 1 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 8.  3. 14.  8.  8.  3.  0. 23. 29. 16.  8.  8. 11. 25.  0. 29.  0. 10.
  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 8. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0] -> size -> 5 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 8.  3. 14.  8.  8.  3.  0. 23. 29. 16.  8.  8. 11. 25.  0. 29.  0. 10.
  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 8. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0] -> size -> 5 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 8.  3. 14.  8.  8.  3.  0. 23. 29. 16.  8.  8. 11. 25.  0. 29.  0. 10.
  0.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 8. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0] -> size -> 5 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [0. 8. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[186.76445]
 [177.10564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0 15] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -9.919926643371582
desired expected reward: 165.06971740722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[175.34554]
 [169.8124 ]
 [190.96623]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 0] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0 15] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -106 

action type: take_action - action -1.0
Learning step: -10.638152122497559
desired expected reward: 177.1167449951172



buy possibilites: [-1] 
expected returns: [[194.4738]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 6. 6.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 0 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0 15] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -40.   0.   0.   0. -30.   0.   0. -30.   0.   0.   0.
   0.   0.] 
sum of rewards: -106.0 

action type: buy - action 0.0
Learning step: -9.691617012023926
desired expected reward: 165.65391540527344






Player: 1 
cards in hand: [ 0.  8. 15.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  0. 25.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 25 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3
  0 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [3. 0. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0] -> size -> 6 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [3. 0. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0] -> size -> 6 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [3. 0. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0] -> size -> 6 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [3. 0. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0] -> size -> 6 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [3. 0. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[210.27373]
 [198.79659]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 6. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 0 0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  8.  0.  8.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3  0  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -8.93982982635498
desired expected reward: 185.53396606445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[189.19215]
 [182.647  ]
 [208.326  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 6. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 0 0] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  5.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  8.  0.  8.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3  0  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -9.85470962524414
desired expected reward: 198.96278381347656



buy possibilites: [-1] 
expected returns: [[156.58527]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 6. 6.] 
cards in discard: [6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 0 0 6] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  8.  0.  8.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3  0  0] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -50.    0.    0.    0.    0.    0.    0.  -30.    0.
    0. -300.    0.    0.] 
sum of rewards: -387.0 

action type: buy - action 6.0
Learning step: -24.95918083190918
desired expected reward: 157.6878204345703






Player: 1 
cards in hand: [ 8. 16.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  8.  0.  8.] 
cards in discard: [0. 8. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 10 11 16  8 29 10  8  3  8  0 23  8 14  8  3  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [3. 6. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0 6] -> size -> 7 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [0. 8. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 29 10 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [3. 6. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0 6] -> size -> 7 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 8. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 29 10 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [3. 6. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0 6] -> size -> 7 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [3. 6. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[159.9229]
 [150.9729]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 8. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 0 0 6] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [11.  8.  0. 10.  0.] 
adversary cards in discard: [0. 8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  3 29 10 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 20 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -8.695387840270996
desired expected reward: 147.88987731933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[121.14654]
 [116.86197]
 [132.78754]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 8. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 0 0 6] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [11.  8.  0. 10.  0.] 
adversary cards in discard: [0. 8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  3 29 10 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 20 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -8.490031242370605
desired expected reward: 130.3596954345703



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  8.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 10.  0.] 
cards in discard: [0. 8. 0. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 10 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [8. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0 6] -> size -> 7 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [0. 8. 0. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [8. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0 6] -> size -> 7 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [0. 8. 0. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [8. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0 6] -> size -> 7 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [8. 6. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[165.21219]
 [157.66743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 0 0 6] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  8.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -7.351891994476318
desired expected reward: 125.4356460571289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[146.34094]
 [141.51042]
 [159.15959]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 0 0 6] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  8.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -9.22598934173584
desired expected reward: 155.82037353515625



buy possibilites: [-1] 
expected returns: [[178.36801]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 6. 0.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 0 0 6 0] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  8.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -87.0 

action type: buy - action 0.0
Learning step: -7.6537675857543945
desired expected reward: 138.68719482421875






Player: 1 
cards in hand: [ 0. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  3.] 
cards in discard: [ 0.  8.  0.  8.  8. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0 6 0] -> size -> 8 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 29.] 
cards in discard: [ 0.  8.  0.  8.  8. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0 6 0] -> size -> 8 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 0.  8.  0.  8.  8. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0 6 0] -> size -> 8 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 0.  8.  0.  8.  8. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 0 0 6 0] -> size -> 8 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[146.62872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 0 0 6 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 14. 23. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -8.46710205078125
desired expected reward: 169.90090942382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[127.57137]
 [131.51193]
 [130.4857 ]
 [123.35908]
 [136.23639]
 [132.37328]
 [131.27766]
 [140.48253]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 0 0 6 0] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  8.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 14. 23. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -7.203195095062256
desired expected reward: 139.5211639404297



buy possibilites: [-1] 
expected returns: [[113.72873]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 14. 23. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -39 

action type: buy - action 11.0
Learning step: -6.2029218673706055
desired expected reward: 130.03343200683594






Player: 1 
cards in hand: [ 0.  3. 14. 23. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14. 23. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  6.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11] -> size -> 9 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14. 23. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  6.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11] -> size -> 9 
adversary victory points: -2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  6.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[118.23027]
 [115.39332]
 [112.67005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  6.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 8. 8. 3. 0.] 
adversary cards in discard: [ 0.  3. 14. 23. 10.] 
adversary owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -5.963107109069824
desired expected reward: 107.765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[105.610344]
 [101.44843 ]
 [115.68181 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  6.  6.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11] -> size -> 9 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 8. 8. 3. 0.] 
adversary cards in discard: [ 0.  3. 14. 23. 10.] 
adversary owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -6.254422187805176
desired expected reward: 110.62396240234375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 3. 0.] 
cards in discard: [ 0.  3. 14. 23. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11] -> size -> 9 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 0.  3. 14. 23. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11] -> size -> 9 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0.  3. 14. 23. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11] -> size -> 9 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0.  3. 14. 23. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11] -> size -> 9 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [6. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[155.08263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 11.  3.  0.] 
adversary cards in discard: [ 0.  3. 14. 23. 10.  0.  8.  8.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0] -> size -> 16 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -4.574701309204102
desired expected reward: 111.10709381103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[135.4142 ]
 [140.81161]
 [139.85045]
 [129.80815]
 [146.55865]
 [141.77231]
 [140.78252]
 [151.64383]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 11.  3.  0.] 
adversary cards in discard: [ 0.  3. 14. 23. 10.  0.  8.  8.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0] -> size -> 16 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -7.065788269042969
desired expected reward: 151.12924194335938



buy possibilites: [-1] 
expected returns: [[167.45581]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 11.  3.  0.] 
adversary cards in discard: [ 0.  3. 14. 23. 10.  0.  8.  8.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0] -> size -> 16 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -29 

action type: buy - action 1.0
Learning step: -4.722824573516846
desired expected reward: 136.08877563476562






Player: 1 
cards in hand: [ 0.  8. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  3.  0.] 
cards in discard: [ 0.  3. 14. 23. 10.  0.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1] -> size -> 10 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  3.  0.] 
cards in discard: [ 0.  3. 14. 23. 10.  0.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1] -> size -> 10 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  3.  0.] 
cards in discard: [ 0.  3. 14. 23. 10.  0.  8.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1] -> size -> 10 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[160.17775]
 [156.2638 ]
 [152.55505]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  3.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0] -> size -> 17 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -7.207579135894775
desired expected reward: 160.24822998046875



action possibilites: [-1] 
expected returns: [[85.23645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 8.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  7. 10.  9.] 
adversary cards in hand: [10.  3.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0] -> size -> 17 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: -6.815642833709717
desired expected reward: 149.85360717773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[72.89421]
 [69.29331]
 [84.09692]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 8.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  7. 10.  9.] 
adversary cards in hand: [10.  3.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0] -> size -> 17 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1
Learning step: -3.894420623779297
desired expected reward: 81.34202575683594






Player: 1 
cards in hand: [10.  3.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 6. 6. 1. 0.] 
adversary cards in discard: [10. 11.  0.  6.  3.  8.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10] -> size -> 11 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 6. 6. 1. 0.] 
adversary cards in discard: [10. 11.  0.  6.  3.  8.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10] -> size -> 11 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 6. 6. 1. 0.] 
adversary cards in discard: [10. 11.  0.  6.  3.  8.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10] -> size -> 11 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [0. 6. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[111.13737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 1. 0.] 
cards in discard: [10. 11.  0.  6.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 8. 14. 23.  0.  0.] 
adversary cards in discard: [29. 10.  3.  0. 29.  3.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0] -> size -> 17 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -3.6368730068206787
desired expected reward: 71.94959259033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 91.34953 ]
 [ 96.01041 ]
 [ 95.04519 ]
 [ 86.49348 ]
 [ 94.634155]
 [100.83613 ]
 [ 96.85059 ]
 [101.26962 ]
 [ 91.774315]
 [ 95.86432 ]
 [ 96.70117 ]
 [105.13173 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 1. 0.] 
cards in discard: [10. 11.  0.  6.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 8. 14. 23.  0.  0.] 
adversary cards in discard: [29. 10.  3.  0. 29.  3.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0] -> size -> 17 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -5.707493305206299
desired expected reward: 105.06807708740234



buy possibilites: [-1] 
expected returns: [[85.080055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 1. 0.] 
cards in discard: [10. 11.  0.  6.  3.  8. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 8. 14. 23.  0.  0.] 
adversary cards in discard: [29. 10.  3.  0. 29.  3.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0] -> size -> 17 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -15 

action type: buy - action 14.0
Learning step: -3.424414873123169
desired expected reward: 88.34989929199219






Player: 1 
cards in hand: [ 8. 14. 23.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 23.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 23.  0.  0.] 
cards in discard: [29. 10.  3.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  8.  9.  7. 10.  9.] 
adversary cards in hand: [10.  1.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14] -> size -> 12 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23.  0.  0.] 
cards in discard: [29. 10.  3.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  8.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [1. 3.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14] -> size -> 12 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 23.  0.  0.] 
cards in discard: [29. 10.  3.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 25. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  8.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [1. 3.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14] -> size -> 12 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 23.  0.  0.] 
cards in discard: [29. 10.  3.  0. 29.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  8.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [1. 3.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14] -> size -> 12 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[57.847584]
 [52.678005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [1. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  8.  9.  7. 10.  9.] 
adversary cards in hand: [11.  0.  8.  8.  0.] 
adversary cards in discard: [29. 10.  3.  0. 29.  3.  1. 14.  8. 23.  0.  0.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1] -> size -> 18 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: discard_down_to_3_cards - action 6
Learning step: -2.602633237838745
desired expected reward: 26.824275970458984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[44.84708 ]
 [46.90647 ]
 [41.753124]
 [48.228283]
 [52.51407 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [1. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  8.  9.  7. 10.  9.] 
adversary cards in hand: [11.  0.  8.  8.  0.] 
adversary cards in discard: [29. 10.  3.  0. 29.  3.  1. 14.  8. 23.  0.  0.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1] -> size -> 18 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -4.104884624481201
desired expected reward: 52.34009552001953



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  8.  0.] 
cards in discard: [29. 10.  3.  0. 29.  3.  1. 14.  8. 23.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  4.  8.  7.  1.  8.  8.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  6.  6. 11.] 
adversary cards in discard: [ 1.  3. 10.  0.  0.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14] -> size -> 12 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [29. 10.  3.  0. 29.  3.  1. 14.  8. 23.  0.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  7.  1.  8.  8.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  6.  6. 11.] 
adversary cards in discard: [ 1.  3. 10.  0.  0.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14] -> size -> 12 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [29. 10.  3.  0. 29.  3.  1. 14.  8. 23.  0.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  7.  1.  8.  8.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  6.  6. 11.] 
adversary cards in discard: [ 1.  3. 10.  0.  0.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14] -> size -> 12 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[130.92142]
 [126.05294]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6.  6. 11.] 
cards in discard: [ 1.  3. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  7.  1.  8.  8.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 8. 23. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -2.1155126094818115
desired expected reward: 50.3985595703125



action possibilites: [-1] 
expected returns: [[94.835686]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [ 1.  3. 10.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  7.  1.  8.  7.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 8. 23. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -11 

action type: gain_card_n - action 7
Learning step: -4.061219692230225
desired expected reward: 108.83922576904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[80.4294 ]
 [76.50819]
 [92.76261]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [ 1.  3. 10.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  7.  1.  8.  7.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 8. 23. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1
Learning step: -4.196752071380615
desired expected reward: 90.63893127441406






Player: 1 
cards in hand: [ 8. 23. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23. 29.  1.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  7.  1.  8.  7.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  1. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29] -> size -> 13 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1.  8. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  7.  1.  8.  7.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  1. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29] -> size -> 13 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 23.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  7.  1.  8.  7.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  1. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29] -> size -> 13 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 23.  1.  0.  0.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  6.  1.  8.  7.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  1. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29] -> size -> 13 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  1. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[95.62053 ]
 [86.68127 ]
 [90.124985]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1. 14.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  6.  1.  8.  7.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 8. 14.  3. 29.  0.] 
adversary cards in discard: [11. 29.  8. 23.  1.  0.  0.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11] -> size -> 20 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -4.99059534072876
desired expected reward: 87.77203369140625



action possibilites: [-1] 
expected returns: [[114.4253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  6.  1.  8.  7.  8.  9.  7. 10.  9.] 
adversary cards in hand: [14.  3. 29.] 
adversary cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11] -> size -> 20 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action 14.0
Learning step: -2.969294309616089
desired expected reward: 80.90797424316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[107.00811 ]
 [109.54384 ]
 [108.63168 ]
 [104.99373 ]
 [104.11037 ]
 [108.74098 ]
 [111.66313 ]
 [110.036545]
 [114.501144]
 [112.10754 ]
 [106.94892 ]
 [108.131714]
 [109.12864 ]
 [105.64959 ]
 [109.431046]
 [113.37794 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  6.  1.  8.  7.  8.  9.  7. 10.  9.] 
adversary cards in hand: [14.  3. 29.] 
adversary cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11] -> size -> 20 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1
Learning step: -4.605896949768066
desired expected reward: 109.81940460205078



buy possibilites: [-1] 
expected returns: [[56.141968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 8.] 
cards in discard: [15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  6.  1.  8.  7.  8.  9.  7. 10.  8.] 
adversary cards in hand: [14.  3. 29.] 
adversary cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11] -> size -> 20 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -40.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -19.0 

action type: buy - action 15.0
Learning step: -5.158358573913574
desired expected reward: 104.27269744873047






Player: 1 
cards in hand: [14.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 29.] 
cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  6.  1.  8.  7.  8.  9.  7. 10.  8.] 
adversary cards in hand: [29.  0. 11.  3. 10.] 
adversary cards in discard: [15. 14.  6.  0.  1.  8.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15] -> size -> 14 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.] 
cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  6.  1.  8.  7.  8.  9.  7. 10.  8.] 
adversary cards in hand: [29.  0.  3.] 
adversary cards in discard: [15. 14.  6.  0.  1.  8. 11. 10.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15] -> size -> 14 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.] 
cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  6.  1.  8.  7.  8.  9.  7. 10.  8.] 
adversary cards in hand: [29.  0.  3.] 
adversary cards in discard: [15. 14.  6.  0.  1.  8. 11. 10.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15] -> size -> 14 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.] 
cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  6.  0.  8.  7.  8.  9.  7. 10.  8.] 
adversary cards in hand: [29.  0.  3.] 
adversary cards in discard: [15. 14.  6.  0.  1.  8. 11. 10.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15] -> size -> 14 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[48.378628]
 [46.116608]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.] 
cards in discard: [15. 14.  6.  0.  1.  8. 11. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  6.  0.  8.  7.  8.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  0. 10.] 
adversary cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.  8. 14.  3. 29.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8] -> size -> 21 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: discard_down_to_3_cards - action 1
Learning step: -2.211888551712036
desired expected reward: 15.801804542541504



action possibilites: [-1.] 
expected returns: [[61.084267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [15. 14.  6.  0.  1.  8. 11. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  6.  0.  8.  7.  8.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  0. 10.] 
adversary cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.  8. 14.  3. 29.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8] -> size -> 21 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: discard_n_cards - action 0
Learning step: -1.8346617221832275
desired expected reward: 35.34648895263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.951576]
 [49.95462 ]
 [61.448578]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [15. 14.  6.  0.  1.  8. 11. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15] -> size -> 14 
action values: 1 
buys: 1 
player value: 1 
card supply: [19. 24. 30. 25. 30.  8.  4.  7.  6.  0.  8.  7.  8.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  0. 10.] 
adversary cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.  8. 14.  3. 29.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8] -> size -> 21 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -3.1559720039367676
desired expected reward: 57.92829513549805



buy possibilites: [-1] 
expected returns: [[107.39135]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [15. 14.  6.  0.  1.  8. 11. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 24. 30. 25. 30.  8.  4.  7.  6.  0.  8.  7.  8.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  0. 10.] 
adversary cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.  8. 14.  3. 29.] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8] -> size -> 21 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -57.0 

action type: buy - action 0.0
Learning step: -3.081273078918457
desired expected reward: 49.870296478271484






Player: 1 
cards in hand: [ 3. 11.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0. 10.] 
cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.  8. 14.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  4.  7.  6.  0.  8.  7.  8.  9.  7. 10.  8.] 
adversary cards in hand: [15.  1.  6.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.  8. 14.  3. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  4.  7.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [15.  1.  6.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [11. 29.  8. 23.  1.  0.  0.  8.  0.  8. 14.  3. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 30. 25. 30.  8.  4.  7.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [15.  1.  6.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [15.  1.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[111.43035]
 [107.07732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  6.  0.  6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  4.  7.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 29.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15] -> size -> 22 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -5.318176746368408
desired expected reward: 102.07317352294922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[ 95.65705 ]
 [ 97.43809 ]
 [ 96.77348 ]
 [ 93.87622 ]
 [ 99.55198 ]
 [ 97.198425]
 [101.494934]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  6.  0.  6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 24. 30. 25. 30.  8.  4.  7.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 29.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15] -> size -> 22 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -5.5823211669921875
desired expected reward: 103.09654998779297



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29.  8. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8. 16.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  4.  7.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 29. 14.] 
adversary cards in discard: [15.  1.  6.  0.  6.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0. 11.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 24. 30. 25. 30.  8.  4.  7.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 29. 14.] 
adversary cards in discard: [15.  1.  6.  0.  6.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0 29 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 24. 30. 25. 30.  8.  4.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 29. 14.] 
adversary cards in discard: [15.  1.  6.  0.  6.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0 29 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 24. 30. 25. 30.  8.  4.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 29. 14.] 
adversary cards in discard: [15.  1.  6.  0.  6.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 16.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0 29 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 24. 30. 24. 30.  8.  4.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 29. 14.] 
adversary cards in discard: [15.  1.  6.  0.  6.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 14.] 
expected returns: [[55.275253]
 [48.154354]
 [52.118507]
 [45.327114]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29. 14.] 
cards in discard: [15.  1.  6.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 24. 30.  8.  4.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 10.  0.  8.] 
adversary cards in discard: [ 8. 16.  3. 29. 16.  0.  0.] 
adversary owned cards: [ 0 29 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -6.809277534484863
desired expected reward: 94.6856918334961



action possibilites: [-1. 29. 14.] 
expected returns: [[76.89413]
 [74.24328]
 [68.88348]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 14.  6.] 
cards in discard: [15.  1.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 24. 30.  8.  4.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 10.  0.  8.] 
adversary cards in discard: [ 8. 16.  3. 29. 16.  0.  0.] 
adversary owned cards: [ 0 29 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action 10.0
Learning step: -2.5418310165405273
desired expected reward: 44.46410369873047



action possibilites: [-1. 14.  8.] 
expected returns: [[62.92856 ]
 [55.17608 ]
 [58.268837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8.] 
cards in discard: [15.  1.  6.  0.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 1 
card supply: [18. 24. 30. 24. 30.  8.  4.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 10.  0.  8.] 
adversary cards in discard: [ 8. 16.  3. 29. 16.  0.  0.] 
adversary owned cards: [ 0 29 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: discard_n_cards - action 1
Learning step: -2.9803338050842285
desired expected reward: 66.27584075927734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[55.78294 ]
 [58.40847 ]
 [57.8911  ]
 [52.6817  ]
 [61.144733]
 [58.348354]
 [63.539368]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  8.] 
cards in discard: [15.  1.  6.  0.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 24. 30. 24. 30.  8.  4.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 10.  0.  8.] 
adversary cards in discard: [ 8. 16.  3. 29. 16.  0.  0.] 
adversary owned cards: [ 0 29 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: -2.6733016967773438
desired expected reward: 60.25526428222656



buy possibilites: [-1] 
expected returns: [[68.98199]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  8.] 
cards in discard: [15.  1.  6.  0.  6.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 24. 30. 24. 30.  8.  4.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 10.  0.  8.] 
adversary cards in discard: [ 8. 16.  3. 29. 16.  0.  0.] 
adversary owned cards: [ 0 29 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -47.0 

action type: buy - action 0.0
Learning step: -3.587053060531616
desired expected reward: 52.195899963378906






Player: 1 
cards in hand: [ 3.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  8.] 
cards in discard: [ 8. 16.  3. 29. 16.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 29 10  3  8  0 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 24. 30.  8.  4.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [15.  6.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0] -> size -> 16 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 16.  3. 29. 16.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 29  8 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 24. 30.  8.  4.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [15.  6.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0] -> size -> 16 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 16.  3. 29. 16.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 29  8 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 24. 30. 24. 30.  8.  4.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [15.  6.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0] -> size -> 16 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 16.  3. 29. 16.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 29  8 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  4.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [15.  6.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0] -> size -> 16 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [15.  6.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[58.65425 ]
 [53.890316]
 [56.12455 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  4.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [23.  8.  0. 29.  0.] 
adversary cards in discard: [ 8. 16.  3. 29. 16.  0.  0.  0.  8.] 
adversary owned cards: [29 29  8 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3  0] -> size -> 20 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -4.558949947357178
desired expected reward: 64.42303466796875



action possibilites: [-1] 
expected returns: [[87.912025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  0.  3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  3.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [23.  8.  0. 29.  0.] 
adversary cards in discard: [ 8. 16.  3. 29. 16.  0.  0.  0.  8.] 
adversary owned cards: [29 29  8 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3  0] -> size -> 20 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3  -50    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -338 

action type: gain_card_n - action 3
Learning step: -17.499191284179688
desired expected reward: 34.0450553894043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[74.933624]
 [71.44599 ]
 [85.81826 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  0.  3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 24. 30.  8.  3.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [23.  8.  0. 29.  0.] 
adversary cards in discard: [ 8. 16.  3. 29. 16.  0.  0.  0.  8.] 
adversary owned cards: [29 29  8 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3  0] -> size -> 20 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1
Learning step: -4.534432411193848
desired expected reward: 83.37759399414062



buy possibilites: [-1] 
expected returns: [[43.77706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  0.  3.] 
cards in discard: [6. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0  6  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [23.  8.  0. 29.  0.] 
adversary cards in discard: [ 8. 16.  3. 29. 16.  0.  0.  0.  8.] 
adversary owned cards: [29 29  8 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3  0] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -349.0 

action type: buy - action 6.0
Learning step: -19.698965072631836
desired expected reward: 44.98002624511719






Player: 1 
cards in hand: [23.  8.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  0. 29.  0.] 
cards in discard: [ 8. 16.  3. 29. 16.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [1. 0. 6. 0. 6.] 
adversary cards in discard: [ 6.  6. 11. 15.  6.  0.  3.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0  6  6] -> size -> 18 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  8.  0. 29.  0.] 
cards in discard: [ 8. 16.  3. 29. 16.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [1. 0. 6. 0. 6.] 
adversary cards in discard: [ 6.  6. 11. 15.  6.  0.  3.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0  6  6] -> size -> 18 
adversary victory points: -4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [1. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[102.79737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 0. 6.] 
cards in discard: [ 6.  6. 11. 15.  6.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0  6  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [11.  8.  1.  3. 14.] 
adversary cards in discard: [ 8. 16.  3. 29. 16.  0.  0.  0.  8. 23.  8.  0. 29.  0.] 
adversary owned cards: [29 29  8 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3  0] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1
Learning step: -3.3603341579437256
desired expected reward: 40.41672897338867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ 92.56369 ]
 [ 95.306755]
 [ 94.80804 ]
 [ 89.63679 ]
 [ 94.51037 ]
 [ 98.415085]
 [ 98.63865 ]
 [ 92.85395 ]
 [ 95.28008 ]
 [ 95.7922  ]
 [101.19132 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 6.] 
cards in discard: [ 6.  6. 11. 15.  6.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0  6  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [11.  8.  1.  3. 14.] 
adversary cards in discard: [ 8. 16.  3. 29. 16.  0.  0.  0.  8. 23.  8.  0. 29.  0.] 
adversary owned cards: [29 29  8 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3  0] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1.0
Learning step: -6.354074001312256
desired expected reward: 94.9134521484375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  8.  1.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  1.  3. 14.] 
cards in discard: [ 8. 16.  3. 29. 16.  0.  0.  0.  8. 23.  8.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8 23  8 14  8  3  0  0  0  0  1 16 11  8 15 16  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [14.  0. 10.  0.  8.] 
adversary cards in discard: [ 6.  6. 11. 15.  6.  0.  3.  1.  0.  6.  0.  6.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0  6  6] -> size -> 18 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8. 16.  3. 29. 16.  0.  0.  0.  8. 23.  8.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 29  8 23  8  8  3  0  0  0  0 16  8 15 16  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [14.  0. 10.  0.  8.] 
adversary cards in discard: [ 6.  6. 11. 15.  6.  0.  3.  1.  0.  6.  0.  6.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0  6  6] -> size -> 18 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 16.  3. 29. 16.  0.  0.  0.  8. 23.  8.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 29  8 23  8  8  3  0  0  0  0 16  8 15 16  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [14.  0. 10.  0.  8.] 
adversary cards in discard: [ 6.  6. 11. 15.  6.  0.  3.  1.  0.  6.  0.  6.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0  6  6] -> size -> 18 
adversary victory points: -4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 16.  3. 29. 16.  0.  0.  0.  8. 23.  8.  0. 29.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 29  8 23  8  8  3  0  0  0  0 16  8 15 16  3  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [14.  0. 10.  0.  8.] 
adversary cards in discard: [ 6.  6. 11. 15.  6.  0.  3.  1.  0.  6.  0.  6.] 
adversary owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0  6  6] -> size -> 18 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [14.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.  8.] 
expected returns: [[70.7035  ]
 [66.842384]
 [68.19712 ]
 [68.752365]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10.  0.  8.] 
cards in discard: [ 6.  6. 11. 15.  6.  0.  3.  1.  0.  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  0  6  0 11  1 10 14 29 15  0  0  6  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 8.  0. 16.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8 23  8  8  3  0  0  0  0 16  8 15 16  3  0  0] -> size -> 18 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1.0
Learning step: -6.979075908660889
desired expected reward: 94.2122573852539



action possibilites: [-1] 
expected returns: [[54.918774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.] 
cards in discard: [ 6.  6. 11. 15.  6.  0.  3.  1.  0.  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  3  6  0  6  0 11  1 14 29 15  0  0  6  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 8.  0. 16.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8 23  8  8  3  0  0  0  0 16  8 15 16  3  0  0] -> size -> 18 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: trash_cards_n_from_hand - action 7
Learning step: -4.561771392822266
desired expected reward: 62.38710403442383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[46.835323]
 [44.13164 ]
 [54.77261 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [ 6.  6. 11. 15.  6.  0.  3.  1.  0.  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  3  6  0  6  0 11  1 14 29 15  0  0  6  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 8.  0. 16.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8 23  8  8  3  0  0  0  0 16  8 15 16  3  0  0] -> size -> 18 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action -1
Learning step: -4.088412761688232
desired expected reward: 50.830360412597656



buy possibilites: [-1] 
expected returns: [[127.02131]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [ 6.  6. 11. 15.  6.  0.  3.  1.  0.  6.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  3  6  0  6  0 11  1 14 29 15  0  0  6  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 8.  0. 16.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8 23  8  8  3  0  0  0  0 16  8 15 16  3  0  0] -> size -> 18 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -60.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -79.0 

action type: buy - action 0.0
Learning step: -3.4337875843048096
desired expected reward: 43.40154266357422






Player: 1 
cards in hand: [ 8.  0. 16.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  8. 15.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8 23  8  8  3  0  0  0  0 16  8 15 16  3  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  6. 11.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  6  0 11  1 14 29 15  0  0  6  6  0] -> size -> 17 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 29 23  8  8  3  0  0  0  8 15 16  3  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  6. 11.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  6  0 11  1 14 29 15  0  0  6  6  0] -> size -> 17 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 29 23  8  8  3  0  0  0  8 15 16  3  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  6. 11.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  0  6  0 11  1 14 29 15  0  0  6  6  0] -> size -> 17 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 6.  6. 11.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[57.110676]
 [55.542156]
 [55.80743 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 11.  6. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  6  0 11  1 14 29 15  0  0  6  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 16.  3.] 
adversary cards in discard: [ 8. 15.] 
adversary owned cards: [29 29 23  8  8  3  0  0  0  8 15 16  3  0  0] -> size -> 15 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1
Learning step: -8.550270080566406
desired expected reward: 118.47103881835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[49.969063]
 [48.174732]
 [55.023106]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 11.  6. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  6  0 11  1 14 29 15  0  0  6  6  0] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 16.  3.] 
adversary cards in discard: [ 8. 15.] 
adversary owned cards: [29 29 23  8  8  3  0  0  0  8 15 16  3  0  0] -> size -> 15 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1.0
Learning step: -5.1115336418151855
desired expected reward: 51.279701232910156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 16.  3.] 
cards in discard: [ 8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29 29 23  8  8  3  0  0  0  8 15 16  3  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  8.  9.  7. 10.  7.] 
adversary cards in hand: [14. 15.  0.  3.  6.] 
adversary cards in discard: [ 6.  6. 11.  6. 29.] 
adversary owned cards: [ 8  6  3  6  0  6  0 11  1 14 29 15  0  0  6  6  0] -> size -> 17 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 8. 15. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 29 23  8  8  0  0  0  8 15 16  3  0  0 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  7. 10.  7.] 
adversary cards in hand: [14. 15.  0.  3.  6.] 
adversary cards in discard: [ 6.  6. 11.  6. 29.] 
adversary owned cards: [ 8  6  3  6  0  6  0 11  1 14 29 15  0  0  6  6  0] -> size -> 17 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 8. 15. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 29 23  8  8  0  0  0  8 15 16  3  0  0 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  7. 10.  7.] 
adversary cards in hand: [14. 15.  0.  3.  6.] 
adversary cards in discard: [ 6.  6. 11.  6. 29.] 
adversary owned cards: [ 8  6  3  6  0  6  0 11  1 14 29 15  0  0  6  6  0] -> size -> 17 
adversary victory points: -4
player victory points: 1 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [14. 15.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[90.13047 ]
 [83.719215]
 [85.96075 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 15.  0.  3.  6.] 
cards in discard: [ 6.  6. 11.  6. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  0  6  0 11  1 14 29 15  0  0  6  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 29.  0.  8.] 
adversary cards in discard: [ 8. 15. 14. 16.  0. 29.  0.] 
adversary owned cards: [29 29 23  8  8  0  0  0  8 15 16  3  0  0 14] -> size -> 15 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1.0
Learning step: -3.774280548095703
desired expected reward: 51.24882507324219



action possibilites: [-1] 
expected returns: [[14.934402]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  6.] 
cards in discard: [ 6.  6. 11.  6. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  6  3  6  6  0 11  1 14 29 15  0  0  6  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 29.  0.  8.] 
adversary cards in discard: [ 8. 15. 14. 16.  0. 29.  0.] 
adversary owned cards: [29 29 23  8  8  0  0  0  8 15 16  3  0  0 14] -> size -> 15 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action 15.0
Learning step: -5.849062919616699
desired expected reward: 78.85267639160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[10.104163]
 [11.866951]
 [11.429308]
 [ 8.395276]
 [13.579797]
 [11.749654]
 [15.021048]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.] 
cards in discard: [ 6.  6. 11.  6. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  6  3  6  6  0 11  1 14 29 15  0  0  6  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 29.  0.  8.] 
adversary cards in discard: [ 8. 15. 14. 16.  0. 29.  0.] 
adversary owned cards: [29 29 23  8  8  0  0  0  8 15 16  3  0  0 14] -> size -> 15 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1
Learning step: -2.4249961376190186
desired expected reward: 12.509406089782715



buy possibilites: [-1] 
expected returns: [[15.292929]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.] 
cards in discard: [ 6.  6. 11.  6. 29. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  6  3  6  6  0 11  1 14 29 15  0  0  6  6  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 29.  0.  8.] 
adversary cards in discard: [ 8. 15. 14. 16.  0. 29.  0.] 
adversary owned cards: [29 29 23  8  8  0  0  0  8 15 16  3  0  0 14] -> size -> 15 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -21 

action type: buy - action 10.0
Learning step: -1.2933920621871948
desired expected reward: 10.456265449523926






Player: 1 
cards in hand: [ 3.  0. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  8.] 
cards in discard: [ 8. 15. 14. 16.  0. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 29 23  8  8  0  0  0  8 15 16  3  0  0 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [8. 0. 1. 0. 0.] 
adversary cards in discard: [ 6.  6. 11.  6. 29. 10. 15. 14.  3.  6.] 
adversary owned cards: [ 8  6  3  6  6  0 11  1 14 29 15  0  0  6  6  0 10] -> size -> 17 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8. 15. 14. 16.  0. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [8. 0. 1. 0. 0.] 
adversary cards in discard: [ 6.  6. 11.  6. 29. 10. 15. 14.  3.  6.] 
adversary owned cards: [ 8  6  3  6  6  0 11  1 14 29 15  0  0  6  6  0 10] -> size -> 17 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 15. 14. 16.  0. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [8. 0. 1. 0. 0.] 
adversary cards in discard: [ 6.  6. 11.  6. 29. 10. 15. 14.  3.  6.] 
adversary owned cards: [ 8  6  3  6  6  0 11  1 14 29 15  0  0  6  6  0 10] -> size -> 17 
adversary victory points: -4
player victory points: 1 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [8. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[45.6838  ]
 [44.104855]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 0. 0.] 
cards in discard: [ 6.  6. 11.  6. 29. 10. 15. 14.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6  0 11  1 14 29 15  0  0  6  6  0 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [29.  0.  0.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [29 23  8  8  0  8 15 16  3  0  0 14] -> size -> 12 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1
Learning step: -2.670689821243286
desired expected reward: 12.622239112854004



action possibilites: [-1] 
expected returns: [[43.516598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 6.  6. 11.  6. 29. 10. 15. 14.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [29.  0.  0.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [29 23  8  8  0  8 15 16  3  0  0 14] -> size -> 12 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: trash_cards_n_from_hand - action 6
Learning step: -2.599547863006592
desired expected reward: 29.973873138427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[32.72964 ]
 [34.74923 ]
 [30.557688]
 [39.69309 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 6.  6. 11.  6. 29. 10. 15. 14.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [29.  0.  0.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [29 23  8  8  0  8 15 16  3  0  0 14] -> size -> 12 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1
Learning step: -3.3388004302978516
desired expected reward: 40.17779541015625



buy possibilites: [-1] 
expected returns: [[6.773179]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 6.  6. 11.  6. 29. 10. 15. 14.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [29.  0.  0.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [29 23  8  8  0  8 15 16  3  0  0 14] -> size -> 12 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -69.0 

action type: buy - action 0.0
Learning step: -4.934085369110107
desired expected reward: 27.795543670654297






Player: 1 
cards in hand: [29.  0.  0.  8. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  8. 23.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [3. 0. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0] -> size -> 15 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  8. 23.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [3. 0. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0] -> size -> 15 
adversary victory points: -4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  8. 23.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [3. 0. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0] -> size -> 15 
adversary victory points: -4
player victory points: 1 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [3. 0. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.287848]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 15. 14. 16.  3.] 
adversary cards in discard: [ 0. 29.  0.  0.  8. 23.] 
adversary owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0] -> size -> 13 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1
Learning step: -2.8740742206573486
desired expected reward: 3.8991048336029053





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[11.267359 ]
 [12.707688 ]
 [12.2992115]
 [ 9.676082 ]
 [12.26976  ]
 [14.037241 ]
 [14.208733 ]
 [11.30837  ]
 [12.570643 ]
 [12.771981 ]
 [15.11073  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 15. 14. 16.  3.] 
adversary cards in discard: [ 0. 29.  0.  0.  8. 23.] 
adversary owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0] -> size -> 13 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1.0
Learning step: -3.582611083984375
desired expected reward: 14.843374252319336



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 15. 14. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 14. 16.  3.] 
cards in discard: [ 0. 29.  0.  0.  8. 23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [14.  8. 11.  6. 15.] 
adversary cards in discard: [3. 0. 1. 0. 6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0] -> size -> 15 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 16.  3.] 
cards in discard: [ 0. 29.  0.  0.  8. 23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [11.  6. 15.] 
adversary cards in discard: [ 3.  0.  1.  0.  6. 14.  8.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0] -> size -> 15 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 16.  3.] 
cards in discard: [ 0. 29.  0.  0.  8. 23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [11.  6. 15.] 
adversary cards in discard: [ 3.  0.  1.  0.  6. 14.  8.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0] -> size -> 15 
adversary victory points: -4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 16.  3.] 
cards in discard: [ 0. 29.  0.  0.  8. 23.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [11.  6. 15.] 
adversary cards in discard: [ 3.  0.  1.  0.  6. 14.  8.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0] -> size -> 15 
adversary victory points: -4
player victory points: 1 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [11.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[31.11426]
 [29.20773]
 [27.29891]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 15.] 
cards in discard: [ 3.  0.  1.  0.  6. 14.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [14.  8. 23.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0  0] -> size -> 14 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[   -5     0    -4   -50     0     0     0     0     0     0     0     0
     0 -1500    27     0] 
sum of rewards: -1532 

action type: discard_down_to_3_cards - action 0
Learning step: -79.18154907226562
desired expected reward: -14.554275512695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.887072]
 [21.556574]
 [30.107924]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 15.] 
cards in discard: [ 3.  0.  1.  0.  6. 14.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 24. 30. 24. 30.  8.  2.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [14.  8. 23.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0  0] -> size -> 14 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1.0
Learning step: -3.9011662006378174
desired expected reward: 26.68515396118164



buy possibilites: [-1] 
expected returns: [[58.576077]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 15.] 
cards in discard: [ 3.  0.  1.  0.  6. 14.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [14.  8. 23.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0  0] -> size -> 14 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5  -60    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -370 

action type: buy - action 6.0
Learning step: -18.259868621826172
desired expected reward: 3.2966976165771484






Player: 1 
cards in hand: [14.  8. 23.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 23.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 23.  0.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 6. 10.  6. 29.  6.] 
adversary cards in discard: [ 3.  0.  1.  0.  6. 14.  8.  6. 11.  6. 15.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0  6] -> size -> 16 
adversary victory points: -5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23.  0.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 6. 29.  6.] 
adversary cards in discard: [ 3.  0.  1.  0.  6. 14.  8.  6. 11.  6. 15. 10.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0  6] -> size -> 16 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 23.  0.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 6. 29.  6.] 
adversary cards in discard: [ 3.  0.  1.  0.  6. 14.  8.  6. 11.  6. 15. 10.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0  6] -> size -> 16 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 23.  0.  8.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 6. 29.  6.] 
adversary cards in discard: [ 3.  0.  1.  0.  6. 14.  8.  6. 11.  6. 15. 10.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0  6] -> size -> 16 
adversary victory points: -5
player victory points: 1 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 6. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[47.43993 ]
 [47.045387]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  6.] 
cards in discard: [ 3.  0.  1.  0.  6. 14.  8.  6. 11.  6. 15. 10.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [29.  0. 16.  8.  0.] 
adversary cards in discard: [ 0. 14.  8. 23.  0.  8.] 
adversary owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0  0  0] -> size -> 15 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[   -5     0    -5   -60     0     0     0     0     0     0     0     0
     0 -1800    27     0] 
sum of rewards: -1843 

action type: discard_down_to_3_cards - action 1
Learning step: -94.07576751708984
desired expected reward: -34.183021545410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.53824 ]
 [43.338196]
 [47.139645]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  6.] 
cards in discard: [ 3.  0.  1.  0.  6. 14.  8.  6. 11.  6. 15. 10.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0  6] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [29.  0. 16.  8.  0.] 
adversary cards in discard: [ 0. 14.  8. 23.  0.  8.] 
adversary owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0  0  0] -> size -> 15 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: take_action - action -1.0
Learning step: -4.867480278015137
desired expected reward: 42.8343391418457



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0. 16.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 16.  8.  0.] 
cards in discard: [ 0. 14.  8. 23.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29 23  8  8  0  8 15 16  3  0  0 14  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 29. 15.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0  6] -> size -> 16 
adversary victory points: -5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 14.  8. 23.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [23  8  8  8 15  3  0  0 14  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 29. 15.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0  6] -> size -> 16 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 14.  8. 23.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [23  8  8  8 15  3  0  0 14  0  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 29. 15.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0  6] -> size -> 16 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 14.  8. 23.  0.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [23  8  8  8 15  3  0  0 14  0  0  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 29. 15.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0  6] -> size -> 16 
adversary victory points: -5
player victory points: 1 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 15.] 
expected returns: [[58.665672]
 [57.051273]
 [58.21838 ]
 [56.476604]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 15.  6.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8  8 15  3  0  0 14  0  0  0  0] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1.0
Learning step: -4.620002746582031
desired expected reward: 42.519649505615234



action possibilites: [-1. 15.] 
expected returns: [[5.296173]
 [4.156643]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  0.  6.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6  0 10  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8  8 15  3  0  0 14  0  0  0  0] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: discard_n_cards - action 1
Learning step: -5.193079948425293
desired expected reward: 50.82204055786133



action possibilites: [-1] 
expected returns: [[24.502113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 9. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8  8 15  3  0  0 14  0  0  0  0] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action 15.0
Learning step: -1.0663273334503174
desired expected reward: 3.0903146266937256





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[23.672668]
 [24.437654]
 [24.076305]
 [22.75879 ]
 [24.178858]
 [25.094084]
 [25.265707]
 [23.582262]
 [24.237354]
 [24.292181]
 [25.610603]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 24. 30. 24. 30.  8.  1.  6.  6.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8  8 15  3  0  0 14  0  0  0  0] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1
Learning step: -2.1754627227783203
desired expected reward: 22.326650619506836



buy possibilites: [-1] 
expected returns: [[23.22954]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 8. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 24. 30. 24. 30.  8.  1.  6.  5.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8  8 15  3  0  0 14  0  0  0  0] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5.    0.   -5.  -60.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -25.5 

action type: buy - action 11.0
Learning step: -2.007039785385132
desired expected reward: 23.087047576904297






Player: 1 
cards in hand: [ 0.  0.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8  8 15  3  0  0 14  0  0  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 24. 30.  8.  1.  6.  5.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  1.  6. 10.] 
adversary cards in discard: [ 8. 11. 29. 15.  6.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11] -> size -> 16 
adversary victory points: -5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [23  8  8  8 15  3  0 14  0  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 24. 30. 24. 30.  8.  1.  6.  5.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  1.  6. 10.] 
adversary cards in discard: [ 8. 11. 29. 15.  6.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11] -> size -> 16 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [23  8  8  8 15  3  0 14  0  0  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 24. 30. 24. 30.  8.  1.  6.  5.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  1.  6. 10.] 
adversary cards in discard: [ 8. 11. 29. 15.  6.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11] -> size -> 16 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [4.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [23  8  8  8 15  3  0 14  0  0  0  0  4] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  1.  6. 10.] 
adversary cards in discard: [ 8. 11. 29. 15.  6.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11] -> size -> 16 
adversary victory points: -5
player victory points: 4 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  1.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[17.024553]
 [14.979987]
 [13.034608]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1.  6. 10.] 
cards in discard: [ 8. 11. 29. 15.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 14.  8.  0.  8.] 
adversary cards in discard: [ 4. 15.  0.  0.  3.] 
adversary owned cards: [23  8  8  8 15  3  0 14  0  0  0  0  4] -> size -> 13 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -100 

action type: buy - action -1
Learning step: -5.810733318328857
desired expected reward: 17.418806076049805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[ 8.328568 ]
 [ 9.719306 ]
 [ 9.522844 ]
 [ 6.867378 ]
 [11.2775955]
 [ 9.758436 ]
 [12.662355 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  1.  6. 10.] 
cards in discard: [ 8. 11. 29. 15.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 14.  8.  0.  8.] 
adversary cards in discard: [ 4. 15.  0.  0.  3.] 
adversary owned cards: [23  8  8  8 15  3  0 14  0  0  0  0  4] -> size -> 13 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -100 

action type: take_action - action -1.0
Learning step: -5.636268138885498
desired expected reward: 11.606237411499023



buy possibilites: [-1] 
expected returns: [[2.9154923]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  1.  6. 10.] 
cards in discard: [ 8. 11. 29. 15.  6.  6. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 0. 14.  8.  0.  8.] 
adversary cards in discard: [ 4. 15.  0.  0.  3.] 
adversary owned cards: [23  8  8  8 15  3  0 14  0  0  0  0  4] -> size -> 13 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -82 

action type: buy - action 10.0
Learning step: -4.522322654724121
desired expected reward: 5.236103057861328






Player: 1 
cards in hand: [ 0. 14.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  0.  8.] 
cards in discard: [ 4. 15.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8  8 15  3  0 14  0  0  0  0  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  6.  6.  6. 14.] 
adversary cards in discard: [ 8. 11. 29. 15.  6.  6. 10.  0. 11.  1.  6. 10.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10] -> size -> 17 
adversary victory points: -5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 4. 15.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [23  8  8  8 15  3  0  0  0  4] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  6.  6.  6. 14.] 
adversary cards in discard: [ 8. 11. 29. 15.  6.  6. 10.  0. 11.  1.  6. 10.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10] -> size -> 17 
adversary victory points: -5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 4. 15.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [23  8  8  8 15  3  0  0  0  4] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  6.  6.  6. 14.] 
adversary cards in discard: [ 8. 11. 29. 15.  6.  6. 10.  0. 11.  1.  6. 10.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10] -> size -> 17 
adversary victory points: -5
player victory points: 4 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  6.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-2.100645]
 [-2.100645]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6.  6. 14.] 
cards in discard: [ 8. 11. 29. 15.  6.  6. 10.  0. 11.  1.  6. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  4.  0.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8  8 15  3  0  0  0  4] -> size -> 10 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -100 

action type: buy - action -1
Learning step: -5.192027568817139
desired expected reward: -2.2765352725982666



action possibilites: [-1] 
expected returns: [[11.303119]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 6.] 
cards in discard: [ 8. 11. 29. 15.  6.  6. 10.  0. 11.  1.  6. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  0. 23.] 
adversary cards in discard: [4. 8.] 
adversary owned cards: [23  8  8  8 15  3  0  0  0  4] -> size -> 10 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -80 

action type: take_action - action 14.0
Learning step: -3.6406476497650146
desired expected reward: -5.741292953491211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[7.7465973]
 [8.170949 ]
 [6.9946404]
 [9.628288 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 6.] 
cards in discard: [ 8. 11. 29. 15.  6.  6. 10.  0. 11.  1.  6. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  0. 23.] 
adversary cards in discard: [4. 8.] 
adversary owned cards: [23  8  8  8 15  3  0  0  0  4] -> size -> 10 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -80 

action type: take_action - action -1
Learning step: -4.378624439239502
desired expected reward: 6.92449426651001






Player: 1 
cards in hand: [ 3.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 23.] 
cards in discard: [4. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8  8 15  3  0  0  0  4] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [11.  6.  8. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10] -> size -> 17 
adversary victory points: -5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 23.] 
cards in discard: [4. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8  8 15  3  0  0  0  4] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [11.  6.  8. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10] -> size -> 17 
adversary victory points: -5
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [11.  6.  8. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29. 14.] 
expected returns: [[-2.1006453]
 [-2.1006453]
 [-2.1006453]
 [-2.1006453]
 [-2.1006453]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  8. 29. 14.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  8.  0.  8. 15.] 
adversary cards in discard: [ 4.  8.  3.  0. 23.] 
adversary owned cards: [23  8  8  8 15  3  0  0  0  4] -> size -> 10 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -100 

action type: buy - action -1.0
Learning step: -5.528679370880127
desired expected reward: 4.099615573883057





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-2.100645]
 [-2.100645]
 [-2.100645]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  8. 29. 14.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 24. 30. 24. 29.  8.  1.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  8.  0.  8. 15.] 
adversary cards in discard: [ 4.  8.  3.  0. 23.] 
adversary owned cards: [23  8  8  8 15  3  0  0  0  4] -> size -> 10 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -100 

action type: take_action - action -1.0
Learning step: -4.942232131958008
desired expected reward: -7.042877197265625



buy possibilites: [-1] 
expected returns: [[1.9817529]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  8. 29. 14.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 24. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  8.  0.  8. 15.] 
adversary cards in discard: [ 4.  8.  3.  0. 23.] 
adversary owned cards: [23  8  8  8 15  3  0  0  0  4] -> size -> 10 
adversary victory points: 4
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -100    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -411 

action type: buy - action 6.0
Learning step: -20.400379180908203
desired expected reward: -22.50102424621582






Player: 1 
cards in hand: [ 0.  8.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  8. 15.] 
cards in discard: [ 4.  8.  3.  0. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8  8 15  3  0  0  0  4] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 24. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 0. 10.  6.  1. 10.] 
adversary cards in discard: [ 6. 11.  6.  8. 29. 14.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
adversary victory points: -6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  8. 15.] 
cards in discard: [ 4.  8.  3.  0. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8  8 15  3  0  0  0  4] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 24. 30. 24. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 0. 10.  6.  1. 10.] 
adversary cards in discard: [ 6. 11.  6.  8. 29. 14.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
adversary victory points: -6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  8. 15.] 
cards in discard: [ 4.  8.  3.  0. 23.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8  8 15  3  0  0  0  4  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 0. 10.  6.  1. 10.] 
adversary cards in discard: [ 6. 11.  6.  8. 29. 14.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
adversary victory points: -6
player victory points: 5 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  6.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[15.541892]
 [12.09506 ]
 [12.09506 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  1. 10.] 
cards in discard: [ 6. 11.  6.  8. 29. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 8.  0. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8  8 15  3  0  0  0  4  3] -> size -> 11 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: buy - action -1
Learning step: -5.868031978607178
desired expected reward: -3.8862791061401367



action possibilites: [-1. 10. 11.] 
expected returns: [[19.830307]
 [17.35116 ]
 [18.603888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  1. 10. 11.] 
cards in discard: [ 6. 11.  6.  8. 29. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 8.  0. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8  8 15  3  0  0  0  4  3] -> size -> 11 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -101 

action type: take_action - action 10.0
Learning step: -5.1777262687683105
desired expected reward: 5.802365779876709





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[16.405409]
 [17.358303]
 [17.15254 ]
 [18.626335]
 [17.33348 ]
 [19.664417]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  1. 10. 11.] 
cards in discard: [ 6. 11.  6.  8. 29. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 8.  0. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8  8 15  3  0  0  0  4  3] -> size -> 11 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -101 

action type: take_action - action -1.0
Learning step: -5.637528896331787
desired expected reward: 14.19278335571289






Player: 1 
cards in hand: [ 8.  0. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  3.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8  8 15  3  0  0  0  4  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 6.  3.  6.  6. 15.] 
adversary cards in discard: [ 6. 11.  6.  8. 29. 14. 10.  0.  6.  1. 10. 11.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
adversary victory points: -6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  3.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8  8 15  3  0  0  0  4  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 6.  3.  6.  6. 15.] 
adversary cards in discard: [ 6. 11.  6.  8. 29. 14. 10.  0.  6.  1. 10. 11.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
adversary victory points: -6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  3.  3.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8  8 15  3  0  0  0  4  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 6.  3.  6.  6. 15.] 
adversary cards in discard: [ 6. 11.  6.  8. 29. 14. 10.  0.  6.  1. 10. 11.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
adversary victory points: -6
player victory points: 5 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  6.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[4.818076 ]
 [3.3386452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  6.  6. 15.] 
cards in discard: [ 6. 11.  6.  8. 29. 14. 10.  0.  6.  1. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [23.  4.  8.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 15.  3.  3.] 
adversary owned cards: [23  8  8  8 15  3  0  0  0  4  3  0] -> size -> 12 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: buy - action -1.0
Learning step: -6.933190822601318
desired expected reward: 12.731229782104492





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[2.6671774]
 [4.8810034]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  6.  6. 15.] 
cards in discard: [ 6. 11.  6.  8. 29. 14. 10.  0.  6.  1. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [23.  4.  8.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 15.  3.  3.] 
adversary owned cards: [23  8  8  8 15  3  0  0  0  4  3  0] -> size -> 12 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: take_action - action -1.0
Learning step: -6.216646194458008
desired expected reward: -1.1336126327514648



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [23.  4.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  4.  8.  0.  0.] 
cards in discard: [ 0.  8.  0. 15.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8  8 15  3  0  0  0  4  3  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  6. 10. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
adversary victory points: -6
player victory points: 5 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 8. 0. 0. 8.] 
cards in discard: [ 0.  8.  0. 15.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.] 
owned cards: [23  8  8  8 15  3  0  0  0  4  3  0] -> size -> 12 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 8. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  6. 10. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
adversary victory points: -6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0.] 
cards in discard: [ 0.  8.  0. 15.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [23  8  8 15  3  0  0  0  4  3  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  6. 10. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
adversary victory points: -6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0.] 
cards in discard: [ 0.  8.  0. 15.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [23  8  8 15  3  0  0  0  4  3  0] -> size -> 11 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 8. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  6. 10. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
adversary victory points: -6
player victory points: 5 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 10. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-2.1041727]
 [-2.1041727]
 [-2.1041727]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10. 11.  6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 23. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 4. 23.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8 15  3  0  0  0  4  3  0] -> size -> 11 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: buy - action -1.0
Learning step: -6.145522594451904
desired expected reward: -5.181956768035889



action possibilites: [-1] 
expected returns: [[0.6717913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  6.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 22. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 4. 23.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8 15  3  0  0  0  4  3  0] -> size -> 11 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    4    0] 
sum of rewards: -86 

action type: gain_card_n - action 2
Learning step: -4.179676055908203
desired expected reward: -6.283848762512207





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[0.15822601]
 [0.8615415 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  6.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 24. 30. 22. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 4. 23.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8 15  3  0  0  0  4  3  0] -> size -> 11 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action -1
Learning step: -4.521295070648193
desired expected reward: -3.849503755569458






Player: 1 
cards in hand: [ 4. 23.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 23.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8 15  3  0  0  0  4  3  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 22. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [10. 11. 15.  6.  6.] 
adversary cards in discard: [ 3. 11.  0.  6. 10.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [23  8  8 15  3  0  0  0  4  3  0] -> size -> 11 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 8. 24. 30. 22. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [10. 11. 15.  6.  6.] 
adversary cards in discard: [ 3. 11.  0.  6. 10.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [23  8  8 15  3  0  3  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 24. 30. 22. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [10. 11. 15.  6.  6.] 
adversary cards in discard: [ 3. 11.  0.  6. 10.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
adversary victory points: -5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [23  8  8 15  3  0  3  0] -> size -> 8 
action values: 0 
buys: 2 
player value: 2 
card supply: [ 8. 24. 30. 22. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [10. 11. 15.  6.  6.] 
adversary cards in discard: [ 3. 11.  0.  6. 10.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
adversary victory points: -5
player victory points: 2 


buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [23  8  8 15  3  0  3  0  3] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [10. 11. 15.  6.  6.] 
adversary cards in discard: [ 3. 11.  0.  6. 10.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
adversary victory points: -5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [23  8  8 15  3  0  3  0  3  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [10. 11. 15.  6.  6.] 
adversary cards in discard: [ 3. 11.  0.  6. 10.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
adversary victory points: -5
player victory points: 3 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [10. 11. 15.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
expected returns: [[24.41757 ]
 [22.561403]
 [23.533579]
 [22.663332]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15.  6.  6.] 
cards in discard: [ 3. 11.  0.  6. 10.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  3.  8.  0. 15.] 
adversary cards in discard: [ 3.  0. 23.  8.  0.] 
adversary owned cards: [23  8  8 15  3  0  3  0  3  0] -> size -> 10 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -90 

action type: buy - action -1.0
Learning step: -4.032042980194092
desired expected reward: -3.170501470565796



action possibilites: [-1] 
expected returns: [[2.205405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  6.  6.] 
cards in discard: [ 3. 11.  0.  6. 10.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  3.  8.  0. 15.] 
adversary cards in discard: [ 3.  0. 23.  8.  0.] 
adversary owned cards: [23  8  8 15  3  0  3  0  3  0] -> size -> 10 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: take_action - action 15.0
Learning step: -4.551820278167725
desired expected reward: 17.477008819580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[0.6596043]
 [2.61356  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  6.  6.] 
cards in discard: [ 3. 11.  0.  6. 10.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  3.  8.  0. 15.] 
adversary cards in discard: [ 3.  0. 23.  8.  0.] 
adversary owned cards: [23  8  8 15  3  0  3  0  3  0] -> size -> 10 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: take_action - action -1
Learning step: -3.5711629390716553
desired expected reward: -1.365757942199707






Player: 1 
cards in hand: [ 3.  3.  8.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8.  0. 15.] 
cards in discard: [ 3.  0. 23.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8 15  3  0  3  0  3  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  6. 29.  6.  8.] 
adversary cards in discard: [ 3. 11.  0.  6. 10.  6. 15. 10. 11.  6.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
adversary victory points: -5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3.  0. 23.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [23  8  8  3  0  3  0  3  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  6. 29.  6.  8.] 
adversary cards in discard: [ 3. 11.  0.  6. 10.  6. 15. 10. 11.  6.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
adversary victory points: -5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3.  0. 23.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [23  8  8  3  0  3  0  3  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  6. 29.  6.  8.] 
adversary cards in discard: [ 3. 11.  0.  6. 10.  6. 15. 10. 11.  6.  6.] 
adversary owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
adversary victory points: -5
player victory points: 3 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 3.  6. 29.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[ 0.6768577 ]
 [ 0.15602136]
 [-0.6125717 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 29.  6.  8.] 
cards in discard: [ 3. 11.  0.  6. 10.  6. 15. 10. 11.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [23.  3.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8  3  0  3  0  3  0] -> size -> 9 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -90 

action type: buy - action -1.0
Learning step: -4.6248369216918945
desired expected reward: -2.011267900466919



action possibilites: [-1] 
expected returns: [[12.0392685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  6.] 
cards in discard: [ 3. 11.  0.  6. 10.  6. 15. 10. 11.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [23.  3.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8  3  0  3  0  3  0] -> size -> 9 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: trash_cards_n_from_hand - action 0
Learning step: -2.575751543045044
desired expected reward: -4.643050670623779





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.797046]
 [11.860888]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  6.] 
cards in discard: [ 3. 11.  0.  6. 10.  6. 15. 10. 11.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [23.  3.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8  3  0  3  0  3  0] -> size -> 9 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1
Learning step: -3.2857367992401123
desired expected reward: 8.753531455993652



buy possibilites: [-1] 
expected returns: [[14.611778]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  6.] 
cards in discard: [ 3. 11.  0.  6. 10.  6. 15. 10. 11.  6.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [23.  3.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  8  3  0  3  0  3  0] -> size -> 9 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action 0.0
Learning step: -4.711087226867676
desired expected reward: 7.085959434509277






Player: 1 
cards in hand: [23.  3.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  8.  8.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  8  3  0  3  0  3  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 6. 15.  6. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [23  8  8  3  0  3  0  3  0] -> size -> 9 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 6. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 6. 15.  6. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [23  8  0  0  3  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 6. 15.  6. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [23  8  0  0  3  0] -> size -> 6 
action values: 0 
buys: 2 
player value: 1 
card supply: [ 6. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 6. 15.  6. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 1 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 6. 15.  6. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[10.394954]
 [ 9.563843]
 [ 9.021501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6. 14.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [23.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  0  3  0] -> size -> 6 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1
Learning step: -3.4794280529022217
desired expected reward: 11.132349967956543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 9.277123]
 [ 9.552479]
 [10.538799]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6. 14.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [23.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  0  3  0] -> size -> 6 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1.0
Learning step: -3.2067906856536865
desired expected reward: 6.369321823120117



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [23.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  0  0  3  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 8. 29. 10.  6.  0.] 
adversary cards in discard: [ 6. 15.  6. 14.  1.] 
adversary owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.] 
owned cards: [23  8  0  0  3  0] -> size -> 6 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 6. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 8. 29. 10.  6.  0.] 
adversary cards in discard: [ 6. 15.  6. 14.  1.] 
adversary owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [23  8  0  3  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 8. 29. 10.  6.  0.] 
adversary cards in discard: [ 6. 15.  6. 14.  1.] 
adversary owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [23  8  0  3  0] -> size -> 5 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 6. 24. 30. 21. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 8. 29. 10.  6.  0.] 
adversary cards in discard: [ 6. 15.  6. 14.  1.] 
adversary owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 1 


buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [23  8  0  3  0  3] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 24. 30. 20. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 8. 29. 10.  6.  0.] 
adversary cards in discard: [ 6. 15.  6. 14.  1.] 
adversary owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [23  8  0  3  0  3  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 24. 30. 20. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 8. 29. 10.  6.  0.] 
adversary cards in discard: [ 6. 15.  6. 14.  1.] 
adversary owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
expected returns: [[6.9327793]
 [5.8584805]
 [6.549569 ]
 [5.5233765]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 10.  6.  0.] 
cards in discard: [ 6. 15.  6. 14.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  6  6 11  1 14 29 15  6  6 10  0  6 11 10  6  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 20. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0] -> size -> 7 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1.0
Learning step: -3.852306842803955
desired expected reward: 6.6864914894104



action possibilites: [-1] 
expected returns: [[-2.1128788]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.] 
cards in discard: [ 6. 15.  6. 14.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 20. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0] -> size -> 7 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: trash_cards_n_from_hand - action 8
Learning step: -2.023435115814209
desired expected reward: -0.5055299997329712





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.1128788]
 [-2.1128788]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [ 6. 15.  6. 14.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 24. 30. 20. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0] -> size -> 7 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1
Learning step: -1.8418956995010376
desired expected reward: -3.9547743797302246






Player: 1 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  0  3  0  3  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 20. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [10.  6. 11.  6.  3.] 
adversary cards in discard: [ 6. 15.  6. 14.  1.  8. 29.  0.] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  0  3  0  3  0] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 24. 30. 20. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [10.  6. 11.  6.  3.] 
adversary cards in discard: [ 6. 15.  6. 14.  1.  8. 29.  0.] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  0  3  0  3  0  3] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 19. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [10.  6. 11.  6.  3.] 
adversary cards in discard: [ 6. 15.  6. 14.  1.  8. 29.  0.] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 3 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [10.  6. 11.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[1.721568 ]
 [1.0485984]
 [1.4970783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 11.  6.  3.] 
cards in discard: [ 6. 15.  6. 14.  1.  8. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 19. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  0.  8.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3] -> size -> 8 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1.0
Learning step: -3.2697722911834717
desired expected reward: -5.382651329040527





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[0.9103521]
 [1.9371799]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 11.  6.  3.] 
cards in discard: [ 6. 15.  6. 14.  1.  8. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 24. 30. 19. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  0.  8.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3] -> size -> 8 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1.0
Learning step: -3.4347176551818848
desired expected reward: -2.07565975189209



buy possibilites: [-1] 
expected returns: [[-1.9267364]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 11.  6.  3.] 
cards in discard: [ 6. 15.  6. 14.  1.  8. 29.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 19. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 3.  0.  8.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3] -> size -> 8 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action 0.0
Learning step: -4.988869667053223
desired expected reward: -4.078518390655518






Player: 1 
cards in hand: [ 3.  0.  8.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  0. 23.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  0  3  0  3  0  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 19. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 6.  0.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0] -> size -> 18 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [23  8  0  3  0  3  0  3] -> size -> 8 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 4. 24. 30. 19. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 6.  0.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0] -> size -> 18 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [23  8  0  3  0  3  0  3] -> size -> 8 
action values: 0 
buys: 2 
player value: 4 
card supply: [ 4. 24. 30. 19. 29.  8.  0.  6.  5.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 6.  0.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0] -> size -> 18 
adversary victory points: -3
player victory points: 3 


buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [23  8  0  3  0  3  0  3 11] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 24. 30. 19. 29.  8.  0.  6.  4.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [ 6.  0.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0] -> size -> 18 
adversary victory points: -3
player victory points: 3 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-1.7367618]
 [-1.995822 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  6. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 19. 29.  8.  0.  6.  4.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3 11] -> size -> 9 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -3.351203203201294
desired expected reward: -5.277939796447754



action possibilites: [-1] 
expected returns: [[2.783372]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3 11] -> size -> 9 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -33 

action type: gain_card_n - action 2
Learning step: -1.4817302227020264
desired expected reward: -3.594609022140503





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[1.9639634]
 [3.3527293]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3 11] -> size -> 9 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -1.9277321100234985
desired expected reward: 0.8556398153305054



buy possibilites: [-1] 
expected returns: [[-2.1128788]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [3. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3 11] -> size -> 9 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -67.0 

action type: buy - action 0.0
Learning step: -3.4957382678985596
desired expected reward: -1.5317713022232056






Player: 1 
cards in hand: [11.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  0  3  0  3  0  3 11] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  7.  9.  5. 10.  7.] 
adversary cards in hand: [29.  1.  0.  3.  6.] 
adversary cards in discard: [ 3.  0. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0] -> size -> 20 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [23  8  0  3  0  3  0  3 11 14] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [29.  1.  0.  3.  6.] 
adversary cards in discard: [ 3.  0. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0] -> size -> 20 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [23  8  0  3  0  3  0  3 11 14] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [29.  1.  0.  3.  6.] 
adversary cards in discard: [ 3.  0. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0] -> size -> 20 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [29.  1.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[7.0941887]
 [7.846695 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  3.  6.] 
cards in discard: [ 3.  0. 11.  6.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  3.  0.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3 11 14] -> size -> 10 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -2.5854108333587646
desired expected reward: -4.69828987121582



action possibilites: [-1.] 
expected returns: [[2.6667843]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0.] 
cards in discard: [ 3.  0. 11.  6.  0.  3.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  3.  0.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3 11 14] -> size -> 10 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: discard_n_cards - action 2
Learning step: -2.206655502319336
desired expected reward: 6.126509666442871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[0.07608199]
 [1.303121  ]
 [0.9960927 ]
 [0.9276341 ]
 [2.5730166 ]
 [2.7075186 ]
 [0.13220668]
 [1.223826  ]
 [1.4236399 ]
 [3.6541958 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0.] 
cards in discard: [ 3.  0. 11.  6.  0.  3.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  3.  0.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3 11 14] -> size -> 10 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -1.9445174932479858
desired expected reward: 0.7222667932510376



buy possibilites: [-1] 
expected returns: [[24.69334]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0.] 
cards in discard: [ 3.  0. 11.  6.  0.  3.  6.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 2. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  3.  0.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3 11 14] -> size -> 10 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -67.0 

action type: buy - action 0.0
Learning step: -2.798204183578491
desired expected reward: -2.7221193313598633






Player: 1 
cards in hand: [ 0.  3.  0.  8. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 23.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  0  3  0  3  0  3 11 14] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [ 6. 14. 11. 10.  8.] 
adversary cards in discard: [ 3.  0. 11.  6.  0.  3.  6.  0.  3.  0. 29.  1.  6.  0.] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  8. 23.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  0  3  0  3  0  3 11 14] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [ 6. 14. 11. 10.  8.] 
adversary cards in discard: [ 3.  0. 11.  6.  0.  3.  6.  0.  3.  0. 29.  1.  6.  0.] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  8. 23.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  0  3  0  3  0  3 11 14  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [ 6. 14. 11. 10.  8.] 
adversary cards in discard: [ 3.  0. 11.  6.  0.  3.  6.  0.  3.  0. 29.  1.  6.  0.] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 6. 14. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 10.  8.] 
expected returns: [[-2.1128788]
 [-2.1128788]
 [-2.1128788]
 [-2.1128788]
 [-2.1128788]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 11. 10.  8.] 
cards in discard: [ 3.  0. 11.  6.  0.  3.  6.  0.  3.  0. 29.  1.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  3. 14.  3. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  8. 23.] 
adversary owned cards: [23  8  0  3  0  3  0  3 11 14  0] -> size -> 11 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -4.132206916809082
desired expected reward: 20.561134338378906



action possibilites: [-1] 
expected returns: [[20.496527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 10.  8.] 
cards in discard: [ 3.  0. 11.  6.  0.  3.  6.  0.  3.  0. 29.  1.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [ 0. 14. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  8. 23.  3.  3.] 
adversary owned cards: [23  8  0  3  0  3  0  3 11 14  0] -> size -> 11 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action 14.0
Learning step: -1.2826100587844849
desired expected reward: -3.406973361968994





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[18.083603]
 [18.551212]
 [20.367329]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 10.  8.] 
cards in discard: [ 3.  0. 11.  6.  0.  3.  6.  0.  3.  0. 29.  1.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [ 0. 14. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  8. 23.  3.  3.] 
adversary owned cards: [23  8  0  3  0  3  0  3 11 14  0] -> size -> 11 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -2.444115161895752
desired expected reward: 18.052412033081055






Player: 1 
cards in hand: [ 0. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11.] 
cards in discard: [ 0.  0.  3.  0.  8. 23.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  0  3  0  3  0  3 11 14  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 18. 29.  8.  0.  6.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  6.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.] 
cards in discard: [ 0.  0.  3.  0.  8. 23.  3.  3. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [23  8  0  3  0  3  0  3 11 14  0 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 18. 29.  8.  0.  5.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  6.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [ 0.  0.  3.  0.  8. 23.  3.  3. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [23  8  0  3  0  3  0  3 11 14  0 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 24. 30. 18. 29.  8.  0.  5.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  6.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[7.92197  ]
 [6.4033384]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  6. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  0  6 11 10  6  3  0  0  3  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 18. 29.  8.  0.  5.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [23.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3 11 14  0 16] -> size -> 12 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -3.7030322551727295
desired expected reward: 16.664302825927734



action possibilites: [-1] 
expected returns: [[-2.1243634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  6 11 10  6  3  0  0  3  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 24. 30. 18. 29.  8.  0.  5.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [23.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3 11 14  0 16] -> size -> 12 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action 15.0
Learning step: -2.218351125717163
desired expected reward: 4.192708969116211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-2.1243634]
 [-2.1243634]
 [-2.1243634]
 [-2.1243634]
 [-2.1243634]
 [-2.1243634]
 [-2.1243634]
 [-2.1243634]
 [-2.1243634]
 [-2.1243634]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  6 11 10  6  3  0  0  3  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 24. 30. 18. 29.  8.  0.  5.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [23.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3 11 14  0 16] -> size -> 12 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -1.791580080986023
desired expected reward: -3.9159436225891113



Player 1 won the game! 



Player 0 bought cards:
Copper: 15 
Silver: 4 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 1 
Workshop: 2 
Chapel: 3 
Witch: 1 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [6. 0. 6.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  3  6 11  1 14 29 15  6  6  6 11 10  6  3  0  0  3  0  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0. 24. 30. 18. 29.  8.  0.  5.  4.  0.  8.  7.  6.  9.  5. 10.  7.] 
adversary cards in hand: [23.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [23  8  0  3  0  3  0  3 11 14  0 16] -> size -> 12 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5 -500   -2  -50    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -567 

action type: buy - action 0.0
Learning step: -28.2437801361084
desired expected reward: -30.36814308166504



