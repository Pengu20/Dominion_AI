 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.554703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0   20    0    0    0    0   -2    0 -300
    0    0] 
sum of rewards: -787 

action type: buy - action 6.0
Learning step: -23.674306869506836
desired expected reward: -21.53074836730957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.737865]
 [20.090462]
 [18.719925]
 [14.528031]
 [18.447235]
 [21.676735]
 [20.694672]
 [21.871578]
 [17.439075]
 [19.324137]
 [19.791666]
 [19.84643 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.542259156703949
desired expected reward: 19.43463897705078



buy possibilites: [-1] 
expected returns: [[20.619068]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.4012136161327362
desired expected reward: 19.68924903869629






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.460041]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5303512811660767
desired expected reward: 20.088716506958008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.019096]
 [23.356611]
 [21.986076]
 [17.863049]
 [24.948519]
 [23.960825]
 [22.590288]
 [23.112581]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5904597640037537
desired expected reward: 22.097227096557617



buy possibilites: [-1] 
expected returns: [[24.484097]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.49249935150146484
desired expected reward: 21.493579864501953






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.994278]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6087839007377625
desired expected reward: 23.87531280517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[24.335402]
 [26.677193]
 [22.996706]
 [25.306658]
 [22.494083]
 [21.155392]
 [25.033968]
 [28.263466]
 [27.281408]
 [30.343374]
 [28.458311]
 [24.043528]
 [24.146282]
 [25.910866]
 [21.848331]
 [26.3784  ]
 [26.433163]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6610872149467468
desired expected reward: 25.599769592285156



buy possibilites: [-1] 
expected returns: [[25.56918]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.5944275856018066
desired expected reward: 27.669038772583008






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 3.  0. 29.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 3.  0. 29.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 3.  0. 29.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.388409]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [11.  0.  0.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6497631072998047
desired expected reward: 24.919416427612305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.424444]
 [24.406506]
 [20.20578 ]
 [26.420774]
 [25.554867]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [11.  0.  0.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6566447615623474
desired expected reward: 24.801660537719727



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 1. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.756285]
 [25.623287]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6528958678245544
desired expected reward: 24.9019718170166



action possibilites: [-1] 
expected returns: [[22.556377]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -8.983400344848633
desired expected reward: 13.358034133911133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.663282]
 [22.935913]
 [21.606018]
 [17.644197]
 [21.344221]
 [24.486372]
 [23.526474]
 [24.676804]
 [20.377016]
 [22.186838]
 [22.643864]
 [22.697315]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.010481758043169975
desired expected reward: 22.566858291625977



buy possibilites: [-1] 
expected returns: [[26.037033]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [6. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: 0.07759460061788559
desired expected reward: 23.604068756103516






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  8. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  8. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  8. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.594381]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 6.  8. 11.  1.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6936236619949341
desired expected reward: 25.343408584594727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.674515]
 [22.992685]
 [21.63162 ]
 [17.687023]
 [24.575281]
 [23.59446 ]
 [22.233395]
 [22.763758]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 6.  8. 11.  1.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5816373229026794
desired expected reward: 21.691890716552734



buy possibilites: [-1] 
expected returns: [[20.78319]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 6.  8. 11.  1.  0.  3.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.12903499603271484
desired expected reward: 24.446247100830078






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 29.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3. 10.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  8.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[23.361383]
 [24.208765]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11  6  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  8.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10. 29.  0.  1.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5220768451690674
desired expected reward: 20.261112213134766



action possibilites: [-1] 
expected returns: [[19.910679]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  8.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10. 29.  0.  1.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 7
Learning step: 0.04774715378880501
desired expected reward: 20.42491340637207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.06529 ]
 [15.114025]
 [20.013319]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  8.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10. 29.  0.  1.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.04364696517586708
desired expected reward: 19.954326629638672






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10. 29.  0.  1.  3.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  8.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11] -> size -> 12 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10. 29.  0.  1.  3.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  8.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11] -> size -> 12 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10. 29.  0.  1.  3.  3. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11] -> size -> 12 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.426508]
 [25.234602]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  8.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10. 29.  0.  1.  3.  3. 10.  8.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4918891489505768
desired expected reward: 19.52142906188965



action possibilites: [-1] 
expected returns: [[23.707014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  7.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10. 29.  0.  1.  3.  3. 10.  8.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 5
Learning step: 0.3117925524711609
desired expected reward: 22.216161727905273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.840326]
 [24.089209]
 [22.77016 ]
 [18.837835]
 [25.624043]
 [24.677443]
 [23.349154]
 [23.865358]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  7.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10. 29.  0.  1.  3.  3. 10.  8.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.01309369970113039
desired expected reward: 23.693920135498047



buy possibilites: [-1] 
expected returns: [[26.753172]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 8. 11. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  6.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10. 29.  0.  1.  3.  3. 10.  8.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.5021870732307434
desired expected reward: 26.12622833251953






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10. 29.  0.  1.  3.  3. 10.  8.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  6.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  1.  0.  0.  6.] 
adversary cards in discard: [ 8. 11. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11] -> size -> 14 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10. 29.  0.  1.  3.  3. 10.  8.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  6.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  1.  0.  0.  6.] 
adversary cards in discard: [ 8. 11. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11] -> size -> 14 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10. 29.  0.  1.  3.  3. 10.  8.  0.  3.  3.  0.  0. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  6.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [11.  1.  0.  0.  6.] 
adversary cards in discard: [ 8. 11. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11] -> size -> 14 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [11.  1.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.084272]
 [25.789022]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  0.  6.] 
cards in discard: [ 8. 11. 11. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  6.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [23.  0.  3.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.688812255859375
desired expected reward: 26.064359664916992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.816946]
 [25.02409 ]
 [23.734503]
 [19.870314]
 [23.484709]
 [26.534506]
 [25.59683 ]
 [26.729906]
 [22.5385  ]
 [24.304663]
 [24.745642]
 [24.807058]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.  0.  6.] 
cards in discard: [ 8. 11. 11. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  6.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [23.  0.  3.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6137157082557678
desired expected reward: 23.485614776611328



buy possibilites: [-1] 
expected returns: [[18.442747]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.  0.  6.] 
cards in discard: [ 8. 11. 11. 11.  3.  0.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  9. 10.  6.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [23.  0.  3.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.5720738172531128
desired expected reward: 24.452016830444336






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [23.  0.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  9. 10.  6.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  1. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1] -> size -> 15 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  9. 10.  6.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  1. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1] -> size -> 15 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  3.  3. 29.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  6.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  1. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1] -> size -> 15 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 0.  8.  1. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[21.499231]
 [22.29017 ]
 [23.212175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1. 11.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  6.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 0. 23.  0.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4662286937236786
desired expected reward: 17.976518630981445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.597242]
 [21.80359 ]
 [20.507635]
 [16.66179 ]
 [23.298548]
 [22.376545]
 [21.08059 ]
 [21.585606]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1. 11.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  6.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 0. 23.  0.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5728035569190979
desired expected reward: 20.993452072143555



buy possibilites: [-1] 
expected returns: [[22.999062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1. 11.  3.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 0. 23.  0.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.0562351793050766
desired expected reward: 22.867942810058594






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 0. 23.  0.  3.  3. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [11. 11.  3.  6.  0.] 
adversary cards in discard: [11.  0.  8.  1. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11] -> size -> 16 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 23.  0.  3.  3. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [11. 11.  3.  6.  0.] 
adversary cards in discard: [11.  0.  8.  1. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11] -> size -> 16 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 23.  0.  3.  3. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [11. 11.  3.  6.  0.] 
adversary cards in discard: [11.  0.  8.  1. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11] -> size -> 16 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [11. 11.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[21.618145]
 [23.285053]
 [23.285053]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  6.  0.] 
cards in discard: [11.  0.  8.  1. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [10.  1. 10.  3.  0.] 
adversary cards in discard: [ 0. 23.  0.  3.  3. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5997768044471741
desired expected reward: 22.39928436279297



action possibilites: [-1] 
expected returns: [[25.55836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6.  0.] 
cards in discard: [11.  0.  8.  1. 11.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  9. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [10.  1. 10.  3.  0.] 
adversary cards in discard: [ 0. 23.  0.  3.  3. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 2
Learning step: 0.2846023738384247
desired expected reward: 18.743284225463867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.530436]
 [20.280272]
 [25.64188 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6.  0.] 
cards in discard: [11.  0.  8.  1. 11.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  9. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [10.  1. 10.  3.  0.] 
adversary cards in discard: [ 0. 23.  0.  3.  3. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06843560934066772
desired expected reward: 25.48992347717285



buy possibilites: [-1] 
expected returns: [[23.900335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6.  0.] 
cards in discard: [11.  0.  8.  1. 11.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  9. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [10.  1. 10.  3.  0.] 
adversary cards in discard: [ 0. 23.  0.  3.  3. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.004959583282470703
desired expected reward: 23.525476455688477






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [10.  1. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 10.  3.  0.] 
cards in discard: [ 0. 23.  0.  3.  3. 29.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  9. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [11.  0.  8.  1. 11.  3.  3.  0. 11. 11.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0] -> size -> 18 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  0.  0.] 
cards in discard: [ 0. 23.  0.  3.  3. 29.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  9. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [11.  0.  8.  1. 11.  3.  3.  0. 11. 11.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0] -> size -> 18 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  0.  0.] 
cards in discard: [ 0. 23.  0.  3.  3. 29.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 27. 30.  8.  9. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [11.  0.  8.  1. 11.  3.  3.  0. 11. 11.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0] -> size -> 18 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  0.  0.] 
cards in discard: [ 0. 23.  0.  3.  3. 29.  8.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 27. 30.  8.  9. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [11.  0.  8.  1. 11.  3.  3.  0. 11. 11.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0] -> size -> 18 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [11.  0.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.966717]
 [23.746956]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  1.  0.] 
cards in discard: [11.  0.  8.  1. 11.  3.  3.  0. 11. 11.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  9. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 23.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6243773698806763
desired expected reward: 23.275957107543945



action possibilites: [-1] 
expected returns: [[20.324106]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [11.  0.  8.  1. 11.  3.  3.  0. 11. 11.  3.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 23.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -8.965492248535156
desired expected reward: 11.997701644897461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.888565]
 [21.074903]
 [19.793612]
 [17.1629  ]
 [15.974186]
 [19.549896]
 [22.546734]
 [21.641682]
 [24.489357]
 [22.740345]
 [18.611488]
 [18.705935]
 [20.360394]
 [16.580885]
 [20.797722]
 [20.857124]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [11.  0.  8.  1. 11.  3.  3.  0. 11. 11.  3.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  5.  8. 10.  9. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 23.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.05958675220608711
desired expected reward: 20.38369369506836



buy possibilites: [-1] 
expected returns: [[22.196638]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [11.  0.  8.  1. 11.  3.  3.  0. 11. 11.  3.  6.  0.  6. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0  6 22] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  5.  8. 10.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 8. 23.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 65 

action type: buy - action 22.0
Learning step: 1.6856379508972168
desired expected reward: 18.266523361206055






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 8. 23.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  5.  8. 10.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 1.  0. 11.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0  6 22] -> size -> 20 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 23.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  5.  8. 10.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 1.  0. 11.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0  6 22] -> size -> 20 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1.  0. 11.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.696314]
 [26.58387 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  1.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0  6 22] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  5.  8. 10.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  0.] 
adversary cards in discard: [ 8. 23.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5442563891410828
desired expected reward: 21.652381896972656



action possibilites: [-1] 
expected returns: [[26.56602]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 3.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0  6 22 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  4.  8. 10.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  0.] 
adversary cards in discard: [ 8. 23.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 5
Learning step: 0.3074250817298889
desired expected reward: 23.358028411865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[25.246326]
 [27.680468]
 [26.243977]
 [23.333708]
 [21.932302]
 [25.97169 ]
 [29.356773]
 [28.325975]
 [31.56945 ]
 [29.577534]
 [24.943289]
 [25.04663 ]
 [26.877138]
 [22.655462]
 [27.365932]
 [27.432335]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0  6 22 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  4.  8. 10.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  0.] 
adversary cards in discard: [ 8. 23.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.058316342532634735
desired expected reward: 26.507701873779297



buy possibilites: [-1] 
expected returns: [[28.716705]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3.] 
cards in discard: [11. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0  6 22 11 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  0.] 
adversary cards in discard: [ 8. 23.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 65 

action type: buy - action 25.0
Learning step: 1.306203007698059
desired expected reward: 32.87565231323242






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.  0.] 
cards in discard: [ 8. 23.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [11. 25. 11.  1.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0  6 22 11 25] -> size -> 22 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  3.  0.] 
cards in discard: [ 8. 23.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [11. 25. 11.  1.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0  6 22 11 25] -> size -> 22 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  3.  0.] 
cards in discard: [ 8. 23.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [11. 25. 11.  1.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0  6 22 11 25] -> size -> 22 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [6. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[26.380318]
 [27.263601]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [11. 25. 11.  1.  0.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11  6  8 11 11 11  1 11  3  0  6 22 11 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [10.  0.  3.  0.  1.] 
adversary cards in discard: [ 8. 23.  0.  0.  0.  3.  3.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3] -> size -> 19 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7287943959236145
desired expected reward: 27.987911224365234



action possibilites: [-1] 
expected returns: [[26.773506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11. 25. 11.  1.  0.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [10.  0.  3.  0.  1.] 
adversary cards in discard: [ 8. 23.  0.  0.  0.  3.  3.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3] -> size -> 19 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 10
Learning step: -0.04048015549778938
desired expected reward: 25.67958641052246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.852478]
 [21.714905]
 [26.89069 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11. 25. 11.  1.  0.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [10.  0.  3.  0.  1.] 
adversary cards in discard: [ 8. 23.  0.  0.  0.  3.  3.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3] -> size -> 19 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.09105216711759567
desired expected reward: 26.682453155517578






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  1.] 
cards in discard: [ 8. 23.  0.  0.  0.  3.  3.  0. 29.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [11.  6.  0.  0. 11.] 
adversary cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25] -> size -> 18 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  1.] 
cards in discard: [ 8. 23.  0.  0.  0.  3.  3.  0. 29.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [11.  6.  0.  0. 11.] 
adversary cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25] -> size -> 18 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  1.] 
cards in discard: [ 8. 23.  0.  0.  0.  3.  3.  0. 29.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [11.  6.  0.  0. 11.] 
adversary cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25] -> size -> 18 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [11.  6.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[26.235992]
 [28.075243]
 [28.075243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0. 11.] 
cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  1.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6666430234909058
desired expected reward: 26.22404670715332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.402243]
 [25.37321 ]
 [21.240314]
 [27.380844]
 [26.518013]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0. 11.] 
cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  1.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6709747910499573
desired expected reward: 25.606731414794922



buy possibilites: [-1] 
expected returns: [[22.96399]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0. 11.] 
cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 25. 30.  8.  7. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  1.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3] -> size -> 20 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.546088218688965
desired expected reward: 11.69422435760498






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  1. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  7. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  3. 11. 11. 22.] 
adversary cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.  6. 11.  6.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6] -> size -> 19 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  7. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  3. 11. 11. 22.] 
adversary cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.  6. 11.  6.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6] -> size -> 19 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 26. 30. 25. 30.  8.  7. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  3. 11. 11. 22.] 
adversary cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.  6. 11.  6.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6] -> size -> 19 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 1. 0.] 
cards in discard: [1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  3. 11. 11. 22.] 
adversary cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.  6. 11.  6.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6] -> size -> 19 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [ 0.  3. 11. 11. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 22.] 
expected returns: [[26.04174 ]
 [27.736832]
 [27.736832]
 [21.987133]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 11. 22.] 
cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.  6. 11.  6.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  8.] 
adversary cards in discard: [ 1. 10.  0.  1.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.563340961933136
desired expected reward: 22.40064811706543



action possibilites: [-1] 
expected returns: [[23.84608]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 22.] 
cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.  6. 11.  6.  0.  0. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  6. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  8.] 
adversary cards in discard: [ 1. 10.  0.  1.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -9.049697875976562
desired expected reward: 15.953052520751953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.082891]
 [19.161911]
 [23.980692]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 22.] 
cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.  6. 11.  6.  0.  0. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 25. 30.  8.  6. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  8.] 
adversary cards in discard: [ 1. 10.  0.  1.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.032391585409641266
desired expected reward: 23.813688278198242



buy possibilites: [-1] 
expected returns: [[24.581264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 22.] 
cards in discard: [11. 25. 11.  1.  0.  1.  3.  8.  6. 11.  6.  0.  0. 11.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 25. 30.  8.  6. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  8.] 
adversary cards in discard: [ 1. 10.  0.  1.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.045616548508405685
desired expected reward: 22.128507614135742






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.  8.] 
cards in discard: [ 1. 10.  0.  1.  3.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 30.  8.  6. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [11.  3.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.  8.] 
cards in discard: [ 1. 10.  0.  1.  3.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 25. 30.  8.  6. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [11.  3.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  3.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[20.687553]
 [22.423277]
 [21.497046]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  0.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 30.  8.  6. 10.  4.  8.  9.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 3. 23.  0.  3.  0.] 
adversary cards in discard: [ 1. 10.  0.  1.  3.  1.  0.  0.  3.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6587576270103455
desired expected reward: 23.92250633239746



action possibilites: [-1] 
expected returns: [[20.789356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 6.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 30.  8.  6. 10.  4.  8.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [ 3. 23.  0.  3.  0.] 
adversary cards in discard: [ 1. 10.  0.  1.  3.  1.  0.  0.  3.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.22347621619701385
desired expected reward: 24.05054473876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.010387]
 [16.017754]
 [20.994055]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 6.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 25. 30.  8.  6. 10.  4.  8.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [ 3. 23.  0.  3.  0.] 
adversary cards in discard: [ 1. 10.  0.  1.  3.  1.  0.  0.  3.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.02726898156106472
desired expected reward: 20.816625595092773



buy possibilites: [-1] 
expected returns: [[23.029497]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 6.] 
cards in discard: [10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 25. 30.  8.  6. 10.  4.  8.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [ 3. 23.  0.  3.  0.] 
adversary cards in discard: [ 1. 10.  0.  1.  3.  1.  0.  0.  3.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.11805965006351471
desired expected reward: 19.243061065673828






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 3. 23.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  0.  3.  0.] 
cards in discard: [ 1. 10.  0.  1.  3.  1.  0.  0.  3.  3. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 25. 30.  8.  6. 10.  4.  8.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [ 3. 25.  1.  0. 11.] 
adversary cards in discard: [10.  0. 11.  3.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0] -> size -> 23 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 29.] 
cards in discard: [ 1. 10.  0.  1.  3.  1.  0.  0.  3.  3. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 25. 30.  8.  6. 10.  4.  8.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [ 3. 25.  1.  0. 11.] 
adversary cards in discard: [10.  0. 11.  3.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0] -> size -> 23 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 29.] 
cards in discard: [ 1. 10.  0.  1.  3.  1.  0.  0.  3.  3. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1] -> size -> 21 
action values: 0 
buys: 2 
player value: 3 
card supply: [24. 25. 30. 25. 30.  8.  6. 10.  4.  8.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [ 3. 25.  1.  0. 11.] 
adversary cards in discard: [10.  0. 11.  3.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0] -> size -> 23 
adversary victory points: -1
player victory points: 6 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 29.] 
cards in discard: [ 1. 10.  0.  1.  3.  1.  0.  0.  3.  3. 10.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 25. 30.  8.  6. 10.  4.  7.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [ 3. 25.  1.  0. 11.] 
adversary cards in discard: [10.  0. 11.  3.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0] -> size -> 23 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 29.] 
cards in discard: [ 1. 10.  0.  1.  3.  1.  0.  0.  3.  3. 10.  8.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 25. 30.  8.  6. 10.  4.  7.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [ 3. 25.  1.  0. 11.] 
adversary cards in discard: [10.  0. 11.  3.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0] -> size -> 23 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [ 3. 25.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[20.596075]
 [24.466948]
 [22.349028]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  1.  0. 11.] 
cards in discard: [10.  0. 11.  3.  8.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 30.  8.  6. 10.  4.  7.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6004889011383057
desired expected reward: 22.42900848388672



action possibilites: [-1] 
expected returns: [[26.05718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 11.  1. 11.] 
cards in discard: [10.  0. 11.  3.  8.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  4.  7.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6] -> size -> 24 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.010747146792709827
desired expected reward: 24.467504501342773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[24.668352]
 [26.790474]
 [25.523495]
 [23.002512]
 [21.774014]
 [25.309147]
 [28.275331]
 [27.360867]
 [30.386116]
 [28.506838]
 [24.395002]
 [24.487665]
 [26.080164]
 [22.407764]
 [26.508417]
 [26.560785]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 11.  1. 11.] 
cards in discard: [10.  0. 11.  3.  8.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  4.  7.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6] -> size -> 24 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.05158521607518196
desired expected reward: 26.00559425354004



buy possibilites: [-1] 
expected returns: [[21.51289]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 11.  1. 11.] 
cards in discard: [10.  0. 11.  3.  8.  0.  6. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  3.  7.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6] -> size -> 24 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 11.0
Learning step: -0.03737457096576691
desired expected reward: 28.23795509338379






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  3.  7.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [11.  6. 11.  0.  0.] 
adversary cards in discard: [10.  0. 11.  3.  8.  0.  6. 11. 25.  3.  1.  0. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11] -> size -> 24 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  3.  7.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [11.  6. 11.  0.  0.] 
adversary cards in discard: [10.  0. 11.  3.  8.  0.  6. 11. 25.  3.  1.  0. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11] -> size -> 24 
adversary victory points: -1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  6. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[21.008907]
 [22.547749]
 [22.547749]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 11.  0.  0.] 
cards in discard: [10.  0. 11.  3.  8.  0.  6. 11. 25.  3.  1.  0. 11.  1. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  3.  7.  9.  9. 10.  9.  7.  9. 10.] 
adversary cards in hand: [23.  1. 10.  1.  3.] 
adversary cards in discard: [6. 8. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6] -> size -> 24 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5629440546035767
desired expected reward: 20.9499454498291



action possibilites: [-1] 
expected returns: [[21.482656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.] 
cards in discard: [10.  0. 11.  3.  8.  0.  6. 11. 25.  3.  1.  0. 11.  1. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  3.  7.  9.  9. 10.  9.  6.  9. 10.] 
adversary cards in hand: [23.  1. 10.  1.  3.] 
adversary cards in discard: [6. 8. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6] -> size -> 24 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.23232346773147583
desired expected reward: 24.00713539123535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.66066 ]
 [20.521654]
 [16.81352 ]
 [22.350054]
 [21.563013]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  0.] 
cards in discard: [10.  0. 11.  3.  8.  0.  6. 11. 25.  3.  1.  0. 11.  1. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  3.  7.  9.  9. 10.  9.  6.  9. 10.] 
adversary cards in hand: [23.  1. 10.  1.  3.] 
adversary cards in discard: [6. 8. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6] -> size -> 24 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.021982382982969284
desired expected reward: 21.504638671875



buy possibilites: [-1] 
expected returns: [[25.412525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  0.] 
cards in discard: [10.  0. 11.  3.  8.  0.  6. 11. 25.  3.  1.  0. 11.  1. 11. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  3.  6.  9.  9. 10.  9.  6.  9. 10.] 
adversary cards in hand: [23.  1. 10.  1.  3.] 
adversary cards in discard: [6. 8. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6] -> size -> 24 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.28632986545562744
desired expected reward: 22.636383056640625






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [23.  1. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  1. 10.  1.  3.] 
cards in discard: [6. 8. 0. 0. 3. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  3.  6.  9.  9. 10.  9.  6.  9. 10.] 
adversary cards in hand: [10. 11.  0.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8] -> size -> 26 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  1. 10.  1.  3.] 
cards in discard: [6. 8. 0. 0. 3. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  3.  6.  9.  9. 10.  9.  6.  9. 10.] 
adversary cards in hand: [10. 11.  0.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8] -> size -> 26 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  1. 10.  1.  3.] 
cards in discard: [ 6.  8.  0.  0.  3.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  2.  6.  9.  9. 10.  9.  6.  9. 10.] 
adversary cards in hand: [10. 11.  0.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8] -> size -> 26 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [10. 11.  0.  6. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 22.] 
expected returns: [[16.142384]
 [15.692858]
 [17.689852]
 [12.191238]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  6. 22.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  2.  6.  9.  9. 10.  9.  6.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11] -> size -> 25 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7448448538780212
desired expected reward: 24.667680740356445



action possibilites: [-1] 
expected returns: [[15.484884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6. 22.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11] -> size -> 25 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.3135520815849304
desired expected reward: 19.281526565551758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.791801]
 [11.1635  ]
 [15.622168]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6. 22.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 25. 30.  8.  5. 10.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11] -> size -> 25 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1318769007921219
desired expected reward: 15.616761207580566



buy possibilites: [-1] 
expected returns: [[18.671213]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6. 22.] 
cards in discard: [10.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 25. 30.  8.  4. 10.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11] -> size -> 25 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.688858032226562
desired expected reward: 2.474641799926758






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 30.  8.  4. 10.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [10.  3.  0.  1. 25.] 
adversary cards in discard: [10.  6. 11. 10.  0.  6. 22.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6] -> size -> 28 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 25. 30.  8.  4. 10.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [10.  3.  0.  1. 25.] 
adversary cards in discard: [10.  6. 11. 10.  0.  6. 22.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6] -> size -> 28 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 25. 30. 25. 30.  8.  4. 10.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [10.  3.  0.  1. 25.] 
adversary cards in discard: [10.  6. 11. 10.  0.  6. 22.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6] -> size -> 28 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [10.  3.  0.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[20.574999]
 [20.084747]
 [24.240185]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  1. 25.] 
cards in discard: [10.  6. 11. 10.  0.  6. 22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  4. 10.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [29.  0.  1.  3. 10.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.  0.  8.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0] -> size -> 26 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4775121808052063
desired expected reward: 18.193700790405273



action possibilites: [-1] 
expected returns: [[17.156475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  1. 11. 11.] 
cards in discard: [10.  6. 11. 10.  0.  6. 22.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  3. 10.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [29.  0.  1.  3. 10.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.  0.  8.  0.  0.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6] -> size -> 27 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.08677053451538086
desired expected reward: 23.810346603393555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[15.792117]
 [17.80924 ]
 [16.594769]
 [13.081348]
 [19.169477]
 [18.34493 ]
 [17.130457]
 [17.58167 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  1. 11. 11.] 
cards in discard: [10.  6. 11. 10.  0.  6. 22.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 25. 30.  8.  3. 10.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [29.  0.  1.  3. 10.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.  0.  8.  0.  0.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6] -> size -> 27 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.11784084141254425
desired expected reward: 17.274316787719727



buy possibilites: [-1] 
expected returns: [[18.964584]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  1. 11. 11.] 
cards in discard: [10.  6. 11. 10.  0.  6. 22.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 25. 30. 25. 30.  8.  2. 10.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [29.  0.  1.  3. 10.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.  0.  8.  0.  0.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6] -> size -> 27 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.74331283569336
desired expected reward: 4.338035583496094






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [29.  0.  1.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  3. 10.] 
cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.  0.  8.  0.  0.  3.  3.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2. 10.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  1.  8. 11.] 
adversary cards in discard: [10.  6. 11. 10.  0.  6. 22.  6. 25. 10.  3.  0.  1. 11. 11.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6] -> size -> 29 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 10.  0.] 
cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.  0.  8.  0.  0.  3.  3.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 25. 30.  8.  2. 10.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  1.  8. 11.] 
adversary cards in discard: [10.  6. 11. 10.  0.  6. 22.  6. 25. 10.  3.  0.  1. 11. 11.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6] -> size -> 29 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 10.  0.] 
cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.  0.  8.  0.  0.  3.  3.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 25. 30. 25. 30.  8.  2. 10.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  1.  8. 11.] 
adversary cards in discard: [10.  6. 11. 10.  0.  6. 22.  6. 25. 10.  3.  0.  1. 11. 11.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6] -> size -> 29 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 10.  0.] 
cards in discard: [ 6.  8.  0.  0.  3.  0. 11. 23.  1. 10.  1.  3.  0.  8.  0.  0.  3.  3.
  6. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  1.  8. 11.] 
adversary cards in discard: [10.  6. 11. 10.  0.  6. 22.  6. 25. 10.  3.  0.  1. 11. 11.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6] -> size -> 29 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  1.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[14.695802]
 [15.35447 ]
 [16.08492 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  8. 11.] 
cards in discard: [10.  6. 11. 10.  0.  6. 22.  6. 25. 10.  3.  0.  1. 11. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  2.  6.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5559806227684021
desired expected reward: 18.40860366821289



action possibilites: [-1] 
expected returns: [[18.631487]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [10.  6. 11. 10.  0.  6. 22.  6. 25. 10.  3.  0.  1. 11. 11.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  2.  5.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 6
Learning step: 0.43734854459762573
desired expected reward: 11.380084037780762





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.201183]
 [19.02587 ]
 [17.930649]
 [14.677465]
 [17.759129]
 [20.31008 ]
 [19.509445]
 [20.530035]
 [16.954863]
 [18.412975]
 [18.77726 ]
 [18.82028 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [10.  6. 11. 10.  0.  6. 22.  6. 25. 10.  3.  0.  1. 11. 11.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  2.  5.  9.  9. 10.  9.  5.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.08810491114854813
desired expected reward: 18.71959114074707



buy possibilites: [-1] 
expected returns: [[22.767591]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [10.  6. 11. 10.  0.  6. 22.  6. 25. 10.  3.  0.  1. 11. 11.  8. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  2.  5.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 1.0331586599349976
desired expected reward: 21.563194274902344






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  2.  5.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [11.  8.  6.  0.  6.] 
adversary cards in discard: [10.  6. 11. 10.  0.  6. 22.  6. 25. 10.  3.  0.  1. 11. 11.  8. 29. 11.
  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29] -> size -> 31 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  2.  5.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [11.  8.  6.  0.  6.] 
adversary cards in discard: [10.  6. 11. 10.  0.  6. 22.  6. 25. 10.  3.  0.  1. 11. 11.  8. 29. 11.
  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29] -> size -> 31 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  1.  5.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [11.  8.  6.  0.  6.] 
adversary cards in discard: [10.  6. 11. 10.  0.  6. 22.  6. 25. 10.  3.  0.  1. 11. 11.  8. 29. 11.
  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29] -> size -> 31 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [11.  8.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[18.423012]
 [19.920895]
 [19.146408]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  6.  0.  6.] 
cards in discard: [10.  6. 11. 10.  0.  6. 22.  6. 25. 10.  3.  0.  1. 11. 11.  8. 29. 11.
  0.  0.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  1.  5.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11] -> size -> 29 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6302209496498108
desired expected reward: 22.137371063232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.806032]
 [14.240191]
 [18.506485]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  6.  0.  6.] 
cards in discard: [10.  6. 11. 10.  0.  6. 22.  6. 25. 10.  3.  0.  1. 11. 11.  8. 29. 11.
  0.  0.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  1.  5.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11] -> size -> 29 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5250791311264038
desired expected reward: 17.897932052612305



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  1.  5.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 8. 11.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29] -> size -> 31 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  1.  5.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 8. 11.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29] -> size -> 31 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  1.  4.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 8. 11.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29] -> size -> 31 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 8. 11.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[17.703568]
 [18.440094]
 [19.249199]
 [19.249199]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  1.  4.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [10. 23.  0.  8. 10.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8] -> size -> 30 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5080228447914124
desired expected reward: 17.99846076965332



action possibilites: [-1] 
expected returns: [[19.167633]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  3.] 
cards in discard: [11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  0.  4.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [10. 23.  0.  8. 10.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8] -> size -> 30 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 5
Learning step: 0.42969954013824463
desired expected reward: 16.815052032470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.54622 ]
 [14.780712]
 [19.349415]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  3.] 
cards in discard: [11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  0.  4.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [10. 23.  0.  8. 10.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8] -> size -> 30 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.06029857322573662
desired expected reward: 19.22793197631836






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [10. 23.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 23.  0.  8. 10.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  0.  4.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [11.  6.  0.  6. 10.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1. 23.  8. 10.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  8. 10.  1.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  0.  4.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [11.  6.  0.  6. 10.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  1.  0.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8] -> size -> 30 
action values: 2 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  0.  4.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [11.  6.  0.  6. 10.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1.  0. 11.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 23. 10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8] -> size -> 30 
action values: 3 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  0.  4.  9.  8. 10.  9.  5.  9. 10.] 
adversary cards in hand: [11.  6.  0.  6. 10.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 23. 10. 11.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8 15] -> size -> 31 
action values: 2 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [11.  6.  0.  6. 10.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 23. 10. 11.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8 15] -> size -> 31 
action values: 0 
buys: 2 
player value: 5 
card supply: [22. 25. 30. 25. 30.  8.  2.  9.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [11.  6.  0.  6. 10.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
adversary victory points: -3
player victory points: 4 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 23. 10. 11.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8 15 16] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 25. 30.  8.  2.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [11.  6.  0.  6. 10.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [11.  6.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[22.752453]
 [24.360474]
 [22.292707]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  6. 10.] 
cards in discard: [11. 11.  8.  0. 11.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [29.  1.  1. 16.  8.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8 15 16] -> size -> 32 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.48498961329460144
desired expected reward: 18.864423751831055



action possibilites: [-1. 11.] 
expected returns: [[21.723717]
 [23.232649]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  6.  3.] 
cards in discard: [11. 11.  8.  0. 11.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [29.  1.  1. 16.  8.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8 15 16] -> size -> 32 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.018662508577108383
desired expected reward: 22.311368942260742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.95556 ]
 [17.366371]
 [21.614494]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  6.  3.] 
cards in discard: [11. 11.  8.  0. 11.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 25. 30.  8.  2.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [29.  1.  1. 16.  8.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8 15 16] -> size -> 32 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.008700885809957981
desired expected reward: 21.732419967651367






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [29.  1.  1. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1. 16.  8.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3  1 10  0 10  8 23  0  1  3  3  1  8  0  6
 11  0  6 16 11  8 15 16] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 30.  8.  2.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [ 8. 25. 11. 29.  0.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  8.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 25. 30.  8.  2.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [ 8. 25. 11. 29.  0.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  8.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 30. 25. 30.  8.  2.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [ 8. 25. 11. 29.  0.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  8.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 25. 30.  8.  2.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [ 8. 25. 11. 29.  0.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 8. 25. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11. 29.] 
expected returns: [[11.967698]
 [12.540134]
 [14.599845]
 [13.139973]
 [13.310862]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 11. 29.  0.] 
cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 30.  8.  2.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.  0.  0. 16. 29.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0] -> size -> 33 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.657636821269989
desired expected reward: 20.956857681274414



action possibilites: [-1.  8. 11. 11.] 
expected returns: [[21.382416]
 [22.083364]
 [22.801266]
 [22.801266]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0. 11.] 
cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 25. 30.  8.  2.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.  0.  0. 16. 29.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0] -> size -> 33 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 2
Learning step: 0.38710227608680725
desired expected reward: 10.314563751220703



action possibilites: [-1] 
expected returns: [[20.781092]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.] 
cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 25. 30.  8.  2.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.  0.  0. 16. 29.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0] -> size -> 33 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 1
Learning step: 0.8870440721511841
desired expected reward: 22.59229278564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.17694 ]
 [19.903505]
 [16.633427]
 [21.546947]
 [20.802372]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.] 
cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 30. 25. 30.  8.  2.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.  0.  0. 16. 29.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0] -> size -> 33 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.6365619897842407
desired expected reward: 21.417654037475586



buy possibilites: [-1] 
expected returns: [[21.973312]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.] 
cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 24. 30. 25. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.  0.  0. 16. 29.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0] -> size -> 33 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -265.0 

action type: buy - action 6.0
Learning step: -8.218282699584961
desired expected reward: 8.415145874023438






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.  0.  0. 16. 29.  1.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 25. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [11. 11.  1.  0.  6.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6. 29. 11.  8.
  0. 11.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6] -> size -> 34 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.  0.  0. 16. 29.  1.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 30. 25. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [11. 11.  1.  0.  6.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6. 29. 11.  8.
  0. 11.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6] -> size -> 34 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.  0.  3.  3.  0.  6. 15. 16. 10. 23. 10. 11.
  0.  8.  1.  0.  0.  0. 16. 29.  1.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [11. 11.  1.  0.  6.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6. 29. 11.  8.
  0. 11.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6] -> size -> 34 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [11. 11.  1.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[11.302853]
 [12.746093]
 [12.746093]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  1.  0.  6.] 
cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6. 29. 11.  8.
  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  9.] 
adversary cards in hand: [23.  6.  6. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0  0] -> size -> 34 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.679406464099884
desired expected reward: 21.29390525817871



action possibilites: [-1] 
expected returns: [[18.487316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  6.] 
cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6. 29. 11.  8.
  0. 11. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  8.] 
adversary cards in hand: [23.  6.  6. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0  0] -> size -> 34 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.7054418325424194
desired expected reward: 14.661274909973145





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[16.95266 ]
 [18.891527]
 [17.716717]
 [14.281484]
 [19.420694]
 [18.228317]
 [18.648634]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.  6.] 
cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6. 29. 11.  8.
  0. 11. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 25. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  8.] 
adversary cards in hand: [23.  6.  6. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0  0] -> size -> 34 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.08513202518224716
desired expected reward: 18.57244873046875



buy possibilites: [-1] 
expected returns: [[15.815091]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.  6.] 
cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6. 29. 11.  8.
  0. 11. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 24. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  8.] 
adversary cards in hand: [23.  6.  6. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0  0] -> size -> 34 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -1.  0.  0.  2.  0.] 
sum of rewards: 16.0 

action type: buy - action 3.0
Learning step: 0.11455690115690231
desired expected reward: 17.831275939941406






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [23.  6.  6. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  6.  6. 29.  1.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 24. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  1. 22.  0. 10.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6. 29. 11.  8.
  0. 11. 15.  3. 11. 11.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15  3] -> size -> 36 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1. 23. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  6.  1. 15.] 
cards in discard: [6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 24. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  1. 22.  0. 10.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6. 29. 11.  8.
  0. 11. 15.  3. 11. 11.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15  3] -> size -> 36 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  6.  1. 15.] 
cards in discard: [6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 24. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  1. 22.  0. 10.] 
adversary cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6. 29. 11.  8.
  0. 11. 15.  3. 11. 11.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15  3] -> size -> 36 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  1. 22.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
expected returns: [[15.676813]
 [12.716791]
 [15.3368  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 22.  0. 10.] 
cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6. 29. 11.  8.
  0. 11. 15.  3. 11. 11.  1.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 24. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 16.  0. 11.  0.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0  0] -> size -> 34 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.46908625960350037
desired expected reward: 15.346004486083984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.341687 ]
 [15.8421335]
 [14.9312105]
 [12.299864 ]
 [14.799742 ]
 [16.248447 ]
 [17.053667 ]
 [14.133668 ]
 [15.328138 ]
 [15.628223 ]
 [15.6567955]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 22.  0. 10.] 
cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6. 29. 11.  8.
  0. 11. 15.  3. 11. 11.  1.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 24. 30. 24. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 16.  0. 11.  0.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0  0] -> size -> 34 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.457526832818985
desired expected reward: 15.219287872314453



buy possibilites: [-1] 
expected returns: [[18.075134]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 22.  0. 10.] 
cards in discard: [11. 11.  8.  0. 11.  3. 10. 11.  6.  0.  6.  3. 25.  1.  6. 29. 11.  8.
  0. 11. 15.  3. 11. 11.  1.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 24. 30. 24. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 16.  0. 11.  0.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0  0] -> size -> 34 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -2.  0.  0.  0.  0.] 
sum of rewards: -7.0 

action type: buy - action 0.0
Learning step: -0.44637709856033325
desired expected reward: 13.895310401916504






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0. 11.  0.] 
cards in discard: [ 6. 29. 23.  6.  1. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6 11
  0  6 16 11  8 15 16  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 24. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  6.  8.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 24. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  6.  8.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 24. 30. 24. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  6.  8.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 24. 30. 23. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  6.  8.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  6.  8.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[15.854331]
 [16.587965]
 [15.477991]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  6. 10.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0  6 22 11 25  6  6  0 10  0 11
 10  8 10  6  6  8 29 11  1  6 15  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 23. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  4.  9.  8.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3] -> size -> 35 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5232425332069397
desired expected reward: 17.551891326904297



action possibilites: [-1] 
expected returns: [[14.243812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 23. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  4.  9.  8.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3] -> size -> 35 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.042302798479795456
desired expected reward: 18.617544174194336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.029443]
 [10.784268]
 [14.505424]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 24. 30. 23. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  4.  9.  8.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3] -> size -> 35 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1604405790567398
desired expected reward: 14.404252052307129






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 3.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 23. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  4.  9.  8.] 
adversary cards in hand: [ 6. 11.  0.  1.  6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0. 3.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 30. 23. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  4.  9.  8.] 
adversary cards in hand: [ 6. 11.  0.  1.  6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0. 3.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  4.  9.  8.] 
adversary cards in hand: [ 6. 11.  0.  1.  6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [ 6. 11.  0.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[18.252872]
 [19.855064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  1.  6.] 
cards in discard: [8. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  4.  9.  8.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3] -> size -> 36 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.38341373205184937
desired expected reward: 14.122010231018066





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[16.734167]
 [18.723724]
 [17.514439]
 [14.0506  ]
 [19.252954]
 [18.042366]
 [18.458258]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  1.  6.] 
cards in discard: [8. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 24. 30. 22. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  4.  9.  8.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3] -> size -> 36 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.509823203086853
desired expected reward: 17.74304962158203



buy possibilites: [-1] 
expected returns: [[18.013954]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  1.  6.] 
cards in discard: [ 8.  0. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3] -> size -> 36 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: 0.03787553682923317
desired expected reward: 18.080242156982422






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 6.  8. 11. 11.  1.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10] -> size -> 35 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 24. 30. 22. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 6.  8. 11. 11.  1.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10] -> size -> 35 
adversary victory points: -1
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  8. 11. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[14.868081]
 [15.548772]
 [16.223427]
 [16.223427]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 11. 11.  1.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 1. 16. 10.  0.  8.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.
  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3] -> size -> 36 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5243356823921204
desired expected reward: 17.4896183013916



action possibilites: [-1] 
expected returns: [[19.501982]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 11.  1.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 22. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 1. 16. 10.  0.  8.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.
  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3] -> size -> 36 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0  9  0] 
sum of rewards: 23 

action type: gain_card_n - action 1
Learning step: 0.4419041872024536
desired expected reward: 15.537457466125488





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.946743]
 [18.699455]
 [15.328192]
 [20.374887]
 [19.608433]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 11.  1.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 23. 30. 22. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 1. 16. 10.  0.  8.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.
  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3] -> size -> 36 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.062216777354478836
desired expected reward: 19.564199447631836






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 1. 16. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16. 10.  0.  8.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.
  0.  0.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 22. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 0. 11. 22. 25. 10.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10  1] -> size -> 36 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16. 10.  0.  8.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.
  0.  0.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 22. 30.  8.  1.  8.  0.  4.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 0. 11. 22. 25. 10.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10  1] -> size -> 36 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16. 10.  0.  8.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.
  0.  0.  3.  0.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 22. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 0. 11. 22. 25. 10.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10  1] -> size -> 36 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [ 0. 11. 22. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22. 25. 10.] 
expected returns: [[14.394958 ]
 [15.6177025]
 [11.504883 ]
 [17.072184 ]
 [14.07295  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 22. 25. 10.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 22. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  0.  3.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.
  0.  0.  3.  0.  3.  8.  1. 16. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8] -> size -> 37 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5803281664848328
desired expected reward: 19.028106689453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.133325 ]
 [11.2173395]
 [14.460302 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 22. 25. 10.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 23. 30. 22. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  0.  3.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.
  0.  0.  3.  0.  3.  8.  1. 16. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8] -> size -> 37 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.44281136989593506
desired expected reward: 13.952146530151367



buy possibilites: [-1] 
expected returns: [[12.284624]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 22. 25. 10.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10  1  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 23. 30. 22. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  0.  3.] 
adversary cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.
  0.  0.  3.  0.  3.  8.  1. 16. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8] -> size -> 37 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -2.  0.  0.  0.  0.] 
sum of rewards: -7.0 

action type: buy - action 0.0
Learning step: -0.4750112295150757
desired expected reward: 12.65831470489502






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  3.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.
  0.  0.  3.  0.  3.  8.  1. 16. 10.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 22. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [11.  8.  0. 11.  3.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10  1  0] -> size -> 37 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.
  0.  0.  3.  0.  3.  8.  1. 16. 10.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 22. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [11.  8.  0. 11.  3.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10  1  0] -> size -> 37 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.
  0.  0.  3.  0.  3.  8.  1. 16. 10.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 22. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [11.  8.  0. 11.  3.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10  1  0] -> size -> 37 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 6. 29. 23.  6.  1. 15. 10.  3. 16.  0.  0.  0.  3.  0.  8.  8.  0.  3.
  0.  0.  3.  0.  3.  8.  1. 16. 10.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 21. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [11.  8.  0. 11.  3.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.] 
adversary owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10  1  0] -> size -> 37 
adversary victory points: -1
player victory points: 7 





Player: 0 
cards in hand: [11.  8.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[13.34572 ]
 [14.656878]
 [13.995273]
 [14.656878]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 11.  3.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 11  8 11 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10
  6  6  8 29 11  1  6 15  3  0 10  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 21. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 3.  6.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3] -> size -> 38 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3687843084335327
desired expected reward: 11.915840148925781



action possibilites: [-1] 
expected returns: [[15.851644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6
  8 29 11  1  6 15  3  0 10  1  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 21. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 3.  6.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3] -> size -> 38 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.3329862654209137
desired expected reward: 9.781519889831543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.421942]
 [11.776365]
 [16.072227]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6
  8 29 11  1  6 15  3  0 10  1  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 23. 30. 21. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 3.  6.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3] -> size -> 38 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.12655983865261078
desired expected reward: 15.978203773498535






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 21. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 0. 29.  3.  6. 11.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6
  8 29 11  1  6 15  3  0 10  1  0] -> size -> 35 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 21. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 0. 29.  3.  6. 11.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6
  8 29 11  1  6 15  3  0 10  1  0] -> size -> 35 
adversary victory points: -1
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[12.80011 ]
 [14.418804]
 [14.213107]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  6. 11.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6
  8 29 11  1  6 15  3  0 10  1  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 21. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3] -> size -> 38 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.48587772250175476
desired expected reward: 15.58635139465332



action possibilites: [-1. 11.] 
expected returns: [[14.503907]
 [16.048681]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6
  8 29 11  1  6 15  3  0 10  1  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 23. 30. 21. 30.  8.  1.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3] -> size -> 38 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.2202722728252411
desired expected reward: 13.278633117675781



action possibilites: [-1] 
expected returns: [[15.530942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6
  8 29 11  1  6 15  3  0 10  1  0  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 23. 30. 21. 30.  8.  0.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3] -> size -> 38 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0    0    0    0   40    0    0    0    0   -1    0 -300
    0    0] 
sum of rewards: -266 

action type: gain_card_n - action 3
Learning step: -8.226298332214355
desired expected reward: 5.419486045837402





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[14.165541]
 [15.82331 ]
 [14.81138 ]
 [16.261286]
 [15.249359]
 [15.579378]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6
  8 29 11  1  6 15  3  0 10  1  0  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 23. 30. 21. 30.  8.  0.  8.  0.  3.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3] -> size -> 38 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.7468668222427368
desired expected reward: 16.277809143066406



buy possibilites: [-1] 
expected returns: [[14.386762]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.  6.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6
  8 29 11  1  6 15  3  0 10  1  0  6  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 23. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3] -> size -> 38 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0. -2.  0.  0.  2.  0.] 
sum of rewards: 35.0 

action type: buy - action 8.0
Learning step: 0.7132223844528198
desired expected reward: 16.97450828552246






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 3.  6.  0.  0. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 0.  3. 15. 10.  1.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.  6.  6.  8. 29. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6
  8 29 11  1  6 15  3  0 10  1  0  6  8] -> size -> 37 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 3.  6.  0.  0. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 23. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 0.  3. 15. 10.  1.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.  6.  6.  8. 29. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6
  8 29 11  1  6 15  3  0 10  1  0  6  8] -> size -> 37 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 22. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [ 0.  3. 15. 10.  1.] 
adversary cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.  6.  6.  8. 29. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6
  8 29 11  1  6 15  3  0 10  1  0  6  8] -> size -> 37 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [ 0.  3. 15. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[11.4013195]
 [11.395314 ]
 [11.0765505]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 10.  1.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.  6.  6.  8. 29. 11.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6
  8 29 11  1  6 15  3  0 10  1  0  6  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1] -> size -> 39 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.46281513571739197
desired expected reward: 13.923946380615234



action possibilites: [-1] 
expected returns: [[11.751004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.  6.  6.  8. 29. 11.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 22. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1] -> size -> 39 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.23152613639831543
desired expected reward: 11.626840591430664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[10.3411875]
 [12.006556 ]
 [10.989944 ]
 [ 9.043235 ]
 [10.851737 ]
 [12.45372  ]
 [14.781027 ]
 [13.315582 ]
 [10.090262 ]
 [10.160831 ]
 [11.429935 ]
 [ 8.570786 ]
 [11.755615 ]
 [11.761625 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.  6.  6.  8. 29. 11.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 22. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1] -> size -> 39 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.22304125130176544
desired expected reward: 11.974045753479004



buy possibilites: [-1] 
expected returns: [[15.638961]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.] 
cards in discard: [ 8.  0. 10.  6. 11.  0.  1.  6.  1. 11.  6.  8. 11.  1.  0.  0. 11. 22.
 25. 10.  8.  0.  3.  6.  6.  8. 29. 11.  0.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1] -> size -> 39 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.  -2.   0.   0.
  4.5  0. ] 
sum of rewards: 17.5 

action type: buy - action 1.0
Learning step: 0.3290124237537384
desired expected reward: 12.33556842803955






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [25. 22.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1] -> size -> 37 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  3.  9.  8.] 
adversary cards in hand: [25. 22.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1] -> size -> 37 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  8.] 
adversary cards in hand: [25. 22.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1] -> size -> 37 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [25. 22.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 22. 11. 11.] 
expected returns: [[ 9.880214]
 [12.766876]
 [ 7.053864]
 [11.186799]
 [11.186799]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 22.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  8.] 
adversary cards in hand: [15. 16. 10. 29.  6.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10] -> size -> 40 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5048731565475464
desired expected reward: 15.134087562561035



action possibilites: [-1] 
expected returns: [[13.6352]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 22.  0. 11.] 
cards in discard: [15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [15. 16. 10. 29.  6.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10] -> size -> 40 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0 16  0] 
sum of rewards: 28 

action type: gain_card_n - action 8
Learning step: 0.6673905849456787
desired expected reward: 11.201753616333008





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.3096 ]
 [13.71215]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 22.  0. 11.] 
cards in discard: [15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [15. 16. 10. 29.  6.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10] -> size -> 40 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1790308803319931
desired expected reward: 13.814229965209961






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [15. 16. 10. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16. 10. 29.  6.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [ 0. 10.  3. 29. 11.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15] -> size -> 38 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16. 10. 29.  6.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10] -> size -> 40 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [ 0. 10.  3. 29. 11.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15] -> size -> 38 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16. 10. 29.  6.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [ 0. 10.  3. 29. 11.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15] -> size -> 38 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [ 0. 10.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[12.608092 ]
 [12.3162565]
 [14.056179 ]
 [13.876256 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 29. 11.] 
cards in discard: [15. 11. 25. 22.  0. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0] -> size -> 41 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4208472669124603
desired expected reward: 13.291302680969238



action possibilites: [-1. 10. 11.] 
expected returns: [[17.078169]
 [16.76943 ]
 [18.409391]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0] -> size -> 41 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0.29412174224853516
desired expected reward: 11.656041145324707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[15.711773]
 [16.342638]
 [17.780107]
 [17.08457 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0] -> size -> 41 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.11552324146032333
desired expected reward: 17.19369125366211



buy possibilites: [-1] 
expected returns: [[16.418308]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0] -> size -> 41 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -4.  0.  0.  0.  0.] 
sum of rewards: 11.0 

action type: buy - action 0.0
Learning step: 0.031039036810398102
desired expected reward: 15.742813110351562






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [10. 15. 11.  6.  1.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [10. 15. 11.  6.  1.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 21. 30. 21. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [10. 15. 11.  6.  1.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [10. 15. 11.  6.  1.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [10. 15. 11.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[13.441413]
 [13.151801]
 [13.448018]
 [14.808861]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 11.  6.  1.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [10.  3.  8.  3.  3.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3] -> size -> 42 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4962654113769531
desired expected reward: 15.922042846679688



action possibilites: [-1] 
expected returns: [[8.82147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  6.  1.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [10.  3.  8.  3.  3.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3] -> size -> 42 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.13918490707874298
desired expected reward: 13.587203025817871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[7.7132964]
 [8.23118  ]
 [9.455061 ]
 [8.853009 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  6.  1.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [10.  3.  8.  3.  3.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3] -> size -> 42 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.27714183926582336
desired expected reward: 9.098611831665039






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [10.  3.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  3.  3.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [ 0.  6.  1. 10.  6.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  3.  3.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [ 0.  6.  1. 10.  6.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  3.  3.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [ 0.  6.  1. 10.  6.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [ 0.  6.  1. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[14.2654085]
 [13.970046 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  1. 10.  6.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [23.  0.  8.  3.  0.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.  0. 10.  3.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3  0] -> size -> 43 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.26704391837120056
desired expected reward: 8.585963249206543



action possibilites: [-1.  8.] 
expected returns: [[13.470564]
 [14.107444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 6. 8.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [23.  0.  8.  3.  0.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.  0. 10.  3.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3  0] -> size -> 43 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.1763519048690796
desired expected reward: 14.14639663696289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[12.2289505]
 [13.7013235]
 [12.787897 ]
 [14.097968 ]
 [13.178296 ]
 [13.461088 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 6. 8.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  2.  9.  7.] 
adversary cards in hand: [23.  0.  8.  3.  0.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.  0. 10.  3.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3  0] -> size -> 43 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.18672657012939453
desired expected reward: 13.657289505004883



buy possibilites: [-1] 
expected returns: [[16.971542]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 6. 8.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [23.  0.  8.  3.  0.] 
adversary cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.  0. 10.  3.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3  0] -> size -> 43 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0 18  0] 
sum of rewards: 28 

action type: buy - action 10.0
Learning step: 0.6228523254394531
desired expected reward: 13.801148414611816






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [23.  0.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  8.  3.  0.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.  0. 10.  3.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  3 10  0 10  8 23  0  1  3  3  1  8  0  6  0
  6 16 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [0. 6. 0. 3. 6.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10] -> size -> 40 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.  0. 10.  3.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 16
 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [0. 6. 0. 3. 6.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10] -> size -> 40 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.  0. 10.  3.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 16
 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [0. 6. 0. 3. 6.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10] -> size -> 40 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 3.  6.  0.  0. 11.  1.  3.  0.  0.  1.  0. 10.  0.  0.  0.  3.  1.  0.
 15. 16. 10. 29.  6.  3. 10.  3.  3.  0.  0.  8.  0. 10.  3.  8.  3.  3.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 16
 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [0. 6. 0. 3. 6.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10] -> size -> 40 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [0. 6. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[12.510987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 6.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [ 1.  3.  3.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 16
 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0] -> size -> 42 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5277808904647827
desired expected reward: 16.443761825561523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[11.24727 ]
 [11.861411]
 [13.262284]
 [12.584589]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 6.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 21. 30. 20. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [ 1.  3.  3.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 16
 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0] -> size -> 42 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.394672155380249
desired expected reward: 12.116314888000488



buy possibilites: [-1] 
expected returns: [[13.415173]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 6.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 19. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [ 1.  3.  3.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 16
 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0] -> size -> 42 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -6  0  0  8  0] 
sum of rewards: -3 

action type: buy - action 3.0
Learning step: -0.3040122091770172
desired expected reward: 11.557397842407227






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  3.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3.  8. 16.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 16
 11  8 15 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 19. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [11.  1.  8.  1. 11.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.  0.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10  3] -> size -> 41 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 11  8 15
 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 19. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [11.  1.  8.  1. 11.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.  0.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10  3] -> size -> 41 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 11  8 15
 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 21. 30. 19. 30.  8.  0.  8.  0.  2.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [11.  1.  8.  1. 11.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.  0.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10  3] -> size -> 41 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [8.] 
cards in deck: 37 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 11  8 15
 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 19. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [11.  1.  8.  1. 11.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.  0.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10  3] -> size -> 41 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [11.  1.  8.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[12.685113]
 [13.746689]
 [13.248278]
 [13.746689]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  8.  1. 11.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.  0.  6.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 19. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [8. 8. 1.] 
adversary owned cards: [ 0  0  0  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 11  8 15
 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0  8] -> size -> 40 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.41139090061187744
desired expected reward: 13.00378131866455





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[11.647495]
 [12.906449]
 [12.125821]
 [12.027391]
 [13.248278]
 [13.89405 ]
 [11.446909]
 [12.462712]
 [12.702205]
 [12.685114]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  8.  1. 11.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.  0.  6.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 21. 30. 19. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [8. 8. 1.] 
adversary owned cards: [ 0  0  0  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 11  8 15
 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0  8] -> size -> 40 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3962528705596924
desired expected reward: 12.288860321044922



buy possibilites: [-1] 
expected returns: [[11.329711]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  8.  1. 11.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.  0.  6.  0.  3.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10  3  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 20. 30. 19. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [8. 8. 1.] 
adversary owned cards: [ 0  0  0  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 11  8 15
 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0  8] -> size -> 40 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  -7.   0.   0.
  4.5  0. ] 
sum of rewards: -7.5 

action type: buy - action 1.0
Learning step: -0.49323147535324097
desired expected reward: 12.413217544555664






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [8. 8. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 11  8 15
 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 19. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [3. 1. 0. 8. 0.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.  0.  6.  0.  3.  6.  1. 11.  1.  8.  1.
 11.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10  3  1] -> size -> 42 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [8. 8. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 11  8 15
 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 20. 30. 19. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [3. 1. 0. 8. 0.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.  0.  6.  0.  3.  6.  1. 11.  1.  8.  1.
 11.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10  3  1] -> size -> 42 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [8. 8. 1. 3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 11  8 15
 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [3. 1. 0. 8. 0.] 
adversary cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.  0.  6.  0.  3.  6.  1. 11.  1.  8.  1.
 11.] 
adversary owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10  3  1] -> size -> 42 
adversary victory points: -1
player victory points: 7 





Player: 0 
cards in hand: [3. 1. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[11.742175]
 [12.290643]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 8. 0.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.  0.  6.  0.  3.  6.  1. 11.  1.  8.  1.
 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8
 29 11  1  6 15  3  0 10  1  0  6  8  1 15  0 10  3  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [ 0.  8. 10.  0.  8.] 
adversary cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 11  8 15
 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 41 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.36314311623573303
desired expected reward: 10.966567993164062



action possibilites: [-1] 
expected returns: [[10.3634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.  0.  6.  0.  3.  6.  1. 11.  1.  8.  1.
 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8 29 11  1
  6 15  3  0 10  1  0  6  8  1 15  0 10  3  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [ 0.  8. 10.  0.  8.] 
adversary cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 11  8 15
 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 41 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: 0.1900964081287384
desired expected reward: 12.48073959350586





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.2270355]
 [10.3634   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15. 11. 25. 22.  0. 11.  3.  8.  0. 29.  0. 10. 11. 15. 10. 11.  6.  1.
 10. 10.  0.  6.  1.  6.  8.  3.  0.  6.  0.  3.  6.  1. 11.  1.  8.  1.
 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8 29 11  1
  6 15  3  0 10  1  0  6  8  1 15  0 10  3  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [ 0.  8. 10.  0.  8.] 
adversary cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 11  8 15
 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 41 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.24314096570014954
desired expected reward: 10.606541633605957






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.  8.] 
cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 29  3 10  0 10  8  0  1  3  3  1  8  0  6  0  6 11  8 15
 16  0  0  0 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [0. 1. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8 29 11  1
  6 15  3  0 10  1  0  6  8  1 15  0 10  3  1] -> size -> 39 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 29  3  0 10  0  1  3  3  1  8  0  6  0  6 11  8 15 16  0  0  0
 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [0. 1. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8 29 11  1
  6 15  3  0 10  1  0  6  8  1 15  0 10  3  1] -> size -> 39 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 29  3  0 10  0  1  3  3  1  8  0  6  0  6 11  8 15 16  0  0  0
 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [0. 1. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8 29 11  1
  6 15  3  0 10  1  0  6  8  1 15  0 10  3  1] -> size -> 39 
adversary victory points: -1
player victory points: 7 





Player: 0 
cards in hand: [0. 1. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[8.008423 ]
 [8.5786495]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 11 11  1 11  3  0 22 11 25  6  0  0 11 10  8 10  6  6  8 29 11  1
  6 15  3  0 10  1  0  6  8  1 15  0 10  3  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0. 8.] 
adversary owned cards: [ 0  3  0 29  3  0 10  0  1  3  3  1  8  0  6  0  6 11  8 15 16  0  0  0
 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 37 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.37322112917900085
desired expected reward: 9.990179061889648



action possibilites: [-1] 
expected returns: [[8.103733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 11 11  1 11  3 22 11 25  6  0 11 10  8 10  6  6  8 29 11  1  6 15
  3  0 10  1  0  6  8  1 15  0 10  3  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0. 8.] 
adversary owned cards: [ 0  3  0 29  3  0 10  0  1  3  3  1  8  0  6  0  6 11  8 15 16  0  0  0
 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 37 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 5
Learning step: 0.3219131827354431
desired expected reward: 7.4277801513671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[7.382349 ]
 [8.60012  ]
 [7.8457475]
 [7.7504086]
 [8.93163  ]
 [9.547147 ]
 [7.1861835]
 [8.16956  ]
 [8.399444 ]
 [8.38309  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 11 11  1 11  3 22 11 25  6  0 11 10  8 10  6  6  8 29 11  1  6 15
  3  0 10  1  0  6  8  1 15  0 10  3  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  8. 10.  9.  1.  9.  7.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0. 8.] 
adversary owned cards: [ 0  3  0 29  3  0 10  0  1  3  3  1  8  0  6  0  6 11  8 15 16  0  0  0
 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 37 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.29598140716552734
desired expected reward: 8.399714469909668



buy possibilites: [-1] 
expected returns: [[9.646657]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [29.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 11 11  1 11  3 22 11 25  6  0 11 10  8 10  6  6  8 29 11  1  6 15
  3  0 10  1  0  6  8  1 15  0 10  3  1 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  7. 10.  9.  1.  9.  7.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0. 8.] 
adversary owned cards: [ 0  3  0 29  3  0 10  0  1  3  3  1  8  0  6  0  6 11  8 15 16  0  0  0
 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 37 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0 32  0] 
sum of rewards: 44 

action type: buy - action 29.0
Learning step: 1.1348755359649658
desired expected reward: 10.682021141052246






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  3.] 
cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0. 8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 29  3  0 10  0  1  3  3  1  8  0  6  0  6 11  8 15 16  0  0  0
 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  7. 10.  9.  1.  9.  7.] 
adversary cards in hand: [6. 3. 1. 1. 0.] 
adversary cards in discard: [29.  8.  1.  1.] 
adversary owned cards: [ 3  8 11 11  1 11  3 22 11 25  6  0 11 10  8 10  6  6  8 29 11  1  6 15
  3  0 10  1  0  6  8  1 15  0 10  3  1 29] -> size -> 38 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0. 8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0 29  3  0 10  0  1  3  3  1  8  0  6  0  6 11  8 15 16  0  0  0
 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  7. 10.  9.  1.  9.  7.] 
adversary cards in hand: [6. 3. 1. 1. 0.] 
adversary cards in discard: [29.  8.  1.  1.] 
adversary owned cards: [ 3  8 11 11  1 11  3 22 11 25  6  0 11 10  8 10  6  6  8 29 11  1  6 15
  3  0 10  1  0  6  8  1 15  0 10  3  1 29] -> size -> 38 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0. 8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0 29  3  0 10  0  1  3  3  1  8  0  6  0  6 11  8 15 16  0  0  0
 10  3  3  8  3  1 10  0  3  0  0  8  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  1.  9.  7. 10.  9.  1.  9.  7.] 
adversary cards in hand: [6. 3. 1. 1. 0.] 
adversary cards in discard: [29.  8.  1.  1.] 
adversary owned cards: [ 3  8 11 11  1 11  3 22 11 25  6  0 11 10  8 10  6  6  8 29 11  1  6 15
  3  0 10  1  0  6  8  1 15  0 10  3  1 29] -> size -> 38 
adversary victory points: -1
player victory points: 7 


Player 1 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 4 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 0 
Workshop: 5 
Chapel: 3 
Witch: 1 
Poacher: 2 
Militia: 0 
Market: 0 
Village: 2 
Library: 1 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [6. 3. 1. 1. 0.] 
cards in discard: [29.  8.  1.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 11 11  1 11  3 22 11 25  6  0 11 10  8 10  6  6  8 29 11  1  6 15
  3  0 10  1  0  6  8  1 15  0 10  3  1 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 18. 30.  8.  0.  8.  0.  0.  9.  7. 10.  9.  1.  9.  7.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [8. 8. 1. 3. 6. 0. 0. 0. 0. 8. 8.] 
adversary owned cards: [ 0  3  0 29  3  0 10  0  1  3  3  1  8  0  6  0  6 11  8 15 16  0  0  0
 10  3  3  8  3  1 10  0  3  0  0  8  3  8] -> size -> 38 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1
Learning step: -15.439399719238281
desired expected reward: -5.792742729187012



