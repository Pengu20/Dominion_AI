 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[292.52875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    1  -20    0    0   20    0    0    0    0   -3    0 -300
    0    0] 
sum of rewards: -807 

action type: buy - action 6.0
Learning step: -40.04508590698242
desired expected reward: -46.143436431884766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[267.0464 ]
 [283.40384]
 [276.83884]
 [231.70651]
 [273.923  ]
 [292.10086]
 [279.9146 ]
 [278.61102]
 [249.26534]
 [275.06146]
 [266.36536]
 [294.81006]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.492530822753906
desired expected reward: 285.8023681640625



buy possibilites: [-1] 
expected returns: [[277.73035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -7.0430121421813965
desired expected reward: 269.7958984375






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  3.  0.  0.  3.  3. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 23] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[285.43094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 23] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.034013271331787
desired expected reward: 270.6963195800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[252.16995]
 [270.75906]
 [264.0134 ]
 [215.86931]
 [281.85272]
 [264.76294]
 [260.57318]
 [286.2762 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 23] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -7.673312664031982
desired expected reward: 276.8824157714844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 23] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8 23] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8 23] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[289.92975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 23.  3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23] -> size -> 9 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -7.291629314422607
desired expected reward: 278.98455810546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[267.35406]
 [284.19547]
 [277.21063]
 [233.9509 ]
 [294.05927]
 [280.019  ]
 [275.298  ]
 [296.49323]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 23.  3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23] -> size -> 9 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -7.767411708831787
desired expected reward: 284.3294677734375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 23.  3.] 
cards in discard: [8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 23.  3.] 
cards in discard: [8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[356.3856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23] -> size -> 9 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -6.311177730560303
desired expected reward: 290.18206787109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[322.31396]
 [339.7774 ]
 [331.23788]
 [285.5262 ]
 [349.54736]
 [334.91214]
 [328.44305]
 [352.0427 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23] -> size -> 9 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -9.847491264343262
desired expected reward: 348.52960205078125



buy possibilites: [-1] 
expected returns: [[323.9671]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23] -> size -> 9 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -302.0 

action type: buy - action 6.0
Learning step: -22.087051391601562
desired expected reward: 263.43914794921875






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[327.03775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 3. 23.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.926634788513184
desired expected reward: 315.04046630859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[299.18622]
 [307.1946 ]
 [268.34085]
 [310.35617]
 [324.04004]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 3. 23.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.499312400817871
desired expected reward: 318.13275146484375



buy possibilites: [-1] 
expected returns: [[329.62323]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 3. 23.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -21.65052032470703
desired expected reward: 246.69033813476562






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 3. 23.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 0. 3. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 0. 3. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[283.95435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6. 3. 0. 3. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  9. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 3. 23.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -10.704063415527344
desired expected reward: 318.9191589355469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[257.64285]
 [276.75787]
 [270.15094]
 [220.33566]
 [265.36813]
 [288.01956]
 [270.9134 ]
 [269.5885 ]
 [238.68048]
 [266.67026]
 [257.2982 ]
 [292.695  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6. 3. 0. 3. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  9. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 3. 23.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.738321304321289
desired expected reward: 276.9104919433594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [ 3. 23.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [ 3. 23.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [ 3. 23.  8.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[337.15186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10 10] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -7.739542484283447
desired expected reward: 284.9554748535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[306.27954]
 [320.63647]
 [313.2452 ]
 [274.5949 ]
 [327.631  ]
 [317.66095]
 [311.89432]
 [328.23697]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10 10] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -10.250089645385742
desired expected reward: 325.0924987792969



buy possibilites: [-1] 
expected returns: [[288.64276]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10 10] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 1.0
Learning step: -8.124938011169434
desired expected reward: 289.2630615234375






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 23.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 6. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1] -> size -> 14 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 23.  0.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 6. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1] -> size -> 14 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10] -> size -> 11 
action values: 2 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 6. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10] -> size -> 11 
action values: 0 
buys: 2 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 6. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 6. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [14.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 6. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1] -> size -> 14 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [6. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[287.2415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 6. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.655167579650879
desired expected reward: 279.9875793457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[262.45453]
 [271.7643 ]
 [229.72267]
 [273.99432]
 [289.23663]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 6. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.754969596862793
desired expected reward: 276.88818359375



buy possibilites: [-1] 
expected returns: [[251.77815]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 6. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -43.0 

action type: buy - action 0.0
Learning step: -9.607719421386719
desired expected reward: 252.84683227539062






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0] -> size -> 15 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0] -> size -> 15 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[263.29422]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [23. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.281684875488281
desired expected reward: 244.4964599609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[233.96115]
 [250.61916]
 [243.3148 ]
 [202.96469]
 [258.66083]
 [245.8428 ]
 [240.26678]
 [260.31183]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [23. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.285727500915527
desired expected reward: 256.4797058105469



buy possibilites: [-1] 
expected returns: [[259.51163]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [23. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 1.0
Learning step: -6.441946506500244
desired expected reward: 244.17721557617188






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [23. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 10.  0.  0.  3.] 
cards in discard: [ 0.  0. 10.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 1.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0.  3.  0.] 
cards in discard: [ 0.  0. 10.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 1.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  0. 10.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0] -> size -> 13 
action values: 2 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 1.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  0. 10.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0] -> size -> 13 
action values: 0 
buys: 2 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 1.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
adversary victory points: 2
player victory points: 3 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  0. 10.  8.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 1.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  0. 10.  8.  3.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0  8  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 1.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [6. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[275.7684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 1.] 
cards in discard: [1. 0. 3. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -7.9904608726501465
desired expected reward: 251.5211639404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[238.54787]
 [256.24576]
 [248.81795]
 [202.40718]
 [245.6577 ]
 [265.52274]
 [251.58269]
 [249.85555]
 [219.75694]
 [246.20494]
 [237.0649 ]
 [267.13452]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 1.] 
cards in discard: [1. 0. 3. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 28. 30.  8.  8. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.093512535095215
desired expected reward: 263.5785217285156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  8. 14.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 23 10 10 14  0  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0. 6. 0. 0. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0. 6. 0. 0. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8.  8. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0. 6. 0. 0. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[215.37178]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [1. 0. 3. 0. 3. 0. 6. 0. 0. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [ 8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -9.129722595214844
desired expected reward: 258.0047607421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[201.93535]
 [214.09642]
 [208.09192]
 [176.37769]
 [220.21237]
 [211.33784]
 [206.87456]
 [220.93417]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [1. 0. 3. 0. 3. 0. 6. 0. 0. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  8. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [ 8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -6.703620910644531
desired expected reward: 210.05203247070312



buy possibilites: [-1] 
expected returns: [[199.54779]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [1. 0. 3. 0. 3. 0. 6. 0. 0. 3. 1. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  7. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [ 8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -324.0 

action type: buy - action 6.0
Learning step: -20.52906036376953
desired expected reward: 155.84866333007812






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 8.] 
cards in discard: [ 8.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  7. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6] -> size -> 17 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 8.] 
cards in discard: [ 8.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8.  7. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6] -> size -> 17 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 8.] 
cards in discard: [ 8.  0. 14.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  7. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6] -> size -> 17 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[234.66034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  7. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 23.  3.  0. 10.] 
adversary cards in discard: [ 8.  0. 14.  0.  0.  3.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -5.907724857330322
desired expected reward: 193.6400604248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[210.60881]
 [224.66425]
 [218.73592]
 [179.93384]
 [232.79724]
 [220.52492]
 [216.55217]
 [234.71962]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8.  7. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 23.  3.  0. 10.] 
adversary cards in discard: [ 8.  0. 14.  0.  0.  3.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.870913982391357
desired expected reward: 226.33641052246094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0. 23.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  3.  0. 10.] 
cards in discard: [ 8.  0. 14.  0.  0.  3.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  7. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6] -> size -> 17 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  7. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6] -> size -> 17 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8.  7. 10. 10.  8. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6] -> size -> 17 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  3.  0.  0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  7. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6] -> size -> 17 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[248.54463]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [3. 0. 3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  7. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [14.  0.  3.  0.  3.] 
adversary cards in discard: [10. 10.  0. 23.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -7.392977237701416
desired expected reward: 227.32667541503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[207.76372]
 [226.08948]
 [218.3836 ]
 [183.5401 ]
 [170.44699]
 [215.12456]
 [235.89766]
 [221.04332]
 [249.32268]
 [219.33835]
 [188.49797]
 [198.32822]
 [215.61974]
 [179.13138]
 [206.27356]
 [238.37369]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [3. 0. 3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 28. 30.  8.  7. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [14.  0.  3.  0.  3.] 
adversary cards in discard: [10. 10.  0. 23.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -8.44282341003418
desired expected reward: 237.9129638671875



buy possibilites: [-1] 
expected returns: [[208.9233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [3. 0. 3. 0. 0. 4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 29.  8.  7. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [14.  0.  3.  0.  3.] 
adversary cards in discard: [10. 10.  0. 23.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 59 

action type: buy - action 4.0
Learning step: -0.7433090209960938
desired expected reward: 167.13836669921875






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [14.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0.  3.] 
cards in discard: [10. 10.  0. 23.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 29.  8.  7. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 4. 1. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4] -> size -> 18 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.  3.] 
cards in discard: [10. 10.  0. 23.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 28. 29.  8.  7. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 4. 1. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4] -> size -> 18 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 6. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[227.4286]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [3. 0. 3. 0. 0. 4. 1. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 29.  8.  7. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [14.  3.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -4.90485954284668
desired expected reward: 204.0184326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[205.45691]
 [212.87096]
 [178.17639]
 [215.26178]
 [226.9793 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [3. 0. 3. 0. 0. 4. 1. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 28. 29.  8.  7. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [14.  3.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -6.024106025695801
desired expected reward: 220.25613403320312



buy possibilites: [-1] 
expected returns: [[169.37714]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [3. 0. 3. 0. 0. 4. 1. 0. 0. 0. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 29.  8.  6. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [14.  3.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -302.0 

action type: buy - action 6.0
Learning step: -20.197834014892578
desired expected reward: 157.97854614257812






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  8.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 23 10 14  0  8  3  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 29.  8.  6. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6] -> size -> 19 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 29.  8.  6. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 28. 29.  8.  6. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8.  6. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6] -> size -> 19 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 6. 3. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[193.33072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8.  6. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 23.  0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -4.204679489135742
desired expected reward: 165.17245483398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[167.46886]
 [182.61877]
 [176.17506]
 [135.62999]
 [191.11365]
 [178.44905]
 [173.74275]
 [192.21095]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 29.  8.  6. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 23.  0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -5.7170023918151855
desired expected reward: 188.24644470214844



buy possibilites: [-1] 
expected returns: [[193.46082]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 1.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 23.  0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -18.078632354736328
desired expected reward: 117.5513916015625






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 23.  0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [6. 0. 6. 3. 6. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0] -> size -> 13 
action values: 1 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [6. 0. 6. 3. 6. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0] -> size -> 13 
action values: 0 
buys: 2 
player value: 4 
card supply: [26. 28. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [6. 0. 6. 3. 6. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 3 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 8. 3. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [6. 0. 6. 3. 6. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [6. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[181.22505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [6. 0. 6. 3. 6. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [23.  0. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -6.234664440155029
desired expected reward: 187.2261505126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[160.5324 ]
 [135.07571]
 [182.3019 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [6. 0. 6. 3. 6. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [23.  0. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -5.9529619216918945
desired expected reward: 175.75265502929688



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [23.  0. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10. 10.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [6. 0. 6. 3. 6. 1. 6. 3. 3. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0  1] -> size -> 14 
action values: 1 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [6. 0. 6. 3. 6. 1. 6. 3. 3. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0  1] -> size -> 14 
action values: 0 
buys: 2 
player value: 4 
card supply: [26. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [6. 0. 6. 3. 6. 1. 6. 3. 3. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 3 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.  0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0  1 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [6. 0. 6. 3. 6. 1. 6. 3. 3. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.  0.] 
cards in discard: [10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0  1 10  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [6. 0. 6. 3. 6. 1. 6. 3. 3. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 4. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[155.66472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 0. 0. 0.] 
cards in discard: [6. 0. 6. 3. 6. 1. 6. 3. 3. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [8. 1. 3. 3. 3.] 
adversary cards in discard: [10.  0. 23.  0. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0  1 10  0] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -6.2401933670043945
desired expected reward: 176.06170654296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[138.1462  ]
 [148.67805 ]
 [144.69052 ]
 [116.812164]
 [142.19893 ]
 [155.86697 ]
 [145.75885 ]
 [144.77194 ]
 [127.82386 ]
 [143.6556  ]
 [138.2955  ]
 [157.77377 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 0. 0.] 
cards in discard: [6. 0. 6. 3. 6. 1. 6. 3. 3. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [8. 1. 3. 3. 3.] 
adversary cards in discard: [10.  0. 23.  0. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0  1 10  0] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -5.1517720222473145
desired expected reward: 151.51051330566406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [8. 1. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 3. 3. 3.] 
cards in discard: [10.  0. 23.  0. 10.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 23 10  0  8  3  0 10  0  1 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10.  0. 23.  0. 10.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 23 10  0  8  0 10  0 10  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  0. 23.  0. 10.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 23 10  0  8  0 10  0 10  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[178.93103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 8. 23.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 23 10  0  8  0 10  0 10  0] -> size -> 12 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -2.9736523628234863
desired expected reward: 154.80010986328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[148.70549]
 [162.65683]
 [155.81174]
 [119.72918]
 [154.28235]
 [169.5077 ]
 [159.06752]
 [157.55527]
 [133.02429]
 [153.9366 ]
 [146.65327]
 [170.24905]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 8. 23.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 23 10  0  8  0 10  0 10  0] -> size -> 12 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -4.597997188568115
desired expected reward: 176.0702667236328



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 8. 23.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 23 10  0  8  0 10  0 10  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [3. 1. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [3. 1. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [3. 1. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [3. 1. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [3. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[170.71825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [3. 1. 0. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10.  0.] 
adversary cards in discard: [ 0.  8. 23.  0.  0.] 
adversary owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -3.87011981010437
desired expected reward: 166.3789520263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[149.255   ]
 [156.05315 ]
 [124.741325]
 [158.36414 ]
 [171.57018 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [3. 1. 0. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10.  0.] 
adversary cards in discard: [ 0.  8. 23.  0.  0.] 
adversary owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -3.9889748096466064
desired expected reward: 164.5592041015625



buy possibilites: [-1] 
expected returns: [[184.97655]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [3. 1. 0. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6 0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10.  0.] 
adversary cards in discard: [ 0.  8. 23.  0.  0.] 
adversary owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -3.7680816650390625
desired expected reward: 145.4869384765625






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.  0.] 
cards in discard: [ 0.  8. 23.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 1. 6. 6.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6 0] -> size -> 21 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 10.] 
cards in discard: [ 0.  8. 23.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 1. 6. 6.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6 0] -> size -> 21 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 0.  8. 23.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0] -> size -> 12 
action values: 3 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 1. 6. 6.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6 0] -> size -> 21 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 0.  8. 23.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 1. 6. 6.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6 0] -> size -> 21 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 0.  8. 23.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 6. 6.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6 0] -> size -> 21 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 1. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[122.856514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 6. 6.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 6. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6 0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10] -> size -> 13 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -5.613835334777832
desired expected reward: 179.3627166748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[106.8452  ]
 [119.84595 ]
 [113.944214]
 [ 85.25286 ]
 [111.87801 ]
 [126.84852 ]
 [116.31435 ]
 [114.86353 ]
 [ 94.89428 ]
 [112.027855]
 [105.25618 ]
 [128.11377 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 6.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 6. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 6 1 0 1 6 4 6 6 0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10] -> size -> 13 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -2.6893107891082764
desired expected reward: 121.08811950683594



buy possibilites: [-1] 
expected returns: [[148.21458]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 6.] 
cards in discard: [ 3.  1.  0.  3.  0.  0.  3.  0.  6.  0.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10] -> size -> 13 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 49 

action type: buy - action 29.0
Learning step: 0.04165229946374893
desired expected reward: 114.90516662597656






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 4. 6.] 
adversary cards in discard: [ 3.  1.  0.  3.  0.  0.  3.  0.  6.  0.  3. 29.  0.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29] -> size -> 22 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 4. 6.] 
adversary cards in discard: [ 3.  1.  0.  3.  0.  0.  3.  0.  6.  0.  3. 29.  0.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29] -> size -> 22 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 28. 29.  8.  5. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 4. 6.] 
adversary cards in discard: [ 3.  1.  0.  3.  0.  0.  3.  0.  6.  0.  3. 29.  0.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29] -> size -> 22 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 10.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 29.  8.  5. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 4. 6.] 
adversary cards in discard: [ 3.  1.  0.  3.  0.  0.  3.  0.  6.  0.  3. 29.  0.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29] -> size -> 22 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 6. 4. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[186.49084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 4. 6.] 
cards in discard: [ 3.  1.  0.  3.  0.  0.  3.  0.  6.  0.  3. 29.  0.  0.  1.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 29.  8.  5. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0. 10.] 
adversary cards in discard: [ 1. 10.  0.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10  1] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -2.46458101272583
desired expected reward: 145.75





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[166.61272]
 [172.64738]
 [132.02696]
 [177.9029 ]
 [184.20299]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 4. 6.] 
cards in discard: [ 3.  1.  0.  3.  0.  0.  3.  0.  6.  0.  3. 29.  0.  0.  1.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 28. 29.  8.  5. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0. 10.] 
adversary cards in discard: [ 1. 10.  0.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10  1] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -4.351417064666748
desired expected reward: 177.6996307373047



buy possibilites: [-1] 
expected returns: [[126.92339]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 4. 6.] 
cards in discard: [ 3.  1.  0.  3.  0.  0.  3.  0.  6.  0.  3. 29.  0.  0.  1.  6.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 28. 29.  8.  4. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0. 10.] 
adversary cards in discard: [ 1. 10.  0.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10  1] -> size -> 14 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -294.0 

action type: buy - action 6.0
Learning step: -18.445571899414062
desired expected reward: 113.58137512207031






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0. 23.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  0.  0. 10.] 
cards in discard: [ 1. 10.  0.  0.  0. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 29.  8.  4. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6] -> size -> 23 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 1. 10.  0.  0.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10  1] -> size -> 14 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 28. 29.  8.  4. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6] -> size -> 23 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 1. 10.  0.  0.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10  1] -> size -> 14 
action values: 0 
buys: 2 
player value: 5 
card supply: [23. 26. 30. 28. 29.  8.  4. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6] -> size -> 23 
adversary victory points: 1
player victory points: 0 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 1. 10.  0.  0.  0. 10. 10.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10  1  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 28. 29.  8.  4. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6] -> size -> 23 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [0. 3. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[179.15933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 28. 29.  8.  4. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10  1  1] -> size -> 15 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -2.033216953277588
desired expected reward: 124.89017486572266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[154.2527 ]
 [164.28642]
 [118.44799]
 [167.332  ]
 [181.18645]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 28. 29.  8.  4. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10  1  1] -> size -> 15 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -4.875548839569092
desired expected reward: 173.47792053222656



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 23 10  0  8  0 10  0 10  0  0 10  1  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 28. 29.  8.  4. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [0. 3. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6] -> size -> 23 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 28. 29.  8.  4. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [0. 3. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6] -> size -> 23 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 28. 29.  8.  4. 10. 10.  8. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [0. 3. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6] -> size -> 23 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 28. 29.  8.  4. 10. 10.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [0. 3. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6] -> size -> 23 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [0. 3. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[158.2172]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [0. 3. 6. 0. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 28. 29.  8.  4. 10. 10.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [23.  0. 10. 10.  0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8] -> size -> 14 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -5.1763224601745605
desired expected reward: 176.01016235351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[142.0168 ]
 [154.33008]
 [149.09496]
 [120.05627]
 [146.8831 ]
 [160.5803 ]
 [151.05229]
 [149.6194 ]
 [129.16539]
 [147.041  ]
 [140.5069 ]
 [160.365  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [0. 3. 6. 0. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 25. 30. 28. 29.  8.  4. 10. 10.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [23.  0. 10. 10.  0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8] -> size -> 14 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -4.2531962394714355
desired expected reward: 154.9913330078125



buy possibilites: [-1] 
expected returns: [[104.73724]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [0. 3. 6. 0. 6. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 28. 29.  8.  4. 10. 10.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [23.  0. 10. 10.  0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8] -> size -> 14 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5.   0.   1.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 10.5 

action type: buy - action 1.0
Learning step: -4.834916114807129
desired expected reward: 149.4951629638672






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [23.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0. 10. 10.  0.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 29.  8.  4. 10. 10.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [29.  0.  0.  4.  0.] 
adversary cards in discard: [0. 3. 6. 0. 6. 1. 0. 3. 0. 6. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1] -> size -> 24 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0. 10. 10.  0.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 28. 29.  8.  4. 10. 10.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [29.  0.  0.  4.  0.] 
adversary cards in discard: [0. 3. 6. 0. 6. 1. 0. 3. 0. 6. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1] -> size -> 24 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0. 10. 10.  0.] 
cards in discard: [8. 8. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 27. 29.  8.  4. 10. 10.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [29.  0.  0.  4.  0.] 
adversary cards in discard: [0. 3. 6. 0. 6. 1. 0. 3. 0. 6. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1] -> size -> 24 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [29.  0.  0.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[147.94096]
 [135.58437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  4.  0.] 
cards in discard: [0. 3. 6. 0. 6. 1. 0. 3. 0. 6. 1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 27. 29.  8.  4. 10. 10.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  1. 10.] 
adversary cards in discard: [ 8.  8.  0.  0.  3. 23.  0. 10. 10.  0.] 
adversary owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -2.23117995262146
desired expected reward: 102.50606536865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[130.00322]
 [142.27115]
 [136.49515]
 [105.96682]
 [148.52606]
 [139.32726]
 [134.72112]
 [150.40852]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  4.  0.] 
cards in discard: [0. 3. 6. 0. 6. 1. 0. 3. 0. 6. 1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 30. 27. 29.  8.  4. 10. 10.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  1. 10.] 
adversary cards in discard: [ 8.  8.  0.  0.  3. 23.  0. 10. 10.  0.] 
adversary owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -4.3334059715271
desired expected reward: 142.0058135986328



buy possibilites: [-1] 
expected returns: [[127.50359]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  4.  0.] 
cards in discard: [ 0.  3.  6.  0.  6.  1.  0.  3.  0.  6.  1. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 27. 29.  8.  4. 10.  9.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  1. 10.] 
adversary cards in discard: [ 8.  8.  0.  0.  3. 23.  0. 10. 10.  0.] 
adversary owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 14 

action type: buy - action 11.0
Learning step: -3.857470750808716
desired expected reward: 144.66856384277344






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  1. 10.] 
cards in discard: [ 8.  8.  0.  0.  3. 23.  0. 10. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 27. 29.  8.  4. 10.  9.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [1. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  1.  0.  3.  0.  6.  1. 11. 29.  0.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11] -> size -> 25 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 27. 29.  8.  4. 10.  9.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [1. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  1.  0.  3.  0.  6.  1. 11. 29.  0.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11] -> size -> 25 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 7 
card supply: [23. 24. 30. 27. 29.  8.  4. 10.  9.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [1. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  1.  0.  3.  0.  6.  1. 11. 29.  0.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11] -> size -> 25 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 24. 30. 27. 29.  8.  4. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [1. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  1.  0.  3.  0.  6.  1. 11. 29.  0.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11] -> size -> 25 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [1. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[96.684044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 3. 6.] 
cards in discard: [ 0.  3.  6.  0.  6.  1.  0.  3.  0.  6.  1. 11. 29.  0.  0.  4.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 27. 29.  8.  4. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 23.  8.  0.] 
adversary cards in discard: [11. 10.  0.  0.  1.  1.  0.] 
adversary owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3 11] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -4.436543941497803
desired expected reward: 123.06704711914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[76.190315]
 [90.59475 ]
 [83.78306 ]
 [51.44767 ]
 [98.23877 ]
 [85.24364 ]
 [80.29673 ]
 [98.33314 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3. 6.] 
cards in discard: [ 0.  3.  6.  0.  6.  1.  0.  3.  0.  6.  1. 11. 29.  0.  0.  4.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 30. 27. 29.  8.  4. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 23.  8.  0.] 
adversary cards in discard: [11. 10.  0.  0.  1.  1.  0.] 
adversary owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3 11] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -2.952798843383789
desired expected reward: 92.0976791381836



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 23.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 23.  8.  0.] 
cards in discard: [11. 10.  0.  0.  1.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 27. 29.  8.  4. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11] -> size -> 25 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 23.  8.  0.] 
cards in discard: [11. 10.  0.  0.  1.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 27. 29.  8.  4. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11] -> size -> 25 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 23.  8.  0.] 
cards in discard: [11. 10.  0.  0.  1.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 27. 29.  8.  4. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11] -> size -> 25 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [0. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[140.93033]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  4. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 8.  0.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3 11  0] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -1.7578766345977783
desired expected reward: 91.08250427246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[119.71251]
 [127.76137]
 [ 91.68325]
 [128.62068]
 [141.61127]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 24. 30. 27. 29.  8.  4. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 8.  0.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3 11  0] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -4.141514778137207
desired expected reward: 132.93148803710938



buy possibilites: [-1] 
expected returns: [[94.683426]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 8.  0.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3 11  0] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -315.0 

action type: buy - action 6.0
Learning step: -18.203786849975586
desired expected reward: 73.47946166992188






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 10.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0 10  0 10  0  0 10  1  1  8  3 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 1. 0.] 
adversary cards in discard: [6. 0. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6] -> size -> 26 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 1. 0.] 
adversary cards in discard: [6. 0. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6] -> size -> 26 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 1. 0.] 
adversary cards in discard: [6. 0. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6] -> size -> 26 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [6. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[74.956795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 1. 0.] 
cards in discard: [6. 0. 6. 6. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [8. 0. 8. 0.] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -3.8209831714630127
desired expected reward: 90.86244201660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[64.632195]
 [77.02574 ]
 [71.58176 ]
 [49.3358  ]
 [41.760868]
 [69.58165 ]
 [83.33488 ]
 [73.75006 ]
 [93.20276 ]
 [72.29351 ]
 [51.888054]
 [57.79244 ]
 [69.54151 ]
 [46.506157]
 [63.00998 ]
 [83.37785 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 0.] 
cards in discard: [6. 0. 6. 6. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  8.  7. 10.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [8. 0. 8. 0.] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -2.715834140777588
desired expected reward: 71.2036361694336



buy possibilites: [-1] 
expected returns: [[66.75167]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 0.] 
cards in discard: [ 6.  0.  6.  6.  0.  3. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  8.  7.  9.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [8. 0. 8. 0.] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 35 

action type: buy - action 25.0
Learning step: -1.408225655555725
desired expected reward: 91.79454040527344






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [8. 0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  8.  7.  9.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 4.  0. 11.  6.  3.] 
adversary cards in discard: [ 6.  0.  6.  6.  0.  3. 25.  6.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25] -> size -> 27 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [8. 0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  8.  7.  9.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 4.  0. 11.  6.  3.] 
adversary cards in discard: [ 6.  0.  6.  6.  0.  3. 25.  6.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25] -> size -> 27 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 8.  0.  8.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  7.  9.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 4.  0. 11.  6.  3.] 
adversary cards in discard: [ 6.  0.  6.  6.  0.  3. 25.  6.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25] -> size -> 27 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [ 4.  0. 11.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[92.340546]
 [92.002815]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0. 11.  6.  3.] 
cards in discard: [ 6.  0.  6.  6.  0.  3. 25.  6.  0.  0.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  7.  9.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [23.  0.  1. 11.  1.] 
adversary cards in discard: [ 8.  0.  8.  0. 11.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -2.047377109527588
desired expected reward: 64.70429229736328



action possibilites: [-1] 
expected returns: [[65.63099]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 6. 3.] 
cards in discard: [ 6.  0.  6.  6.  0.  3. 25.  6.  0.  0.  1.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  7.  9.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [23.  0.  1. 11.  1.] 
adversary cards in discard: [ 8.  0.  8.  0. 11.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 14 

action type: gain_card_n - action 9
Learning step: -2.458634614944458
desired expected reward: 90.24800109863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[53.31778 ]
 [32.17166 ]
 [65.510956]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 6. 3.] 
cards in discard: [ 6.  0.  6.  6.  0.  3. 25.  6.  0.  0.  1.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  7.  9.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [23.  0.  1. 11.  1.] 
adversary cards in discard: [ 8.  0.  8.  0. 11.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -1.7683842182159424
desired expected reward: 63.862606048583984






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [23.  0.  1. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  1. 11.  1.] 
cards in discard: [ 8.  0.  8.  0. 11.  0.  0. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  7.  9.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  6.  3.] 
adversary cards in discard: [ 6.  0.  6.  6.  0.  3. 25.  6.  0.  0.  1.  0. 10. 11.  4.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10] -> size -> 28 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  1. 11.  1.] 
cards in discard: [ 8.  0.  8.  0. 11.  0.  0. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  7.  9.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  6.  3.] 
adversary cards in discard: [ 6.  0.  6.  6.  0.  3. 25.  6.  0.  0.  1.  0. 10. 11.  4.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10] -> size -> 28 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  1. 11.  1.] 
cards in discard: [ 8.  0.  8.  0. 11.  0.  0. 10.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  7.  9.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  6.  3.] 
adversary cards in discard: [ 6.  0.  6.  6.  0.  3. 25.  6.  0.  0.  1.  0. 10. 11.  4.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10] -> size -> 28 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0. 29.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[41.75497]
 [35.2472 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  6.  3.] 
cards in discard: [ 6.  0.  6.  6.  0.  3. 25.  6.  0.  0.  1.  0. 10. 11.  4.  0.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  7.  9.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -3.1312615871429443
desired expected reward: 62.37971115112305



action possibilites: [-1.] 
expected returns: [[40.300316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [ 6.  0.  6.  6.  0.  3. 25.  6.  0.  0.  1.  0. 10. 11.  4.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  7.  9.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: -0.6056031584739685
desired expected reward: 34.6416015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.365114]
 [33.1736  ]
 [14.050089]
 [38.250996]
 [41.842407]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [ 6.  0.  6.  6.  0.  3. 25.  6.  0.  0.  1.  0. 10. 11.  4.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  7.  9.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: -0.9695004820823669
desired expected reward: 39.330814361572266



buy possibilites: [-1] 
expected returns: [[20.71665]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [ 6.  0.  6.  6.  0.  3. 25.  6.  0.  0.  1.  0. 10. 11.  4.  0.  6.  3.
  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  6.  9.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 13 

action type: buy - action 8.0
Learning step: -0.7964248061180115
desired expected reward: 37.45456314086914






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  6.  9.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [8. 1. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8] -> size -> 29 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  6.  9.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [8. 1. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8] -> size -> 29 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 10.  0.] 
cards in discard: [25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [8. 1. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8] -> size -> 29 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [8. 1. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[47.10234]
 [37.04294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  8. 11.] 
adversary cards in discard: [25.  1.  0.  0. 10.  0.] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -0.8693510293960571
desired expected reward: 19.847299575805664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[33.93673 ]
 [43.201675]
 [31.036047]
 [39.78586 ]
 [24.526537]
 [20.99681 ]
 [37.561657]
 [48.785816]
 [40.468628]
 [55.53107 ]
 [39.550323]
 [26.977293]
 [31.026178]
 [38.364384]
 [23.59779 ]
 [33.77965 ]
 [50.5105  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 24. 30. 27. 29.  8.  3. 10.  7.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  8. 11.] 
adversary cards in discard: [25.  1.  0.  0. 10.  0.] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -1.931968331336975
desired expected reward: 41.39504623413086



buy possibilites: [-1] 
expected returns: [[95.78027]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 1. 0.] 
cards in discard: [1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 23. 30. 27. 29.  8.  3. 10.  7.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  8. 11.] 
adversary cards in discard: [25.  1.  0.  0. 10.  0.] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -10.5 

action type: buy - action 1.0
Learning step: -0.38811570405960083
desired expected reward: 39.97532272338867






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 11.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  8. 11.] 
cards in discard: [25.  1.  0.  0. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 27. 29.  8.  3. 10.  7.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  4.  0.] 
adversary cards in discard: [1. 8. 1. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1] -> size -> 30 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8. 11.] 
cards in discard: [25.  1.  0.  0. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  3. 10.  7.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  4.  0.] 
adversary cards in discard: [1. 8. 1. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1] -> size -> 30 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8. 11.] 
cards in discard: [25.  1.  0.  0. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 23. 30. 27. 29.  8.  3. 10.  7.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  4.  0.] 
adversary cards in discard: [1. 8. 1. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1] -> size -> 30 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8. 11.] 
cards in discard: [25.  1.  0.  0. 10.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  3. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  4.  0.] 
adversary cards in discard: [1. 8. 1. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1] -> size -> 30 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [ 6. 29.  0.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[96.84721 ]
 [86.033295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  4.  0.] 
cards in discard: [1. 8. 1. 0. 1. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  3. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0. 10.] 
adversary cards in discard: [25.  1.  0.  0. 10.  0.  0. 11. 11.  0.  1.  8. 11.] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25  0 11] -> size -> 21 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -3.473400115966797
desired expected reward: 92.30686950683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[82.08113]
 [87.64718]
 [60.63808]
 [89.37435]
 [97.51883]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  0.  4.  0.] 
cards in discard: [1. 8. 1. 0. 1. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 23. 30. 27. 29.  8.  3. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0. 10.] 
adversary cards in discard: [25.  1.  0.  0. 10.  0.  0. 11. 11.  0.  1.  8. 11.] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25  0 11] -> size -> 21 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -3.508385419845581
desired expected reward: 91.63471984863281



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0. 10.] 
cards in discard: [25.  1.  0.  0. 10.  0.  0. 11. 11.  0.  1.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  3. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [6. 6. 3. 6. 0.] 
adversary cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1] -> size -> 30 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0. 10.] 
cards in discard: [25.  1.  0.  0. 10.  0.  0. 11. 11.  0.  1.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 23. 30. 27. 29.  8.  3. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [6. 6. 3. 6. 0.] 
adversary cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1] -> size -> 30 
adversary victory points: 0
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 6. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[9.301655]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 6. 0.] 
cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  3. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 1.  8.  0.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25  0 11] -> size -> 21 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -5.416654109954834
desired expected reward: 92.1021728515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.8396914]
 [-3.5392928]
 [ 8.854825 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6. 0.] 
cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 30. 27. 29.  8.  3. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 1.  8.  0.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25  0 11] -> size -> 21 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -1.1181272268295288
desired expected reward: 8.183527946472168



buy possibilites: [-1] 
expected returns: [[40.01004]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6. 0.] 
cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 27. 29.  8.  2. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 1.  8.  0.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25  0 11] -> size -> 21 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -326.0 

action type: buy - action 6.0
Learning step: -15.222810745239258
desired expected reward: -18.76209831237793






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 1.  8.  0.  8. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  8. 23.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 23  0  8  0  0 10  0  0 10  1  1  8  3 11  0 11 10 25  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  2. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  1. 25.] 
adversary cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6] -> size -> 31 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  2. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  1. 25.] 
adversary cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6] -> size -> 31 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 23.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  2. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  1. 25.] 
adversary cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6] -> size -> 31 
adversary victory points: -1
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0.  3.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[39.13135 ]
 [56.604424]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  1. 25.] 
cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  2. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  8. 23.] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11] -> size -> 19 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -2.1482620239257812
desired expected reward: 37.861778259277344



action possibilites: [-1] 
expected returns: [[73.83939]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0. 6.] 
cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  1. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  8. 23.  6.] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6] -> size -> 20 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -5 

action type: take_action - action 25.0
Learning step: -1.4188350439071655
desired expected reward: 55.18559265136719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[62.815792]
 [70.35864 ]
 [66.16164 ]
 [57.222565]
 [55.029232]
 [65.54262 ]
 [73.70401 ]
 [68.30184 ]
 [81.02203 ]
 [67.33009 ]
 [57.33791 ]
 [58.878162]
 [64.836296]
 [56.01635 ]
 [61.294544]
 [73.72399 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0. 6.] 
cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 23. 30. 27. 29.  8.  1. 10.  6.  6.  8.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  8. 23.  6.] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6] -> size -> 20 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1
Learning step: -2.3919050693511963
desired expected reward: 71.4474868774414



buy possibilites: [-1] 
expected returns: [[102.92167]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0. 6.] 
cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  8. 23.  6.] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6] -> size -> 20 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: 44 

action type: buy - action 25.0
Learning step: 0.46463584899902344
desired expected reward: 81.4866714477539






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  8. 23.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  6. 10.] 
adversary cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0. 25.
 25.  0.  0.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25] -> size -> 32 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  8. 23.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  6. 10.] 
adversary cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0. 25.
 25.  0.  0.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25] -> size -> 32 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  8. 23.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 5 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  6. 10.] 
adversary cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0. 25.
 25.  0.  0.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25] -> size -> 32 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 0.  6.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[78.33045 ]
 [70.015305]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  6. 10.] 
cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0. 25.
 25.  0.  0.  3.  1.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [11. 10. 11.  1. 11.] 
adversary cards in discard: [ 8.  8. 23.  6.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0] -> size -> 21 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -4.241401672363281
desired expected reward: 98.68026733398438



action possibilites: [-1. 11.] 
expected returns: [[109.43638]
 [108.03439]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  6. 11.] 
cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0. 25.
 25.  0.  0.  3.  1.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [11. 10. 11.  1. 11.] 
adversary cards in discard: [ 8.  8. 23.  6.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0] -> size -> 21 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action 10.0
Learning step: -0.848183810710907
desired expected reward: 69.1671142578125



action possibilites: [-1.] 
expected returns: [[43.120644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6.] 
cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0. 25.
 25.  0.  0.  3.  1.  0.  6. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  8.  9.  3. 10. 10.] 
adversary cards in hand: [11. 10. 11.  1. 11.] 
adversary cards in discard: [ 8.  8. 23.  6.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0] -> size -> 21 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 40 

action type: gain_card_n - action 8
Learning step: -2.0348899364471436
desired expected reward: 98.06719970703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.208126]
 [17.614902]
 [45.053223]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6.] 
cards in discard: [ 1.  8.  1.  0.  1.  0.  6. 29.  0.  4.  0.  6.  6.  6.  3.  6.  0. 25.
 25.  0.  0.  3.  1.  0.  6. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  8.  9.  3. 10. 10.] 
adversary cards in hand: [11. 10. 11.  1. 11.] 
adversary cards in discard: [ 8.  8. 23.  6.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0] -> size -> 21 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 24 

action type: take_action - action -1.0
Learning step: -0.13812141120433807
desired expected reward: 42.982521057128906






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [11. 10. 11.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  1. 11.] 
cards in discard: [ 8.  8. 23.  6.  0.  0.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  8.  9.  3. 10. 10.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  1. 11.] 
cards in discard: [ 8.  8. 23.  6.  0.  0.  0.  0.  0.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  1. 11.] 
cards in discard: [ 8.  8. 23.  6.  0.  0.  0.  0.  0.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [29.  1.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[88.05723]
 [75.6327 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10. 25.] 
adversary cards in discard: [ 8.  8. 23.  6.  0.  0.  0.  0.  0.  0. 15. 11. 10. 11.  1. 11.] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15] -> size -> 22 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -1.1932300329208374
desired expected reward: 43.8599967956543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[67.0329  ]
 [77.08974 ]
 [74.68551 ]
 [47.429348]
 [71.07157 ]
 [83.06395 ]
 [73.15097 ]
 [72.357574]
 [55.96502 ]
 [71.90983 ]
 [66.40163 ]
 [86.35639 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10. 25.] 
adversary cards in discard: [ 8.  8. 23.  6.  0.  0.  0.  0.  0.  0. 15. 11. 10. 11.  1. 11.] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15] -> size -> 22 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -3.2430970668792725
desired expected reward: 80.08589935302734



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10. 25.] 
cards in discard: [ 8.  8. 23.  6.  0.  0.  0.  0.  0.  0. 15. 11. 10. 11.  1. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 6.] 
adversary cards in discard: [29.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10. 25.] 
cards in discard: [ 8.  8. 23.  6.  0.  0.  0.  0.  0.  0. 15. 11. 10. 11.  1. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  6.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 6.] 
adversary cards in discard: [29.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10. 25.] 
cards in discard: [ 8.  8. 23.  6.  0.  0.  0.  0.  0.  0. 15. 11. 10. 11.  1. 11.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 6.] 
adversary cards in discard: [29.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [1. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[48.18332]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 6.] 
cards in discard: [29.  1.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [11.  0. 15. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15  8] -> size -> 23 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -4.033694744110107
desired expected reward: 82.32269287109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[40.560097]
 [47.23992 ]
 [44.264194]
 [26.9203  ]
 [43.193504]
 [49.541805]
 [45.10356 ]
 [44.320103]
 [32.950645]
 [42.66866 ]
 [39.229618]
 [49.258785]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 6.] 
cards in discard: [29.  1.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [11.  0. 15. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15  8] -> size -> 23 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -2.1977906227111816
desired expected reward: 45.98552703857422



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [11.  0. 15. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15. 25.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [11. 25.  1.  0.  0.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 15. 25.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 30. 27. 29.  8.  1. 10.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [11. 25.  1.  0.  0.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 15. 25.  3.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 27. 29.  8.  1. 10.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [11. 25.  1.  0.  0.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [11. 25.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[ 9.270208]
 [ 9.024664]
 [12.917335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  1.  0.  0.] 
cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 27. 29.  8.  1. 10.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [ 0. 11.  0. 15. 25.  3.] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15  8  0] -> size -> 24 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -3.007211208343506
desired expected reward: 46.2515754699707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[13.542321]
 [16.780268]
 [15.340947]
 [ 8.019108]
 [14.752238]
 [18.75437 ]
 [16.164967]
 [15.746625]
 [10.51867 ]
 [15.175515]
 [13.365111]
 [18.51679 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  1.  0.  0.] 
cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 23. 30. 27. 29.  8.  1. 10.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [ 0. 11.  0. 15. 25.  3.] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15  8  0] -> size -> 24 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -0.8975357413291931
desired expected reward: 8.372669219970703



buy possibilites: [-1] 
expected returns: [[83.305016]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  1.  0.  0.] 
cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 27. 29.  8.  1.  9.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [ 0. 11.  0. 15. 25.  3.] 
adversary owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15  8  0] -> size -> 24 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 16 

action type: buy - action 16.0
Learning step: 1.9367516040802002
desired expected reward: 16.688976287841797






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  8. 11.] 
cards in discard: [ 0. 11.  0. 15. 25.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [23  0  8  0  0 10  0  0 10  1  8  3 11  0 11 10 25  0 11  6  0 15  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 27. 29.  8.  1.  9.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 6. 8. 0. 6.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16] -> size -> 34 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 0. 11.  0. 15. 25.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [23  8  0 10  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 27. 29.  8.  1.  9.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 6. 8. 0. 6.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16] -> size -> 34 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 0. 11.  0. 15. 25.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [23  8  0 10  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 23. 30. 27. 29.  8.  1.  9.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 6. 8. 0. 6.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16] -> size -> 34 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [0. 6. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[59.601494]
 [52.602436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 6.] 
cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 27. 29.  8.  1.  9.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  0. 15. 25.  3.  8. 11.] 
adversary owned cards: [23  8  0 10  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0] -> size -> 21 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -3.6728293895721436
desired expected reward: 79.63218688964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[49.18428 ]
 [52.960655]
 [39.298096]
 [52.987114]
 [60.06139 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 6.] 
cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 23. 30. 27. 29.  8.  1.  9.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  0. 15. 25.  3.  8. 11.] 
adversary owned cards: [23  8  0 10  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0] -> size -> 21 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -2.555978775024414
desired expected reward: 57.0455322265625



buy possibilites: [-1] 
expected returns: [[19.12278]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 6.] 
cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 27. 29.  8.  0.  9.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  0. 15. 25.  3.  8. 11.] 
adversary owned cards: [23  8  0 10  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0] -> size -> 21 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -327.0 

action type: buy - action 6.0
Learning step: -17.884641647338867
desired expected reward: 21.413461685180664






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 6. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [ 0. 11.  0. 15. 25.  3.  8. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  0 10  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 27. 29.  8.  0.  9.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [25.  6.  6. 10.  1.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 0. 11.  0. 15. 25.  3.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [23  8  0 10  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 27. 29.  8.  0.  9.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [25.  6.  6. 10.  1.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 0. 11.  0. 15. 25.  3.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [23  8  0 10  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 23. 30. 27. 29.  8.  0.  9.  6.  5.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [25.  6.  6. 10.  1.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 0. 11.  0. 15. 25.  3.  8. 11.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [23  8  0 10  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 27. 29.  8.  0.  9.  6.  4.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [25.  6.  6. 10.  1.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [25.  6.  6. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[-11.500537]
 [-11.394408]
 [ -9.472573]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  6. 10.  1.] 
cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 27. 29.  8.  0.  9.  6.  4.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [23.  8.  8. 10. 10.] 
adversary cards in discard: [ 0. 11.  0. 15. 25.  3.  8. 11.  8. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [23  8  0 10  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8] -> size -> 22 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -2.5375609397888184
desired expected reward: 16.58521842956543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ -9.654369]
 [ -8.182936]
 [-10.596829]
 [-10.293119]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.  6. 10.  1.] 
cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 23. 30. 27. 29.  8.  0.  9.  6.  4.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [23.  8.  8. 10. 10.] 
adversary cards in discard: [ 0. 11.  0. 15. 25.  3.  8. 11.  8. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [23  8  0 10  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8] -> size -> 22 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -0.9799100756645203
desired expected reward: -12.480446815490723



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [23.  8.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.  8. 10. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  8. 10. 10.] 
cards in discard: [ 0. 11.  0. 15. 25.  3.  8. 11.  8. 10.  6.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [23  8  0 10  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 27. 29.  8.  0.  9.  6.  4.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [14.  6.  0.  3.  6.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6. 25.  6.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.] 
cards in discard: [ 0. 11.  0. 15. 25.  3.  8. 11.  8. 10.  6.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 27. 29.  8.  0.  9.  6.  4.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [14.  6.  0.  3.  6.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6. 25.  6.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.] 
cards in discard: [ 0. 11.  0. 15. 25.  3.  8. 11.  8. 10.  6.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 23. 30. 27. 29.  8.  0.  9.  6.  4.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [14.  6.  0.  3.  6.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6. 25.  6.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.] 
cards in discard: [ 0. 11.  0. 15. 25.  3.  8. 11.  8. 10.  6.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  4.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [14.  6.  0.  3.  6.] 
adversary cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6. 25.  6.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [14.  6.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-2.0014482]
 [-5.539301 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.  3.  6.] 
cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6. 25.  6.  6. 10.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  4.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0] -> size -> 21 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -0.9049488306045532
desired expected reward: -11.19806957244873



action possibilites: [-1] 
expected returns: [[-16.477331]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6. 25.  6.  6. 10.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  4.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0] -> size -> 21 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action 14.0
Learning step: -0.4437744617462158
desired expected reward: -5.983083724975586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-18.451889]
 [-15.595151]
 [-17.114923]
 [-14.747258]
 [-16.238464]
 [-17.76089 ]
 [-15.999317]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6. 25.  6.  6. 10.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  4.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0] -> size -> 21 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1
Learning step: 0.11689644306898117
desired expected reward: -16.360435485839844



buy possibilites: [-1] 
expected returns: [[8.070995]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [29.  1.  0.  0.  3.  1.  3.  0.  0.  6. 16. 11. 25.  1.  0.  0.  6.  0.
  6.  8.  0.  6. 25.  6.  6. 10.  1.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  3.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0] -> size -> 21 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -20.   0.   0.  20.   0.   0.   0.   0.  -1.   0.   0.
   2.   0.] 
sum of rewards: -6.0 

action type: buy - action 8.0
Learning step: 0.6935204267501831
desired expected reward: -15.544939994812012






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  3.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 25.  6.  4.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8] -> size -> 36 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  3.  7.  9.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 25.  6.  4.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8] -> size -> 36 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 11. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  3.  7.  9.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 25.  6.  4.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8] -> size -> 36 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 3. 25.  6.  4.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[40.59069]
 [44.1885 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  6.  4.  3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  3.  7.  9.  8.  9.  2. 10.  9.] 
adversary cards in hand: [3. 8. 0. 8. 0.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10] -> size -> 22 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -0.8023778200149536
desired expected reward: 7.268617630004883



action possibilites: [-1] 
expected returns: [[45.671715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  4.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  3.  7.  9.  8.  9.  2. 10.  9.] 
adversary cards in hand: [3. 8. 0. 8. 0.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10] -> size -> 22 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action 25.0
Learning step: -1.3547919988632202
desired expected reward: 39.29331588745117





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[36.08247 ]
 [46.092167]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  4.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  3.  7.  9.  8.  9.  2. 10.  9.] 
adversary cards in hand: [3. 8. 0. 8. 0.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10] -> size -> 22 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1
Learning step: -1.6660345792770386
desired expected reward: 44.005680084228516






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 8. 0.] 
cards in discard: [ 0. 11. 10.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  3.  7.  9.  8.  9.  2. 10.  9.] 
adversary cards in hand: [11.  1. 16.  3.  0.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8] -> size -> 36 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 8. 0.] 
cards in discard: [ 0. 11. 10.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  3.  7.  9.  8.  9.  2. 10.  9.] 
adversary cards in hand: [11.  1. 16.  3.  0.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8] -> size -> 36 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 8. 0.] 
cards in discard: [ 0. 11. 10.  0.  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  2.  7.  9.  8.  9.  2. 10.  9.] 
adversary cards in hand: [11.  1. 16.  3.  0.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8] -> size -> 36 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [11.  1. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[38.542294]
 [38.688812]
 [33.68325 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 16.  3.  0.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  2.  7.  9.  8.  9.  2. 10.  9.] 
adversary cards in hand: [11.  6. 10.  8. 25.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8] -> size -> 23 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -2.8079679012298584
desired expected reward: 43.284236907958984



action possibilites: [-1] 
expected returns: [[38.680847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  3.  0.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  2.  7.  9.  8.  9.  2. 10.  8.] 
adversary cards in hand: [11.  6. 10.  8. 25.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8] -> size -> 23 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0  -2   0   0  16   0] 
sum of rewards: 7 

action type: gain_card_n - action 9
Learning step: -0.7863858342170715
desired expected reward: 39.347713470458984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[32.925014]
 [35.949017]
 [33.845585]
 [38.316   ]
 [34.450226]
 [33.187607]
 [37.671257]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  3.  0.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  6.  2.  7.  9.  8.  9.  2. 10.  8.] 
adversary cards in hand: [11.  6. 10.  8. 25.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8] -> size -> 23 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1
Learning step: -1.4653265476226807
desired expected reward: 37.215518951416016



buy possibilites: [-1] 
expected returns: [[-0.54671717]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  3.  0.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  5.  2.  7.  9.  8.  9.  2. 10.  8.] 
adversary cards in hand: [11.  6. 10.  8. 25.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8] -> size -> 23 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0  -3   0   0  18   0] 
sum of rewards: 8 

action type: buy - action 11.0
Learning step: -1.5281004905700684
desired expected reward: 36.78788757324219






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [11.  6. 10.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 10.  8. 25.] 
cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  5.  2.  7.  9.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0. 14.  1.  1.  3.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11] -> size -> 38 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 10.  8. 25.] 
cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  5.  2.  7.  9.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0. 14.  1.  1.  3.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11] -> size -> 38 
adversary victory points: -2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 14.  1.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[ 6.8347387]
 [-4.4740305]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  1.  3.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  5.  2.  7.  9.  8.  9.  2. 10.  8.] 
adversary cards in hand: [15.  8. 11.  0. 10.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0. 11.  6. 10.  8. 25.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8] -> size -> 23 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -1.2474278211593628
desired expected reward: -1.7941449880599976



action possibilites: [-1] 
expected returns: [[-0.4093294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 3.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  5.  2.  7.  9.  8.  9.  2. 10.  8.] 
adversary cards in hand: [11.  0. 10.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0. 11.  6. 10.  8. 25. 15.
  8.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8] -> size -> 23 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action 14.0
Learning step: -0.13550780713558197
desired expected reward: -4.6095499992370605





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-2.2669835]
 [-2.3669891]
 [-2.6973326]
 [-2.944731 ]
 [-6.191124 ]
 [-2.2933176]
 [-3.0467086]
 [-2.1156502]
 [-2.3006897]
 [-2.2183578]
 [-4.064867 ]
 [-2.914956 ]
 [-2.8900764]
 [-5.7114077]
 [-2.933936 ]
 [-3.7283213]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 3.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 7 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  5.  2.  7.  9.  8.  9.  2. 10.  8.] 
adversary cards in hand: [11.  0. 10.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0. 11.  6. 10.  8. 25. 15.
  8.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8] -> size -> 23 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1
Learning step: -0.3917516767978668
desired expected reward: -0.8010810613632202



buy possibilites: [-1] 
expected returns: [[0.00541401]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 3.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  4.  2.  7.  9.  8.  9.  2. 10.  8.] 
adversary cards in hand: [11.  0. 10.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0. 11.  6. 10.  8. 25. 15.
  8.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8] -> size -> 23 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5.    0.   -2.  -20.    0.    0.   20.    0.    0.    0.    0.   -4.
   0.    0.    4.5   0. ] 
sum of rewards: -6.5 

action type: buy - action 11.0
Learning step: -0.1725425124168396
desired expected reward: -3.2192561626434326






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.] 
cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0. 11.  6. 10.  8. 25. 15.
  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  4.  2.  7.  9.  8.  9.  2. 10.  8.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0. 11.  6. 10.  8. 25. 15.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  4.  2.  7.  9.  8.  9.  2. 10.  8.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0. 11.  6. 10.  8. 25. 15.
  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  4.  2.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0. 11.  6. 10.  8. 25. 15.
  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  4.  2.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0. 11. 10.  0.  0.  0.  8.  3.  8.  0.  8.  0. 11.  6. 10.  8. 25. 15.
  8. 29.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  4.  1.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [6. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-13.303622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  4.  1.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8] -> size -> 25 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -1.6496021747589111
desired expected reward: -1.6441881656646729





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-21.85897 ]
 [-18.732006]
 [-20.096783]
 [-16.66856 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  4.  1.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8] -> size -> 25 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -1.096957802772522
desired expected reward: -14.400580406188965



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10. 15.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  4.  1.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0.  6. 29.  6.  0.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10. 15.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 23. 30. 27. 29.  8.  0.  9.  4.  1.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0.  6. 29.  6.  0.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10. 15.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 23. 30. 27. 29.  8.  0.  9.  4.  1.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0.  6. 29.  6.  0.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  6. 29.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-10.63365 ]
 [-12.199184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  6.  0.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.  6.  0.  0.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 27. 29.  8.  0.  9.  4.  1.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 29.  0.] 
adversary cards in discard: [ 0.  0.  8.  0. 10. 15.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0] -> size -> 26 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -0.7667025923728943
desired expected reward: -17.435264587402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-10.900667]
 [ -9.746249]
 [-11.07537 ]
 [ -9.730726]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29.  6.  0.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.  6.  0.  0.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 27. 29.  8.  0.  9.  4.  1.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 29.  0.] 
adversary cards in discard: [ 0.  0.  8.  0. 10. 15.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0] -> size -> 26 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -1.0460455417633057
desired expected reward: -11.679691314697266



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 29.  0.] 
cards in discard: [ 0.  0.  8.  0. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 27. 29.  8.  0.  9.  4.  1.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [8. 0. 0. 6. 1.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.  6.  0.  0.  6.  6.  0.  6. 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 29.  0.] 
cards in discard: [ 0.  0.  8.  0. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 23. 30. 27. 29.  8.  0.  9.  4.  1.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [8. 0. 0. 6. 1.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.  6.  0.  0.  6.  6.  0.  6. 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 29.  0.] 
cards in discard: [ 0.  0.  8.  0. 10. 15.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 23. 30. 27. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [8. 0. 0. 6. 1.] 
adversary cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.  6.  0.  0.  6.  6.  0.  6. 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [8. 0. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-21.134857]
 [-22.207901]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 1.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.  6.  0.  0.  6.  6.  0.  6. 29.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 27. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 25. 11.] 
adversary cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8] -> size -> 27 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -1.3464511632919312
desired expected reward: -11.077170372009277





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-22.406797]
 [-22.519245]
 [-21.313215]
 [-22.485561]
 [-22.00044 ]
 [-22.895847]
 [-21.326715]
 [-21.796406]
 [-21.440268]
 [-22.029636]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6. 1.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.  6.  0.  0.  6.  6.  0.  6. 29.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 23. 30. 27. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 25. 11.] 
adversary cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8] -> size -> 27 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -0.7379030585289001
desired expected reward: -22.767539978027344



buy possibilites: [-1] 
expected returns: [[-2.370797]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6. 1.] 
cards in discard: [25.  3.  6.  4.  3. 10.  8. 15. 11. 11.  1. 16.  3.  0. 11. 14.  0.  1.
  1.  3.  6.  0.  0.  6.  6.  0.  6. 29.  6.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 25. 11.] 
adversary cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8] -> size -> 27 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -10.   0.   0.   0.   0.   0.   0.   0.  -5.   0.   0.
   2.   0.] 
sum of rewards: -19.0 

action type: buy - action 3.0
Learning step: 0.062317945063114166
desired expected reward: -21.250898361206055






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 25. 11.] 
cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0.  6. 25.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3] -> size -> 40 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 25. 11.] 
cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0.  6. 25.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3] -> size -> 40 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  6. 25.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-6.408877 ]
 [-4.2943683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 25.  6.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 8. 11.  8. 10. 10.] 
adversary cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.  0.  8.  0. 25. 11.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8] -> size -> 27 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -0.7927697896957397
desired expected reward: -3.1635665893554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-10.085808 ]
 [ -8.2198925]
 [ -6.1756988]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 25.  6.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 8. 11.  8. 10. 10.] 
adversary cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.  0.  8.  0. 25. 11.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8] -> size -> 27 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -0.6460796594619751
desired expected reward: -7.054959297180176



buy possibilites: [-1] 
expected returns: [[30.59344]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 25.  6.  0.] 
cards in discard: [0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 8. 11.  8. 10. 10.] 
adversary cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.  0.  8.  0. 25. 11.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8] -> size -> 27 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -10.   0.   0.   0. -30.   0.   0.   0.  -6.   0.   0.
   0.   0.] 
sum of rewards: -52.0 

action type: buy - action 0.0
Learning step: -1.407357096672058
desired expected reward: -11.49316692352295






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8. 10. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8. 10. 10.] 
cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.  0.  8.  0. 25. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  8.] 
adversary cards in hand: [ 0.  6.  6. 25.  8.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0] -> size -> 41 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10. 10.] 
cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.  0.  8.  0. 25. 11. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  6.  6. 25.  8.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0] -> size -> 41 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10. 10.] 
cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.  0.  8.  0. 25. 11. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  6.  6. 25.  8.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0] -> size -> 41 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10. 10.] 
cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.  0.  8.  0. 25. 11. 15.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8 15  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  6.  6. 25.  8.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0] -> size -> 41 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 0.  6.  6. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[ 8.566561]
 [12.158037]
 [ 1.307394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 25.  8.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 3.  6.  8.  0. 11.] 
adversary cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.  0.  8.  0. 25. 11. 15.
  0. 11.  8.  8. 10. 10.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8 15  0] -> size -> 29 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -2.122988224029541
desired expected reward: 28.47045135498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.3766232]
 [ 8.609697 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 25.  8.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 3.  6.  8.  0. 11.] 
adversary cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.  0.  8.  0. 25. 11. 15.
  0. 11.  8.  8. 10. 10.] 
adversary owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8 15  0] -> size -> 29 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -1.1178611516952515
desired expected reward: 7.44870138168335



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  8.  0. 11.] 
cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.  0.  8.  0. 25. 11. 15.
  0. 11.  8.  8. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10  8  3 11  0 11 10 25  0 11  6  0 15  8  0  8  0 10  8 29
  8  0  8 15  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [1. 0. 1. 6. 0.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0] -> size -> 41 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.  0.  8.  0. 25. 11. 15.
  0. 11.  8.  8. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [1. 0. 1. 6. 0.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0] -> size -> 41 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  0.  8.  0. 10. 15.  8.  0.  8.  0. 29.  0.  0.  8.  0. 25. 11. 15.
  0. 11.  8.  8. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [1. 0. 1. 6. 0.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0] -> size -> 41 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [1. 0. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[6.4693303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 6. 0.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10.  8. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15
  0] -> size -> 25 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -1.0849250555038452
desired expected reward: 7.524774074554443





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.14023519]
 [ 1.5199451 ]
 [-0.9775531 ]
 [ 0.7361622 ]
 [-5.9625425 ]
 [ 0.41847968]
 [ 2.54183   ]
 [ 4.1891136 ]
 [ 0.73347235]
 [-2.6085832 ]
 [-1.0296671 ]
 [ 0.39017344]
 [-7.3458624 ]
 [-0.43981194]
 [ 2.786273  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 6. 0.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 23. 30. 26. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10.  8. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15
  0] -> size -> 25 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -1.0922077894210815
desired expected reward: 5.377122402191162



buy possibilites: [-1] 
expected returns: [[32.13198]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 6. 0.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 4 
card supply: [15. 23. 30. 25. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10.  8. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15
  0] -> size -> 25 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -7.  0.  0.  2.  0.] 
sum of rewards: -10.0 

action type: buy - action 3.0
Learning step: 0.1861613541841507
desired expected reward: 0.9223249554634094






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [10.  8. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 15. 10.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 25. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [16.  0.  6.  3.  6.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3] -> size -> 42 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1.  8. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  0  0 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 25. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [16.  0.  6.  3.  6.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3] -> size -> 42 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 8  0 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 3 
card supply: [15. 23. 30. 25. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [16.  0.  6.  3.  6.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3] -> size -> 42 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 23. 30. 25. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [16.  0.  6.  3.  6.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3] -> size -> 42 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 23. 30. 25. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [16.  0.  6.  3.  6.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3] -> size -> 42 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [16.  0.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-10.597832]
 [-18.333704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  3.  6.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 25. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 8. 11. 25.  0.  8.] 
adversary cards in discard: [10. 15.  8. 10.] 
adversary owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0] -> size -> 23 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -2.14877986907959
desired expected reward: 29.983200073242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-19.42675  ]
 [-10.0131035]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  3.  6.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 23. 30. 25. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 8. 11. 25.  0.  8.] 
adversary cards in discard: [10. 15.  8. 10.] 
adversary owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0] -> size -> 23 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.010786915197968483
desired expected reward: -10.608597755432129



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 8. 11. 25.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 25.  0.  8.] 
cards in discard: [10. 15.  8. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 25. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [11.  0. 11. 14.  3.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3] -> size -> 42 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0.  8.] 
cards in discard: [10. 15.  8. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [11.  0. 11. 14.  3.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3] -> size -> 42 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  0.  8.] 
cards in discard: [10. 15.  8. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [11.  0. 11. 14.  3.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3] -> size -> 42 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [11.  0. 11. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 14.] 
expected returns: [[-15.6061535]
 [-14.90777  ]
 [-14.90777  ]
 [-19.290089 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 14.  3.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  4.  0.  7.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8.] 
adversary owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3] -> size -> 24 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -0.6024138331413269
desired expected reward: -10.61551570892334



action possibilites: [-1] 
expected returns: [[-8.976209]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 14.  3.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  4.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8.] 
adversary owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3] -> size -> 24 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0  -8   0   0  16   0] 
sum of rewards: 13 

action type: gain_card_n - action 5
Learning step: 1.3624786138534546
desired expected reward: -16.9263858795166





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-10.535734]
 [ -8.725441]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 14.  3.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  4.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8.] 
adversary owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3] -> size -> 24 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0.4899146258831024
desired expected reward: -8.48629379272461



buy possibilites: [-1] 
expected returns: [[23.48046]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 14.  3.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 23. 30. 24. 29.  8.  0.  9.  4.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8.] 
adversary owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3] -> size -> 24 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -10.   0.   0.  20. -30.   0.   0.   0.  -9.   0.   0.
   0.   0.] 
sum of rewards: -34.0 

action type: buy - action 0.0
Learning step: -0.6553165316581726
desired expected reward: -10.982780456542969






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  8. 11.] 
cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 24. 29.  8.  0.  9.  4.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [3. 4. 6. 6. 3.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0] -> size -> 44 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 24. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [3. 4. 6. 6. 3.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0] -> size -> 44 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 23. 30. 24. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [3. 4. 6. 6. 3.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0] -> size -> 44 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3
 11  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 23. 30. 24. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [3. 4. 6. 6. 3.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0] -> size -> 44 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [3. 4. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[1.2655447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 4. 6. 6. 3.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 24. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8. 11.  0. 11.  8.  0.  0.  8.] 
adversary owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3
 11  0] -> size -> 26 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -1.8955482244491577
desired expected reward: 21.584911346435547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-1.883862 ]
 [ 1.2655447]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4. 6. 6. 3.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0] -> size -> 44 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 23. 30. 24. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8. 11.  0. 11.  8.  0.  0.  8.] 
adversary owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3
 11  0] -> size -> 26 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -0.8066768050193787
desired expected reward: 0.4588678479194641



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8. 11.  0. 11.  8.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  0 11 10 25  0 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3
 11  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 24. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  1. 29.  8. 11.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0] -> size -> 44 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8. 11.  0. 11.  8.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 24. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  1. 29.  8. 11.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0] -> size -> 44 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8. 11.  0. 11.  8.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 23. 30. 24. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  1. 29.  8. 11.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0] -> size -> 44 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [10. 15.  8. 10.  3. 11.  8. 25.  0.  8. 11.  0. 11.  8.  0.  0.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 23. 30. 24. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  1. 29.  8. 11.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0] -> size -> 44 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [ 0.  1. 29.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
expected returns: [[-16.478403]
 [-16.061825]
 [-15.883644]
 [-14.85493 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  8. 11.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 24. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [11.  0. 15. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -1.1609147787094116
desired expected reward: 0.10462987422943115





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-15.787814]
 [-15.230972]
 [-14.421825]
 [-14.854931]
 [-15.297825]
 [-16.478405]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29.  8. 11.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 23. 30. 24. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [11.  0. 15. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -0.2633989453315735
desired expected reward: -16.74180030822754



buy possibilites: [-1] 
expected returns: [[-18.892067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29.  8. 11.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 24. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [11.  0. 15. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0 -10   0   0  18   0] 
sum of rewards: -7 

action type: buy - action 1.0
Learning step: -0.013522910885512829
desired expected reward: -15.244494438171387






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [11.  0. 15. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 29. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15. 29. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 24. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 1. 10. 15.  0.  3.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.  1.  0.
  1. 29.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1] -> size -> 45 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29. 10.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 23. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 1. 10. 15.  0.  3.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.  1.  0.
  1. 29.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1] -> size -> 45 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 29. 10.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 22. 30. 23. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 1. 10. 15.  0.  3.] 
adversary cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.  1.  0.
  1. 29.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1] -> size -> 45 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [ 1. 10. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[-4.448283]
 [-8.38772 ]
 [-9.242141]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 15.  0.  3.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.  1.  0.
  1. 29.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1
 11  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 23. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10. 11.  0.  0.  0.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.] 
adversary owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -0.4459211528301239
desired expected reward: -19.337987899780273



action possibilites: [-1] 
expected returns: [[-19.165274]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.  1.  0.
  1. 29.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 22. 30. 23. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10. 11.  0.  0.  0.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.] 
adversary owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 15.0
Learning step: -0.21911168098449707
desired expected reward: -9.461250305175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-15.642896]
 [-18.072985]
 [-16.190807]
 [-13.208871]
 [-16.579659]
 [-18.749132]
 [-18.913916]
 [-17.27941 ]
 [-13.242129]
 [-13.856988]
 [-16.032867]
 [-12.308192]
 [-14.85408 ]
 [-19.16527 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.  1.  0.
  1. 29.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 22. 30. 23. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10. 11.  0.  0.  0.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.] 
adversary owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: 0.3799498975276947
desired expected reward: -18.785324096679688



buy possibilites: [-1] 
expected returns: [[19.133457]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.] 
cards in discard: [ 0.  0.  6. 25.  6.  0.  0.  6.  6. 25.  8.  3.  1.  0.  1.  6.  0. 16.
  0.  6.  3.  6. 29.  0. 11.  0. 11. 14.  3.  3.  4.  6.  6.  3.  1.  0.
  1. 29.  8. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 22. 30. 23. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [10. 11.  0.  0.  0.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.] 
adversary owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -20.    0.    0.   20.    0.    0.    0.    0.  -10.
   0.    0.    4.5   0. ] 
sum of rewards: -10.5 

action type: buy - action 10.0
Learning step: 0.7071463465690613
desired expected reward: -15.325724601745605






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [10. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.  0.] 
cards in discard: [ 3. 11.  0. 15. 29. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 23. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10] -> size -> 45 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.  0.] 
cards in discard: [ 3. 11.  0. 15. 29. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 22. 30. 23. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10] -> size -> 45 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.  0.] 
cards in discard: [ 3. 11.  0. 15. 29. 10.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10] -> size -> 45 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[9.702027]
 [9.589123]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  6.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.] 
adversary owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3  1] -> size -> 27 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -1.9891613721847534
desired expected reward: 17.144296646118164



action possibilites: [-1] 
expected returns: [[45.421032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 20. 30. 23. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.] 
adversary owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3  1] -> size -> 27 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0 -11   0   0   9   0] 
sum of rewards: -7 

action type: gain_card_n - action 1
Learning step: 0.29203325510025024
desired expected reward: 7.890832901000977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[26.714293]
 [37.79225 ]
 [44.439625]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 20. 30. 23. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.] 
adversary owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3  1] -> size -> 27 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: -1.6340141296386719
desired expected reward: 43.787017822265625



buy possibilites: [-1] 
expected returns: [[17.400236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [1. 3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 20. 30. 22. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.] 
adversary owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3  1] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0 -12   0   0   8   0] 
sum of rewards: 2 

action type: buy - action 3.0
Learning step: -1.398107886314392
desired expected reward: 36.3941535949707






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8.  0. 10.] 
cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0
  0  3  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 30. 22. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [6. 1. 6. 0. 3.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3] -> size -> 47 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0  0
  3  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 20. 30. 22. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [6. 1. 6. 0. 3.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3] -> size -> 47 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0  0
  3  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 20. 30. 22. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [6. 1. 6. 0. 3.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3] -> size -> 47 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [6. 1. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[13.202337]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 6. 0. 3.] 
cards in discard: [ 1.  3. 11.  0.  0.  3.  6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 30. 22. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [0. 8. 8. 8. 0.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.  8.  3.  0. 10.] 
adversary owned cards: [10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0  0
  3  1] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -1.2729592323303223
desired expected reward: 16.127277374267578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[11.402403 ]
 [13.256285 ]
 [12.34309  ]
 [13.9893875]
 [11.973408 ]
 [13.776907 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 0. 3.] 
cards in discard: [ 1.  3. 11.  0.  0.  3.  6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 20. 30. 22. 29.  8.  0.  9.  3.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [0. 8. 8. 8. 0.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.  8.  3.  0. 10.] 
adversary owned cards: [10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0  0
  3  1] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -1.0006368160247803
desired expected reward: 10.974176406860352



buy possibilites: [-1] 
expected returns: [[25.153412]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 0. 3.] 
cards in discard: [ 1.  3. 11.  0.  0.  3.  6. 11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3 11] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 20. 30. 22. 29.  8.  0.  9.  2.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [0. 8. 8. 8. 0.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.  8.  3.  0. 10.] 
adversary owned cards: [10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0  0
  3  1] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0 -13   0   0  18   0] 
sum of rewards: -9 

action type: buy - action 11.0
Learning step: -0.5835176706314087
desired expected reward: 13.405869483947754






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 8. 0.] 
cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.  8.  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11 10 25 11  0 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0  0
  3  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 30. 22. 29.  8.  0.  9.  2.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [11.  6.  1.  6.  0.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  3.  6. 11.  6.  1.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3 11] -> size -> 48 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0.] 
cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.  8.  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8 11 10 25 11 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0  0  3
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 20. 30. 22. 29.  8.  0.  9.  2.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [11.  6.  1.  6.  0.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  3.  6. 11.  6.  1.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3 11] -> size -> 48 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.  8.  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8 11 10 25 11 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0  0  3
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 20. 30. 22. 29.  8.  0.  9.  2.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [11.  6.  1.  6.  0.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  3.  6. 11.  6.  1.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3 11] -> size -> 48 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.  8.  3.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8 11 10 25 11 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0  0  3
  1  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 20. 30. 22. 29.  8.  0.  9.  2.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [11.  6.  1.  6.  0.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  3.  6. 11.  6.  1.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3 11] -> size -> 48 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [11.  6.  1.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[9.209396]
 [9.230488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  1.  6.  0.] 
cards in discard: [ 1.  3. 11.  0.  0.  3.  6. 11.  6.  1.  6.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3 11] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 30. 22. 29.  8.  0.  9.  2.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [ 8.  8. 11. 15. 25.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.  8.  3.  0. 10.  0.  8.
  8.  8.  0.] 
adversary owned cards: [10  8 11 10 25 11 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0  0  3
  1  0] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -1.7501310110092163
desired expected reward: 23.40328025817871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[6.963774]
 [7.422136]
 [6.668077]
 [7.97743 ]
 [7.34928 ]
 [8.053535]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  1.  6.  0.] 
cards in discard: [ 1.  3. 11.  0.  0.  3.  6. 11.  6.  1.  6.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3 11] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 20. 30. 22. 29.  8.  0.  9.  2.  0.  7.  7.  8.  9.  1. 10.  7.] 
adversary cards in hand: [ 8.  8. 11. 15. 25.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.  8.  3.  0. 10.  0.  8.
  8.  8.  0.] 
adversary owned cards: [10  8 11 10 25 11 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0  0  3
  1  0] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -0.9882646799087524
desired expected reward: 8.221138954162598



Player 1 won the game! 



Player 0 bought cards:
Copper: 4 
Silver: 5 
Gold: 0 
Estate: 4 
Duchy: 1 
Province: 0 
Curse: 9 

Remodel: 1 
Workshop: 4 
Chapel: 2 
Witch: 2 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11.  6.  1.  6.  0.] 
cards in discard: [ 1.  3. 11.  0.  0.  3.  6. 11.  6.  1.  6.  0.  3. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  6  6  1  0  1  6  4  6  6  0 29  6  1 11
  6 25 10  8  1  6 25 14 16  6  8 15 11 11  3  0  3 29  0  1 10  1  3 11
 10] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 20. 30. 22. 29.  8.  0.  9.  2.  0.  7.  7.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  8. 11. 15. 25.] 
adversary cards in discard: [ 3. 11.  0. 15. 29. 10.  1. 10. 11.  0.  0.  0.  8.  3.  0. 10.  0.  8.
  8.  8.  0.] 
adversary owned cards: [10  8 11 10 25 11 15  8  0  8  0 10  8 29  8  0  8 15  0  3 11  0  0  3
  1  0] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5 -500    1  -10    0    0    0    0    0    0    0  -14    0    0
    9    0] 
sum of rewards: -519 

action type: buy - action 10.0
Learning step: -26.31746482849121
desired expected reward: -18.96817970275879



