 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[311.23642]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   4  30   0   0  60 -30   0   0   0  -7   0   0   0   0] 
sum of rewards: 552 

action type: buy - action 0.0
Learning step: 27.971759796142578
desired expected reward: 20.53656578063965





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[286.506  ]
 [296.28876]
 [294.00305]
 [275.7158 ]
 [271.039  ]
 [290.13586]
 [305.4396 ]
 [296.26025]
 [312.7022 ]
 [301.0202 ]
 [282.46533]
 [287.48712]
 [294.15543]
 [276.2131 ]
 [293.7393 ]
 [312.77972]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.238696098327637
desired expected reward: 305.6831970214844



buy possibilites: [-1] 
expected returns: [[268.64835]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 6.0 

action type: buy - action 15.0
Learning step: -8.342373847961426
desired expected reward: 285.3968505859375






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[307.95422]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [15.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.5921244621276855
desired expected reward: 262.05621337890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[286.97095]
 [294.1208 ]
 [273.19455]
 [296.20624]
 [312.347  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [15.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.90942096710205
desired expected reward: 299.5480651855469



buy possibilites: [-1] 
expected returns: [[293.65646]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [15.  0.  0.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -22.70245933532715
desired expected reward: 250.49212646484375






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [15.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[283.92358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.935957908630371
desired expected reward: 284.72052001953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[249.74852]
 [258.64975]
 [256.13474]
 [238.05858]
 [267.76672]
 [258.75723]
 [256.316  ]
 [276.08804]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.03869915008545
desired expected reward: 275.2664489746094



buy possibilites: [-1] 
expected returns: [[295.81766]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 3.0
Learning step: -6.1508402824401855
desired expected reward: 249.98390197753906






Player: 1 
cards in hand: [ 0. 15.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  6.  3.  0. 15.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  6.  3.  0. 15.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  3.  0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  6.  3.  0. 15.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[291.43295]
 [272.2076 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  0. 15.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 8.  0. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.51311206817627
desired expected reward: 287.3045349121094



action possibilites: [-1] 
expected returns: [[301.01132]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 8.  0. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 15.0
Learning step: -5.984592437744141
desired expected reward: 267.162353515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[277.00067]
 [286.41412]
 [284.02188]
 [262.07037]
 [280.48438]
 [294.8934 ]
 [286.40594]
 [290.73068]
 [272.94193]
 [284.1726 ]
 [283.66272]
 [301.46835]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 8.  0. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -7.739990234375
desired expected reward: 293.2713317871094






Player: 1 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [ 8.  0. 15.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 8.  0. 15.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 8.  0. 15.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 8.  0. 15.  0.  3.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[262.0495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.218541145324707
desired expected reward: 292.2497863769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[230.4146 ]
 [238.00824]
 [235.94348]
 [218.40457]
 [246.26425]
 [238.05603]
 [236.11737]
 [254.72531]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.968001842498779
desired expected reward: 256.6931457519531



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 15.  3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 15.  3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  3.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 15.  3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[287.89966]
 [267.61392]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 15.  3.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  6  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -6.576793670654297
desired expected reward: 248.1485137939453



action possibilites: [-1] 
expected returns: [[322.66086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  6  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 15.0
Learning step: -5.2078537940979
desired expected reward: 262.1466064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[294.80222]
 [304.33948]
 [302.26346]
 [279.8096 ]
 [298.3728 ]
 [313.54654]
 [304.27307]
 [309.0751 ]
 [290.97693]
 [302.38095]
 [302.02686]
 [321.26743]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  6  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -8.40967082977295
desired expected reward: 314.2511901855469



buy possibilites: [-1] 
expected returns: [[282.63644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  6  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -12.0 

action type: buy - action 0.0
Learning step: -8.696556091308594
desired expected reward: 280.42095947265625






Player: 1 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [ 1.  0.  0. 15.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  6  3  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 1.  0.  0. 15.  0.  3. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  6  3  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 1.  0.  0. 15.  0.  3. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  6  3  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[252.95934]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  6  3  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [1. 0. 3. 3. 8.] 
adversary cards in discard: [ 1.  0.  0. 15.  0.  3. 14. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.519061088562012
desired expected reward: 274.11737060546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[230.9975 ]
 [238.63269]
 [236.84167]
 [218.94437]
 [245.70337]
 [238.60043]
 [236.94595]
 [251.3025 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  6  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [1. 0. 3. 3. 8.] 
adversary cards in discard: [ 1.  0.  0. 15.  0.  3. 14. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.435187816619873
desired expected reward: 246.46531677246094



buy possibilites: [-1] 
expected returns: [[264.28995]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  6  3  0  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [1. 0. 3. 3. 8.] 
adversary cards in discard: [ 1.  0.  0. 15.  0.  3. 14. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -20.65069580078125
desired expected reward: 198.29368591308594






Player: 1 
cards in hand: [1. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 8.] 
cards in discard: [ 1.  0.  0. 15.  0.  3. 14. 11.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [6. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  6  3  0  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 8.] 
cards in discard: [ 1.  0.  0. 15.  0.  3. 14. 11.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [6. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  6  3  0  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 8.] 
cards in discard: [ 1.  0.  0. 15.  0.  3. 14. 11.  0.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [6. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  6  3  0  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[283.2504 ]
 [266.98334]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [6. 3. 0. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  6  3  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14 10] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.654171943664551
desired expected reward: 256.6357727050781



action possibilites: [-1] 
expected returns: [[250.85362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [6. 3. 0. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14 10] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action 15.0
Learning step: -7.361538887023926
desired expected reward: 259.75335693359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[226.92943]
 [235.73239]
 [234.12943]
 [217.34763]
 [213.16298]
 [230.25897]
 [244.6069 ]
 [235.5865 ]
 [250.85962]
 [240.4269 ]
 [223.68895]
 [228.63152]
 [234.16075]
 [218.16827]
 [234.03275]
 [251.80066]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [6. 3. 0. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14 10] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -6.9321208000183105
desired expected reward: 243.9215087890625



buy possibilites: [-1] 
expected returns: [[188.29022]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6.  3.  0.  0.  0.  6. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14 10] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: 57 

action type: buy - action 25.0
Learning step: -5.4564528465271
desired expected reward: 245.4031982421875






Player: 1 
cards in hand: [ 3.  0.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [3. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14 10  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[228.25659]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  8.  0.] 
adversary cards in discard: [ 1. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14 10  1] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: discard_down_to_3_cards - action 3
Learning step: -7.227344036102295
desired expected reward: 227.7074737548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[202.2671 ]
 [188.95308]
 [225.34395]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  8.  0.] 
adversary cards in discard: [ 1. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14 10  1] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.482575416564941
desired expected reward: 222.2684326171875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  8.  0.] 
cards in discard: [ 1. 14.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14 10  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  6. 15.] 
adversary cards in discard: [3. 6. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 1. 14.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  6. 15.] 
adversary cards in discard: [3. 6. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1. 14.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  6. 15.] 
adversary cards in discard: [3. 6. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[235.19737]
 [216.71004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 15.] 
cards in discard: [3. 6. 0. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  1.  0.] 
adversary cards in discard: [ 1. 14.  3.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -6.821712017059326
desired expected reward: 218.52223205566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[212.8314 ]
 [220.03455]
 [198.56123]
 [221.83318]
 [237.37943]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6. 15.] 
cards in discard: [3. 6. 0. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  1.  0.] 
adversary cards in discard: [ 1. 14.  3.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.484227180480957
desired expected reward: 227.95506286621094



buy possibilites: [-1] 
expected returns: [[249.34822]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6. 15.] 
cards in discard: [3. 6. 0. 3. 3. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  1.  0.] 
adversary cards in discard: [ 1. 14.  3.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -324.0 

action type: buy - action 6.0
Learning step: -20.51772689819336
desired expected reward: 178.04348754882812






Player: 1 
cards in hand: [ 0. 15.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  1.  0.] 
cards in discard: [ 1. 14.  3.  0.  0.  0.  8.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  6. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25  6] -> size -> 14 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0.] 
cards in discard: [ 1. 14.  3.  0.  0.  0.  8.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  6. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25  6] -> size -> 14 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 1. 14.  3.  0.  0.  0.  8.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  6. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25  6] -> size -> 14 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 1. 14.  3.  0.  0.  0.  8.  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 3.  6. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25  6] -> size -> 14 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3.  6. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[252.8769 ]
 [253.70982]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  3.  1.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -7.991462707519531
desired expected reward: 241.35675048828125



action possibilites: [-1] 
expected returns: [[262.30182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  6. 10.  9.  9.  9. 10.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  3.  1.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 25.0
Learning step: -6.562809944152832
desired expected reward: 246.0893096923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[232.91252]
 [239.47017]
 [219.71054]
 [241.96594]
 [257.0147 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  6. 10.  9.  9.  9. 10.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  3.  1.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -7.926100254058838
desired expected reward: 254.37571716308594



buy possibilites: [-1] 
expected returns: [[187.58821]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 6. 3.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  5. 10.  9.  9.  9. 10.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  3.  1.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -315.0 

action type: buy - action 6.0
Learning step: -22.51479148864746
desired expected reward: 197.1957550048828






Player: 1 
cards in hand: [ 0.  3.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  0. 11.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  5. 10.  9.  9.  9. 10.  9. 10.  9. 10.  7.] 
adversary cards in hand: [15.  0.  0.  6.  3.] 
adversary cards in discard: [ 6. 25.  3.  6.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25  6  6] -> size -> 15 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 11.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8.  5. 10.  9.  9.  9. 10.  9. 10.  9. 10.  7.] 
adversary cards in hand: [15.  0.  0.  6.  3.] 
adversary cards in discard: [ 6. 25.  3.  6.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25  6  6] -> size -> 15 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 11.] 
cards in discard: [6. 1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 29. 30.  8.  5. 10.  9.  9.  9. 10.  9. 10.  9. 10.  7.] 
adversary cards in hand: [15.  0.  0.  6.  3.] 
adversary cards in discard: [ 6. 25.  3.  6.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25  6  6] -> size -> 15 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[213.56844]
 [198.9398 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  6.  3.] 
cards in discard: [ 6. 25.  3.  6.  0.  0.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  6  3  0  6 25  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  5. 10.  9.  9.  9. 10.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 1. 15.  3. 15.  0.] 
adversary cards in discard: [ 6.  1.  0.  3.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1] -> size -> 19 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -5.9614787101745605
desired expected reward: 181.62673950195312



action possibilites: [-1] 
expected returns: [[188.69452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [ 6. 25.  3.  6.  0.  0.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 26. 30. 29. 30.  8.  5. 10.  9.  9.  9. 10.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 1. 15.  3. 15.  0.] 
adversary cards in discard: [ 6.  1.  0.  3.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1] -> size -> 19 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 15.0
Learning step: -5.976095199584961
desired expected reward: 193.45834350585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[170.67323]
 [177.58882]
 [175.7317 ]
 [159.6779 ]
 [173.23097]
 [184.1482 ]
 [177.5803 ]
 [180.75005]
 [167.54765]
 [175.82845]
 [175.32632]
 [189.12968]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [ 6. 25.  3.  6.  0.  0.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 29. 30.  8.  5. 10.  9.  9.  9. 10.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 1. 15.  3. 15.  0.] 
adversary cards in discard: [ 6.  1.  0.  3.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1] -> size -> 19 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: -5.712718486785889
desired expected reward: 182.98179626464844



buy possibilites: [-1] 
expected returns: [[133.24922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [ 6. 25.  3.  6.  0.  0.  6.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 1. 15.  3. 15.  0.] 
adversary cards in discard: [ 6.  1.  0.  3.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1] -> size -> 19 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: -4.689395427703857
desired expected reward: 176.06065368652344






Player: 1 
cards in hand: [ 1. 15.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  3. 15.  0.] 
cards in discard: [ 6.  1.  0.  3.  1.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [29.  0. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29] -> size -> 15 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  3. 15.  0.] 
cards in discard: [ 6.  1.  0.  3.  1.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 29. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  9. 10.  7.] 
adversary cards in hand: [29.  0. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29] -> size -> 15 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  3. 15.  0.] 
cards in discard: [ 6.  1.  0.  3.  1.  0. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [29.  0. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29] -> size -> 15 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29.  0. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[158.2201 ]
 [150.74104]
 [145.6992 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0. 14.  8.  0.] 
adversary cards in discard: [ 6.  1.  0.  3.  1.  0. 11. 10.  1. 15.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10] -> size -> 20 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -4.425212860107422
desired expected reward: 128.82400512695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[141.7966 ]
 [146.72108]
 [131.12741]
 [148.50066]
 [158.96606]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0. 14.  8.  0.] 
adversary cards in discard: [ 6.  1.  0.  3.  1.  0. 11. 10.  1. 15.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10] -> size -> 20 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -6.016798973083496
desired expected reward: 155.17935180664062



buy possibilites: [-1] 
expected returns: [[193.51033]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 15.  0.  3.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0. 14.  8.  0.] 
adversary cards in discard: [ 6.  1.  0.  3.  1.  0. 11. 10.  1. 15.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -6 

action type: buy - action 3.0
Learning step: -3.282073736190796
desired expected reward: 143.4390411376953






Player: 1 
cards in hand: [ 3.  0. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  8.  0.] 
cards in discard: [ 6.  1.  0.  3.  1.  0. 11. 10.  1. 15.  3. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [6. 6. 0. 6. 3.] 
adversary cards in discard: [ 3. 29.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3] -> size -> 16 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  8.  0.] 
cards in discard: [ 6.  1.  0.  3.  1.  0. 11. 10.  1. 15.  3. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 28. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [6. 6. 0. 6. 3.] 
adversary cards in discard: [ 3. 29.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3] -> size -> 16 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [6. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[156.98299]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 3.] 
cards in discard: [ 3. 29.  0. 15.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -6.868231296539307
desired expected reward: 186.64210510253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[131.29836 ]
 [119.025085]
 [151.38258 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 3.] 
cards in discard: [ 3. 29.  0. 15.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -5.454061031341553
desired expected reward: 150.42529296875



buy possibilites: [-1] 
expected returns: [[214.77951]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 3.] 
cards in discard: [ 3. 29.  0. 15.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -44.0 

action type: buy - action 0.0
Learning step: -3.9323787689208984
desired expected reward: 127.36597442626953






Player: 1 
cards in hand: [0. 3. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  6.  0. 25.  3.] 
adversary cards in discard: [ 3. 29.  0. 15.  0.  3.  0.  6.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0] -> size -> 17 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 26. 30. 28. 30.  8.  5. 10.  9.  9.  9.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  6.  0. 25.  3.] 
adversary cards in discard: [ 3. 29.  0. 15.  0.  3.  0.  6.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0] -> size -> 17 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  5. 10.  9.  9.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  6.  0. 25.  3.] 
adversary cards in discard: [ 3. 29.  0. 15.  0.  3.  0.  6.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0] -> size -> 17 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[143.68768]
 [143.88193]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 25.  3.] 
cards in discard: [ 3. 29.  0. 15.  0.  3.  0.  6.  6.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  5. 10.  9.  9.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11. 10.] 
adversary cards in discard: [25.  0.  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -8.25528621673584
desired expected reward: 206.52423095703125



action possibilites: [-1] 
expected returns: [[176.24861]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  4. 10.  9.  9.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11. 10.] 
adversary cards in discard: [25.  0.  3.  1.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 7 

action type: take_action - action 25.0
Learning step: -2.7692596912384033
desired expected reward: 138.9278106689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[150.2552 ]
 [157.03993]
 [138.31851]
 [158.28355]
 [173.79832]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 28. 30.  8.  4. 10.  9.  9.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11. 10.] 
adversary cards in discard: [25.  0.  3.  1.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -4.984481334686279
desired expected reward: 171.26412963867188



buy possibilites: [-1] 
expected returns: [[181.21622]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 28. 30.  8.  4. 10.  9.  9.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11. 10.] 
adversary cards in discard: [25.  0.  3.  1.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -24.0 

action type: buy - action 0.0
Learning step: -4.470578193664551
desired expected reward: 145.7846221923828






Player: 1 
cards in hand: [ 6.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11. 10.] 
cards in discard: [25.  0.  3.  1.  1.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  4. 10.  9.  9.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [ 0. 25.  3.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11. 10.] 
cards in discard: [25.  0.  3.  1.  1.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 28. 30.  8.  4. 10.  9.  9.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [ 0. 25.  3.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11. 10.] 
cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  4. 10.  9.  8.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [ 0. 25.  3.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[146.99527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [ 0. 25.  3.  6.  0.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  4. 10.  9.  8.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8. 1. 1. 3.] 
adversary cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.  6.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8] -> size -> 23 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -6.03449010848999
desired expected reward: 175.18173217773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[128.2974 ]
 [133.54507]
 [118.04961]
 [135.2048 ]
 [147.7718 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [ 0. 25.  3.  6.  0.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 28. 30.  8.  4. 10.  9.  8.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8. 1. 1. 3.] 
adversary cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.  6.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8] -> size -> 23 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -4.3631205558776855
desired expected reward: 139.02891540527344



buy possibilites: [-1] 
expected returns: [[176.87094]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [ 0. 25.  3.  6.  0.  3.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  9.  8.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8. 1. 1. 3.] 
adversary cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.  6.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8] -> size -> 23 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -34.0 

action type: buy - action 0.0
Learning step: -4.135273456573486
desired expected reward: 124.16210174560547






Player: 1 
cards in hand: [0. 8. 1. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 1. 3.] 
cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.  6.  0.  0. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  9.  8.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 0. 15.  6. 29.  3.] 
adversary cards in discard: [ 0. 25.  3.  6.  0.  3.  0.  3.  0.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1.] 
cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.  6.  0.  0. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  9.  8.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 0. 15.  6. 29.  3.] 
adversary cards in discard: [ 0. 25.  3.  6.  0.  3.  0.  3.  0.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0] -> size -> 19 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.  6.  0.  0. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  9.  8.  8.  9.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 0. 15.  6. 29.  3.] 
adversary cards in discard: [ 0. 25.  3.  6.  0.  3.  0.  3.  0.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0] -> size -> 19 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.  6.  0.  0. 11. 10. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  9.  8.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 0. 15.  6. 29.  3.] 
adversary cards in discard: [ 0. 25.  3.  6.  0.  3.  0.  3.  0.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0] -> size -> 19 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  6. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[226.57877]
 [210.28012]
 [216.78836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6. 29.  3.] 
cards in discard: [ 0. 25.  3.  6.  0.  3.  0.  3.  0.  0.  0.  3.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  9.  8.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 0. 14. 15. 15.  3.] 
adversary cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.  6.  0.  0. 11. 10. 15.  8.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -3.692617177963257
desired expected reward: 173.17832946777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[202.07422]
 [188.26811]
 [224.69336]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6. 29.  3.] 
cards in discard: [ 0. 25.  3.  6.  0.  3.  0.  3.  0.  0.  0.  3.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  9.  8.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 0. 14. 15. 15.  3.] 
adversary cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.  6.  0.  0. 11. 10. 15.  8.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -6.243525505065918
desired expected reward: 217.49282836914062



buy possibilites: [-1] 
expected returns: [[181.75612]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6. 29.  3.] 
cards in discard: [ 0. 25.  3.  6.  0.  3.  0.  3.  0.  0.  0.  3.  6.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  9.  8.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 0. 14. 15. 15.  3.] 
adversary cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.  6.  0.  0. 11. 10. 15.  8.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15] -> size -> 23 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -20.57389259338379
desired expected reward: 167.6942138671875






Player: 1 
cards in hand: [ 0. 14. 15. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 15. 15.  3.] 
cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.  6.  0.  0. 11. 10. 15.  8.  0.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  9.  8.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 15. 15.  3.] 
cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.  6.  0.  0. 11. 10. 15.  8.  0.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  9.  8.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 15. 15.  3.] 
cards in discard: [25.  0.  3.  1.  1.  0.  6.  8.  6.  0.  0. 11. 10. 15.  8.  0.  1.  1.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  9.  8.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [6. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[95.98287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  9.  8.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -7.187348365783691
desired expected reward: 174.5687713623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[75.53132 ]
 [80.322365]
 [66.52302 ]
 [81.50354 ]
 [92.93972 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  9.  8.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -3.2220497131347656
desired expected reward: 92.35385131835938



buy possibilites: [-1] 
expected returns: [[120.21186]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  9.  7.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -1.2204102277755737
desired expected reward: 80.28312683105469






Player: 1 
cards in hand: [0. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  9.  7.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 3.  3.  0. 25. 15.] 
adversary cards in discard: [8. 6. 0. 6. 6. 0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8] -> size -> 21 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  9.  7.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 3.  3.  0. 25. 15.] 
adversary cards in discard: [8. 6. 0. 6. 6. 0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8] -> size -> 21 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  9.  7.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 3.  3.  0. 25. 15.] 
adversary cards in discard: [8. 6. 0. 6. 6. 0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8] -> size -> 21 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  9.  7.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 3.  3.  0. 25. 15.] 
adversary cards in discard: [8. 6. 0. 6. 6. 0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8] -> size -> 21 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
expected returns: [[111.81206]
 [111.81093]
 [100.1835 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 25. 15.] 
cards in discard: [8. 6. 0. 6. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  9.  7.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 3.  0.  1. 15. 14.] 
adversary cards in discard: [3. 8. 1.] 
adversary owned cards: [ 0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0  3] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -4.443182468414307
desired expected reward: 115.7686767578125



action possibilites: [-1] 
expected returns: [[91.465576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.] 
cards in discard: [8. 6. 0. 6. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  9.  7.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 3.  0.  1. 15. 14.] 
adversary cards in discard: [3. 8. 1.] 
adversary owned cards: [ 0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0  3] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 15.0
Learning step: -2.449286699295044
desired expected reward: 92.69595336914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[76.45562 ]
 [83.07724 ]
 [81.66145 ]
 [66.18262 ]
 [89.06471 ]
 [82.9292  ]
 [81.63145 ]
 [95.062805]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25.] 
cards in discard: [8. 6. 0. 6. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  9.  7.  8.  9.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 3.  0.  1. 15. 14.] 
adversary cards in discard: [3. 8. 1.] 
adversary owned cards: [ 0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0  3] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -2.45784854888916
desired expected reward: 89.00772857666016



buy possibilites: [-1] 
expected returns: [[63.25259]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25.] 
cards in discard: [ 8.  6.  0.  6.  6.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  0.  1. 15. 14.] 
adversary cards in discard: [3. 8. 1.] 
adversary owned cards: [ 0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0  3] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 23 

action type: buy - action 10.0
Learning step: -1.5083903074264526
desired expected reward: 80.12307739257812






Player: 1 
cards in hand: [ 3.  0.  1. 15. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 15. 14.] 
cards in discard: [3. 8. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  6.  0.  6.  6.  0. 10. 15.  3.  3. 25.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 14.] 
cards in discard: [3. 8. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  6.  0.  6.  6.  0. 10. 15.  3.  3. 25.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 14.] 
cards in discard: [3. 8. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  6.  0.  6.  6.  0. 10. 15.  3.  3. 25.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 14.] 
cards in discard: [ 3.  8.  1. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0  3 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  3.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  6.  0.  6.  6.  0. 10. 15.  3.  3. 25.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[66.095]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 8.  6.  0.  6.  6.  0. 10. 15.  3.  3. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 8.  0.  1. 11. 15.] 
adversary cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.] 
adversary owned cards: [ 0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0  3 16] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -2.433384656906128
desired expected reward: 60.81920623779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[53.525566]
 [57.102245]
 [45.88113 ]
 [58.51552 ]
 [66.60518 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 8.  6.  0.  6.  6.  0. 10. 15.  3.  3. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 27. 30.  8.  3.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 8.  0.  1. 11. 15.] 
adversary cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.] 
adversary owned cards: [ 0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0  3 16] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -2.753934383392334
desired expected reward: 62.99027633666992



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  1. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 11. 15.] 
cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 15 11  8  0  1  1 14  1 15  6  1 10 25  6  8 15  0  3 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0.  6. 29.  6.] 
adversary cards in discard: [ 8.  6.  0.  6.  6.  0. 10. 15.  3.  3. 25.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0.  6. 29.  6.] 
adversary cards in discard: [ 8.  6.  0.  6.  6.  0. 10. 15.  3.  3. 25.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0.  6. 29.  6.] 
adversary cards in discard: [ 8.  6.  0.  6.  6.  0. 10. 15.  3.  3. 25.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 27. 30.  8.  3.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0.  6. 29.  6.] 
adversary cards in discard: [ 8.  6.  0.  6.  6.  0. 10. 15.  3.  3. 25.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[103.00473]
 [ 93.34837]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 29.  6.] 
cards in discard: [ 8.  6.  0.  6.  6.  0. 10. 15.  3.  3. 25.  3.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 27. 30.  8.  3.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [15.  6. 10.  6. 25.] 
adversary cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.  0.  8. 11.] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0] -> size -> 20 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -1.8669828176498413
desired expected reward: 64.73819732666016



action possibilites: [-1. 25.] 
expected returns: [[62.594685]
 [61.7635  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  6. 25.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 27. 30.  8.  3.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [15.  6. 10.  6. 25.] 
adversary cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.  0.  8. 11.] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0] -> size -> 20 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: -2.81854248046875
desired expected reward: 86.54579162597656



action possibilites: [-1] 
expected returns: [[78.38676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  6. 15. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [15.  6. 10.  6. 25.] 
adversary cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.  0.  8. 11.  6.] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6] -> size -> 21 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 25.0
Learning step: -0.07447262108325958
desired expected reward: 61.68901824951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[62.4331  ]
 [67.991745]
 [66.63666 ]
 [54.33333 ]
 [73.20111 ]
 [67.96182 ]
 [66.70577 ]
 [77.30278 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  6. 15. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [15.  6. 10.  6. 25.] 
adversary cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.  0.  8. 11.  6.] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6] -> size -> 21 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: -1.1443756818771362
desired expected reward: 77.24237823486328



buy possibilites: [-1] 
expected returns: [[104.83974]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  6. 15. 10.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [15.  6. 10.  6. 25.] 
adversary cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.  0.  8. 11.  6.] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6] -> size -> 21 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -10.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -1.012761116027832
desired expected reward: 61.42034149169922






Player: 1 
cards in hand: [15.  6. 10.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 25.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6. 10.  6. 25.] 
cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.  0.  8. 11.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 3. 6. 6. 3.] 
adversary cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0] -> size -> 22 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6. 25.] 
cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.  0.  8. 11.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 3. 6. 6. 3.] 
adversary cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0] -> size -> 22 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6. 25.] 
cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.  0.  8. 11.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 3. 6. 6. 3.] 
adversary cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0] -> size -> 22 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6. 25.] 
cards in discard: [ 3.  8.  1. 16. 15.  3.  1. 14.  0.  8. 11.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 3. 6. 6. 3.] 
adversary cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0] -> size -> 22 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [3. 3. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[89.58876]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 6. 3.] 
cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [8. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -3.5173451900482178
desired expected reward: 101.32239532470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.58917]
 [68.37923]
 [89.42739]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 6. 3.] 
cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [8. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -2.869588613510132
desired expected reward: 84.89226531982422



buy possibilites: [-1] 
expected returns: [[59.501125]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 6. 3.] 
cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [8. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action 0.0
Learning step: -4.190683364868164
desired expected reward: 71.39849090576172






Player: 1 
cards in hand: [8. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.  0.  3.  3.  6.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  9. 10.  7. 10.  6.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.  0.  3.  3.  6.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 1.] 
cards in discard: [14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.  0.  3.  3.  6.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [0. 6. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[66.26221]
 [59.75189]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 3. 0.] 
cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.  0.  3.  3.  6.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8.  1. 14. 15.] 
adversary cards in discard: [14.  8.  0.  0.  3.  1.] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14] -> size -> 23 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.8023490905761719
desired expected reward: 57.69877624511719



action possibilites: [-1] 
expected returns: [[27.51455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.  0.  3.  3.  6.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8.  1. 14. 15.] 
adversary cards in discard: [14.  8.  0.  0.  3.  1.] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14] -> size -> 23 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 3
Learning step: -1.6605287790298462
desired expected reward: 58.93159103393555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.666108]
 [10.92273 ]
 [24.894978]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.  0.  3.  3.  6.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8.  1. 14. 15.] 
adversary cards in discard: [14.  8.  0.  0.  3.  1.] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14] -> size -> 23 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.22760410606861115
desired expected reward: 27.286945343017578



buy possibilites: [-1] 
expected returns: [[23.348202]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 0. 29. 25.  0.  0.  6.  6. 15. 10.  0.  3.  3.  6.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8.  1. 14. 15.] 
adversary cards in discard: [14.  8.  0.  0.  3.  1.] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14] -> size -> 23 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action 0.0
Learning step: -1.0079700946807861
desired expected reward: 14.658123016357422






Player: 1 
cards in hand: [ 6.  8.  1. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  1. 14. 15.] 
cards in discard: [14.  8.  0.  0.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  1. 14. 15.] 
cards in discard: [14.  8.  0.  0.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 27. 30.  8.  2.  9.  9.  7.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  1. 14. 15.] 
cards in discard: [14.  8.  0.  0.  3.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  2.  9.  9.  7.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[88.94672]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  2.  9.  9.  7.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [16.  0.  6. 15.  6.] 
adversary cards in discard: [14.  8.  0.  0.  3.  1.  3.  6.  8.  1. 14. 15.] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3] -> size -> 24 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: 0.08133488148450851
desired expected reward: 23.429536819458008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[66.26933 ]
 [70.69014 ]
 [69.46983 ]
 [59.886333]
 [75.502365]
 [70.74167 ]
 [69.614   ]
 [79.683464]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 26. 30.  8.  2.  9.  9.  7.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [16.  0.  6. 15.  6.] 
adversary cards in discard: [14.  8.  0.  0.  3.  1.  3.  6.  8.  1. 14. 15.] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3] -> size -> 24 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -3.596773862838745
desired expected reward: 85.23634338378906



buy possibilites: [-1] 
expected returns: [[119.25124]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  2.  9.  9.  7.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [16.  0.  6. 15.  6.] 
adversary cards in discard: [14.  8.  0.  0.  3.  1.  3.  6.  8.  1. 14. 15.] 
adversary owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3] -> size -> 24 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -2.0 

action type: buy - action 3.0
Learning step: -0.8903375864028931
desired expected reward: 68.57947540283203






Player: 1 
cards in hand: [16.  0.  6. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6. 15.  6.] 
cards in discard: [14.  8.  0.  0.  3.  1.  3.  6.  8.  1. 14. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  2.  9.  9.  7.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3] -> size -> 23 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6.] 
cards in discard: [14.  8.  0.  0.  3.  1.  3.  6.  8.  1. 14. 15.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  2.  9.  9.  6.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3] -> size -> 23 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6.] 
cards in discard: [14.  8.  0.  0.  3.  1.  3.  6.  8.  1. 14. 15.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  2.  9.  9.  6.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3] -> size -> 23 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [25.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[125.35079]
 [124.91935]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0.  0.] 
cards in discard: [3. 3. 0. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  2.  9.  9.  6.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [11. 25.  1.  3.  0.] 
adversary cards in discard: [14.  8.  0.  0.  3.  1.  3.  6.  8.  1. 14. 15.  8. 16.  6. 15.  6.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8] -> size -> 24 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -3.4263367652893066
desired expected reward: 115.82490539550781



action possibilites: [-1] 
expected returns: [[67.311615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 6. 6.] 
cards in discard: [3. 3. 0. 0. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  1.  9.  9.  6.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [11. 25.  1.  3.  0.] 
adversary cards in discard: [14.  8.  0.  0.  3.  1.  3.  6.  8.  1. 14. 15.  8. 16.  6. 15.  6.  6.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6] -> size -> 25 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action 25.0
Learning step: -3.7166640758514404
desired expected reward: 116.90684509277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[52.90577 ]
 [56.823784]
 [55.059372]
 [47.040833]
 [59.42287 ]
 [57.067234]
 [55.279034]
 [60.61227 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6. 6.] 
cards in discard: [3. 3. 0. 0. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 25. 30.  8.  1.  9.  9.  6.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [11. 25.  1.  3.  0.] 
adversary cards in discard: [14.  8.  0.  0.  3.  1.  3.  6.  8.  1. 14. 15.  8. 16.  6. 15.  6.  6.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6] -> size -> 25 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -1.3083490133285522
desired expected reward: 66.00326538085938






Player: 1 
cards in hand: [11. 25.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  1.  3.  0.] 
cards in discard: [14.  8.  0.  0.  3.  1.  3.  6.  8.  1. 14. 15.  8. 16.  6. 15.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  1.  9.  9.  6.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  6. 29.  0.  6.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  3. 25.  3.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3] -> size -> 23 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  3.  0.] 
cards in discard: [14.  8.  0.  0.  3.  1.  3.  6.  8.  1. 14. 15.  8. 16.  6. 15.  6.  6.
  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  1.  9.  9.  5.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  6. 29.  0.  6.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  3. 25.  3.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3] -> size -> 23 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  3.  0.] 
cards in discard: [14.  8.  0.  0.  3.  1.  3.  6.  8.  1. 14. 15.  8. 16.  6. 15.  6.  6.
  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 25. 30.  8.  1.  9.  9.  5.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  6. 29.  0.  6.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  3. 25.  3.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3] -> size -> 23 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  3.  0.] 
cards in discard: [14.  8.  0.  0.  3.  1.  3.  6.  8.  1. 14. 15.  8. 16.  6. 15.  6.  6.
  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  6. 29.  0.  6.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  3. 25.  3.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3] -> size -> 23 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 6.  6. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[51.371807]
 [43.971096]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 29.  0.  6.] 
cards in discard: [ 3.  3.  0.  0.  0.  3. 25.  3.  0.  0.  0.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 1.  3.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8] -> size -> 27 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -1.6522674560546875
desired expected reward: 58.96001434326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.899193]
 [22.477287]
 [47.79646 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 29.  0.  6.] 
cards in discard: [ 3.  3.  0.  0.  0.  3. 25.  3.  0.  0.  0.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 1.  3.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8] -> size -> 27 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -1.487966775894165
desired expected reward: 49.88381576538086



buy possibilites: [-1] 
expected returns: [[113.33326]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 29.  0.  6.] 
cards in discard: [ 3.  3.  0.  0.  0.  3. 25.  3.  0.  0.  0.  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 1.  3.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8] -> size -> 27 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -24.0 

action type: buy - action 0.0
Learning step: -0.19496117532253265
desired expected reward: 30.704227447509766






Player: 1 
cards in hand: [ 1.  3.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  8.  3. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 8.  3. 10.  3. 15.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  3. 25.  3.  0.  0.  0.  6.  6.  0.  6.  6. 29.  0.
  6.] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0] -> size -> 24 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  8.  3. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 8.  3. 10.  3. 15.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  3. 25.  3.  0.  0.  0.  6.  6.  0.  6.  6. 29.  0.
  6.] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0] -> size -> 24 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 10.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 15.] 
expected returns: [[61.787548]
 [56.146427]
 [55.169292]
 [54.8529  ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  3. 15.] 
cards in discard: [ 3.  3.  0.  0.  0.  3. 25.  3.  0.  0.  0.  6.  6.  0.  6.  6. 29.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8.  6.  3. 15.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8] -> size -> 27 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -4.076967239379883
desired expected reward: 109.25629425048828



action possibilites: [-1] 
expected returns: [[65.30746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  3.] 
cards in discard: [ 3.  3.  0.  0.  0.  3. 25.  3.  0.  0.  0.  6.  6.  0.  6.  6. 29.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8.  6.  3. 15.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8] -> size -> 27 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action 15.0
Learning step: 0.02677307091653347
desired expected reward: 54.87966537475586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[51.46247]
 [43.43178]
 [64.75208]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 10.  3.] 
cards in discard: [ 3.  3.  0.  0.  0.  3. 25.  3.  0.  0.  0.  6.  6.  0.  6.  6. 29.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8.  6.  3. 15.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8] -> size -> 27 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -0.7501323819160461
desired expected reward: 64.55732727050781



buy possibilites: [-1] 
expected returns: [[25.950207]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 10.  3.] 
cards in discard: [ 3.  3.  0.  0.  0.  3. 25.  3.  0.  0.  0.  6.  6.  0.  6.  6. 29.  0.
  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8.  6.  3. 15.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8] -> size -> 27 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   1  10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: buy - action 0.0
Learning step: -2.189244508743286
desired expected reward: 49.27323913574219






Player: 1 
cards in hand: [ 6.  8.  6.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  6.  3. 15.] 
cards in discard: [ 1.  3.  8.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 3.] 
cards in discard: [ 1.  3.  8.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 3.] 
cards in discard: [ 1.  3.  8.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 3.] 
cards in discard: [ 1.  3.  8.  3. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 6. 15.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[68.43853]
 [58.33238]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  0  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 8.  6. 15.  6. 14.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0] -> size -> 28 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: 0.389787495136261
desired expected reward: 26.339994430541992



action possibilites: [-1] 
expected returns: [[44.16557]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 8.  6. 15.  6. 14.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0] -> size -> 28 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action 15.0
Learning step: -0.5194042325019836
desired expected reward: 55.74318313598633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[31.931038]
 [36.40005 ]
 [35.678574]
 [27.071068]
 [25.130405]
 [33.648155]
 [41.397945]
 [36.299435]
 [44.899204]
 [39.069725]
 [30.34665 ]
 [32.932884]
 [35.686302]
 [27.629234]
 [35.650295]
 [45.90465 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 8.  6. 15.  6. 14.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0] -> size -> 28 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -0.10429058223962784
desired expected reward: 44.061279296875



buy possibilites: [-1] 
expected returns: [[47.170265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 5 
card supply: [15. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 8.  6. 15.  6. 14.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0] -> size -> 28 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -4.0 

action type: buy - action 0.0
Learning step: -0.7352215051651001
desired expected reward: 31.19582748413086






Player: 1 
cards in hand: [ 8.  6. 15.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 15.  6. 14.] 
cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 15.  6.] 
cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 25.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 15.  6.] 
cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 25. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 25.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 15.  6.] 
cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 25.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[27.380138]
 [26.765265]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.] 
cards in discard: [ 0. 15.  6.  0.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  1.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 25.  0. 14.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3. 14.  8.  6. 15.  6.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0  3] -> size -> 29 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: discard_down_to_3_cards - action 3
Learning step: -1.0180280208587646
desired expected reward: 27.53478240966797



action possibilites: [-1] 
expected returns: [[22.234087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8.] 
cards in discard: [ 0. 15.  6.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 25.  0. 14.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3. 14.  8.  6. 15.  6.  6.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0  3  6] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action 25.0
Learning step: -0.05152540281414986
desired expected reward: 26.713729858398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.850382]
 [23.60143 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 8.] 
cards in discard: [ 0. 15.  6.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 24. 30.  8.  0.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 25.  0. 14.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3. 14.  8.  6. 15.  6.  6.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0  3  6] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: 0.0962412878870964
desired expected reward: 22.3303279876709






Player: 1 
cards in hand: [ 0.  0. 25.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  0. 14.] 
cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3. 14.  8.  6. 15.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  6. 10.  0.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.  0.  0. 25.  0.  3.  6.  8.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  1.  8.] 
cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3. 14.  8.  6. 15.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0  3  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  6. 10.  0.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.  0.  0. 25.  0.  3.  6.  8.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.  1.  8.] 
cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3. 14.  8.  6. 15.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0  3  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 26. 30. 24. 30.  8.  0.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  6. 10.  0.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.  0.  0. 25.  0.  3.  6.  8.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 6.  6. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[80.88082 ]
 [68.787346]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10.  0.  3.] 
cards in discard: [ 0. 15.  6.  0.  0.  0.  0. 25.  0.  3.  6.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [16. 11.  8.  1.  3.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3. 14.  8.  6. 15.  6.  6.
 25.  0.  0.  0. 14.  1.  8.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0  3  6] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: 0.8130736351013184
desired expected reward: 24.414505004882812



action possibilites: [-1.] 
expected returns: [[41.544014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 3. 3.] 
cards in discard: [ 0. 15.  6.  0.  0.  0.  0. 25.  0.  3.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [16. 11.  8.  1.  3.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3. 14.  8.  6. 15.  6.  6.
 25.  0.  0.  0. 14.  1.  8.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0  3  6] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action 10.0
Learning step: -1.2046270370483398
desired expected reward: 67.58271789550781





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[35.89796 ]
 [41.592396]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 3.] 
cards in discard: [ 0. 15.  6.  0.  0.  0.  0. 25.  0.  3.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 24. 30.  8.  0.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [16. 11.  8.  1.  3.] 
adversary cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3. 14.  8.  6. 15.  6.  6.
 25.  0.  0.  0. 14.  1.  8.] 
adversary owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0  3  6] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: 0.09898167103528976
desired expected reward: 41.64299392700195






Player: 1 
cards in hand: [16. 11.  8.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  8.  1.  3.] 
cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3. 14.  8.  6. 15.  6.  6.
 25.  0.  0.  0. 14.  1.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8
  6  8  8  0  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0.  9.  9.  4.  8.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  6. 29.  0.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.  0.  0. 25.  0.  3.  6.  8. 10.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 3.] 
cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3. 14.  8.  6. 15.  6.  6.
 25.  0.  0.  0. 14.  1.  8. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 3.  6. 29.  0.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.  0.  0. 25.  0.  3.  6.  8. 10.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 3.] 
cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3. 14.  8.  6. 15.  6.  6.
 25.  0.  0.  0. 14.  1.  8. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 24. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 3.  6. 29.  0.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.  0.  0. 25.  0.  3.  6.  8. 10.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 3.] 
cards in discard: [ 1.  3.  8.  3. 10.  0. 15.  6.  8.  6.  3.  3. 14.  8.  6. 15.  6.  6.
 25.  0.  0.  0. 14.  1.  8. 23.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 3.  6. 29.  0.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.  0.  0. 25.  0.  3.  6.  8. 10.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3.  6. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[73.011894]
 [68.84826 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 29.  0.  3.] 
cards in discard: [ 0. 15.  6.  0.  0.  0.  0. 25.  0.  3.  6.  8. 10.  6.  6.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 3.  3.  6.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3] -> size -> 31 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -0.6804647445678711
desired expected reward: 40.91193771362305





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[63.87643 ]
 [73.513695]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 29.  0.  3.] 
cards in discard: [ 0. 15.  6.  0.  0.  0.  0. 25.  0.  3.  6.  8. 10.  6.  6.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 23. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 3.  3.  6.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3] -> size -> 31 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -2.2974822521209717
desired expected reward: 70.71440887451172



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3.  6.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6.  0. 15.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6.  0. 15.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 23. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6.  0. 15.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 23. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [3. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[38.044292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 23. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [3. 8. 1. 8. 8.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.] 
adversary owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0] -> size -> 32 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -3.0256760120391846
desired expected reward: 70.48802947998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.532005]
 [39.056484]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 23. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [3. 8. 1. 8. 8.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.] 
adversary owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0] -> size -> 32 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -1.341326355934143
desired expected reward: 36.436859130859375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 8. 1. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 1. 8. 8.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 23. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 6. 25.  6.  0.  0.] 
adversary cards in discard: [3. 6. 6. 0. 3.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 8. 8.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 23. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 6. 25.  6.  0.  0.] 
adversary cards in discard: [3. 6. 6. 0. 3.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 8. 8.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 26. 30. 23. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 6. 25.  6.  0.  0.] 
adversary cards in discard: [3. 6. 6. 0. 3.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6. 25.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[9.749168]
 [9.129631]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  6.  0.  0.] 
cards in discard: [3. 6. 6. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [25. 14. 15.  1.  3.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.] 
adversary owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -1.9399572610855103
desired expected reward: 37.11652755737305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 5.624402 ]
 [ 6.8423433]
 [ 6.9602585]
 [11.000718 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  6.  0.  0.] 
cards in discard: [3. 6. 6. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 23. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [25. 14. 15.  1.  3.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.] 
adversary owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -0.5110389590263367
desired expected reward: 9.23813247680664



buy possibilites: [-1] 
expected returns: [[9.269984]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  6.  0.  0.] 
cards in discard: [3. 6. 6. 0. 3. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 22. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [25. 14. 15.  1.  3.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.] 
adversary owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 15 

action type: buy - action 3.0
Learning step: 0.6164576411247253
desired expected reward: 7.458797931671143






Player: 1 
cards in hand: [25. 14. 15.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 14. 15.  1.  3.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 22. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 14. 15.  1.  3.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 22. 30.  8.  0.  9.  9.  4.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 14. 15.  1.  3.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 22. 30.  8.  0.  9.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[36.711773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 22. 30.  8.  0.  9.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 8.  8. 10.  6. 14.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.] 
adversary owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0  0  8] -> size -> 34 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: 0.7125157117843628
desired expected reward: 9.982500076293945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[31.24216 ]
 [33.306004]
 [33.132496]
 [38.92484 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 22. 30.  8.  0.  9.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 8.  8. 10.  6. 14.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.] 
adversary owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0  0  8] -> size -> 34 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -0.7097792029380798
desired expected reward: 36.00199508666992



buy possibilites: [-1] 
expected returns: [[59.477436]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  0.  9.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 8.  8. 10.  6. 14.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.] 
adversary owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0  0  8] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 26 

action type: buy - action 3.0
Learning step: 0.9729418158531189
desired expected reward: 34.278953552246094






Player: 1 
cards in hand: [ 8.  8. 10.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  6. 14.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  1 14  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6
  8  8  0  3  6 23  3  0  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  0.  9.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [15.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.  3.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3  3] -> size -> 27 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  0.  9.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [15.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.  3.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3  3] -> size -> 27 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  0.  9.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [15.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.  3.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3  3] -> size -> 27 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  8.  0.  9.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [15.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.  3.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3  3] -> size -> 27 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[99.485634]
 [85.211624]
 [85.722435]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0. 10.] 
cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.  3.  6.  3.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  8.  0.  9.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [16.  6.  6. 23.  3.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -0.031229401007294655
desired expected reward: 59.446205139160156



action possibilites: [-1. 15.] 
expected returns: [[77.80414]
 [71.07535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.  0.] 
cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.  3.  6.  3.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3  3] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  8.  0.  9.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [16.  6.  6. 23.  3.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 39 

action type: take_action - action 10.0
Learning step: -0.6236068606376648
desired expected reward: 85.09883117675781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[72.22469 ]
 [76.474174]
 [74.64148 ]
 [73.71201 ]
 [79.62159 ]
 [76.60647 ]
 [77.825645]
 [69.71947 ]
 [74.78654 ]
 [74.13502 ]
 [80.89262 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.  0.] 
cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.  3.  6.  3.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 26. 30. 21. 30.  8.  0.  9.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [16.  6.  6. 23.  3.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: -0.2828269898891449
desired expected reward: 77.52130889892578



buy possibilites: [-1] 
expected returns: [[74.48136]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.  0.] 
cards in discard: [ 3.  6.  6.  0.  3.  3.  6. 25.  6.  0.  0.  3.  6.  3.  0.  3.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3  3 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [16.  6.  6. 23.  3.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 70 

action type: buy - action 16.0
Learning step: 1.490230917930603
desired expected reward: 75.20223236083984






Player: 1 
cards in hand: [16.  6.  6. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  6. 23.  3.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  3.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3  3 16] -> size -> 28 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  6. 23.  3.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  3.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3  3 16] -> size -> 28 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  6. 23.  3.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  3.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3  3 16] -> size -> 28 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[76.83742 ]
 [71.94297 ]
 [73.374695]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  8. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  6  3  6 25  6  6 29  3  0  0  0  6  8 10  0  0  0  3  0  0
  0  3  3 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.  0. 16.  6.  6. 23.  3.] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -1.1535844802856445
desired expected reward: 73.32777404785156



action possibilites: [-1] 
expected returns: [[62.54755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  0  6  8 10  0  0  0  3  0  0  0  3  3
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.  0. 16.  6.  6. 23.  3.] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.7116838693618774
desired expected reward: 76.66838836669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[37.192364]
 [56.401394]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  0  6  8 10  0  0  0  3  0  0  0  3  3
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.  0. 16.  6.  6. 23.  3.] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -1.2595516443252563
desired expected reward: 61.28799819946289



buy possibilites: [-1] 
expected returns: [[59.1684]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  0  6  8 10  0  0  0  3  0  0  0  3  3
 16  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.  0. 16.  6.  6. 23.  3.] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5   0   1   0   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action 0.0
Learning step: -1.2283269166946411
desired expected reward: 35.9639892578125






Player: 1 
cards in hand: [0. 0. 6. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 1.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.  0. 16.  6.  6. 23.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  6. 15.] 
adversary cards in discard: [ 0.  8. 29.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  0  6  8 10  0  0  0  3  0  0  0  3  3
 16  0] -> size -> 26 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 1.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.  0. 16.  6.  6. 23.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  6. 15.] 
adversary cards in discard: [ 0.  8. 29.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  0  6  8 10  0  0  0  3  0  0  0  3  3
 16  0] -> size -> 26 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 1.] 
cards in discard: [ 0.  3.  3.  6.  0. 15.  0.  3.  8.  1.  8.  8.  8. 25. 14. 15.  1.  3.
  0.  8. 10.  6.  0. 16.  6.  6. 23.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  6. 15.] 
adversary cards in discard: [ 0.  8. 29.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  0  6  8 10  0  0  0  3  0  0  0  3  3
 16  0] -> size -> 26 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[3.782393 ]
 [2.1209373]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 15.] 
cards in discard: [ 0.  8. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  0  6  8 10  0  0  0  3  0  0  0  3  3
 16  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -3.090718984603882
desired expected reward: 56.07768249511719



action possibilites: [-1] 
expected returns: [[44.484356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [ 0.  8. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action 15.0
Learning step: 1.6948509216308594
desired expected reward: 3.815791606903076





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[33.44279 ]
 [37.920048]
 [37.012405]
 [28.762003]
 [35.16524 ]
 [42.107185]
 [37.82374 ]
 [45.760326]
 [39.96117 ]
 [31.637182]
 [34.036613]
 [36.993023]
 [29.099424]
 [36.751347]
 [46.086967]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 0.  8. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  9.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -0.5810327529907227
desired expected reward: 43.903324127197266



buy possibilites: [-1] 
expected returns: [[82.5925]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 0.  8. 29. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5.   0.   1.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 20.5 

action type: buy - action 11.0
Learning step: 0.7779712677001953
desired expected reward: 42.885169982910156






Player: 1 
cards in hand: [6. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  3.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0  0  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[2.4685445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0. 16.  8. 15.  0.] 
adversary cards in discard: [8. 6. 3. 6. 0. 0.] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0  0  8] -> size -> 36 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -4.274082660675049
desired expected reward: 78.31841278076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-0.26160526]
 [ 0.55549955]
 [ 0.7296972 ]
 [ 3.256795  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0. 16.  8. 15.  0.] 
adversary cards in discard: [8. 6. 3. 6. 0. 0.] 
adversary owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0  0  8] -> size -> 36 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -0.29595857858657837
desired expected reward: 2.172585964202881



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16.  8. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8. 15.  0.] 
cards in discard: [8. 6. 3. 6. 0. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1 15  6  1 10 25  6  8 15  0  3 16  0  6  0 14  3  8  6  8  8
  0  3  6 23  3  0  0  8  0  0  0  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 3.  6. 10.  3.  6.] 
adversary cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.  3.  0.  6.  0.  6.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [8. 6. 3. 6. 0. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 3.  6. 10.  3.  6.] 
adversary cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.  3.  0.  6.  0.  6.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 6. 3. 6. 0. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 3.  6. 10.  3.  6.] 
adversary cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.  3.  0.  6.  0.  6.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 3.  6. 10.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[30.424665]
 [25.023556]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  3.  6.] 
cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.  3.  0.  6.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 1.  0. 23.  6. 15.] 
adversary cards in discard: [8. 6. 3. 6. 0. 0. 8. 0.] 
adversary owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8] -> size -> 33 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: 0.2651413679122925
desired expected reward: 3.521933078765869



action possibilites: [-1.] 
expected returns: [[35.184933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 6. 0.] 
cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.  3.  0.  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 1.  0. 23.  6. 15.] 
adversary cards in discard: [8. 6. 3. 6. 0. 0. 8. 0.] 
adversary owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8] -> size -> 33 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 17 

action type: take_action - action 10.0
Learning step: 0.39048320055007935
desired expected reward: 25.41404151916504





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[27.987595]
 [35.55885 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6. 0.] 
cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.  3.  0.  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 1.  0. 23.  6. 15.] 
adversary cards in discard: [8. 6. 3. 6. 0. 0. 8. 0.] 
adversary owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8] -> size -> 33 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: -0.23847781121730804
desired expected reward: 34.94645309448242






Player: 1 
cards in hand: [ 1.  0. 23.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 23.  6. 15.] 
cards in discard: [8. 6. 3. 6. 0. 0. 8. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  3. 16. 25.  0.] 
adversary cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.  3.  0.  6.  0.  6. 10.  3.  6.  3.  6.
  0.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 23.  6. 15.] 
cards in discard: [8. 6. 3. 6. 0. 0. 8. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  3. 16. 25.  0.] 
adversary cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.  3.  0.  6.  0.  6. 10.  3.  6.  3.  6.
  0.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 23.  6. 15.] 
cards in discard: [8. 6. 3. 6. 0. 0. 8. 0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  3. 16. 25.  0.] 
adversary cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.  3.  0.  6.  0.  6. 10.  3.  6.  3.  6.
  0.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 16. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
expected returns: [[21.931866]
 [17.906582]
 [22.401167]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16. 25.  0.] 
cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.  3.  0.  6.  0.  6. 10.  3.  6.  3.  6.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0. 14.  3.  6.  3.] 
adversary cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15.] 
adversary owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -1.5138323307037354
desired expected reward: 34.150081634521484



action possibilites: [-1] 
expected returns: [[25.018719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  3.  3.] 
cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.  3.  0.  6.  0.  6. 10.  3.  6.  3.  6.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0. 14.  3.  6.  3.] 
adversary cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15.] 
adversary owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action 25.0
Learning step: 0.24286317825317383
desired expected reward: 22.64402198791504





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[12.313485]
 [15.566369]
 [16.420603]
 [24.739794]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  3.  3.] 
cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.  3.  0.  6.  0.  6. 10.  3.  6.  3.  6.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 21. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0. 14.  3.  6.  3.] 
adversary cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15.] 
adversary owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -0.05098371580243111
desired expected reward: 24.967735290527344



buy possibilites: [-1] 
expected returns: [[46.013527]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  3.  3.] 
cards in discard: [ 0.  8. 29. 11. 15.  0.  0.  6.  3.  0.  6.  0.  6. 10.  3.  6.  3.  6.
  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0. 14.  3.  6.  3.] 
adversary cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15.] 
adversary owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0] -> size -> 34 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 35 

action type: buy - action 3.0
Learning step: 2.006985902786255
desired expected reward: 17.573352813720703






Player: 1 
cards in hand: [ 0. 14.  3.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  6.  3.] 
cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 25.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [25.  6. 29.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  7. 10.  6.] 
adversary cards in hand: [25.  6. 29.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [25.  6. 29.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [25.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[0.34754133]
 [0.07159162]
 [0.16583586]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6. 29.] 
cards in discard: [0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 1.  8.  8. 10.  3.] 
adversary cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15. 10. 14.  0.  3.
  6.  3.] 
adversary owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0 10] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: discard_down_to_3_cards - action 1
Learning step: -2.048100709915161
desired expected reward: 46.00638961791992



action possibilites: [-1. 25.] 
expected returns: [[1.8403947]
 [1.6033223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.] 
cards in discard: [0. 0. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 1.  8.  8. 10.  3.] 
adversary cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15. 10. 14.  0.  3.
  6.  3.] 
adversary owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0 10] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: discard_n_cards - action 0
Learning step: 1.3684929609298706
desired expected reward: 1.7771474123001099





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-0.6597054]
 [ 1.8235171]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.] 
cards in discard: [0. 0. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 1.  8.  8. 10.  3.] 
adversary cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15. 10. 14.  0.  3.
  6.  3.] 
adversary owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0 10] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: 1.2729988098144531
desired expected reward: 3.1133944988250732






Player: 1 
cards in hand: [ 1.  8.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  8. 10.  3.] 
cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15. 10. 14.  0.  3.
  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 8. 3. 1.] 
cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15. 10. 14.  0.  3.
  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  1  1  6  1 10 25  6  8 15  3  0  6  0 14  3  8  6  8  8  0  3  6
 23  3  0  0  8  0  0  0  8  0 10] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15. 10. 14.  0.  3.
  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15. 10. 14.  0.  3.
  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[49.87275 ]
 [48.327805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 11.] 
cards in discard: [ 0.  0.  6. 29. 25.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15. 10. 14.  0.  3.
  6.  3. 10.  8.  1.] 
adversary owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: 1.8647785186767578
desired expected reward: 3.68829607963562





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[45.157158]
 [51.429924]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  3. 11.] 
cards in discard: [ 0.  0.  6. 29. 25.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15. 10. 14.  0.  3.
  6.  3. 10.  8.  1.] 
adversary owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -0.5521686673164368
desired expected reward: 49.32058334350586



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 8.] 
cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15. 10. 14.  0.  3.
  6.  3. 10.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [15.  0.  3.  0.  8.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 8.] 
cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15. 10. 14.  0.  3.
  6.  3. 10.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 20. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [15.  0.  3.  0.  8.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 8.] 
cards in discard: [ 8.  6.  3.  6.  0.  0.  8.  0.  0.  1.  0. 23.  6. 15. 10. 14.  0.  3.
  6.  3. 10.  8.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 19. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [15.  0.  3.  0.  8.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [15.  0.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[47.606243]
 [45.323273]
 [45.81218 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  0.  8.] 
cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 19. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  3.  0.  6. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10  3] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -1.178826093673706
desired expected reward: 50.25110626220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[44.174652]
 [45.071533]
 [45.50604 ]
 [47.30011 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  0.  8.] 
cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 19. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  3.  0.  6. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10  3] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -1.003496527671814
desired expected reward: 46.60274887084961



buy possibilites: [-1] 
expected returns: [[21.952698]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  0.  8.] 
cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  3.  0.  6. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10  3] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 26 

action type: buy - action 3.0
Learning step: -0.4596416652202606
desired expected reward: 44.611907958984375






Player: 1 
cards in hand: [ 3.  3.  0.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  6. 25.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [6. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.  3. 15.  0.  3.  0.  8.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  6. 15.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [6. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.  3. 15.  0.  3.  0.  8.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  6. 15.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  2.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [6. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.  3. 15.  0.  3.  0.  8.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  6. 15.  0.] 
cards in discard: [8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10  3  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [6. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.  3. 15.  0.  3.  0.  8.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [6. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.42849]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 6.] 
cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.  3. 15.  0.  3.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [8. 3. 3. 8. 8.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.] 
adversary owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10  3  8] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: 0.23950615525245667
desired expected reward: 22.192203521728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[14.507556]
 [19.779266]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 6.] 
cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.  3. 15.  0.  3.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [8. 3. 3. 8. 8.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.] 
adversary owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10  3  8] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: 0.3183903694152832
desired expected reward: 19.74687957763672



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 3. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 8. 8.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  6  1 10 25  6 15  3  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0
  0  8  0  0  0  8  0 10  3  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [10.  3.  0.  6. 16.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.  3. 15.  0.  3.  0.  8.  6.
  0.  6.  3.  6.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  6  1 10 25  6 15  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0  0  8
  0  0  0  8  0 10  3  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [10.  3.  0.  6. 16.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.  3. 15.  0.  3.  0.  8.  6.
  0.  6.  3.  6.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  6  1 10 25  6 15  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0  0  8
  0  0  0  8  0 10  3  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [10.  3.  0.  6. 16.] 
adversary cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.  3. 15.  0.  3.  0.  8.  6.
  0.  6.  3.  6.] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[42.331203]
 [39.171432]
 [38.561123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  6. 16.] 
cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.  3. 15.  0.  3.  0.  8.  6.
  0.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8.] 
adversary owned cards: [ 1  6  1 10 25  6 15  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0  0  8
  0  0  0  8  0 10  3  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1.0
Learning step: 1.7989345788955688
desired expected reward: 21.901458740234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[36.392143]
 [40.973324]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  6. 16.] 
cards in discard: [ 0.  0.  6. 29. 25.  3.  3.  3.  0.  3. 11.  3. 15.  0.  3.  0.  8.  6.
  0.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8.] 
adversary owned cards: [ 1  6  1 10 25  6 15  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0  0  8
  0  0  0  8  0 10  3  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 0.6573541760444641
desired expected reward: 42.98855209350586



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  6.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  6  1 10 25  6 15  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0  0  8
  0  0  0  8  0 10  3  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  6.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  6  1 10 25  6 15  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0  0  8
  0  0  0  8  0 10  3  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  8.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  6.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  6  1 10 25  6 15  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0  0  8
  0  0  0  8  0 10  3  8 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[13.077563]
 [11.11415 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  6  3  6 25  6  6 29  3  0  6  8 10  0  0  0  3  0  0  0  3  3 16
  0 11  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [10.  0.  0.  8.  6.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 1  6  1 10 25  6 15  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0  0  8
  0  0  0  8  0 10  3  8 11] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1.0
Learning step: 0.1250133514404297
desired expected reward: 41.09833526611328



action possibilites: [-1] 
expected returns: [[96.61348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [10.  0.  0.  8.  6.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 1  6  1 10 25  6 15  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0  0  8
  0  0  0  8  0 10  3  8 11] -> size -> 33 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: trash_cards_n_from_hand - action 11
Learning step: 3.9651901721954346
desired expected reward: 15.137447357177734





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[82.23586 ]
 [91.700905]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [10.  0.  0.  8.  6.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 1  6  1 10 25  6 15  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0  0  8
  0  0  0  8  0 10  3  8 11] -> size -> 33 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1
Learning step: -0.5165454745292664
desired expected reward: 96.09693145751953






Player: 1 
cards in hand: [10.  0.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8.  6.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  6  1 10 25  6 15  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0  0  8
  0  0  0  8  0 10  3  8 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [29.  0.  0.  6.  3.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3] -> size -> 25 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 6.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  6  1 10 25  6 15  0  6  0 14  3  8  6  8  8  0  3  6 23  3  0  0  8
  0  0  0  8  0 10  3  8 11] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [29.  0.  0.  6.  3.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3] -> size -> 25 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [29.  0.  0.  6.  3.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3] -> size -> 25 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [29.  0.  0.  6.  3.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3] -> size -> 25 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [29.  0.  0.  6.  3.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3] -> size -> 25 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[30.13735 ]
 [27.031229]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  6.  3.] 
cards in discard: [8. 6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  1.  1. 14.  3.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.
 10.  8.  6.  6.] 
adversary owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1.0
Learning step: -2.5894908905029297
desired expected reward: 89.1114273071289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[23.493855]
 [25.568316]
 [26.517122]
 [30.879507]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  6.  3.] 
cards in discard: [8. 6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 26. 30. 18. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  1.  1. 14.  3.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.
 10.  8.  6.  6.] 
adversary owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: 0.4485781788825989
desired expected reward: 30.585920333862305



buy possibilites: [-1] 
expected returns: [[13.571506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  6.  3.] 
cards in discard: [8. 6. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  1.  1. 14.  3.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.
 10.  8.  6.  6.] 
adversary owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 46 

action type: buy - action 3.0
Learning step: 1.3269435167312622
desired expected reward: 26.895252227783203






Player: 1 
cards in hand: [ 3.  1.  1. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1. 14.  3.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.
 10.  8.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [16.  0.  6.  0. 10.] 
adversary cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.] 
adversary owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3  3] -> size -> 26 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 1. 3.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.
 10.  8.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [16.  6.  0.] 
adversary cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.] 
adversary owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3  3] -> size -> 26 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 3.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.
 10.  8.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 7. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [16.  6.  0.] 
adversary cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.] 
adversary owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3  3] -> size -> 26 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 3.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.
 10.  8.  6.  6. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  5.] 
adversary cards in hand: [16.  6.  0.] 
adversary cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.] 
adversary owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3  3] -> size -> 26 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[8.976361 ]
 [2.8284314]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.] 
cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [15  6  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  5.] 
adversary cards in hand: [23.  6.  0.  0.  8.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.
 10.  8.  6.  6. 15. 14.  3.  1.  1.  3.] 
adversary owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: discard_down_to_3_cards - action 1
Learning step: 2.4114863872528076
desired expected reward: -5.066807746887207



action possibilites: [-1] 
expected returns: [[12.349201]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  5.] 
adversary cards in hand: [23.  6.  0.  0.  8.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.
 10.  8.  6.  6. 15. 14.  3.  1.  1.  3.] 
adversary owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   4  50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 39 

action type: gain_card_n - action 0
Learning step: 0.6815263032913208
desired expected reward: 31.60814094543457





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 5.877507]
 [10.950032]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  5.] 
adversary cards in hand: [23.  6.  0.  0.  8.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.
 10.  8.  6.  6. 15. 14.  3.  1.  1.  3.] 
adversary owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1
Learning step: 3.0257833003997803
desired expected reward: 15.374984741210938



buy possibilites: [-1] 
expected returns: [[30.069662]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  5.] 
adversary cards in hand: [23.  6.  0.  0.  8.] 
adversary cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.
 10.  8.  6.  6. 15. 14.  3.  1.  1.  3.] 
adversary owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 39.0 

action type: buy - action 0.0
Learning step: 2.3316876888275146
desired expected reward: 8.209193229675293






Player: 1 
cards in hand: [23.  6.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  6.  0.  0.  8.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.
 10.  8.  6.  6. 15. 14.  3.  1.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  5.] 
adversary cards in hand: [ 3. 25.  6.  3.  0.] 
adversary cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.  0. 16.  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0] -> size -> 27 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  6.  0.  0.  8.] 
cards in discard: [ 8. 25.  3.  3.  0.  6. 15.  0.  8.  8.  8. 11. 10.  0.  0.  0.  6.  0.
 10.  8.  6.  6. 15. 14.  3.  1.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  5.] 
adversary cards in hand: [ 3. 25.  6.  3.  0.] 
adversary cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.  0. 16.  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0] -> size -> 27 
adversary victory points: 4
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[0.63879585]
 [0.14097881]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  6.  3.  0.] 
cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.  0. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  5.] 
adversary cards in hand: [15.  1.  1.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: 0.9556754231452942
desired expected reward: 31.02533721923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-1.7246891]
 [ 0.6816559]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  6.  3.  0.] 
cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.  0. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  5.] 
adversary cards in hand: [15.  1.  1.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1.0
Learning step: 2.4081921577453613
desired expected reward: 3.0469884872436523



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  1.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  1.  8.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  3.  6. 11.  0.] 
adversary cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.  0. 16.  0.  3. 25.  6.  3.
  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0] -> size -> 27 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  1.  8.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  3.  6. 11.  0.] 
adversary cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.  0. 16.  0.  3. 25.  6.  3.
  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0] -> size -> 27 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  1.  8.  0.] 
cards in discard: [22.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15 22] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  3.  6. 11.  0.] 
adversary cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.  0. 16.  0.  3. 25.  6.  3.
  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0] -> size -> 27 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[20.82085 ]
 [19.409636]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 11.  0.] 
cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.  0. 16.  0.  3. 25.  6.  3.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 17. 30.  8.  0.  8.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [0. 6. 8. 6. 0.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.] 
adversary owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15 22] -> size -> 34 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1.0
Learning step: 2.8696045875549316
desired expected reward: 3.5512616634368896



action possibilites: [-1] 
expected returns: [[31.287111]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.  0. 16.  0.  3. 25.  6.  3.
  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [0. 6. 8. 6. 0.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.] 
adversary owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15 22] -> size -> 34 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 85 

action type: gain_card_n - action 3
Learning step: 3.9137113094329834
desired expected reward: 24.718687057495117





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[22.99276 ]
 [29.501062]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.  0. 16.  0.  3. 25.  6.  3.
  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [0. 6. 8. 6. 0.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.] 
adversary owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15 22] -> size -> 34 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1
Learning step: 2.4812469482421875
desired expected reward: 33.76835632324219



buy possibilites: [-1] 
expected returns: [[-2.134059]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 8.  6.  3. 29.  0.  0.  6.  3.  0. 10.  0.  0. 16.  0.  3. 25.  6.  3.
  0. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0 16  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [0. 6. 8. 6. 0.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.] 
adversary owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15 22] -> size -> 34 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 39.0 

action type: buy - action 0.0
Learning step: 0.7523461580276489
desired expected reward: 23.74509620666504






Player: 1 
cards in hand: [0. 6. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 6. 0.] 
cards in discard: [22. 15.  1.  1.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  6  1 10 25  6 15  6 14  3  8  6  8  8  0  3  6 23  3  0  0  8  0  0
  0  8  0 10  3  8 11  0 15 22] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0 16  0] -> size -> 29 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [22. 15.  1.  1.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1 10 25 15  6 14  3  8  6  8  8  3  6 23  3  0  0  8  0  0  0  8  0
 10  3  8 11  0 15 22] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0 16  0] -> size -> 29 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [22. 15.  1.  1.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1 10 25 15  6 14  3  8  6  8  8  3  6 23  3  0  0  8  0  0  0  8  0
 10  3  8 11  0 15 22] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0 16  0] -> size -> 29 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[48.32896 ]
 [46.481506]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 15.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  0  3  0  0  0  3  3 16  0 11  3  3
  3  0  0 16  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 10.  3. 23.  8.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.] 
adversary owned cards: [ 1  1 10 25 15  6 14  3  8  6  8  8  3  6 23  3  0  0  8  0  0  0  8  0
 10  3  8 11  0 15 22] -> size -> 31 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: 2.624753475189209
desired expected reward: 0.490694522857666



action possibilites: [-1] 
expected returns: [[17.822311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 10.  3. 23.  8.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.] 
adversary owned cards: [ 1  1 10 25 15  6 14  3  8  6  8  8  3  6 23  3  0  0  8  0  0  0  8  0
 10  3  8 11  0 15 22] -> size -> 31 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action 15.0
Learning step: 0.5269266366958618
desired expected reward: 47.0084342956543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[13.648701]
 [14.615648]
 [14.711479]
 [13.967716]
 [16.456768]
 [14.539768]
 [15.77943 ]
 [13.709061]
 [14.696407]
 [14.874769]
 [18.377934]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 10.  3. 23.  8.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.] 
adversary owned cards: [ 1  1 10 25 15  6 14  3  8  6  8  8  3  6 23  3  0  0  8  0  0  0  8  0
 10  3  8 11  0 15 22] -> size -> 31 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1
Learning step: 1.9023427963256836
desired expected reward: 19.724655151367188






Player: 1 
cards in hand: [ 0. 10.  3. 23.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 23.  8.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 10 25 15  6 14  3  8  6  8  8  3  6 23  3  0  0  8  0  0  0  8  0
 10  3  8 11  0 15 22] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [6. 0. 6. 3. 3.] 
adversary cards in discard: [15.  0.  3.  3.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0] -> size -> 28 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1 10 25 15  6 14  8  6  8  8  3  6  3  0  0  8  0  0  0  8  0 10  3
  8 11  0 15 22] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [6. 0. 6. 3. 3.] 
adversary cards in discard: [15.  0.  3.  3.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0] -> size -> 28 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1 10 25 15  6 14  8  6  8  8  3  6  3  0  0  8  0  0  0  8  0 10  3
  8 11  0 15 22] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [6. 0. 6. 3. 3.] 
adversary cards in discard: [15.  0.  3.  3.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0] -> size -> 28 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [6. 0. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[0.12756872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 3.] 
cards in discard: [15.  0.  3.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 8.  0.  3.  0. 25.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.] 
adversary owned cards: [ 1  1 10 25 15  6 14  8  6  8  8  3  6  3  0  0  8  0  0  0  8  0 10  3
  8 11  0 15 22] -> size -> 29 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: 1.0339739322662354
desired expected reward: 19.411903381347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.0542784 ]
 [ 0.31728458]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 3.] 
cards in discard: [15.  0.  3.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 8.  0.  3.  0. 25.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.] 
adversary owned cards: [ 1  1 10 25 15  6 14  8  6  8  8  3  6  3  0  0  8  0  0  0  8  0 10  3
  8 11  0 15 22] -> size -> 29 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: 1.9154452085494995
desired expected reward: 2.0430140495300293



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0. 25.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 10 25 15  6 14  8  6  8  8  3  6  3  0  0  8  0  0  0  8  0 10  3
  8 11  0 15 22] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6.  3. 25.  0.  6.] 
adversary cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0] -> size -> 28 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6.  3. 25.  0.  6.] 
adversary cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0] -> size -> 28 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6.  3. 25.  0.  6.] 
adversary cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0] -> size -> 28 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 6.  3. 25.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-7.6676073]
 [-8.840436 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 25.  0.  6.] 
cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [11.  3.  3.  6.  8.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22] -> size -> 26 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1.0
Learning step: 2.2493302822113037
desired expected reward: 2.566607713699341



action possibilites: [-1] 
expected returns: [[27.78528]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 6. 0. 0.] 
cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [11.  3.  3.  6.  8.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22] -> size -> 26 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 71 

action type: take_action - action 25.0
Learning step: 4.617190361022949
desired expected reward: -4.22324275970459





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[16.213013]
 [19.191181]
 [18.017952]
 [21.149405]
 [19.27103 ]
 [18.118448]
 [23.394686]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 0. 0.] 
cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 26. 30. 17. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [11.  3.  3.  6.  8.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22] -> size -> 26 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1
Learning step: 2.5021018981933594
desired expected reward: 30.287382125854492



buy possibilites: [-1] 
expected returns: [[22.312222]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 0. 0.] 
cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 26. 30. 16. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [11.  3.  3.  6.  8.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22] -> size -> 26 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 60.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 82.0 

action type: buy - action 3.0
Learning step: 3.670339345932007
desired expected reward: 21.688304901123047






Player: 1 
cards in hand: [11.  3.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  6.  8.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 16. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 16.  8. 10.  0.] 
adversary cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0  3] -> size -> 29 
adversary victory points: 5
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 8.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 15. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 16.  8. 10.  0.] 
adversary cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0  3] -> size -> 29 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 8.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 26. 30. 15. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 16.  8. 10.  0.] 
adversary cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0  3] -> size -> 29 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 8.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 15. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 16.  8. 10.  0.] 
adversary cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0  3] -> size -> 29 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 10.] 
expected returns: [[41.523563]
 [36.67757 ]
 [39.0892  ]
 [37.521725]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8. 10.  0.] 
cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  0  3  0  0  0  3  3 16  0 11  3  3  3
  0  0 16  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 15. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  6.  6.  0. 10.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.  3.  0. 11.  3.  3.
  6.  8.] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0] -> size -> 28 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1
Learning step: 2.2595813274383545
desired expected reward: 24.571802139282227



action possibilites: [-1] 
expected returns: [[-0.05759668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.] 
cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 14. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  6.  6.  0. 10.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.  3.  0. 11.  3.  3.
  6.  8.] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0] -> size -> 28 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 85 

action type: gain_card_n - action 1
Learning step: 1.6734354496002197
desired expected reward: 53.178810119628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-1.0213153]
 [-0.8151219]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.] 
cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 26. 30. 14. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  6.  6.  0. 10.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.  3.  0. 11.  3.  3.
  6.  8.] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0] -> size -> 28 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1
Learning step: 4.032379627227783
desired expected reward: 3.974782943725586



buy possibilites: [-1] 
expected returns: [[35.464344]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.] 
cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.  3.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 14. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  6.  6.  0. 10.] 
adversary cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.  3.  0. 11.  3.  3.
  6.  8.] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0] -> size -> 28 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  60.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 51.0 

action type: buy - action 0.0
Learning step: 3.3990135192871094
desired expected reward: 2.3776955604553223






Player: 1 
cards in hand: [ 0.  6.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  0. 10.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.  3.  0. 11.  3.  3.
  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 14. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  3.  3. 11. 16.] 
adversary cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.  3.
  0. 16.  8. 10.  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3  0] -> size -> 30 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  0. 14.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.  3.  0. 11.  3.  3.
  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 14. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  3.  3. 11. 16.] 
adversary cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.  3.
  0. 16.  8. 10.  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3  0] -> size -> 30 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  0. 14.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.  3.  0. 11.  3.  3.
  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 26. 30. 14. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  3.  3. 11. 16.] 
adversary cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.  3.
  0. 16.  8. 10.  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3  0] -> size -> 30 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  0. 14.] 
cards in discard: [22. 15.  1.  1.  8.  0.  8.  0.  8.  0. 10.  8.  0.  3.  0. 11.  3.  3.
  6.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 26. 30. 14. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  3.  3. 11. 16.] 
adversary cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.  3.
  0. 16.  8. 10.  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3  0] -> size -> 30 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[17.55312 ]
 [17.474085]
 [16.412   ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 11. 16.] 
cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.  3.
  0. 16.  8. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 14. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0.  8. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0] -> size -> 29 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1
Learning step: 1.6632078886032104
desired expected reward: 37.1275520324707





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.470588]
 [17.205067]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 11. 16.] 
cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.  3.
  0. 16.  8. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3  0] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 1. 26. 30. 14. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0.  8. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0] -> size -> 29 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: 2.541289806365967
desired expected reward: 20.094417572021484



buy possibilites: [-1] 
expected returns: [[75.06278]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 11. 16.] 
cards in discard: [15.  0.  3.  3.  6.  0.  6.  3.  3.  3. 25.  6.  3.  0.  6.  0.  0.  3.
  0. 16.  8. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 14. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0.  8. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0] -> size -> 29 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  60   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 31 

action type: buy - action 0.0
Learning step: 2.465383291244507
desired expected reward: 17.935972213745117






Player: 1 
cards in hand: [ 0.  0.  8. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 15.  8.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 14. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 8.  0. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3  0  0] -> size -> 31 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 15.  8.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 30. 14. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 8.  0. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3  0  0] -> size -> 31 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 15.  8.] 
cards in discard: [3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 8.  0. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3  0  0] -> size -> 31 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29.] 
expected returns: [[53.347103]
 [49.94553 ]
 [51.721054]
 [50.94932 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  0  3  3 16  0 11  3  3  3  0
  0 16  0  3  3  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  1. 10.  0.  6.] 
adversary cards in discard: [ 3.  0.  0.  8. 15.  8.] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0  3] -> size -> 30 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -0.04171791300177574
desired expected reward: 75.02106475830078



action possibilites: [-1] 
expected returns: [[66.734825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  1. 10.  0.  6.] 
adversary cards in discard: [ 3.  0.  0.  8. 15.  8.] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0  3] -> size -> 30 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: trash_cards_n_from_hand - action 7
Learning step: 2.565467596054077
desired expected reward: 52.28678894042969





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[65.44107]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  1. 10.  0.  6.] 
adversary cards in discard: [ 3.  0.  0.  8. 15.  8.] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0  3] -> size -> 30 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1
Learning step: 1.6856826543807983
desired expected reward: 68.4205093383789






Player: 1 
cards in hand: [ 0.  1. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.  0.  6.] 
cards in discard: [ 3.  0.  0.  8. 15.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  0.  3. 10.  6.] 
adversary cards in discard: [ 8.  0. 29.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [ 3.  0.  0.  8. 15.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0  3] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  0.  3. 10.  6.] 
adversary cards in discard: [ 8.  0. 29.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [ 3.  0.  0.  8. 15.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  7.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  0.  3. 10.  6.] 
adversary cards in discard: [ 8.  0. 29.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [ 3.  0.  0.  8. 15.  8. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0  3 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  0.  3. 10.  6.] 
adversary cards in discard: [ 8.  0. 29.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[20.840565]
 [19.424034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  6.] 
cards in discard: [ 8.  0. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6.  0.  8.  8. 22.] 
adversary cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0  3 11] -> size -> 31 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: -0.2679782807826996
desired expected reward: 65.173095703125





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[20.90498]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  6.] 
cards in discard: [ 8.  0. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6.  0.  8.  8. 22.] 
adversary cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.] 
adversary owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0  3 11] -> size -> 31 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: 1.9783340692520142
desired expected reward: 22.818897247314453



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  0.  8.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8.  8. 22.] 
cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 10 15  6 14  8  6  8  8  6  3  0  8  0  0  0  8  0 10  3  8 11  0
 15 22  3  0  0  3 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3. 15.  3.  3.  6.] 
adversary cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3. 15.  3.  3.  6.] 
adversary cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3. 15.  3.  3.  6.] 
adversary cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-7.364438 ]
 [-6.5904245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  3.  6.] 
cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6.  8.  3. 14.  3.] 
adversary cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.  8.  6.] 
adversary owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: 1.3483591079711914
desired expected reward: 22.253337860107422





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[-7.291544]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  3.  6.] 
cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6.  8.  3. 14.  3.] 
adversary cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.  8.  6.] 
adversary owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: 2.7505173683166504
desired expected reward: -4.541026592254639



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  8.  3. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  3. 14.  3.] 
cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [16.  6.  0.  3. 25.] 
adversary cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 3.] 
cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6.  3. 25.] 
adversary cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 3.] 
cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 30. 13. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6.  3. 25.] 
adversary cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 3.] 
cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.  8.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6.  3. 25.] 
adversary cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 6.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[40.65436 ]
 [40.084373]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 25.] 
cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [15. 10.  0.  3. 11.] 
adversary cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.  8.  6.  3. 14.  6.
  8.  3.  3.] 
adversary owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11  3] -> size -> 29 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[  -5    0    6   40    0    0    0  -30    0    0    0    0    0 -300
   97    0] 
sum of rewards: -192 

action type: discard_down_to_3_cards - action 0
Learning step: -8.213621139526367
desired expected reward: -17.766157150268555





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[42.055504]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 25.] 
cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [15. 10.  0.  3. 11.] 
adversary cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.  8.  6.  3. 14.  6.
  8.  3.  3.] 
adversary owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11  3] -> size -> 29 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: 0.963530957698822
desired expected reward: 41.617889404296875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15. 10.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  3. 11.] 
cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.  8.  6.  3. 14.  6.
  8.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3. 16.  6.  3.  0.] 
adversary cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.  6.  3. 25.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  3. 11.] 
cards in discard: [ 3.  0.  0.  8. 15.  8. 11. 10.  0.  1.  0.  6.  0.  8.  6.  3. 14.  6.
  8.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3. 16.  6.  3.  0.] 
adversary cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.  6.  3. 25.] 
adversary owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 3. 16.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-3.781373]
 [-4.458807]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.  3.  0.] 
cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.  6.  3. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16
  0  3  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 10.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11  3] -> size -> 29 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1.0
Learning step: -0.14495182037353516
desired expected reward: 41.910552978515625



action possibilites: [-1] 
expected returns: [[41.456707]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.  6.  3. 25.
 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [ 6. 10.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11  3] -> size -> 29 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 66 

action type: gain_card_n - action 8
Learning step: 3.744335889816284
desired expected reward: 13.513137817382812





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[38.051514]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.  6.  3. 25.
 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [ 6. 10.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11  3] -> size -> 29 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1
Learning step: 1.283323884010315
desired expected reward: 42.74003219604492






Player: 1 
cards in hand: [ 6. 10.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  8.  1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.  6.  3. 25.
 15. 16.  6.  3.  0.] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15] -> size -> 29 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 1. 6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  1 10 15  6 14  6  8  8  6  3  8  0  0  0  8  0 10  3  8 11  0 15  3
  0  0  3 11  3] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.  6.  3. 25.
 15. 16.  6.  3.  0.] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15] -> size -> 29 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  0  8  0 10  3  8 11  0 15  3  0  0  3 11
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.  6.  3. 25.
 15. 16.  6.  3.  0.] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15] -> size -> 29 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  0  8  0 10  3  8 11  0 15  3  0  0  3 11
  3] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.  6.  3. 25.
 15. 16.  6.  3.  0.] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15] -> size -> 29 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[5.7234488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.  6.  3. 25.
 15. 16.  6.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [ 3. 15.  3.  0. 11.] 
adversary cards in discard: [10.  8.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  0  8  0 10  3  8 11  0 15  3  0  0  3 11
  3] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1.0
Learning step: -1.2737981081008911
desired expected reward: 36.777713775634766





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[2.3149977]
 [2.5672975]
 [1.6728973]
 [4.1394444]
 [2.2389827]
 [3.4282913]
 [1.2017367]
 [2.5479355]
 [2.7801776]
 [6.257103 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.  6.  3. 25.
 15. 16.  6.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 26. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [ 3. 15.  3.  0. 11.] 
adversary cards in discard: [10.  8.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  0  8  0 10  3  8 11  0 15  3  0  0  3 11
  3] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: 0.28459617495536804
desired expected reward: 6.008044719696045



buy possibilites: [-1] 
expected returns: [[-6.004015]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8.  0. 29.  3.  0.  3. 10.  6.  3. 15.  3.  3.  6. 16.  0.  6.  3. 25.
 15. 16.  6.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 25. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [ 3. 15.  3.  0. 11.] 
adversary cards in discard: [10.  8.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  0  8  0 10  3  8 11  0 15  3  0  0  3 11
  3] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.   0.   5.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 14.5 

action type: buy - action 1.0
Learning step: 0.47415992617607117
desired expected reward: 2.789154291152954






Player: 1 
cards in hand: [ 3. 15.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  0. 11.] 
cards in discard: [10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  0  8  0 10  3  8 11  0 15  3  0  0  3 11
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  1. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1] -> size -> 30 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.] 
cards in discard: [10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8 11  0 15  3  0  0  3 11  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 25. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  1. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1] -> size -> 30 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.] 
cards in discard: [10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8 11  0 15  3  0  0  3 11  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 25. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  1. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1] -> size -> 30 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.] 
cards in discard: [10.  8.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8 11  0 15  3  0  0  3 11  3
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  1. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1] -> size -> 30 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[ 4.096678  ]
 [-0.77794635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [ 8.  6.  0.  0. 10.] 
adversary cards in discard: [10.  8.  1. 15.  3.  3. 11.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8 11  0 15  3  0  0  3 11  3
  1] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1
Learning step: 0.8284751772880554
desired expected reward: -5.175539970397949





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.3873849 ]
 [-0.5686792 ]
 [-1.4616306 ]
 [ 2.0421934 ]
 [-0.44861794]
 [ 0.9235854 ]
 [-1.9385998 ]
 [-0.5726372 ]
 [-0.5209365 ]
 [ 4.3021975 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 24. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  8.  9.  6.  9.  4.] 
adversary cards in hand: [ 8.  6.  0.  0. 10.] 
adversary cards in discard: [10.  8.  1. 15.  3.  3. 11.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8 11  0 15  3  0  0  3 11  3
  1] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: 0.33362361788749695
desired expected reward: 3.8519814014434814



buy possibilites: [-1] 
expected returns: [[36.288197]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 15.  0.  3.] 
cards in discard: [14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1 14] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 8.  6.  0.  0. 10.] 
adversary cards in discard: [10.  8.  1. 15.  3.  3. 11.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8 11  0 15  3  0  0  3 11  3
  1] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 42 

action type: buy - action 14.0
Learning step: 3.013414144515991
desired expected reward: 1.0748193264007568






Player: 1 
cards in hand: [ 8.  6.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0.  0. 10.] 
cards in discard: [10.  8.  1. 15.  3.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8 11  0 15  3  0  0  3 11  3
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3.] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1 14] -> size -> 31 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0.  0. 11.] 
cards in discard: [10.  8.  1. 15.  3.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8 11  0 15  3  0  0  3 11  3
  1] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3.] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1 14] -> size -> 31 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [10.  8.  1. 15.  3.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3.] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1 14] -> size -> 31 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [10.  8.  1. 15.  3.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 30. 12. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3.] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1 14] -> size -> 31 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [10.  8.  1. 15.  3.  3. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 11. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3.] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1 14] -> size -> 31 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[5.7241135]
 [3.6080217]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 15.] 
cards in discard: [14.  0.  1. 15.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  0  3  3 16  0  3  3  3  0  0 16  0
  3  3  0  0 15  1 14] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 11. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3.  0.  8. 15.  8.] 
adversary cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -1.7077823877334595
desired expected reward: 34.580413818359375



action possibilites: [-1] 
expected returns: [[-7.2118397]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [14.  0.  1. 15.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3
  3  0  0 15  1 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 24. 30. 11. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3.  0.  8. 15.  8.] 
adversary cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action 15.0
Learning step: 0.6645453572273254
desired expected reward: 4.128311634063721





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[-7.399831 ]
 [-6.7598047]
 [-7.6174965]
 [-7.4331512]
 [-6.778759 ]
 [-7.2118397]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [14.  0.  1. 15.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3
  3  0  0 15  1 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 24. 30. 11. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3.  0.  8. 15.  8.] 
adversary cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1
Learning step: 1.1992716789245605
desired expected reward: -6.01256799697876



buy possibilites: [-1] 
expected returns: [[-2.4723916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [14.  0.  1. 15.  0.  3. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3
  3  0  0 15  1 14 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 11. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 3.  0.  8. 15.  8.] 
adversary cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 38 

action type: buy - action 10.0
Learning step: 2.183309316635132
desired expected reward: -4.595449447631836






Player: 1 
cards in hand: [ 3.  0.  8. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 15.  8.] 
cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 11. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3
  3  0  0 15  1 14 10] -> size -> 31 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 15.  8.] 
cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 24. 30. 11. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.] 
adversary owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3
  3  0  0 15  1 14 10] -> size -> 31 
adversary victory points: 5
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 3. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[19.82706 ]
 [14.353971]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  0.  0.] 
cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  3  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3
  3  0  0 15  1 14 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 11. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 0.  3. 14.  0.  1.] 
adversary cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.  3.  0.  8. 15.  8.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: 0.5124004483222961
desired expected reward: -1.959991216659546



action possibilites: [-1] 
expected returns: [[14.607005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 10. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 0.  3. 14.  0.  1.] 
adversary cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.  3.  0.  8. 15.  8.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.14694499969482422
desired expected reward: 27.78119659423828





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[11.30918 ]
 [11.358449]
 [13.742522]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 30. 10. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 0.  3. 14.  0.  1.] 
adversary cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.  3.  0.  8. 15.  8.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1
Learning step: 0.54521644115448
desired expected reward: 15.1522216796875



buy possibilites: [-1] 
expected returns: [[-4.0873137]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 0.  3. 14.  0.  1.] 
adversary cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.  3.  0.  8. 15.  8.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 39 

action type: buy - action 3.0
Learning step: 1.2925766706466675
desired expected reward: 12.601755142211914






Player: 1 
cards in hand: [ 0.  3. 14.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  0.  1.] 
cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.  3.  0.  8. 15.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 6. 16. 25.  6.  0.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3  3] -> size -> 32 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.  3.  0.  8. 15.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [6. 6. 0.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0. 16.
 25.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3  3] -> size -> 32 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.  3.  0.  8. 15.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  8.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [6. 6. 0.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0. 16.
 25.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3  3] -> size -> 32 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [10.  8.  1. 15.  3.  3. 11.  3. 10.  8.  6.  0.  0.  3.  0.  8. 15.  8.
 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [6. 6. 0.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0. 16.
 25.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3  3] -> size -> 32 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.820112]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0. 16.
 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3 25] -> size -> 26 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[  -5    0    6   10    0    0    0  -60    0    0    0    0    0 -900
   89    0] 
sum of rewards: -860 

action type: discard_down_to_3_cards - action 4
Learning step: -43.834293365478516
desired expected reward: -24.97936248779297





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[2.3213084]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0. 16.
 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3 25] -> size -> 26 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 11 

action type: take_action - action -1.0
Learning step: 0.36122384667396545
desired expected reward: 5.181335926055908



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  0  8  0 10  3  8  0 15  3  0  0  3 11  3  1
  3 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 3.  0.  3.  6. 29.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0. 16.
 25.  6.  6.  0.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3  3] -> size -> 32 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 3.  0.  3.  6. 29.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0. 16.
 25.  6.  6.  0.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3  3] -> size -> 32 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 3.  0.  3.  6. 29.] 
adversary cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0. 16.
 25.  6.  6.  0.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3  3] -> size -> 32 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[9.009764 ]
 [8.6619835]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  6. 29.] 
cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0. 16.
 25.  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 1.  8.  8.  3. 15.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25] -> size -> 23 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 11 

action type: buy - action -1.0
Learning step: 0.6330114603042603
desired expected reward: 2.954319953918457



action possibilites: [-1. 10.] 
expected returns: [[-7.174926 ]
 [-7.0322247]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0. 16.
 25.  6.  6.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 1.  8.  8.  3. 15.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25] -> size -> 23 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: discard_n_cards - action 4
Learning step: 0.9937631487846375
desired expected reward: 8.924104690551758



action possibilites: [-1.  8.] 
expected returns: [[10.7135315]
 [ 5.3393326]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0. 16.
 25.  6.  6.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [15  6 25  6  6 29  6  8 10  3  0  3  3 16  0  3  3  3  0  0 16  0  3  3
  0  0 15  1 14 10  3  3] -> size -> 32 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 1.  8.  8.  3. 15.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25] -> size -> 23 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action 10.0
Learning step: 3.0945937633514404
desired expected reward: -3.9376299381256104



action possibilites: [-1.] 
expected returns: [[-7.1065283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0. 16.
 25.  6.  6.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [15  6 25  6  6 29  6  8 10  0  3  3 16  0  3  3  3  0  0 16  0  3  3  0
  0 15  1 14 10  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 1.  8.  8.  3. 15.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25] -> size -> 23 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: trash_cards_n_from_hand - action 0
Learning step: 2.6876821517944336
desired expected reward: 5.736101150512695





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[-7.1065283]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [14.  0.  1. 15.  0.  3. 10. 15.  3.  3.  3.  3.  3. 16.  3.  0.  0. 16.
 25.  6.  6.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [15  6 25  6  6 29  6  8 10  0  3  3 16  0  3  3  3  0  0 16  0  3  3  0
  0 15  1 14 10  3  3] -> size -> 31 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 1.  8.  8.  3. 15.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25] -> size -> 23 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action -1.0
Learning step: 3.195429563522339
desired expected reward: -3.9110987186431885






Player: 1 
cards in hand: [ 1.  8.  8.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  8.  3. 15.] 
cards in discard: [8. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  0  3  3 16  0  3  3  3  0  0 16  0  3  3  0
  0 15  1 14 10  3  3] -> size -> 31 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  8.  3. 15.] 
cards in discard: [8. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 30.  9. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  0  3  3 16  0  3  3  3  0  0 16  0  3  3  0
  0 15  1 14 10  3  3] -> size -> 31 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  8.  3. 15.] 
cards in discard: [8. 3. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  8. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  0  3  3 16  0  3  3  3  0  0 16  0  3  3  0
  0 15  1 14 10  3  3] -> size -> 31 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-7.1065283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  6  8 10  0  3  3 16  0  3  3  3  0  0 16  0  3  3  0
  0 15  1 14 10  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  8. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 3. 10.  3.  3.  8.] 
adversary cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3] -> size -> 24 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1.0
Learning step: -0.3045704960823059
desired expected reward: -7.411098957061768





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[-6.7039013]
 [-7.375496 ]
 [-7.1065283]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  6  8 10  0  3  3 16  0  3  3  3  0  0 16  0  3  3  0
  0 15  1 14 10  3  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 30.  8. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 3. 10.  3.  3.  8.] 
adversary cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3] -> size -> 24 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -0.3030126690864563
desired expected reward: -7.409541130065918



buy possibilites: [-1] 
expected returns: [[26.27414]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  6  8 10  0  3  3 16  0  3  3  3  0  0 16  0  3  3  0
  0 15  1 14 10  3  3  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  7. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 3. 10.  3.  3.  8.] 
adversary cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3] -> size -> 24 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 9 

action type: buy - action 3.0
Learning step: 1.3763631582260132
desired expected reward: -5.327538967132568






Player: 1 
cards in hand: [ 3. 10.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  3.  8.] 
cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  7. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 6. 14. 15.  0.  3.] 
adversary cards in discard: [3. 6. 0. 3. 0. 6.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  0  3  3 16  0  3  3  3  0  0 16  0  3  3  0
  0 15  1 14 10  3  3  3] -> size -> 32 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  3.  8.] 
cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 24. 30.  7. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 6. 14. 15.  0.  3.] 
adversary cards in discard: [3. 6. 0. 3. 0. 6.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  0  3  3 16  0  3  3  3  0  0 16  0  3  3  0
  0 15  1 14 10  3  3  3] -> size -> 32 
adversary victory points: 6
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [ 6. 14. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[-7.0092974]
 [-5.2593994]
 [-6.34346  ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 15.  0.  3.] 
cards in discard: [3. 6. 0. 3. 0. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  6  8 10  0  3  3 16  0  3  3  3  0  0 16  0  3  3  0
  0 15  1 14 10  3  3  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  7. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [25. 11.  0. 15.  1.] 
adversary cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.  3. 10.  3.  3.  8.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3] -> size -> 24 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 1 

action type: buy - action -1
Learning step: -1.4018330574035645
desired expected reward: 24.87230682373047



action possibilites: [-1] 
expected returns: [[-5.255862]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  3.] 
cards in discard: [3. 6. 0. 3. 0. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 24. 30.  7. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [25. 11.  0. 15.  1.] 
adversary cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.  3. 10.  3.  3.  8.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3] -> size -> 24 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: take_action - action 15.0
Learning step: 1.2489161491394043
desired expected reward: -5.094545841217041





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[-6.9334135]
 [-6.3864336]
 [-6.5200567]
 [-6.977311 ]
 [-6.4107466]
 [-5.145121 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  3.] 
cards in discard: [3. 6. 0. 3. 0. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 24. 30.  7. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [25. 11.  0. 15.  1.] 
adversary cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.  3. 10.  3.  3.  8.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3] -> size -> 24 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: take_action - action -1
Learning step: 1.1708334684371948
desired expected reward: -4.085028648376465






Player: 1 
cards in hand: [25. 11.  0. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0. 15.  1.] 
cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.  3. 10.  3.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  7. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 3. 10.  0.  8. 15.] 
adversary cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 11.  0. 15.  1.] 
cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.  3. 10.  3.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 24. 30.  7. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 3. 10.  0.  8. 15.] 
adversary cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
adversary victory points: 6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 11.  0. 15.  1.] 
cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.  3. 10.  3.  3.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 3. 10.  0.  8. 15.] 
adversary cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
adversary victory points: 6
player victory points: 7 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
expected returns: [[-3.5568628]
 [-4.0231524]
 [-3.9355195]
 [-3.9541128]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  8. 15.] 
cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 6.  8.  3. 10. 14.] 
adversary cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.  3. 10.  3.  3.  8.  3. 25. 11.  0. 15.
  1.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: buy - action -1.0
Learning step: -0.2792789041996002
desired expected reward: -5.424403190612793



action possibilites: [-1.  8. 15. 16.] 
expected returns: [[-10.783011]
 [-13.091863]
 [-12.849398]
 [-13.486586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 15. 16.] 
cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 6.  8.  3. 10. 14.] 
adversary cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.  3. 10.  3.  3.  8.  3. 25. 11.  0. 15.
  1.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 11 

action type: take_action - action 10.0
Learning step: 0.4714665114879608
desired expected reward: -3.551689624786377





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[-10.458855]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 15. 16.] 
cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 6.  8.  3. 10. 14.] 
adversary cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.  3. 10.  3.  3.  8.  3. 25. 11.  0. 15.
  1.] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 11 

action type: take_action - action -1.0
Learning step: 0.8538268208503723
desired expected reward: -9.929193496704102






Player: 1 
cards in hand: [ 6.  8.  3. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  3. 10. 14.] 
cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.  3. 10.  3.  3.  8.  3. 25. 11.  0. 15.
  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [25. 16.  6.  0.  0.] 
adversary cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3. 10.  3.  0.  8. 15. 16.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  3. 10. 14.] 
cards in discard: [ 8.  3.  3.  1.  8.  8.  3. 15.  3. 10.  3.  3.  8.  3. 25. 11.  0. 15.
  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3
  3] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [25. 16.  6.  0.  0.] 
adversary cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3. 10.  3.  0.  8. 15. 16.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
adversary victory points: 6
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [25. 16.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16.] 
expected returns: [[-6.7635956]
 [-6.7872524]
 [-4.5446796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 16.  6.  0.  0.] 
cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3. 10.  3.  0.  8. 15. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 8.  3.  8. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: buy - action -1.0
Learning step: -0.0604671947658062
desired expected reward: -10.51932144165039





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[-4.0763817]
 [-4.247757 ]
 [-5.7504764]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 16.  6.  0.  0.] 
cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3. 10.  3.  0.  8. 15. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [ 8.  3.  8. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: take_action - action -1.0
Learning step: -0.21642565727233887
desired expected reward: -6.980023384094238



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  3.  8. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8. 15.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10 15 14  8  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [29.  3.  0.  1.  3.] 
adversary cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3. 10.  3.  0.  8. 15. 16. 25. 16.
  6.  0.  0.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
adversary victory points: 6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 10 14  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [29.  3.  0.  1.  3.] 
adversary cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3. 10.  3.  0.  8. 15. 16. 25. 16.
  6.  0.  0.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 10 14  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [29.  3.  0.  1.  3.] 
adversary cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3. 10.  3.  0.  8. 15. 16. 25. 16.
  6.  0.  0.] 
adversary owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
adversary victory points: 6
player victory points: 7 





         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-6.9550114]
 [-7.269038 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  1.  3.] 
cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3. 10.  3.  0.  8. 15. 16. 25. 16.
  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [25. 10.  6.  3.  3.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 1 10 14  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3  3] -> size -> 23 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: buy - action -1.0
Learning step: -0.32225313782691956
desired expected reward: -6.072731018066406



action possibilites: [-1.] 
expected returns: [[-7.014012]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3. 10.  3.  0.  8. 15. 16. 25. 16.
  6.  0.  0.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [25. 10.  6.  3.  3.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 1 10 14  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3  3] -> size -> 23 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 11 

action type: discard_n_cards - action 1
Learning step: 0.7538827061653137
desired expected reward: -6.480075836181641





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[-6.6827865]
 [-7.5152807]
 [-6.974584 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3. 10.  3.  0.  8. 15. 16. 25. 16.
  6.  0.  0.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  1.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [25. 10.  6.  3.  3.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 1 10 14  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3  3] -> size -> 23 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 11 

action type: take_action - action -1.0
Learning step: 0.7424869537353516
desired expected reward: -6.271524906158447



Player 1 won the game! 



Player 0 bought cards:
Copper: 15 
Silver: 1 
Gold: 0 
Estate: 11 
Duchy: 0 
Province: 0 
Curse: 5 

Remodel: 1 
Workshop: 1 
Chapel: 2 
Witch: 1 
Poacher: 1 
Militia: 1 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 3. 3.] 
cards in discard: [ 3.  6.  0.  3.  0.  6. 15.  6. 14.  3. 10.  3.  0.  8. 15. 16. 25. 16.
  6.  0.  0.  3.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [15  6 25  6  6 29  6  8 10  3  3 16  0  3  3  3  0  0 16  0  3  3  0  0
 15  1 14 10  3  3  3  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30.  6. 30.  8.  0.  7.  6.  0.  7.  9.  7.  9.  5.  9.  4.] 
adversary cards in hand: [25. 10.  6.  3.  3.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 1 10 14  8  6  3  8  8 10  3  8 15  3  0  0  3 11  3  1  3 25  3  3] -> size -> 23 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[  -5 -500    6  -10    0    0   20    0    0    0    0    0    0    0
    4    0] 
sum of rewards: -485 

action type: buy - action 8.0
Learning step: -23.874235153198242
desired expected reward: -31.389514923095703



