 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.524096]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1
Learning step: -15.594629287719727
desired expected reward: -0.7736654281616211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.869305]
 [21.568752]
 [21.508656]
 [20.345161]
 [21.136951]
 [22.78188 ]
 [22.142529]
 [22.645576]
 [21.618387]
 [22.082432]
 [22.317835]
 [22.785862]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6056034564971924
desired expected reward: 22.28493309020996



buy possibilites: [-1] 
expected returns: [[22.145014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.527831077575684
desired expected reward: 10.817330360412598






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.575354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5646790862083435
desired expected reward: 21.58033561706543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.212517]
 [22.911966]
 [22.851871]
 [21.688375]
 [24.125093]
 [23.485744]
 [23.425648]
 [24.129076]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6186035871505737
desired expected reward: 23.15961456298828



buy possibilites: [-1] 
expected returns: [[24.921156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 6.  0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.07208066433668137
desired expected reward: 24.05301284790039






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.415808]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6280689239501953
desired expected reward: 24.293087005615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.643396]
 [24.282747]
 [23.11925 ]
 [24.91662 ]
 [25.559954]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6623550653457642
desired expected reward: 25.010574340820312



buy possibilites: [-1] 
expected returns: [[26.83775]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.356685996055603
desired expected reward: 23.92605972290039






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [3. 3. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [3. 3. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [3. 3. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.27867 ]
 [22.274687]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [3. 3. 0. 6. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7197195887565613
desired expected reward: 26.118030548095703



action possibilites: [-1] 
expected returns: [[26.317606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 6. 3. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -8.918885231018066
desired expected reward: 12.588444709777832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.838514]
 [25.537958]
 [25.477863]
 [24.314371]
 [26.75109 ]
 [26.111738]
 [26.051643]
 [26.75507 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 6. 3. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06721235066652298
desired expected reward: 26.25039291381836



buy possibilites: [-1] 
expected returns: [[26.823387]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 6. 3. 0. 6. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 1.0
Learning step: 0.505506694316864
desired expected reward: 26.043466567993164






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1] -> size -> 15 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1] -> size -> 15 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1] -> size -> 15 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.527948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6844431757926941
desired expected reward: 26.138944625854492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.791138]
 [24.490587]
 [24.430487]
 [23.266994]
 [25.703714]
 [25.064363]
 [25.004267]
 [25.707697]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6608483791351318
desired expected reward: 25.078044891357422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  8.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  0. 15.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 6. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1] -> size -> 15 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 6. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1] -> size -> 15 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 6. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1] -> size -> 15 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [1. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.452593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6525496244430542
desired expected reward: 25.055147171020508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.923075]
 [23.606934]
 [23.546282]
 [22.406693]
 [23.185593]
 [24.791994]
 [24.168789]
 [24.659437]
 [23.652405]
 [24.108137]
 [24.336266]
 [24.795189]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6390807628631592
desired expected reward: 24.076828002929688



buy possibilites: [-1] 
expected returns: [[25.645016]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 3.] 
cards in discard: [ 3.  3.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.4689713716506958
desired expected reward: 23.639163970947266






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 11.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  0. 10.  1.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10] -> size -> 16 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 11.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  0. 10.  1.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10] -> size -> 16 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0. 15. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 11.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  0. 10.  1.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10] -> size -> 16 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.925146]
 [24.92195 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 11.  0.] 
cards in discard: [ 3.  3.  0.  0.  0. 10.  1.  0.  6.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6564816236495972
desired expected reward: 24.988534927368164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.188477]
 [23.811682]
 [22.672094]
 [24.434189]
 [25.060593]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 11.  0.] 
cards in discard: [ 3.  3.  0.  0.  0. 10.  1.  0.  6.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6482643485069275
desired expected reward: 24.38814353942871



buy possibilites: [-1] 
expected returns: [[25.678215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 11.  0.] 
cards in discard: [ 3.  3.  0.  0.  0. 10.  1.  0.  6.  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11] -> size -> 13 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.560541152954102
desired expected reward: 13.111553192138672






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6] -> size -> 17 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6] -> size -> 17 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  9. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 6. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6] -> size -> 17 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 6. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[24.651546]
 [24.648352]
 [23.96449 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  9. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  8. 11.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.661993682384491
desired expected reward: 25.01622200012207



action possibilites: [-1. 11.] 
expected returns: [[25.5774  ]
 [25.574203]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  9. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  8. 11.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.00451177591457963
desired expected reward: 24.097524642944336



action possibilites: [-1.] 
expected returns: [[25.973833]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  9. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  8. 11.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0.8236590623855591
desired expected reward: 26.459199905395508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.133091]
 [24.7563  ]
 [23.616713]
 [25.378805]
 [26.005209]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  9. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  8. 11.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.5335312485694885
desired expected reward: 26.50736427307129






Player: 1 
cards in hand: [ 0.  0. 15.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  8. 11.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  9. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 6. 3. 0. 3.] 
adversary cards in discard: [10. 10. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10] -> size -> 18 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  8.] 
cards in discard: [15.  0.  0.  0.  3.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 6. 3. 0. 3.] 
adversary cards in discard: [10. 10. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10] -> size -> 18 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  8.] 
cards in discard: [15.  0.  0.  0.  3.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 6. 3. 0. 3.] 
adversary cards in discard: [10. 10. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10] -> size -> 18 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  8.] 
cards in discard: [15.  0.  0.  0.  3.  0. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 6. 3. 0. 3.] 
adversary cards in discard: [10. 10. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10] -> size -> 18 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.09373]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 3.] 
cards in discard: [10. 10. 11.  6.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6550047397613525
desired expected reward: 25.350204467773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.374596]
 [24.997805]
 [23.858215]
 [25.62031 ]
 [26.246712]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 3.] 
cards in discard: [10. 10. 11.  6.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6708649396896362
desired expected reward: 25.534038543701172



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [6. 0. 3. 1. 0.] 
adversary cards in discard: [10. 10. 11.  6.  0.  0.  3.  0.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10] -> size -> 18 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [6. 0. 3. 1. 0.] 
adversary cards in discard: [10. 10. 11.  6.  0.  0.  3.  0.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10] -> size -> 18 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [6. 0. 3. 1. 0.] 
adversary cards in discard: [10. 10. 11.  6.  0.  0.  3.  0.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10] -> size -> 18 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.16289]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 1. 0.] 
cards in discard: [10. 10. 11.  6.  0.  0.  3.  0.  6.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6823254823684692
desired expected reward: 25.564388275146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.61489 ]
 [23.298746]
 [23.238094]
 [22.098505]
 [22.877405]
 [24.483807]
 [23.8606  ]
 [24.35125 ]
 [23.344217]
 [23.799946]
 [24.028078]
 [24.487003]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 0.] 
cards in discard: [10. 10. 11.  6.  0.  0.  3.  0.  6.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6296278834342957
desired expected reward: 23.663318634033203



buy possibilites: [-1] 
expected returns: [[24.833717]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 0.] 
cards in discard: [10. 10. 11.  6.  0.  0.  3.  0.  6.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5676925778388977
desired expected reward: 22.047195434570312






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 3. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 3. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[23.844412]
 [23.157354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11. 15.  8. 14.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6459192633628845
desired expected reward: 24.18779754638672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.301859]
 [21.909817]
 [20.795753]
 [22.520393]
 [23.127705]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11. 15.  8. 14.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6119009852409363
desired expected reward: 22.544448852539062



buy possibilites: [-1] 
expected returns: [[23.612976]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  3.  0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11. 15.  8. 14.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.3193582594394684
desired expected reward: 21.590457916259766






Player: 1 
cards in hand: [ 0. 11. 15.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.  8. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15.  8. 14.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 10.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 14.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 10.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 14.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 10.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 14.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 10.  0.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.78126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [ 3.  6.  0. 10.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [14. 11.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6282913088798523
desired expected reward: 22.984683990478516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.49333 ]
 [21.162746]
 [21.101288]
 [19.987225]
 [20.749973]
 [22.31982 ]
 [21.711863]
 [22.189812]
 [21.202291]
 [21.650404]
 [21.871712]
 [22.319174]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [ 3.  6.  0. 10.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  8.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [14. 11.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5808192491531372
desired expected reward: 21.333267211914062



buy possibilites: [-1] 
expected returns: [[24.220009]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [ 3.  6.  0. 10.  3.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  7.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [14. 11.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.4302845001220703
desired expected reward: 21.889535903930664






Player: 1 
cards in hand: [14. 11.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  7.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0. 11.  3.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  7.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0. 11.  3.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  0.  0. 15.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0. 11.  3.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[20.808975]
 [20.80962 ]
 [20.140203]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 10.  0.] 
cards in discard: [ 3.  6.  0. 10.  3.  0. 11.  3.  3.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 0. 14. 11.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6588931679725647
desired expected reward: 23.561115264892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.132072]
 [19.740028]
 [18.625965]
 [20.350605]
 [20.957918]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 10.  0.] 
cards in discard: [ 3.  6.  0. 10.  3.  0. 11.  3.  3.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  9. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 0. 14. 11.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5673547387123108
desired expected reward: 20.344694137573242



buy possibilites: [-1] 
expected returns: [[22.59778]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 10.  0.] 
cards in discard: [ 3.  6.  0. 10.  3.  0. 11.  3.  3.  0.  1.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 0. 14. 11.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.2832413911819458
desired expected reward: 20.06736183166504






Player: 1 
cards in hand: [ 3.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 0. 14. 11.  0.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  6.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 0. 14. 11.  0.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  6.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [10.  0.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[22.128948]
 [21.460176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  6.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 0. 14. 11.  0.  0. 15.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.597297728061676
desired expected reward: 22.0004825592041





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.689331]
 [21.297285]
 [20.183224]
 [21.907864]
 [22.515175]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  6.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 0. 14. 11.  0.  0. 15.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5906262993812561
desired expected reward: 21.642181396484375



buy possibilites: [-1] 
expected returns: [[24.895035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  6.  0.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 0. 14. 11.  0.  0. 15.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.3058379590511322
desired expected reward: 21.60202407836914






Player: 1 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [ 0. 14. 11.  0.  0. 15.  3.  0.  0. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  6.  0.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 0. 14. 11.  0.  0. 15.  3.  0.  0. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  6.  0.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 0. 14. 11.  0.  0. 15.  3.  0.  0. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  6.  0.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 0. 14. 11.  0.  0. 15.  3.  0.  0. 15.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  6.  0.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[19.768705]
 [19.099936]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  0. 10.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [11. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6907825469970703
desired expected reward: 24.204252243041992



action possibilites: [-1.] 
expected returns: [[21.263908]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 3.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [11. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.09654178470373154
desired expected reward: 19.320850372314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.377542]
 [19.985502]
 [18.87144 ]
 [20.596077]
 [21.203388]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 3.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [11. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.024666881188750267
desired expected reward: 21.288576126098633



buy possibilites: [-1] 
expected returns: [[24.119305]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 3.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  7.  6. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [11. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.3253704011440277
desired expected reward: 20.92144775390625






Player: 1 
cards in hand: [11. 15.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  7.  6. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  1.  0. 11.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  7.  6. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  1.  0. 11.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  0.  0.  3.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  7.  5. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  1.  0. 11.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.852968]
 [21.853613]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  0. 11.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  7.  5. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  3. 10.] 
adversary cards in discard: [ 8. 11. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6439946293830872
desired expected reward: 23.475309371948242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.771946]
 [20.433825]
 [20.37121 ]
 [19.271757]
 [20.024643]
 [21.576805]
 [20.977541]
 [21.446287]
 [20.469099]
 [20.914928]
 [21.130978]
 [21.56833 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1.  0. 11.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  7.  5. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  3. 10.] 
adversary cards in discard: [ 8. 11. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5718818306922913
desired expected reward: 20.786895751953125



buy possibilites: [-1] 
expected returns: [[23.867685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1.  0. 11.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  6.  5. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  3. 10.] 
adversary cards in discard: [ 8. 11. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.4116934835910797
desired expected reward: 21.16511344909668






Player: 1 
cards in hand: [ 0.  0. 14.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3. 10.] 
cards in discard: [ 8. 11. 15.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  6.  5. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3. 11.  3.  0.  1.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8
 11] -> size -> 25 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [ 8. 11. 15.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  6.  5. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3. 11.  3.  0.  1.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8
 11] -> size -> 25 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [ 8. 11. 15.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  6.  5. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3. 11.  3.  0.  1.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8
 11] -> size -> 25 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [ 8. 11. 15.  0.  0.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  5.  5. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3. 11.  3.  0.  1.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8
 11] -> size -> 25 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[20.168385]
 [20.17686 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3. 11.  3.  0.  1.  0.
 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  5.  5. 10. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11. 15.  0.  0.  3. 11. 10.  0.  0. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6542090773582458
desired expected reward: 23.213476181030273



action possibilites: [-1] 
expected returns: [[26.534742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3. 11.  3.  0.  1.  0.
 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  5.  5. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11. 15.  0.  0.  3. 11. 10.  0.  0. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.3914305567741394
desired expected reward: 20.630903244018555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.947397]
 [25.546665]
 [24.44721 ]
 [26.152992]
 [26.743786]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3. 11.  3.  0.  1.  0.
 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  5.  5. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11. 15.  0.  0.  3. 11. 10.  0.  0. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07511243969202042
desired expected reward: 26.45962905883789



buy possibilites: [-1] 
expected returns: [[27.852491]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  8. 10.  3.  6.  0.  0.  3. 11.  3.  0.  1.  0.
 11. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8
 11 10  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  5.  4. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11. 15.  0.  0.  3. 11. 10.  0.  0. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.19786129891872406
desired expected reward: 26.350854873657227






Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [ 8. 11. 15.  0.  0.  3. 11. 10.  0.  0. 14.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  5.  4. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8
 11 10  8] -> size -> 27 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [ 8. 11. 15.  0.  0.  3. 11. 10.  0.  0. 14.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  5.  4. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8
 11 10  8] -> size -> 27 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[24.427626]
 [23.836832]
 [23.836832]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8  8
 11 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  5.  4. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7311203479766846
desired expected reward: 27.121370315551758



action possibilites: [-1] 
expected returns: [[24.415174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  5.  4. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 3
Learning step: 0.009797629900276661
desired expected reward: 23.2285213470459





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.914646]
 [22.414457]
 [24.71103 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  7. 10.  5.  4. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.0344497486948967
desired expected reward: 24.38072395324707



buy possibilites: [-1] 
expected returns: [[25.934824]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  6. 10.  5.  4. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.950118064880371
desired expected reward: 13.464337348937988






Player: 1 
cards in hand: [ 0.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6. 10.  5.  4. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [11.  8.  3. 11.  0.] 
adversary cards in discard: [6. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  6. 10.  5.  4. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [11.  8.  3. 11.  0.] 
adversary cards in discard: [6. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 29. 30. 27. 30.  8.  6. 10.  5.  4. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [11.  8.  3. 11.  0.] 
adversary cards in discard: [6. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  6. 10.  5.  4. 10. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [11.  8.  3. 11.  0.] 
adversary cards in discard: [6. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11.  8.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[22.709684]
 [22.718157]
 [22.118893]
 [22.718157]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3. 11.  0.] 
cards in discard: [6. 8. 0. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6. 10.  5.  4. 10. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  8. 11.  0. 10.] 
adversary cards in discard: [22. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.689717173576355
desired expected reward: 25.245107650756836



action possibilites: [-1] 
expected returns: [[28.505846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  0.] 
cards in discard: [ 6.  8.  0.  6. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6. 10.  5.  4. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  8. 11.  0. 10.] 
adversary cards in discard: [22. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.5627578496932983
desired expected reward: 22.78120994567871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.806398]
 [26.306208]
 [28.602781]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  0.] 
cards in discard: [ 6.  8.  0.  6. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  6. 10.  5.  4. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  8. 11.  0. 10.] 
adversary cards in discard: [22. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.11630647629499435
desired expected reward: 28.38953971862793



buy possibilites: [-1] 
expected returns: [[26.938454]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  0.] 
cards in discard: [ 6.  8.  0.  6. 14.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  5. 10.  5.  4. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  8. 11.  0. 10.] 
adversary cards in discard: [22. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22] -> size -> 22 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -9.034700393676758
desired expected reward: 16.550451278686523






Player: 1 
cards in hand: [ 0.  8. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0. 10.] 
cards in discard: [22. 15.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5. 10.  5.  4. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  0. 11.  0.  3.] 
adversary cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6] -> size -> 28 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  0. 10.] 
cards in discard: [22. 15.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  5. 10.  5.  4. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  0. 11.  0.  3.] 
adversary cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6] -> size -> 28 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  0. 10.] 
cards in discard: [22. 15.  0.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  5. 10.  5.  4. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  0. 11.  0.  3.] 
adversary cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6] -> size -> 28 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.306557]
 [22.322407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.  3.] 
cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  5. 10.  5.  4. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0. 15.  0.  3.] 
adversary cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7238348722457886
desired expected reward: 26.214618682861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.64299 ]
 [21.226448]
 [20.154802]
 [21.826456]
 [22.397709]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  0.  3.] 
cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 26. 30.  8.  5. 10.  5.  4. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0. 15.  0.  3.] 
adversary cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5936641693115234
desired expected reward: 21.712892532348633



buy possibilites: [-1] 
expected returns: [[20.056444]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  0.  3.] 
cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  4. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11.  0. 15.  0.  3.] 
adversary cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.558696985244751
desired expected reward: 20.084293365478516






Player: 1 
cards in hand: [11.  0. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15.  0.  3.] 
cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  4. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 10. 10.  1.  3.] 
adversary cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0] -> size -> 29 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.] 
cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  4. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 10. 10.  1.  3.] 
adversary cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0] -> size -> 29 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.] 
cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  4. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 10. 10.  1.  3.] 
adversary cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0] -> size -> 29 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.] 
cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  3. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3. 10. 10.  1.  3.] 
adversary cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0] -> size -> 29 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[18.225155]
 [17.595917]
 [17.595917]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  1.  3.] 
cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  3. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.  8. 15. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5638529062271118
desired expected reward: 19.492591857910156



action possibilites: [-1. 10.] 
expected returns: [[20.459572]
 [19.8248  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1.  3.  0.] 
cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  3. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.  8. 15. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.1342819333076477
desired expected reward: 17.730199813842773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.599491]
 [19.25011 ]
 [19.186594]
 [18.107016]
 [20.373707]
 [19.786602]
 [19.72309 ]
 [20.357857]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  3.  0.] 
cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  3. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.  8. 15. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.04215139150619507
desired expected reward: 20.501720428466797



buy possibilites: [-1] 
expected returns: [[21.123056]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  3.  0.] 
cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  2. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.  8. 15. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: 0.1381940394639969
desired expected reward: 19.924795150756836






Player: 1 
cards in hand: [14.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  3.] 
cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.  8. 15. 11.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  2. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [10.  0.  0.  8.  3.] 
adversary cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.  8.
 10.  3. 10.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0  8] -> size -> 30 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.  8. 15. 11.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  2. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [10.  0.  3.] 
adversary cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.  8.
 10.  3. 10.  1.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0  8] -> size -> 30 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.  8. 15. 11.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  2. 10. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [10.  0.  3.] 
adversary cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.  8.
 10.  3. 10.  1.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0  8] -> size -> 30 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [22. 15.  0.  0.  0.  3.  0.  8. 11.  0. 10.  8. 15. 11.  0.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [10.  0.  3.] 
adversary cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.  8.
 10.  3. 10.  1.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0  8] -> size -> 30 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[19.807915]
 [19.173147]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.] 
cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.  8.
 10.  3. 10.  1.  3.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  0. 15.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0     0
     0 -1500    44     0] 
sum of rewards: -1461 

action type: discard_down_to_3_cards - action 6
Learning step: -44.23539733886719
desired expected reward: -23.878215789794922



action possibilites: [-1.] 
expected returns: [[21.602839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6.] 
cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.  8.
 10.  3. 10.  1.  3.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0  8] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  0. 15.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.10163532197475433
desired expected reward: 19.274784088134766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.7182  ]
 [19.225727]
 [21.476566]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [ 6.  8.  0.  6. 14.  6. 11.  8.  3. 11.  0.  0.  6.  0. 11.  0.  3.  8.
 10.  3. 10.  1.  3.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  0. 15.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.01619298942387104
desired expected reward: 21.61903190612793






Player: 1 
cards in hand: [ 3.  0. 15.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  8.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  8.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0  8] -> size -> 30 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  8.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  8.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0  8] -> size -> 30 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  8.  3.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  8.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0  8] -> size -> 30 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.  8.] 
expected returns: [[22.727182]
 [22.155928]
 [22.155928]
 [22.74303 ]
 [22.155928]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11  8  8 11 10
  8  6 14  6  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  0.  0. 15.  0.] 
adversary cards in discard: [ 0.  3.  0. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5578517317771912
desired expected reward: 20.91871452331543



action possibilites: [-1] 
expected returns: [[24.928995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  0.  0. 15.  0.] 
adversary cards in discard: [ 0.  3.  0. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.030675888061523438
desired expected reward: 22.733295440673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.239532]
 [22.74706 ]
 [24.997902]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  0.  0. 15.  0.] 
adversary cards in discard: [ 0.  3.  0. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.04661767929792404
desired expected reward: 24.88237762451172



buy possibilites: [-1] 
expected returns: [[24.672462]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  0.  0. 15.  0.] 
adversary cards in discard: [ 0.  3.  0. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.029577426612377167
desired expected reward: 22.67902374267578






Player: 1 
cards in hand: [ 8.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 15.  0.] 
cards in discard: [ 0.  3.  0. 15.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [14.  0.  0. 11.  6.] 
adversary cards in discard: [ 0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8  0] -> size -> 28 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 15.  0.] 
cards in discard: [ 0.  3.  0. 15.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  6.  9.  8.] 
adversary cards in hand: [14.  0.  0. 11.  6.] 
adversary cards in discard: [ 0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8  0] -> size -> 28 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 15.  0.] 
cards in discard: [ 0.  3.  0. 15.  8.  3. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [14.  0.  0. 11.  6.] 
adversary cards in discard: [ 0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8  0] -> size -> 28 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [14.  0.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[21.02768 ]
 [19.972095]
 [21.04794 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 11.  6.] 
cards in discard: [ 0.  8. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  5. 10.  5.  2.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [14. 11. 11. 25.  8.] 
adversary cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6717509031295776
desired expected reward: 24.00071144104004



action possibilites: [-1] 
expected returns: [[22.026794]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  6.] 
cards in discard: [ 0.  8. 11.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8  0  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  4. 10.  5.  2.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [14. 11. 11. 25.  8.] 
adversary cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -8.916327476501465
desired expected reward: 11.0039701461792





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.497831]
 [21.074959]
 [20.011684]
 [21.668201]
 [22.22507 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  6.] 
cards in discard: [ 0.  8. 11.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 26. 30.  8.  4. 10.  5.  2.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [14. 11. 11. 25.  8.] 
adversary cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.01307144109159708
desired expected reward: 22.039865493774414



buy possibilites: [-1] 
expected returns: [[25.657694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  6.] 
cards in discard: [ 0.  8. 11.  6.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8  0  6  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  4. 10.  5.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [14. 11. 11. 25.  8.] 
adversary cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.30935972929000854
desired expected reward: 21.977563858032227






Player: 1 
cards in hand: [14. 11. 11. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 11. 25.  8.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11. 11. 25.  8.] 
cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  4. 10.  5.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [8. 6. 6. 6. 0.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8  0  6  8] -> size -> 30 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11. 11.  8.  0.  0.] 
cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  3. 10.  5.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [8. 6. 6. 6. 0.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8  0  6  8  6] -> size -> 31 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11. 11.  8.  0.  0.] 
cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 26. 30.  8.  3. 10.  5.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [8. 6. 6. 6. 0.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8  0  6  8  6] -> size -> 31 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [8. 6. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[19.687176]
 [19.135168]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 6. 0.] 
cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14
  6  0  8  0  6  8  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  3. 10.  5.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [22.  0.  3.  3.  0.] 
adversary cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0. 25. 14. 11. 11.  8.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1
Learning step: -9.715332984924316
desired expected reward: 15.942360877990723



action possibilites: [-1] 
expected returns: [[18.288952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  3. 10.  5.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [22.  0.  3.  3.  0.] 
adversary cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0. 25. 14. 11. 11.  8.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.1053801104426384
desired expected reward: 17.99384307861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.630955]
 [16.149044]
 [18.343134]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 26. 30.  8.  3. 10.  5.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [22.  0.  3.  3.  0.] 
adversary cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0. 25. 14. 11. 11.  8.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.08299678564071655
desired expected reward: 18.3719482421875






Player: 1 
cards in hand: [22.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  3.  3.  0.] 
cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0. 25. 14. 11. 11.  8.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  3. 10.  5.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [11.  3.  1.  0.  0.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6] -> size -> 30 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0.  0. 10.] 
cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0. 25. 14. 11. 11.  8.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  3. 10.  5.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [11.  3.  1.  0.  0.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6] -> size -> 30 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0.  0. 10.] 
cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0. 25. 14. 11. 11.  8.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 26. 30.  8.  3. 10.  5.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [11.  3.  1.  0.  0.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6] -> size -> 30 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0.  0. 10.] 
cards in discard: [ 0.  3.  0. 15.  8.  3. 10.  8.  0.  0. 15.  0. 25. 14. 11. 11.  8.  0.
  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  3. 10.  5.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [11.  3.  1.  0.  0.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6] -> size -> 30 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [11.  3.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.823841]
 [21.844099]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  1.  0.  0.] 
cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  3. 10.  5.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [15.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10  1] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4710160493850708
desired expected reward: 17.87211799621582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.26759 ]
 [20.90472 ]
 [20.84146 ]
 [19.785679]
 [20.508379]
 [22.011833]
 [21.434706]
 [21.882544]
 [20.935991]
 [21.371445]
 [21.576376]
 [21.991575]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  1.  0.  0.] 
cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 26. 30.  8.  3. 10.  5.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [15.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10  1] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5810317397117615
desired expected reward: 21.242809295654297



buy possibilites: [-1] 
expected returns: [[21.649014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  1.  0.  0.] 
cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 26. 30.  8.  3. 10.  4.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [15.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10  1] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.44804033637046814
desired expected reward: 21.563793182373047






Player: 1 
cards in hand: [15.  3.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25
  0 10  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  3. 10.  4.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [6. 3. 3. 3. 0.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0. 11. 11.  3.
  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11] -> size -> 31 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 28. 30. 26. 30.  8.  3. 10.  4.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [6. 3. 3. 3. 0.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0. 11. 11.  3.
  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11] -> size -> 31 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 26. 30.  8.  3. 10.  4.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [6. 3. 3. 3. 0.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0. 11. 11.  3.
  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11] -> size -> 31 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 25. 30.  8.  3. 10.  4.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [6. 3. 3. 3. 0.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0. 11. 11.  3.
  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11] -> size -> 31 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [6. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.35732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 3. 0.] 
cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0. 11. 11.  3.
  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  3. 10.  4.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  0. 11. 10. 25.] 
adversary cards in discard: [ 3. 15.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3] -> size -> 27 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5962185263633728
desired expected reward: 21.05279541015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.684278]
 [17.202366]
 [19.396458]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 0.] 
cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0. 11. 11.  3.
  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 25. 30.  8.  3. 10.  4.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  0. 11. 10. 25.] 
adversary cards in discard: [ 3. 15.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3] -> size -> 27 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.537994384765625
desired expected reward: 18.819326400756836



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 11. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10. 25.] 
cards in discard: [ 3. 15.  3.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  3. 10.  4.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [10. 10. 10.  0.  3.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0. 11. 11.  3.
  1.  0.  0.  6.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11] -> size -> 31 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10. 22.  3.] 
cards in discard: [ 3. 15.  3.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  2. 10.  4.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [10. 10. 10.  0.  3.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0. 11. 11.  3.
  1.  0.  0.  6.  3.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6] -> size -> 32 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 10. 22.  3.] 
cards in discard: [ 3. 15.  3.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  2. 10.  4.  1.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [10. 10. 10.  0.  3.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0. 11. 11.  3.
  1.  0.  0.  6.  3.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6] -> size -> 32 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 10. 22.  3.] 
cards in discard: [ 3. 15.  3.  3.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  2. 10.  4.  0.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [10. 10. 10.  0.  3.] 
adversary cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0. 11. 11.  3.
  1.  0.  0.  6.  3.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6] -> size -> 32 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10. 10. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[18.765947]
 [18.145817]
 [18.145817]
 [18.145817]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  0.  3.] 
cards in discard: [ 0.  8. 11.  6.  8. 11. 14.  0.  0.  6.  6.  8.  6.  6.  0. 11. 11.  3.
  1.  0.  0.  6.  3.  3.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  2. 10.  4.  0.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [15.  0.  8.  1.  0.] 
adversary cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1.0
Learning step: -9.53875732421875
desired expected reward: 9.85770034790039



action possibilites: [-1. 10. 10.] 
expected returns: [[21.20982]
 [20.62015]
 [20.62015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  2. 10.  4.  0.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [15.  0.  8.  1.  0.] 
adversary cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.1500856578350067
desired expected reward: 17.460596084594727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[19.560514]
 [20.114307]
 [19.090595]
 [21.218029]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  2. 10.  4.  0.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [15.  0.  8.  1.  0.] 
adversary cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.026228541508316994
desired expected reward: 21.236045837402344



buy possibilites: [-1] 
expected returns: [[24.15934]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  3.  0.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  1. 10.  4.  0.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [15.  0.  8.  1.  0.] 
adversary cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8] -> size -> 28 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.869044303894043
desired expected reward: 10.221550941467285






Player: 1 
cards in hand: [15.  0.  8.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.  1.  0.] 
cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  1. 10.  4.  0.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [6. 0. 3. 1. 0.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6] -> size -> 33 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  8.  1.  0.] 
cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 25. 30.  8.  1. 10.  4.  0.  9. 10.  8. 10.  5.  9.  8.] 
adversary cards in hand: [6. 0. 3. 1. 0.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6] -> size -> 33 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  8.  1.  0.] 
cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  1. 10.  4.  0.  9. 10.  7. 10.  5.  9.  8.] 
adversary cards in hand: [6. 0. 3. 1. 0.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6] -> size -> 33 
adversary victory points: -3
player victory points: 5 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.081184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 1. 0.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  1. 10.  4.  0.  9. 10.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  0. 11.] 
adversary cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3. 14. 15.  0.  8.  1.
  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8 14] -> size -> 29 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.65342777967453
desired expected reward: 23.50591278076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[19.348902]
 [19.96537 ]
 [19.902697]
 [18.878984]
 [19.581982]
 [21.033216]
 [20.907108]
 [19.994892]
 [20.416752]
 [20.611359]
 [21.00642 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 0.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 25. 30.  8.  1. 10.  4.  0.  9. 10.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  0. 11.] 
adversary cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3. 14. 15.  0.  8.  1.
  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8 14] -> size -> 29 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5690075159072876
desired expected reward: 20.512176513671875



buy possibilites: [-1] 
expected returns: [[21.686527]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 0.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 25. 30.  8.  1. 10.  3.  0.  9. 10.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  0. 11.] 
adversary cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3. 14. 15.  0.  8.  1.
  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8 14] -> size -> 29 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.4182880222797394
desired expected reward: 20.614931106567383






Player: 1 
cards in hand: [ 0.  3. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0. 11.] 
cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3. 14. 15.  0.  8.  1.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  1. 10.  3.  0.  9. 10.  7. 10.  5.  9.  8.] 
adversary cards in hand: [8. 0. 0. 8. 6.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11] -> size -> 34 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3. 14. 15.  0.  8.  1.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8 14] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  1. 10.  3.  0.  9. 10.  7. 10.  5.  9.  8.] 
adversary cards in hand: [8. 0. 0. 8. 6.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11] -> size -> 34 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3. 14. 15.  0.  8.  1.
  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8 14 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  1. 10.  3.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [8. 0. 0. 8. 6.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11] -> size -> 34 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 3. 15.  3.  3.  8.  8. 25.  0.  0. 11. 10. 22.  3. 14. 15.  0.  8.  1.
  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8 14 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 25. 30.  8.  1. 10.  3.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [8. 0. 0. 8. 6.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11] -> size -> 34 
adversary victory points: -3
player victory points: 5 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[17.150793]
 [16.623796]
 [16.623796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 6.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  1. 10.  3.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [10. 14.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8 14 10] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6234636902809143
desired expected reward: 21.06306266784668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[15.472886]
 [16.02668 ]
 [15.002968]
 [17.130402]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 6.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  1. 10.  3.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [10. 14.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8 14 10] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4949207901954651
desired expected reward: 16.655872344970703



buy possibilites: [-1] 
expected returns: [[19.171213]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 6.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  1. 10.  3.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [10. 14.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8 14 10] -> size -> 30 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.18950265645980835
desired expected reward: 15.837177276611328






Player: 1 
cards in hand: [10. 14.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8 14 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  1. 10.  3.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11.  0.  3.  6.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3] -> size -> 35 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1. 14.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 15  0  8 11 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0
 10  1  3  8 14 10] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  1. 10.  3.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11.  0.  3.  6.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3] -> size -> 35 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  1. 10.  3.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11.  0.  3.  6.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3] -> size -> 35 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8. 14.] 
owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 24. 30.  8.  1. 10.  3.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [11.  0.  6.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3] -> size -> 35 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8. 14.] 
owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 24. 30.  8.  1. 10.  3.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [11.  0.  6.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3] -> size -> 35 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8. 14.] 
owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 24. 30.  8.  1. 10.  2.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [11.  0.  6.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3] -> size -> 35 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[16.928083]
 [16.954882]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  1. 10.  2.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11.  0.  3.  0.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11] -> size -> 30 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0     0
     0 -2400    40     0] 
sum of rewards: -2365 

action type: discard_down_to_3_cards - action 6
Learning step: -71.32914733886719
desired expected reward: -52.760536193847656



action possibilites: [-1] 
expected returns: [[17.493439]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11.  0.  3.  0.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0   -1    0 -300
    0    0] 
sum of rewards: -286 

action type: gain_card_n - action 3
Learning step: -8.871049880981445
desired expected reward: 6.953310966491699





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.8212805]
 [17.478796 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 24. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11.  0.  3.  0.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.10176263749599457
desired expected reward: 17.59520149230957



buy possibilites: [-1] 
expected returns: [[14.0271]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11.  0.  3.  0.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -2.  0.  0.  0.  0.] 
sum of rewards: 13.0 

action type: buy - action 0.0
Learning step: 0.06264612823724747
desired expected reward: 15.883926391601562






Player: 1 
cards in hand: [ 8. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  3.  0.] 
cards in discard: [11. 10.  8. 14.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [ 3.  6.  6.  6. 11.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.  0. 11.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0] -> size -> 37 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  3.  0.] 
cards in discard: [11. 10.  8. 14.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [ 3.  6.  6.  6. 11.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.  0. 11.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0] -> size -> 37 
adversary victory points: -3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[15.962524]
 [15.989323]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6.  6. 11.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.  0. 11.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  4.  9.  8.] 
adversary cards in hand: [ 3. 14.  1.  3.  0.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4030376374721527
desired expected reward: 13.624061584472656



action possibilites: [-1] 
expected returns: [[15.106465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 6.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.  0. 11.  0.  6. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 3. 14.  1.  3.  0.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0  9  0] 
sum of rewards: 21 

action type: gain_card_n - action 7
Learning step: 0.37702512741088867
desired expected reward: 14.096782684326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.571569]
 [15.186228]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 6.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.  0. 11.  0.  6. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 3. 14.  1.  3.  0.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.14947983622550964
desired expected reward: 15.255945205688477






Player: 1 
cards in hand: [ 3. 14.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  1.  3.  0.] 
cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 3.  0. 11. 14.  6.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.  0. 11.  0.  6. 10. 11.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10] -> size -> 38 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  1.  3.  0.] 
cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 3.  0. 11. 14.  6.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.  0. 11.  0.  6. 10. 11.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10] -> size -> 38 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  1.  3.  0.] 
cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 3.  0. 11. 14.  6.] 
adversary cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.  0. 11.  0.  6. 10. 11.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10] -> size -> 38 
adversary victory points: -3
player victory points: 6 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[15.4573965]
 [15.485981 ]
 [14.473181 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 14.  6.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.  0. 11.  0.  6. 10. 11.  3.  6.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 0. 25. 15.  0. 15.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11  3] -> size -> 31 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4458998739719391
desired expected reward: 14.740327835083008



action possibilites: [-1] 
expected returns: [[15.394244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  6.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.  0. 11.  0.  6. 10. 11.  3.  6.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  0. 15.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11  3] -> size -> 31 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.17744413018226624
desired expected reward: 14.650625228881836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[13.779587]
 [14.379988]
 [14.317663]
 [15.422828]
 [14.822424]
 [15.394244]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  6.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.  0. 11.  0.  6. 10. 11.  3.  6.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  0. 15.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11  3] -> size -> 31 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.14392401278018951
desired expected reward: 15.538167953491211



buy possibilites: [-1] 
expected returns: [[14.569523]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  6.] 
cards in discard: [ 6. 10. 10. 10.  0.  3.  0. 11.  6.  0.  3.  1.  0.  3.  8.  0.  0.  8.
  6.  8.  3.  6.  0. 11.  0.  6. 10. 11.  3.  6.  6.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 28. 30. 23. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  0. 15.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15.] 
adversary owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11  3] -> size -> 31 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -4.  0.  0.  0.  0.] 
sum of rewards: 11.0 

action type: buy - action 0.0
Learning step: 0.0695924386382103
desired expected reward: 13.849177360534668






Player: 1 
cards in hand: [ 0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.] 
cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10
  1  3  8 14 10 11  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 3.  3.  1. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0] -> size -> 39 
adversary victory points: -3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10  1
  3  8 14 10 11  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 28. 30. 23. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 3.  3.  1. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0] -> size -> 39 
adversary victory points: -3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10  1
  3  8 14 10 11  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 23. 30.  8.  0. 10.  2.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 3.  3.  1. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0] -> size -> 39 
adversary victory points: -3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10  1
  3  8 14 10 11  3 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 23. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 3.  3.  1. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0] -> size -> 39 
adversary victory points: -3
player victory points: 6 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  1. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[18.934282]
 [18.362463]
 [18.962866]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 10. 11.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  3.  9.  8.] 
adversary cards in hand: [ 8. 22.  0. 10.  3.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15. 11. 15.  0.] 
adversary owned cards: [ 0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10  1
  3  8 14 10 11  3 11] -> size -> 31 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.38973677158355713
desired expected reward: 14.17978572845459



action possibilites: [-1] 
expected returns: [[19.3646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 10.] 
cards in discard: [10.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 8. 22.  0. 10.  3.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15. 11. 15.  0.] 
adversary owned cards: [ 0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10  1
  3  8 14 10 11  3 11] -> size -> 31 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0  9  0] 
sum of rewards: 19 

action type: gain_card_n - action 7
Learning step: 0.24996910989284515
desired expected reward: 17.695276260375977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[17.82189 ]
 [18.359968]
 [19.442078]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 10.] 
cards in discard: [10.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 23. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 8. 22.  0. 10.  3.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15. 11. 15.  0.] 
adversary owned cards: [ 0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10  1
  3  8 14 10 11  3 11] -> size -> 31 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.06563741713762283
desired expected reward: 19.43023681640625



buy possibilites: [-1] 
expected returns: [[18.735783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 10.] 
cards in discard: [10.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 8. 22.  0. 10.  3.] 
adversary cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15. 11. 15.  0.] 
adversary owned cards: [ 0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10  1
  3  8 14 10 11  3 11] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -6  0  0  8  0] 
sum of rewards: 17 

action type: buy - action 3.0
Learning step: 0.1559266597032547
desired expected reward: 18.515893936157227






Player: 1 
cards in hand: [ 8. 22.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  0. 10.  3.] 
cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15. 11. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10  1
  3  8 14 10 11  3 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 11.  6.  6.  8.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 41 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  0.  3.  3.] 
cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15. 11. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10  1
  3  8 14 10 11  3 11] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 11.  6.  6.  8.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 41 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  3. 10.  0.  8.] 
cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15. 11. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 22.] 
owned cards: [ 0  0  3  3 15  0  8 15 14  3  0 10  0  0  0  8 11 22  3  8 25  0 10  1
  3  8 14 10 11  3 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 11.  6.  6.  8.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 41 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15. 11. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 22.  8.] 
owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 11.  6.  6.  8.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 41 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15. 11. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 22.  8.] 
owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 11.  6.  6.  8.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 41 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11. 10.  8. 14.  0.  0.  8. 11.  0.  3.  0.  3.  3. 14.  1.  3.  0. 25.
 15. 11. 15.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 22.  8.] 
owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 22. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 11.  6.  6.  8.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 41 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[15.904373]
 [15.932955]
 [15.394877]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  6.  8.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3  6  1 10  6 10  0  3 11 11 10  8  6 14  6
  0  8  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5463641285896301
desired expected reward: 18.18941879272461



action possibilites: [-1] 
expected returns: [[17.456436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0] -> size -> 28 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.21894223988056183
desired expected reward: 14.030620574951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.800632]
 [17.41529 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 22. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0] -> size -> 28 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.10238593816757202
desired expected reward: 17.558822631835938






Player: 1 
cards in hand: [ 0.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 6. 10. 11.  0.  0.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 39 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 30. 22. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 6. 10. 11.  0.  0.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 39 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 11.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 6. 10. 11.  0.  0.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 39 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 6. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[16.653984]
 [16.081291]
 [16.679611]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 11.  0.  0.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [11.  0. 15. 14. 11.] 
adversary cards in discard: [ 3.  0.  0.  0. 10. 11.] 
adversary owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3] -> size -> 29 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.49511826038360596
desired expected reward: 16.7884521484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[15.092306]
 [15.628834]
 [16.706394]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10. 11.  0.  0.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [11.  0. 15. 14. 11.] 
adversary cards in discard: [ 3.  0.  0.  0. 10. 11.] 
adversary owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3] -> size -> 29 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.48173898458480835
desired expected reward: 16.172245025634766



buy possibilites: [-1] 
expected returns: [[15.120692]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10. 11.  0.  0.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 28. 30. 21. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [11.  0. 15. 14. 11.] 
adversary cards in discard: [ 3.  0.  0.  0. 10. 11.] 
adversary owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3] -> size -> 29 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -5.  0.  0.  0.  0.] 
sum of rewards: -10.0 

action type: buy - action 0.0
Learning step: -0.5940018892288208
desired expected reward: 14.49830436706543






Player: 1 
cards in hand: [11.  0. 15. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15. 14. 11.] 
cards in discard: [ 3.  0.  0.  0. 10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 21. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0.  6.  6. 11. 14.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 15. 14. 11.] 
cards in discard: [ 3.  0.  0.  0. 10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 21. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0.  6.  6. 11. 14.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
adversary victory points: -1
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  6. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[14.83982 ]
 [14.865445]
 [13.856947]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 11. 14.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 21. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0.  3.  0. 25.  1.] 
adversary cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11.] 
adversary owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3] -> size -> 29 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.45042914152145386
desired expected reward: 14.670263290405273





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.188103]
 [14.802193]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 11. 14.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 21. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0.  3.  0. 25.  1.] 
adversary cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11.] 
adversary owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3] -> size -> 29 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.44655072689056396
desired expected reward: 14.393268585205078



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 25.  1.] 
cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 21. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 3. 10.  6.  3.  6.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 25.  1.] 
cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 28. 30. 21. 30.  8.  0. 10.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 3. 10.  6.  3.  6.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 25.  1.] 
cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 21. 30.  8.  0.  9.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 3. 10.  6.  3.  6.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[15.017529]
 [14.444834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  3.  6.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 21. 30.  8.  0.  9.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [15.  3.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.] 
adversary owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3 16] -> size -> 30 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.438787043094635
desired expected reward: 14.363405227661133





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.452564]
 [15.066654]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  3.  6.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 21. 30.  8.  0.  9.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [15.  3.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.] 
adversary owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3 16] -> size -> 30 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4491051435470581
desired expected reward: 14.5684232711792



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0. 10.] 
cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10
 11  3 11  0  3 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 21. 30.  8.  0.  9.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10 11
  3 11  0  3 16] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 28. 30. 21. 30.  8.  0.  9.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10 11
  3 11  0  3 16] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 28. 30. 21. 30.  8.  0.  9.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10 11
  3 11  0  3 16  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 21. 30.  8.  0.  9.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[14.689312]
 [14.116617]
 [14.178408]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  8.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0.  9.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [22.  3.  3.  8.  8.] 
adversary cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.  1.
 15.  3.  0. 10.] 
adversary owned cards: [ 3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10 11
  3 11  0  3 16  1] -> size -> 30 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4507959187030792
desired expected reward: 14.61585807800293



action possibilites: [-1.  8.] 
expected returns: [[15.456121]
 [14.945219]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0.  9.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [22.  3.  3.  8.  8.] 
adversary cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.  1.
 15.  3.  0. 10.] 
adversary owned cards: [ 3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10 11
  3 11  0  3 16  1] -> size -> 30 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.18664495646953583
desired expected reward: 14.303261756896973





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[13.81138 ]
 [14.4097  ]
 [14.347908]
 [14.038207]
 [15.451093]
 [15.329533]
 [14.442596]
 [14.852776]
 [15.040915]
 [15.425468]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 21. 30.  8.  0.  9.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [22.  3.  3.  8.  8.] 
adversary cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.  1.
 15.  3.  0. 10.] 
adversary owned cards: [ 3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10 11
  3 11  0  3 16  1] -> size -> 30 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.14236930012702942
desired expected reward: 15.598490715026855



buy possibilites: [-1] 
expected returns: [[14.637442]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [22.  3.  3.  8.  8.] 
adversary cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.  1.
 15.  3.  0. 10.] 
adversary owned cards: [ 3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10 11
  3 11  0  3 16  1] -> size -> 30 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -6  0  0 32  0] 
sum of rewards: 41 

action type: buy - action 16.0
Learning step: 0.9625470042228699
desired expected reward: 15.000753402709961






Player: 1 
cards in hand: [22.  3.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  3.  8.  8.] 
cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.  1.
 15.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  0 15 14  3  0  0  0  0  8 11 22  3  8 25  0 10  1  3  8 14 10 11
  3 11  0  3 16  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [3. 8. 6. 0. 6.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6. 16. 10.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 41 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.  1.
 15.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [3. 8. 6. 0. 6.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6. 16. 10.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 41 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.  1.
 15.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [3. 8. 6. 0. 6.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6. 16. 10.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 41 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 3.  0.  0.  0. 10. 11. 11.  0. 15. 14. 11. 16.  0.  3.  0. 25.  1.  1.
 15.  3.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [3. 8. 6. 0. 6.] 
adversary cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6. 16. 10.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 41 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [3. 8. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[14.692832]
 [14.181929]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 0. 6.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6. 16. 10.  0.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1 10  6 10  0  3 11 11 10  8  6 14  6  0  8
  0  6  8  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 8. 11.  3. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4369942843914032
desired expected reward: 14.200447082519531



action possibilites: [-1] 
expected returns: [[14.760899]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6. 16. 10.  0.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  3  1 10 10  0  3 11 11 10  8  6 14  6  0  8  0  6  8
  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 8. 11.  3. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.16158202290534973
desired expected reward: 14.941829681396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.14681 ]
 [14.760899]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [10.  3. 11.  3.  3.  1. 10.  8. 11.  6.  0.  6. 10. 11.  0.  0.  0.  6.
  6. 11. 14.  3. 10.  6.  3.  6. 16. 10.  0.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  3  1 10 10  0  3 11 11 10  8  6 14  6  0  8  0  6  8
  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 8. 11.  3. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.15538330376148224
desired expected reward: 14.916281700134277






Player: 1 
cards in hand: [ 8. 11.  3. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3. 14.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [14.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3  1 10 10  0  3 11 11 10  8  6 14  6  0  8  0  6  8
  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 38 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [14.  0.  3.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  3  3 11  3  1 10 10  0  3 11 11 10  8  6 14  6  0  8  0  6  8
  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 38 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [14.  0.  3.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  3  3 11  3  1 10 10  0  3 11 11 10  8  6 14  6  0  8  0  6  8
  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 38 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  8.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [14.  0.  3.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  3  3 11  3  1 10 10  0  3 11 11 10  8  6 14  6  0  8  0  6  8
  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 38 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[14.457751]
 [13.493453]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.] 
cards in discard: [ 0. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  1 10 10  0  3 11 11 10  8  6 14  6  0  8  0  6  8
  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 16.  1.  0.  0.] 
adversary cards in discard: [ 0. 14.  8. 11.  3.  8.] 
adversary owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0  0] -> size -> 29 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0    -3
     0 -2100    53     0] 
sum of rewards: -2055 

action type: discard_down_to_3_cards - action 5
Learning step: -61.86473846435547
desired expected reward: -49.78147888183594



action possibilites: [-1] 
expected returns: [[17.02831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 0. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 11  3  1 10 10  0  3 11 11 10  8  6 14  6  0  8  0  6  8
  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [16.  1.  0.] 
adversary cards in discard: [ 0. 14.  8. 11.  3.  8.  0.  0.] 
adversary owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0  0] -> size -> 29 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.22399365901947021
desired expected reward: 13.717445373535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[15.457738]
 [16.051792]
 [15.989635]
 [17.086702]
 [16.49265 ]
 [17.057161]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 11  3  1 10 10  0  3 11 11 10  8  6 14  6  0  8  0  6  8
  6 11  6  6 11  3  6  0 10  0 10  3  0 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 27. 30. 21. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [16.  1.  0.] 
adversary cards in discard: [ 0. 14.  8. 11.  3.  8.  0.  0.] 
adversary owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0  0] -> size -> 29 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.11242268979549408
desired expected reward: 17.14073371887207



buy possibilites: [-1] 
expected returns: [[19.034443]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0. 11.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 11  3  1 10 10  0  3 11 11 10  8  6 14  6  0  8  0  6  8
  6 11  6  6 11  3  6  0 10  0 10  3  0 16  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 20. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [16.  1.  0.] 
adversary cards in discard: [ 0. 14.  8. 11.  3.  8.  0.  0.] 
adversary owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0  0] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -4.  0.  0.  2.  0.] 
sum of rewards: 13.0 

action type: buy - action 3.0
Learning step: 0.1101725846529007
desired expected reward: 16.099809646606445






Player: 1 
cards in hand: [16.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0.] 
cards in discard: [ 0. 14.  8. 11.  3.  8.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 20. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 6. 10.  8.  0.  6.] 
adversary cards in discard: [ 0. 11.  3. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  3  1 10 10  0  3 11 11 10  8  6 14  6  0  8  0  6  8
  6 11  6  6 11  3  6  0 10  0 10  3  0 16  3] -> size -> 39 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.] 
cards in discard: [ 0. 14.  8. 11.  3.  8.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 27. 30. 20. 30.  8.  0.  8.  1.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [ 6. 10.  8.  0.  6.] 
adversary cards in discard: [ 0. 11.  3. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  3  1 10 10  0  3 11 11 10  8  6 14  6  0  8  0  6  8
  6 11  6  6 11  3  6  0 10  0 10  3  0 16  3] -> size -> 39 
adversary victory points: 0
player victory points: 4 


Player 1 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 1 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 5 

Remodel: 1 
Workshop: 5 
Chapel: 6 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6. 10.  8.  0.  6.] 
cards in discard: [ 0. 11.  3. 14.  0.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  1 10 10  0  3 11 11 10  8  6 14  6  0  8  0  6  8
  6 11  6  6 11  3  6  0 10  0 10  3  0 16  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 20. 30.  8.  0.  8.  0.  0.  9. 10.  7. 10.  2.  9.  8.] 
adversary cards in hand: [16.  1.  0.] 
adversary cards in discard: [ 0. 14.  8. 11.  3.  8.  0.  0. 11.] 
adversary owned cards: [15  0 15 14  0  0  0  0  8 11  3  8 25  0 10  1  3  8 14 10 11  3 11  0
  3 16  1  0  0 11] -> size -> 30 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1
Learning step: -15.72103214263916
desired expected reward: 3.313410758972168



